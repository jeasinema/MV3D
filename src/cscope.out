cscope 15 /home/maxiaojian/workspace/eval-kitti/MV3D/src -c 0000568515
	@./didi_data/__init__.py


	@./preprocess_for_mv3d.py

4 import 
	~glob

5 import 
	~numpy
 as 
np

6 import 
	~data

7 import 
	~cv2

8 from 
	~config
 import *

9 from 
	~raw_data
 import 
Lidar

10 from 
	~multiprocessing
 import 
Pool

11 import 
	~os

13 
dataset
 = { '2011_09_26'

23 
p
 = 
data
 . 
Preprocess
 ( )

24 
lidar
 = 
Lidar
 ( 
dataset
 )

26 
base_dataset_path
 = "~/data/kitti/"

28 def 
	$handler_train
 ( 
fname
 ) :

29 
scan
 = 
np
 . 
fromfile
 ( 
fname
 , 
dtype
 = 
np
 . 
float32
 ) . 
reshape
 ( ( - 1 , 4 ) )

30 
top
 = 
data
 . 
lidar_to_top
 ( 
scan
 )

31 
tag
 = 
fname
 . 
split
 ( '/' ) [ - 1 ] . 
split
 ( '.' ) [ - 2 ]

32 
front
 = 
p
 . 
lidar_to_front_fast
 ( 
scan
 )

33 
os
 . 
makedirs
 ( 
os
 . 
path
 . 
join
 ( 
base_dataset_path
 , "training" , "front_view" ) , 
exist_ok
 = True )

34 
os
 . 
makedirs
 ( 
os
 . 
path
 . 
join
 ( 
base_dataset_path
 , "training" , "top_view" ) , 
exist_ok
 = True )

35 
np
 . 
save
 ( 
os
 . 
path
 . 
join
 ( 
base_dataset_path
 , "training" , "front_view" , 
tag
 + '.npy' ) , 
front
 )

36 
np
 . 
save
 ( 
os
 . 
path
 . 
join
 ( 
base_dataset_path
 , "training" , "top_view" , 
tag
 + '.npy' ) , 
top
 )

37 
print
 ( 
fname
 ) 
	}

39 def 
	$handler_test
 ( 
fname
 ) :

40 
scan
 = 
np
 . 
fromfile
 ( 
fname
 , 
dtype
 = 
np
 . 
float32
 ) . 
reshape
 ( ( - 1 , 4 ) )

41 
top
 = 
data
 . 
lidar_to_top
 ( 
scan
 )

42 
tag
 = 
fname
 . 
split
 ( '/' ) [ - 1 ] . 
split
 ( '.' ) [ - 2 ]

43 
front
 = 
p
 . 
lidar_to_front_fast
 ( 
scan
 )

44 
os
 . 
makedirs
 ( 
os
 . 
path
 . 
join
 ( 
base_dataset_path
 , "testing" , "front_view" ) , 
exist_ok
 = True )

45 
os
 . 
makedirs
 ( 
os
 . 
path
 . 
join
 ( 
base_dataset_path
 , "testing" , "top_view" ) , 
exist_ok
 = True )

46 
np
 . 
save
 ( 
os
 . 
path
 . 
join
 ( 
base_dataset_path
 , "testing" , "front_view" , 
tag
 + '.npy' ) , 
front
 )

47 
np
 . 
save
 ( 
os
 . 
path
 . 
join
 ( 
base_dataset_path
 , "testing" , "top_view" , 
tag
 + '.npy' ) , 
top
 )

48 
print
 ( 
fname
 ) 
	}

50 def 
	$handler_raw
 ( 
tag
 ) :

51 
scan
 = 
lidar
 . 
load
 ( 
tag
 )

52 
top
 = 
data
 . 
lidar_to_top
 ( 
scan
 )

53 
front
 = 
p
 . 
lidar_to_front_fast
 ( 
scan
 )

54 
os
 . 
makedirs
 ( 
os
 . 
path
 . 
join
 ( 
cfg
 . 
RAW_DATA_SETS_DIR
 , 'top_view' , * 
tag
 . 
split
 ( '/' ) [ : - 1 ] ) , 
exist_ok
 = True )

55 
os
 . 
makedirs
 ( 
os
 . 
path
 . 
join
 ( 
cfg
 . 
RAW_DATA_SETS_DIR
 , 'front_view' , * 
tag
 . 
split
 ( '/' ) [ : - 1 ] ) , 
exist_ok
 = True )

56 
np
 . 
save
 ( 
os
 . 
path
 . 
join
 ( 
cfg
 . 
RAW_DATA_SETS_DIR
 , 'top_view' , 
tag
 + '.npy' ) , 
top
 )

57 
np
 . 
save
 ( 
os
 . 
path
 . 
join
 ( 
cfg
 . 
RAW_DATA_SETS_DIR
 , 'front_view' , 
tag
 + '.npy' ) , 
front
 )

58 
print
 ( 
tag
 ) 
	}

60 def 
	$main_train
 ( ) :

61 
fl
 = 
glob
 . 
glob
 ( 
os
 . 
path
 . 
join
 ( 
base_dataset_path
 , "training" , "velodyne" , "*.bin" ) )

62 
pro
 = 
Pool
 ( 12 )

63 
pro
 . 
map
 ( 
handler_train
 , 
fl
 ) 
	}

65 def 
	$main_test
 ( ) :

66 
fl
 = 
glob
 . 
glob
 ( 
os
 . 
path
 . 
join
 ( 
base_dataset_path
 , "testing" , "velodyne" , "*.bin" ) )

67 
pro
 = 
Pool
 ( 12 )

68 
pro
 . 
map
 ( 
handler_train
 , 
fl
 ) 
	}

70 def 
	$main_raw
 ( ) :

71 
tags
 = 
lidar
 . 
get_paths_mapping
 ( )

72 
pro
 = 
Pool
 ( 32 )

73 
pro
 . 
map
 ( 
handler_raw
 , 
tags
 ) 
	}

76 if 
__name__
 == '__main__' :

77 
main_raw
 ( )


	@./convert_mv3d_for_eval.py

4 import 
	~glob

5 import 
	~numpy
 as 
np

6 import 
	~math

7 import 
	~os

8 from 
	~config
 import *

9 from 
	~multiprocessing
 import 
Pool

10 import 
	~data

11 import 
	~cv2

12 import 
	~argparse

14 import 
	~net.utility.draw
 as 
nud

15 import 
	~net.processing.boxes3d
 as 
box

18 
parser
 = 
argparse
 . 
ArgumentParser
 ( 
description
 = 'testing' )

20 
parser
 . 
add_argument
 ( '-t' , '--target-dir' , 
type
 = 
str
 , 
nargs
 = '?' , 
required
 = True )

21 
parser
 . 
add_argument
 ( '-s' , '--source-dir' , 
type
 = 
str
 , 
nargs
 = '?' , 
required
 = True )

23 
args
 = 
parser
 . 
parse_args
 ( )

25 
print
 ( '\n\n{}\n\n' . 
format
 ( 
args
 ) )

27 
os
 . 
makedirs
 ( 
os
 . 
path
 . 
join
 ( 
args
 . 
target_dir
 , 'result' ) , 
exist_ok
 = True )

28 
os
 . 
makedirs
 ( 
os
 . 
path
 . 
join
 ( 
args
 . 
target_dir
 , 'image' ) , 
exist_ok
 = True )

30 
base_res_path
 = 
args
 . 
source_dir

31 
f_boxes3d
 = 
glob
 . 
glob
 ( 
os
 . 
path
 . 
join
 ( 
base_res_path
 , '*_boxes3d.npy' ) )

32 
f_boxes3d
 . 
sort
 ( )

33 
f_label
 = 
glob
 . 
glob
 ( 
os
 . 
path
 . 
join
 ( 
base_res_path
 , '*_labels.npy' ) )

34 
f_label
 . 
sort
 ( )

35 
f_probs
 = 
glob
 . 
glob
 ( 
os
 . 
path
 . 
join
 ( 
base_res_path
 , '*_probs.npy' ) )

36 
f_probs
 . 
sort
 ( )

37 
base_dataset_path
 = '/data/mxj/kitti/object_3dop/training'

38 
f_top_view
 = 
glob
 . 
glob
 ( 
os
 . 
path
 . 
join
 ( 
base_dataset_path
 , 'top_view' , '*.npy' ) )

39 
f_top_view
 . 
sort
 ( )

40 
f_top_view
 = 
f_top_view

41 
f_rgb
 = 
glob
 . 
glob
 ( 
os
 . 
path
 . 
join
 ( 
base_dataset_path
 , 'image_2' , '*.png' ) )

42 
f_rgb
 . 
sort
 ( )

43 
f_rgb
 = 
f_rgb

44 
tags
 = [ 
name
 . 
split
 ( '/' ) [ - 1 ] . 
split
 ( '.' ) [ - 2 ] for 
name
 in 
f_rgb
 ]

45 assert ( 
len
 ( 
f_boxes3d
 ) == 
len
 ( 
f_label
 ) == 
len
 ( 
f_probs
 ) == 
len
 ( 
f_top_view
 ) == 
len
 ( 
f_rgb
 ) )

48 def 
	$box3d_to_rgb_box
 ( 
boxes3d
 , 
Mt
 = None , 
Kt
 = None ) :

49 if 
Mt
 is None : 
Mt
 = 
np
 . 
array
 ( 
cfg
 . 
MATRIX_Mt
 )

50 if 
Kt
 is None : 
Kt
 = 
np
 . 
array
 ( 
cfg
 . 
MATRIX_Kt
 )

52 
num
 = 
len
 ( 
boxes3d
 )

53 
projections
 = 
np
 . 
zeros
 ( ( 
num
 , 8 , 3 ) , 
dtype
 = 
np
 . 
float32
 )

54 for 
n
 in 
range
 ( 
num
 ) :

55 
box3d
 = 
boxes3d
 [ 
n
 ]

56 
Ps
 = 
np
 . 
hstack
 ( ( 
box3d
 , 
np
 . 
ones
 ( ( 8 , 1 ) ) ) )

57 
Qs
 = 
np
 . 
matmul
 ( 
Ps
 , 
Mt
 )

58 
Qs
 = 
Qs
 [ : , 0 : 3 ]

59 
qs
 = 
np
 . 
matmul
 ( 
Qs
 , 
Kt
 )

60 
zs
 = 
qs
 [ : , 2 ] . 
reshape
 ( 8 , 1 )

61 
qs
 = ( 
qs
 / 
zs
 )

62 
projections
 [ 
n
 ] = 
qs

63 return 
projections
 
	}

65 def 
	$project_to_rgb_roi
 ( 
rois3d
 ) :

66 
num
 = 
len
 ( 
rois3d
 )

67 
rois
 = 
np
 . 
zeros
 ( ( 
num
 , 5 ) , 
dtype
 = 
np
 . 
int32
 )

68 
projections
 = 
box3d_to_rgb_box
 ( 
rois3d
 )

69 for 
n
 in 
range
 ( 
num
 ) :

70 
qs
 = 
projections
 [ 
n
 ]

71 
minx
 = 
int
 ( 
np
 . 
min
 ( 
qs
 [ : , 0 ] ) )

72 
maxx
 = 
int
 ( 
np
 . 
max
 ( 
qs
 [ : , 0 ] ) )

73 
miny
 = 
int
 ( 
np
 . 
min
 ( 
qs
 [ : , 1 ] ) )

74 
maxy
 = 
int
 ( 
np
 . 
max
 ( 
qs
 [ : , 1 ] ) )

75 
rois
 [ 
n
 , 1 : 5 ] = 
minx
 , 
miny
 , 
maxx
 , 
maxy

77 return 
rois
 , 
projections
 
	}

79 def 
	$generate_result
 ( 
tag
 , 
boxes3d
 , 
prob
 ) :

80 def 
corner2center
 ( 
rois3d
 ) :

81 
ret
 = [ ]

82 for 
roi
 in 
rois3d
 :

84 
roi
 = 
np
 . 
array
 ( 
roi
 )

85 
h
 = 
abs
 ( 
np
 . 
sum
 ( 
roi
 [ : 4 , 1 ] - 
roi
 [ 4 : , 1 ] ) / 4 )

86 
w
 = 
np
 . 
sum
 (

87 
np
 . 
sqrt
 ( 
np
 . 
sum
 ( ( 
roi
 [ 0 , [ 0 , 2 ] ] - 
roi
 [ 3 , [ 0 , 2 ] ] ) ** 2 ) ) +

88 
np
 . 
sqrt
 ( 
np
 . 
sum
 ( ( 
roi
 [ 1 , [ 0 , 2 ] ] - 
roi
 [ 2 , [ 0 , 2 ] ] ) ** 2 ) ) +

89 
np
 . 
sqrt
 ( 
np
 . 
sum
 ( ( 
roi
 [ 4 , [ 0 , 2 ] ] - 
roi
 [ 7 , [ 0 , 2 ] ] ) ** 2 ) ) +

90 
np
 . 
sqrt
 ( 
np
 . 
sum
 ( ( 
roi
 [ 5 , [ 0 , 2 ] ] - 
roi
 [ 6 , [ 0 , 2 ] ] ) ** 2 ) )

92 
l
 = 
np
 . 
sum
 (

93 
np
 . 
sqrt
 ( 
np
 . 
sum
 ( ( 
roi
 [ 0 , [ 0 , 2 ] ] - 
roi
 [ 1 , [ 0 , 2 ] ] ) ** 2 ) ) +

94 
np
 . 
sqrt
 ( 
np
 . 
sum
 ( ( 
roi
 [ 2 , [ 0 , 2 ] ] - 
roi
 [ 3 , [ 0 , 2 ] ] ) ** 2 ) ) +

95 
np
 . 
sqrt
 ( 
np
 . 
sum
 ( ( 
roi
 [ 4 , [ 0 , 2 ] ] - 
roi
 [ 5 , [ 0 , 2 ] ] ) ** 2 ) ) +

96 
np
 . 
sqrt
 ( 
np
 . 
sum
 ( ( 
roi
 [ 6 , [ 0 , 2 ] ] - 
roi
 [ 7 , [ 0 , 2 ] ] ) ** 2 ) )

98 
x
 , 
y
 , 
z
 = 
np
 . 
sum
 ( 
roi
 , 
axis
 = 0 ) / 8

99 
ry
 = 
np
 . 
sum
 (

100 
math
 . 
atan2
 ( 
roi
 [ 2 , 0 ] - 
roi
 [ 1 , 0 ] , 
roi
 [ 2 , 2 ] - 
roi
 [ 1 , 2 ] ) +

101 
math
 . 
atan2
 ( 
roi
 [ 6 , 0 ] - 
roi
 [ 5 , 0 ] , 
roi
 [ 6 , 2 ] - 
roi
 [ 5 , 2 ] ) +

102 
math
 . 
atan2
 ( 
roi
 [ 3 , 0 ] - 
roi
 [ 0 , 0 ] , 
roi
 [ 3 , 2 ] - 
roi
 [ 0 , 2 ] ) +

103 
math
 . 
atan2
 ( 
roi
 [ 7 , 0 ] - 
roi
 [ 4 , 0 ] , 
roi
 [ 7 , 2 ] - 
roi
 [ 4 , 2 ] ) +

104 
math
 . 
atan2
 ( 
roi
 [ 0 , 2 ] - 
roi
 [ 1 , 2 ] , 
roi
 [ 1 , 0 ] - 
roi
 [ 0 , 0 ] ) +

105 
math
 . 
atan2
 ( 
roi
 [ 4 , 2 ] - 
roi
 [ 5 , 2 ] , 
roi
 [ 5 , 0 ] - 
roi
 [ 4 , 0 ] ) +

106 
math
 . 
atan2
 ( 
roi
 [ 3 , 2 ] - 
roi
 [ 2 , 2 ] , 
roi
 [ 2 , 0 ] - 
roi
 [ 3 , 0 ] ) +

107 
math
 . 
atan2
 ( 
roi
 [ 7 , 2 ] - 
roi
 [ 6 , 2 ] , 
roi
 [ 6 , 0 ] - 
roi
 [ 7 , 0 ] )

110 
h
 = 
max
 ( 
abs
 ( 
roi
 [ : 4 , 1 ] - 
roi
 [ 4 : , 1 ] ) )

111 
w
 = 
np
 . 
max
 (

112 
np
 . 
sqrt
 ( 
np
 . 
sum
 ( ( 
roi
 [ 0 , [ 0 , 2 ] ] - 
roi
 [ 3 , [ 0 , 2 ] ] ) ** 2 ) ) +

113 
np
 . 
sqrt
 ( 
np
 . 
sum
 ( ( 
roi
 [ 1 , [ 0 , 2 ] ] - 
roi
 [ 2 , [ 0 , 2 ] ] ) ** 2 ) ) +

114 
np
 . 
sqrt
 ( 
np
 . 
sum
 ( ( 
roi
 [ 4 , [ 0 , 2 ] ] - 
roi
 [ 7 , [ 0 , 2 ] ] ) ** 2 ) ) +

115 
np
 . 
sqrt
 ( 
np
 . 
sum
 ( ( 
roi
 [ 5 , [ 0 , 2 ] ] - 
roi
 [ 6 , [ 0 , 2 ] ] ) ** 2 ) )

117 
l
 = 
np
 . 
max
 (

118 
np
 . 
sqrt
 ( 
np
 . 
sum
 ( ( 
roi
 [ 0 , [ 0 , 2 ] ] - 
roi
 [ 1 , [ 0 , 2 ] ] ) ** 2 ) ) +

119 
np
 . 
sqrt
 ( 
np
 . 
sum
 ( ( 
roi
 [ 2 , [ 0 , 2 ] ] - 
roi
 [ 3 , [ 0 , 2 ] ] ) ** 2 ) ) +

120 
np
 . 
sqrt
 ( 
np
 . 
sum
 ( ( 
roi
 [ 4 , [ 0 , 2 ] ] - 
roi
 [ 5 , [ 0 , 2 ] ] ) ** 2 ) ) +

121 
np
 . 
sqrt
 ( 
np
 . 
sum
 ( ( 
roi
 [ 6 , [ 0 , 2 ] ] - 
roi
 [ 7 , [ 0 , 2 ] ] ) ** 2 ) )

123 
x
 , 
y
 , 
z
 = 
np
 . 
sum
 ( 
roi
 , 
axis
 = 0 ) / 8

124 
ry
 = 
np
 . 
sum
 (

125 
math
 . 
atan2
 ( 
roi
 [ 2 , 0 ] - 
roi
 [ 1 , 0 ] , 
roi
 [ 2 , 2 ] - 
roi
 [ 1 , 2 ] ) +

126 
math
 . 
atan2
 ( 
roi
 [ 6 , 0 ] - 
roi
 [ 5 , 0 ] , 
roi
 [ 6 , 2 ] - 
roi
 [ 5 , 2 ] ) +

127 
math
 . 
atan2
 ( 
roi
 [ 3 , 0 ] - 
roi
 [ 0 , 0 ] , 
roi
 [ 3 , 2 ] - 
roi
 [ 0 , 2 ] ) +

128 
math
 . 
atan2
 ( 
roi
 [ 7 , 0 ] - 
roi
 [ 4 , 0 ] , 
roi
 [ 7 , 2 ] - 
roi
 [ 4 , 2 ] ) +

129 
math
 . 
atan2
 ( 
roi
 [ 0 , 2 ] - 
roi
 [ 1 , 2 ] , 
roi
 [ 1 , 0 ] - 
roi
 [ 0 , 0 ] ) +

130 
math
 . 
atan2
 ( 
roi
 [ 4 , 2 ] - 
roi
 [ 5 , 2 ] , 
roi
 [ 5 , 0 ] - 
roi
 [ 4 , 0 ] ) +

131 
math
 . 
atan2
 ( 
roi
 [ 3 , 2 ] - 
roi
 [ 2 , 2 ] , 
roi
 [ 2 , 0 ] - 
roi
 [ 3 , 0 ] ) +

132 
math
 . 
atan2
 ( 
roi
 [ 7 , 2 ] - 
roi
 [ 6 , 2 ] , 
roi
 [ 6 , 0 ] - 
roi
 [ 7 , 0 ] )

134 
ret
 . 
append
 ( [ 
h
 , 
w
 , 
l
 , 
x
 , 
y
 , 
z
 , 
ry
 ] )

135 return 
ret

137 
line
 = "Car 0 0 0 {:.2f} {:.2f} {:.2f} {:.2f} {:.2f} {:.2f} {:.2f} {:.2f} {:.2f} {:.2f} {:.2f} {:.2f}\n"

138 
rgb_rois2d
 , 
_
 = 
project_to_rgb_roi
 ( 
boxes3d
 )

139 
rgb_rois3d
 = 
box
 . 
box3d_to_camera_box3d
 ( 
boxes3d
 )

140 
rgb_rois3d
 = 
np
 . 
array
 ( 
corner2center
 ( 
rgb_rois3d
 ) )

141 with 
open
 ( 
os
 . 
path
 . 
join
 ( 
args
 . 
target_dir
 , 'result' , 
tag
 + '.txt' ) , 'w+' ) as 
of
 :

142 for 
box2d
 , 
box3d
 , 
p
 in 
zip
 ( 
rgb_rois2d
 , 
rgb_rois3d
 , 
prob
 ) :

143 if 
p
 > 0 :

144 
res
 = 
line
 . 
format
 ( * 
box2d
 [ 1 : 5 ] , * 
box3d
 , 
p
 )

145 
of
 . 
write
 ( 
res
 ) 
	}

147 def 
	$handler
 ( 
i
 ) :

148 
tag
 = 
tags
 [ 
i
 ]

149 
top
 = 
np
 . 
load
 ( 
f_top_view
 [ 
i
 ] )

150 
rgb
 = 
cv2
 . 
imread
 ( 
f_rgb
 [ 
i
 ] )

151 
boxes3d
 = 
np
 . 
load
 ( 
f_boxes3d
 [ 
i
 ] )

152 
prob
 = 
np
 . 
load
 ( 
f_probs
 [ 
i
 ] )

153 
visualize_result
 ( 
tag
 , 
top
 , 
rgb
 , 
boxes3d
 , 
prob
 )

154 
generate_result
 ( 
tag
 , 
boxes3d
 , 
prob
 )

155 
print
 ( 
i
 ) 
	}

157 def 
	$main
 ( 
args
 ) :

158 
pro
 = 
Pool
 ( 10 )

160 
pro
 . 
map
 ( 
handler
 , [ 
i
 for 
i
 in 
range
 ( 
len
 ( 
f_top_view
 ) ) ] ) 
	}

162 def 
	$top_image_padding
 ( 
top_image
 ) :

163 return 
np
 . 
concatenate
 ( ( 
top_image
 , 
np
 . 
zeros_like
 ( 
top_image
 ) * 255 , 
np
 . 
zeros_like
 ( 
top_image
 ) * 255 ) , 1 ) 
	}

165 def 
	$visualize_result
 ( 
tag
 , 
top_view
 , 
rgb
 , 
boxes3d
 , 
probs
 , 
gt_boxes3d
 = [ ] ) :

166 
top_image
 = 
data
 . 
draw_top_image
 ( 
top_view
 )

167 
top_image
 = 
top_image_padding
 ( 
top_image
 )

169 
text_lables
 = [ 'No.%d class:1 prob: %.4f' % ( 
i
 , 
prob
 ) for 
i
 , 
prob
 in 
enumerate
 ( 
probs
 ) ]

170 
predict_camera_view
 = 
nud
 . 
draw_box3d_on_camera
 ( 
rgb
 , 
boxes3d
 , 
text_lables
 = 
text_lables
 )

172 
predict_top_view
 = 
data
 . 
draw_box3d_on_top
 ( 
top_image
 , 
boxes3d
 )

175 if 
len
 ( 
gt_boxes3d
 ) > 0 :

176 
predict_top_view
 = 
data
 . 
draw_box3d_on_top
 ( 
predict_top_view
 , 
gt_boxes3d
 , 
color
 = ( 0 , 0 , 255 ) )

177 
predict_camera_view
 = 
draw_box3d_on_camera
 ( 
predict_camera_view
 , 
gt_boxes3d
 , 
color
 = ( 0 , 0 , 255 ) )

179 
new_size
 = ( 
predict_camera_view
 . 
shape
 [ 1 ] // 2 , 
predict_camera_view
 . 
shape
 [ 0 ] // 2 )

180 
predict_camera_view
 = 
cv2
 . 
resize
 ( 
predict_camera_view
 , 
new_size
 )

181 
cv2
 . 
imwrite
 ( 
os
 . 
path
 . 
join
 ( 
args
 . 
target_dir
 , 'image' , 
tag
 + 'rgb_.png' ) , 
predict_camera_view
 )

182 
cv2
 . 
imwrite
 ( 
os
 . 
path
 . 
join
 ( 
args
 . 
target_dir
 , 'image' , 
tag
 + 'top_.png' ) , 
predict_top_view
 ) 
	}

185 if 
__name__
 == '__main__' :

186 
main
 ( 
args
 )


	@./tracker.py

1 import 
	~os

2 
os
 . 
environ
 [ 'DISPLAY' ] = ':0'

3 import 
	~tensorflow
 as 
tf

4 
tf
 . 
set_random_seed
 ( 7 )

5 import 
	~numpy
 as 
np

6 
np
 . 
random
 . 
seed
 ( 7 )

7 from 
	~net.blocks
 import *

8 from 
	~tensorflow.contrib
 import 
rnn

9 from 
	~time
 import 
strftime
 , 
localtime

10 from 
	~config
 import 
cfg

11 import 
	~utils.batch_loading
 as 
ub

12 import 
	~net.processing.boxes3d
 as 
boxes3d

14 
n_max_objects_output
 = 1

15 
n_max_objects_input
 = 5

16 
ground_truth
 = 
np
 . 
c_
 [ 
np
 . 
array
 ( 
range
 ( 0 , 100 ) ) , 
np
 . 
ones
 ( ( 100 ) ) , 
np
 . 
ones
 ( ( 100 ) ) * 2 ] . 
astype
 ( 
np
 . 
float32
 )

19 def 
	$get_noise
 ( 
n_max
 , 
probality
 = 0.4 ) :

20 
n_noise
 = 0

21 if 
np
 . 
random
 . 
random
 ( ) > 1 - 
probality
 :

22 
n_noise
 = 
int
 ( 
np
 . 
random
 . 
random
 ( ) * 
n_max
 )

24 
noise_list
 = [ 
np
 . 
random
 . 
random
 ( ( 3 ) ) * 100 for 
i
 in 
range
 ( 
n_noise
 ) ]

25 return 
np
 . 
array
 ( 
noise_list
 ) 
	}

27 def 
	$get_train_data
 ( 
idx
 , 
n_max_objects
 ) :

28 
obj_miss_probality
 = 0.5

29 
data_trans_gt
 = [ ]

31 if 
np
 . 
random
 . 
random
 ( ) > 
obj_miss_probality
 :

32 
data_trans_gt
 = 
ground_truth
 [ 
j
 : 
j
 + 1 , : ] + 
np
 . 
random
 . 
random
 ( 3 ) * 2

33 
noise
 = 
get_noise
 ( 
n_max_objects_input
 - 1 )

35 
n_objs
 = 
len
 ( 
noise
 ) + 
len
 ( 
data_trans_gt
 )

36 
padding
 = 
np
 . 
zeros
 ( ( 
n_max_objects
 - 
n_objs
 , 3 ) )

38 
data_trans_noised
 = 
padding

41 if 
len
 ( 
data_trans_gt
 ) != 0 :

42 
data_trans_noised
 = 
np
 . 
r_
 [ 
data_trans_gt
 , 
padding
 ]

45 if 
len
 ( 
noise
 ) != 0 :

46 
data_trans_noised
 = 
np
 . 
r_
 [ 
data_trans_noised
 , 
noise
 ]

48 
np
 . 
random
 . 
shuffle
 ( 
data_trans_noised
 )

49 
data_trans_noised
 = 
data_trans_noised
 . 
reshape
 ( ( 1 , 1 , 
n_max_objects
 , 3 ) )

50 return 
data_trans_noised
 . 
astype
 ( 
np
 . 
float32
 ) , 
n_objs
 
	}

52 def 
	$get_train_data2
 ( 
n_max_objects
 , 
data_trans_gt
 ) :

53 
obj_miss_probality
 = 0.2

55 if 
np
 . 
random
 . 
random
 ( ) > 
obj_miss_probality
 :

56 
data_trans_noised
 = 
data_trans_gt
 + 
np
 . 
random
 . 
random
 ( 3 ) * 2

58 
data_trans_noised
 = 
np
 . 
random
 . 
random
 ( ( 1 , 3 ) ) * 2

59 
noise
 = 
get_noise
 ( 
n_max_objects_input
 - 1 )

61 
n_objs
 = 
len
 ( 
noise
 ) + 
len
 ( 
data_trans_noised
 )

62 
padding
 = 
np
 . 
zeros
 ( ( 
n_max_objects
 - 
n_objs
 , 3 ) )

64 if 
len
 ( 
padding
 ) != 0 :

65 
data_trans_noised
 = 
np
 . 
r_
 [ 
data_trans_noised
 , 
padding
 ]

69 if 
len
 ( 
noise
 ) != 0 :

70 
data_trans_noised
 = 
np
 . 
r_
 [ 
data_trans_noised
 , 
noise
 ]

72 
np
 . 
random
 . 
shuffle
 ( 
data_trans_noised
 )

73 
data_trans_noised
 = 
data_trans_noised
 . 
reshape
 ( ( 1 , 1 , 
n_max_objects
 , 3 ) )

74 return 
data_trans_noised
 , 
n_objs
 
	}

76 class 
	cValidation
 ( 
object
 ) :

80 def 
	$__init__
 ( 
self
 , 
sess
 , 
net_trans_history
 , 
net_trans_gt
 , 
net_rnn_states_c
 , 
net_rnn_states_h
 ) :

81 
self
 . 
sess
 = 
sess

82 
time_str
 = 
strftime
 ( "%Y_%m_%d_%H_%M_%S" , 
localtime
 ( ) )

83 
self
 . 
summary_writer
 = 
tf
 . 
summary
 . 
FileWriter
 ( 
os
 . 
path
 . 
join
 ( 
cfg
 . 
LOG_DIR
 , 'tensorboard/%s_tracker_val' %

84 ( 
time_str
 ) ) , 
sess
 . 
graph
 )

86 
validation_dataset
 = { '1'

91 
self
 . 
val_set_loader
 = 
ub
 . 
batch_loading
 ( 
cfg
 . 
PREPROCESSED_DATA_SETS_DIR
 , 
validation_dataset
 )

93 
self
 . 
last_states_c
 = 
np
 . 
zeros
 ( ( 1 , 
n_hidden
 ) )

94 
self
 . 
last_states_h
 = 
np
 . 
zeros
 ( ( 1 , 
n_hidden
 ) )

96 
self
 . 
net_trans_history
 = 
net_trans_history
 ,

97 
self
 . 
net_trans_gt
 = 
net_trans_gt
 ,

98 
self
 . 
net_rnn_states_c
 = 
net_rnn_states_c
 ,

99 
self
 . 
net_rnn_states_h
 = 
net_rnn_states_h
 , 
	}

101 def 
	$run
 ( 
self
 , 
iter
 ) :

103 
train_rgbs
 , 
train_tops
 , 
train_fronts
 , 
train_gt_labels
 , 
train_gt_boxes3d
 ,

104 
frame_id
 = 
self
 . 
val_set_loader
 . 
load
 ( 1 )

107 if 
frame_id
 [ 0 ] . 
split
 ( '/' ) [ 2 ] == '00000' :

108 
self
 . 
last_states_c
 = 
np
 . 
zeros
 ( ( 1 , 
n_hidden
 ) )

109 
self
 . 
last_states_h
 = 
np
 . 
zeros
 ( ( 1 , 
n_hidden
 ) )

110 
n_history_saved
 = 0

112 
trans_gt
 , 
size
 , 
rotation
 = 
boxes3d
 . 
boxes3d_decompose
 ( 
train_gt_boxes3d
 [ 0 ] )

113 
trans_history
 , 
_
 = 
get_train_data2
 ( 
n_max_objects_input
 , 
trans_gt
 )

115 
feed
 = {

116 
self
 . 
net_trans_history
 : 
trans_history
 ,

117 
self
 . 
net_trans_gt
 : 
trans_gt
 ,

118 
self
 . 
net_rnn_states_c
 : 
self
 . 
last_states_c
 ,

119 
self
 . 
net_rnn_states_h
 : 
self
 . 
last_states_h
 ,

120 
IS_TRAIN_PHASE
 : True

123 
self
 . 
last_states_c
 , 
self
 . 
last_states_h
 = 
last_states
 . 
c
 , 
last_states
 . 
h

125 
summary
 , 
total_loss
 , 
trans_reg_loss
 , 
error_reg_loss
 , 
predict_tans
 , 
error_predict
 , =

126 
sess
 . 
run
 ( [ 
summary_op
 , 
net_loss
 , 
net_trans_reg_loss
 , 
net_score_reg_loss
 ,

127 
net_trans_predict
 , 
net_score_predict
 ] , 
feed
 )

128 
self
 . 
summary_writer
 . 
add_summary
 ( 
summary
 , 
iter
 ) 
	}

136 if 
__name__
 == '__main__' :

138 
model_num
 = 1

139 
n_steps
 = 1

140 
n_hidden
 = 64

141 
error_threshold
 = 10

144 
net_trans_history
 = 
tf
 . 
placeholder
 ( 
dtype
 = 
tf
 . 
float32
 , 
shape
 = [ None , 
n_steps
 , 
n_max_objects_input
 , 3 ] , 
name
 = 'trans_history' )

145 
net_trans_gt
 = 
tf
 . 
placeholder
 ( 
dtype
 = 
tf
 . 
float32
 , 
shape
 = [ None , 3 ] , 
name
 = 'trans_history' )

146 
net_rnn_states_c
 = 
tf
 . 
placeholder
 ( 
dtype
 = 
tf
 . 
float32
 , 
shape
 = [ None , 
n_hidden
 ] , 
name
 = 'rnn_states_c' )

147 
net_rnn_states_h
 = 
tf
 . 
placeholder
 ( 
dtype
 = 
tf
 . 
float32
 , 
shape
 = [ None , 
n_hidden
 ] , 
name
 = 'rnn_states_h' )

148 
net_last_states
 = 
tf
 . 
contrib
 . 
rnn
 . 
LSTMStateTuple
 ( 
net_rnn_states_c
 , 
net_rnn_states_h
 )

154 
input
 = 
tf
 . 
reshape
 ( 
net_trans_history
 , [ - 1 , 1 , 
n_max_objects_input
 * 3 ] )

157 
lstm_cell
 = 
rnn
 . 
BasicLSTMCell
 ( 
n_hidden
 , 
forget_bias
 = 1.0 )

158 
lstm_cell
 = 
rnn
 . 
DropoutWrapper
 ( 
lstm_cell
 , 
input_keep_prob
 = 0.5 , 
output_keep_prob
 = 0.5 )

161 
outputs
 , 
net_states
 = 
tf
 . 
nn
 . 
dynamic_rnn
 ( 
lstm_cell
 , 
input
 , 
initial_state
 = 
net_last_states
 , 
dtype
 = 
tf
 . 
float32
 )

163 
block
 = 
outputs
 [ : , - 1 , : ]

165 
net_predict
 = 
linear
 ( 
block
 , 
num_hiddens
 = ( 3 + 1 ) * 
n_max_objects_output
 , 
name
 = 'fc_3' )

166 
net_trans_predict
 = 
net_predict
 [ : , 0 : 3 ]

167 
net_score_predict
 = 
tf
 . 
abs
 ( 
net_predict
 [ : , 3 ] )

168 
sign
 = 
tf
 . 
cast
 ( 
tf
 . 
less_equal
 ( 
net_score_predict
 , 1 ) , 
tf
 . 
float32
 )

169 
net_score_predict
 = 
sign
 * 
net_score_predict

172 
detal
 = 
net_trans_predict
 - 
net_trans_gt

173 
detal_l2
 = 
tf
 . 
sqrt
 ( 
tf
 . 
reduce_mean
 ( 
tf
 . 
reduce_sum
 ( 
detal
 * 
detal
 , 
axis
 = 1 ) ) )

174 
net_trans_reg_loss
 = 
detal_l2

177 
sign
 = 
tf
 . 
cast
 ( 
tf
 . 
less
 ( 
detal_l2
 , 
error_threshold
 ) , 
tf
 . 
float32
 )

178 
net_score_gt
 = 
sign
 * ( 1 - 
detal_l2
 / 
error_threshold
 )

179 
net_score_reg_loss
 = 
tf
 . 
reduce_mean
 ( 
tf
 . 
abs
 ( 
net_score_predict
 - 
net_score_gt
 ) )

181 
net_loss
 = 
net_trans_reg_loss

185 
solver
 = 
tf
 . 
train
 . 
AdamOptimizer
 ( 
learning_rate
 = 0.001 )

186 
solver_step
 = 
solver
 . 
minimize
 ( 
net_loss
 )

188 
sess
 = 
tf
 . 
Session
 ( )

189 
time_str
 = 
strftime
 ( "%Y_%m_%d_%H_%M_%S" , 
localtime
 ( ) )

190 
summary_writer
 = 
tf
 . 
summary
 . 
FileWriter
 ( 
os
 . 
path
 . 
join
 ( 
cfg
 . 
LOG_DIR
 , 'tensorboard/%s_tracker_tra' %

191 ( 
time_str
 ) ) , 
sess
 . 
graph
 )

193 
tf
 . 
summary
 . 
scalar
 ( 'total_loss' , 
net_loss
 )

194 
tf
 . 
summary
 . 
scalar
 ( 'net_trans_reg_loss' , 
net_trans_reg_loss
 )

195 
tf
 . 
summary
 . 
scalar
 ( 'net_score_reg_loss' , 
net_score_reg_loss
 )

196 
summary_op
 = 
tf
 . 
summary
 . 
merge_all
 ( )

200 
training_dataset
 = { '1'

206 
tra_set_loader
 = 
ub
 . 
batch_loading
 ( 
cfg
 . 
PREPROCESSED_DATA_SETS_DIR
 , 
training_dataset
 )

207 
saver
 = 
tf
 . 
train
 . 
Saver
 ( )

209 
validation
 = 
Validation
 ( 
sess
 , 
net_trans_history
 , 
net_trans_gt
 , 
net_rnn_states_c
 , 
net_rnn_states_h
 )

210 with 
sess
 . 
as_default
 ( ) :

211 
os
 . 
makedirs
 ( 
os
 . 
path
 . 
join
 ( 
cfg
 . 
CHECKPOINT_DIR
 , 'tracker_net' ) , 
exist_ok
 = True )

212 
pretrained_model_path
 = 
os
 . 
path
 . 
join
 ( 
cfg
 . 
CHECKPOINT_DIR
 , 'tracker_net' , 'tracker.ckpt' )

213 if 0 and 
tf
 . 
train
 . 
checkpoint_exists
 ( 
pretrained_model_path
 ) :

214 
print
 ( 'load pretrained model' )

215 
saver
 . 
restore
 ( 
sess
 , 
pretrained_model_path
 )

217 
sess
 . 
run
 ( 
tf
 . 
global_variables_initializer
 ( ) , 
feed_dict
 = { 
IS_TRAIN_PHASE
 : True } )

219 
last_states_c
 = 
np
 . 
zeros
 ( ( 1 , 
n_hidden
 ) )

220 
last_states_h
 = 
np
 . 
zeros
 ( ( 1 , 
n_hidden
 ) )

222 for 
i
 in 
range
 ( 20000 ) :

225 
train_rgbs
 , 
train_tops
 , 
train_fronts
 , 
train_gt_labels
 , 
train_gt_boxes3d
 ,

226 
frame_id
 = 
tra_set_loader
 . 
load
 ( 1 )

229 if 
frame_id
 [ 0 ] . 
split
 ( '/' ) [ 2 ] == '00000' :

230 
last_states_c
 = 
np
 . 
zeros
 ( ( 1 , 
n_hidden
 ) )

231 
last_states_h
 = 
np
 . 
zeros
 ( ( 1 , 
n_hidden
 ) )

232 
n_history_saved
 = 0

234 
trans_gt
 , 
size
 , 
rotation
 = 
boxes3d
 . 
boxes3d_decompose
 ( 
train_gt_boxes3d
 [ 0 ] )

235 
trans_history
 , 
_
 = 
get_train_data2
 ( 
n_max_objects_input
 , 
trans_gt
 )

238 
feed
 = {

239 
net_trans_history
 : 
trans_history
 ,

240 
net_trans_gt
 : 
trans_gt
 ,

241 
net_rnn_states_c
 : 
last_states_c
 ,

242 
net_rnn_states_h
 : 
last_states_h
 ,

243 
IS_TRAIN_PHASE
 : True

247 
_
 , 
total_loss
 , 
trans_reg_loss
 , 
error_reg_loss
 , 
predict_tans
 , 
error_predict
 , 
last_states
 =

248 
sess
 . 
run
 ( [ 
solver_step
 , 
net_loss
 , 
net_trans_reg_loss
 , 
net_score_reg_loss
 ,

249 
net_trans_predict
 , 
net_score_predict
 , 
net_states
 ] , 
feed
 )

251 
last_states_c
 , 
last_states_h
 = 
last_states
 . 
c
 , 
last_states
 . 
h

252 if 
np
 . 
random
 . 
random
 ( ) < ( 1. / 20 ) :

253 
summary
 , 
total_loss
 , 
trans_reg_loss
 , 
error_reg_loss
 , 
predict_tans
 , 
error_predict
 , =

254 
sess
 . 
run
 ( [ 
summary_op
 , 
net_loss
 , 
net_trans_reg_loss
 , 
net_score_reg_loss
 ,

255 
net_trans_predict
 , 
net_score_predict
 ] , 
feed
 )

256 
summary_writer
 . 
add_summary
 ( 
summary
 , 
i
 )

257 
validation
 . 
run
 ( 
i
 )

259 if 
i
 % 200 == 0 :

260 
print
 ( 'loss: {} {} {}  | predict: {} gt: {} score:{} frame: {}\n{}\n\n' .

261 
format
 ( 
total_loss
 , 
trans_reg_loss
 , 
error_reg_loss
 , 
predict_tans
 , 
trans_gt
 ,

262 
error_predict
 , 
frame_id
 , 
trans_history
 ) )

263 if 
i
 >= 800 and 
i
 % 800 == 0 :

264 
saver
 . 
save
 ( 
sess
 , 
pretrained_model_path
 )

265 
print
 ( 'saved model' )


	@./main.py

3 import 
	~cv2

4 import 
	~numpy
 as 
np

5 from 
	~config
 import 
cfg

8 def 
	$convert_points_to_croped_image
 ( 
img_points
 ) :

9 
img_points
 = 
img_points
 . 
copy
 ( )

11 
left
 = 
cfg
 . 
IMAGE_CROP_LEFT

12 
right
 = 
cfg
 . 
IMAGE_CROP_RIGHT

13 
top
 = 
cfg
 . 
IMAGE_CROP_TOP

14 
bottom
 = 
cfg
 . 
IMAGE_CROP_BOTTOM

16 
croped_img_h
 = 
proj
 . 
image_height
 - 
top
 - 
bottom

17 
croped_img_w
 = 
proj
 . 
image_width
 - 
left
 - 
right

19 
img_points
 [ : , 1 ] -= 
top

20 
mask
 = 
img_points
 [ : , 1 ] < 0

21 
img_points
 [ 
mask
 , 1 ] = 0

22 
out_range_mask
 = 
mask

24 
mask
 = 
img_points
 [ : , 1 ] >= 
croped_img_h

25 
img_points
 [ 
mask
 , 1 ] = 
croped_img_h
 - 1

26 
out_range_mask
 = 
np
 . 
logical_or
 ( 
out_range_mask
 , 
mask
 )

28 
img_points
 [ : , 0 ] -= 
left

29 
mask
 = 
img_points
 [ : , 0 ] < 0

30 
img_points
 [ 
mask
 , 0 ] = 0

31 
out_range_mask
 = 
np
 . 
logical_or
 ( 
out_range_mask
 , 
mask
 )

33 
mask
 = 
img_points
 [ : , 0 ] >= 
croped_img_w

34 
img_points
 [ 
mask
 , 0 ] = 
croped_img_w
 - 1

35 
out_range_mask
 = 
np
 . 
logical_or
 ( 
out_range_mask
 , 
mask
 )

37 return 
img_points
 , 
out_range_mask
 
	}

40 def 
	$box3d_to_rgb_projection_cv2
 ( 
points
 ) :

61 
projMat
 = 
np
 . 
matrix
 ( [ [ 6.24391515e+02 , - 1.35999541e+03 , - 3.47685065e+01 , - 8.19238784e+02 ] ,

65 
imagePoints
 = [ ]

66 for 
pt
 in 
points
 :

67 
X
 = 
projMat
 * 
np
 . 
matrix
 ( 
list
 ( 
pt
 ) + [ 1 ] ) . 
T

68 
X
 = 
np
 . 
array
 ( 
X
 [ : 2 , 0 ] / 
X
 [ 2 , 0 ] ) . 
flatten
 ( )

69 
imagePoints
 . 
append
 ( 
X
 )

70 
imagePoints
 = 
np
 . 
array
 ( 
imagePoints
 )

72 return 
imagePoints
 . 
astype
 ( 
np
 . 
int
 ) 
	}

75 def 
	$draw_rgb_projections
 ( 
image
 , 
projections
 , 
color
 = ( 255 , 0 , 255 ) , 
thickness
 = 2 , 
darker
 = 1.0 ) :

77 
img
 = ( 
image
 . 
copy
 ( ) * 
darker
 ) . 
astype
 ( 
np
 . 
uint8
 )

78 
num
 = 
len
 ( 
projections
 )

79 for 
n
 in 
range
 ( 
num
 ) :

80 
qs
 = 
projections
 [ 
n
 ]

81 for 
k
 in 
range
 ( 0 , 4 ) :

83 
i
 , 
j
 = 
k
 , ( 
k
 + 1 ) % 4

84 
cv2
 . 
line
 ( 
img
 , ( 
qs
 [ 
i
 , 0 ] , 
qs
 [ 
i
 , 1 ] ) , ( 
qs
 [ 
j
 , 0 ] ,

85 
qs
 [ 
j
 , 1 ] ) , 
color
 , 
thickness
 , 
cv2
 . 
LINE_AA
 )

87 
i
 , 
j
 = 
k
 + 4 , ( 
k
 + 1 ) % 4 + 4

88 
cv2
 . 
line
 ( 
img
 , ( 
qs
 [ 
i
 , 0 ] , 
qs
 [ 
i
 , 1 ] ) , ( 
qs
 [ 
j
 , 0 ] ,

89 
qs
 [ 
j
 , 1 ] ) , 
color
 , 
thickness
 , 
cv2
 . 
LINE_AA
 )

91 
i
 , 
j
 = 
k
 , 
k
 + 4

92 
cv2
 . 
line
 ( 
img
 , ( 
qs
 [ 
i
 , 0 ] , 
qs
 [ 
i
 , 1 ] ) , ( 
qs
 [ 
j
 , 0 ] ,

93 
qs
 [ 
j
 , 1 ] ) , 
color
 , 
thickness
 , 
cv2
 . 
LINE_AA
 )

95 return 
img
 
	}

98 def 
	$box3d_to_rgb_box
 ( 
boxes3d
 , 
Mt
 = None , 
Kt
 = None ) :

100 if 
Mt
 is None :

101 
Mt
 = 
np
 . 
array
 ( 
cfg
 . 
MATRIX_Mt
 )

102 if 
Kt
 is None :

103 
Kt
 = 
np
 . 
array
 ( 
cfg
 . 
MATRIX_Kt
 )

105 
num
 = 
len
 ( 
boxes3d
 )

106 
projections
 = 
np
 . 
zeros
 ( ( 
num
 , 8 , 2 ) , 
dtype
 = 
np
 . 
int32
 )

107 for 
n
 in 
range
 ( 
num
 ) :

108 
box3d
 = 
boxes3d
 [ 
n
 ]

109 
Ps
 = 
np
 . 
hstack
 ( ( 
box3d
 , 
np
 . 
ones
 ( ( 8 , 1 ) ) ) )

110 
Qs
 = 
np
 . 
matmul
 ( 
Ps
 , 
Mt
 )

111 
Qs
 = 
Qs
 [ : , 0 : 3 ]

112 
qs
 = 
np
 . 
matmul
 ( 
Qs
 , 
Kt
 )

113 
zs
 = 
qs
 [ : , 2 ] . 
reshape
 ( 8 , 1 )

114 
qs
 = ( 
qs
 / 
zs
 )

115 
projections
 [ 
n
 ] = 
qs
 [ : , 0 : 2 ]

116 return 
projections

119 
num
 = 
len
 ( 
boxes3d
 )

120 
projections
 = 
np
 . 
zeros
 ( ( 
num
 , 8 , 2 ) , 
dtype
 = 
np
 . 
int32
 )

121 for 
n
 in 
range
 ( 
num
 ) :

122 
box3d
 = 
boxes3d
 [ 
n
 ] . 
copy
 ( )

123 if 
np
 . 
sum
 ( 
box3d
 [ : , 0 ] > 0 ) > 0 :

124 
box2d
 = 
box3d_to_rgb_projection_cv2
 ( 
box3d
 )

125 
box2d
 , 
out_range
 = 
convert_points_to_croped_image
 ( 
box2d
 )

126 if 
np
 . 
sum
 ( 
out_range
 == False ) >= 2 :

127 
projections
 [ 
n
 ] = 
box2d

128 return 
projections
 
	}

131 def 
	$draw_box3d_on_camera
 ( 
rgb
 , 
boxes3d
 , 
color
 = ( 255 , 0 , 255 ) , 
thickness
 = 1 , 
text_lables
 = [ ] ) :

132 
projections
 = 
box3d_to_rgb_box
 ( 
boxes3d
 )

133 
rgb
 = 
draw_rgb_projections
 (

134 
rgb
 , 
projections
 , 
color
 = 
color
 , 
thickness
 = 
thickness
 )

135 
font
 = 
cv2
 . 
FONT_HERSHEY_SIMPLEX

136 return 
rgb
 
	}

139 def 
	$draw_fusion_target
 ( ) :

140 
boxes3d
 = 
np
 . 
load
 ( '/home/mxj/boxes3d.npy' )

141 
labels
 = 
np
 . 
load
 ( '/home/mxj/labels.npy' )

142 
cam_img
 = 
np
 . 
load
 ( '/home/mxj/cam_raw.npy' )

143 
class_color
 = [ ( 10 , 20 , 10 ) , ( 255 , 0 , 0 ) ]

144 for 
i
 , 
label
 in 
enumerate
 ( 
labels
 ) :

145 
color
 = 
class_color
 [ 
label
 ]

146 
cam_img
 = 
draw_box3d_on_camera
 (

147 
cam_img
 , 
boxes3d
 [ 
i
 : 
i
 + 1 , : , : ] , ( 
color
 [ 0 ] , 
color
 [ 1 ] , 
color
 [ 2 ] ) )

148 return 
cam_img
 
	}

151 def 
	$main
 ( ) :

152 
cv2
 . 
imwrite
 ( '1.png' , 
draw_fusion_target
 ( ) ) 
	}

155 if 
__name__
 == '__main__' :

156 
main
 ( )


	@./data.py

1 from 
	~kitti_data
 import 
pykitti

4 from 
	~kitti_data.io
 import *

5 import 
	~net.utility.draw
 as 
draw

6 from 
	~net.processing.boxes3d
 import *

7 from 
	~config
 import 
TOP_X_MAX
 , 
TOP_X_MIN
 , 
TOP_Y_MAX
 , 
TOP_Z_MIN
 , 
TOP_Z_MAX
 ,

8 
TOP_Y_MIN
 , 
TOP_X_DIVISION
 , 
TOP_Y_DIVISION
 , 
TOP_Z_DIVISION

9 from 
	~config
 import 
cfg

10 import 
	~os

11 import 
	~cv2

12 import 
	~numpy

13 import 
	~glob

14 from 
	~multiprocessing
 import 
Pool

15 from 
	~collections
 import 
OrderedDict

16 import 
	~config

17 import 
	~ctypes

18 import 
	~math

20 if 
config
 . 
cfg
 . 
USE_CLIDAR_TO_TOP
 :

21 
SharedLib
 = 
ctypes
 . 
cdll
 . 
LoadLibrary
 ( '/home/stu/MV3D/src/lidar_data_preprocess/' 'Python_to_C_Interface/ver3/LidarTopPreprocess.so'

24 class 
	cPreprocess
 ( 
object
 ) :

27 def 
	$rgb
 ( 
self
 , 
rgb
 ) :

31 return 
cv2
 . 
resize
 ( 
rgb
 , ( 
cfg
 . 
IMAGE_WIDTH
 , 
cfg
 . 
IMAGE_HEIGHT
 ) ) 
	}

34 def 
	$bbox3d
 ( 
self
 , 
obj
 ) :

35 return 
box3d_compose
 ( 
translation
 = 
obj
 . 
translation
 , 
rotation
 = 
obj
 . 
rotation
 , 
size
 = 
obj
 . 
size
 ) 
	}

38 def 
	$label
 ( 
self
 , 
obj
 ) :

39 
label
 = 0

40 if 
obj
 . 
type
 == 'Van' or 
obj
 . 
type
 == 'Truck' or 
obj
 . 
type
 == 'Car' or 
obj
 . 
type
 == 'Tram' :

41 
label
 = 1

42 return 
label
 
	}

46 def 
	$lidar_to_top
 ( 
self
 , 
lidar
 ) :

47 if 
cfg
 . 
USE_CLIDAR_TO_TOP
 :

48 
top
 = 
clidar_to_top
 ( 
lidar
 )

50 
top
 = 
lidar_to_top
 ( 
lidar
 )

52 return 
top
 
	}

54 def 
	$lidar_to_front
 ( 
self
 , 
lidar
 ) :

56 def 
cal_height
 ( 
point
 ) :

57 return 
np
 . 
clip
 ( 
point
 [ 2 ] + 
cfg
 . 
VELODYNE_HEIGHT
 , 
a_min
 = 0 , 
a_max
 = None )

58 def 
cal_distance
 ( 
point
 ) :

59 return 
math
 . 
sqrt
 ( 
sum
 ( 
np
 . 
array
 ( 
point
 ) ** 2 ) )

60 def 
cal_intensity
 ( 
point
 ) :

61 return 
point
 [ 3 ]

62 def 
to_front
 ( 
point
 ) :

64 
int
 ( 
math
 . 
atan2
 ( 
point
 [ 1 ] , 
point
 [ 0 ] ) / 
cfg
 . 
VELODYNE_ANGULAR_RESOLUTION
 ) ,

65 
int
 ( 
math
 . 
atan2
 ( 
point
 [ 2 ] , 
math
 . 
sqrt
 ( 
point
 [ 0 ] ** 2 + 
point
 [ 1 ] ** 2 ) )

66 / 
cfg
 . 
VELODYNE_VERTICAL_RESOLUTION
 )

70 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 0 ] > 
TOP_X_MIN
 )

71 
lidar
 = 
lidar
 [ 
idx
 ]

72 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 0 ] < 
TOP_X_MAX
 )

73 
lidar
 = 
lidar
 [ 
idx
 ]

75 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 1 ] > 
TOP_Y_MIN
 )

76 
lidar
 = 
lidar
 [ 
idx
 ]

77 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 1 ] < 
TOP_Y_MAX
 )

78 
lidar
 = 
lidar
 [ 
idx
 ]

80 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 2 ] > 
TOP_Z_MIN
 )

81 
lidar
 = 
lidar
 [ 
idx
 ]

82 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 2 ] < 
TOP_Z_MAX
 )

83 
lidar
 = 
lidar
 [ 
idx
 ]

85 
r
 , 
c
 , 
l
 = [ ] , [ ] , [ ]

86 for 
point
 in 
lidar
 :

87 
pc
 , 
pr
 = 
to_front
 ( 
point
 )

88 if 
cfg
 . 
FRONT_C_MIN
 < 
pc
 < 
cfg
 . 
FRONT_C_MAX
 and 
cfg
 . 
FRONT_R_MIN
 < 
pr
 < 
cfg
 . 
FRONT_R_MAX
 :

89 
c
 . 
append
 ( 
pc
 )

90 
r
 . 
append
 ( 
pr
 )

91 
l
 . 
append
 ( 
point
 )

92 
c
 , 
r
 = 
np
 . 
array
 ( 
c
 ) . 
astype
 ( 
np
 . 
int32
 ) , 
np
 . 
array
 ( 
r
 ) . 
astype
 ( 
np
 . 
int32
 )

93 
c
 += 
int
 ( 
cfg
 . 
FRONT_C_OFFSET
 )

94 
r
 += 
int
 ( 
cfg
 . 
FRONT_R_OFFSET
 )

100 
channel
 = 3

101 
front
 = 
np
 . 
zeros
 ( ( 
cfg
 . 
FRONT_WIDTH
 , 
cfg
 . 
FRONT_HEIGHT
 , 
channel
 + 1 ) , 
dtype
 = 
np
 . 
float32
 )

102 for 
point
 , 
p_c
 , 
p_r
 in 
zip
 ( 
l
 , 
c
 , 
r
 ) :

103 if 0 <= 
p_c
 < 
cfg
 . 
FRONT_WIDTH
 and 0 <= 
p_r
 < 
cfg
 . 
FRONT_HEIGHT
 :

104 
front
 [ 
p_c
 , 
p_r
 , 0 : 
channel
 ] *= 
front
 [ 
p_c
 , 
p_r
 , 
channel
 ]

105 
front
 [ 
p_c
 , 
p_r
 , 0 : 
channel
 ] += 
np
 . 
array
 ( [ 
cal_height
 ( 
point
 ) , 
cal_distance
 ( 
point
 ) , 
cal_intensity
 ( 
point
 ) ] )

106 
front
 [ 
p_c
 , 
p_r
 , 
channel
 ] += 1

107 
front
 [ 
p_c
 , 
p_r
 , 0 : 
channel
 ] /= 
front
 [ 
p_c
 , 
p_r
 , 
channel
 ]

109 return 
front
 [ : , : , 0 : 
channel
 ] 
	}

111 def 
	$lidar_to_front_fast
 ( 
self
 , 
lidar
 ) :

113 def 
cal_height
 ( 
points
 ) :

114 return 
np
 . 
clip
 ( 
points
 [ : , 2 ] + 
cfg
 . 
VELODYNE_HEIGHT
 , 
a_min
 = 0 , 
a_max
 = None ) . 
astype
 ( 
np
 . 
float32
 ) . 
reshape
 ( ( - 1 , 1 ) )

115 def 
cal_distance
 ( 
points
 ) :

116 return 
np
 . 
sqrt
 ( 
np
 . 
sum
 ( 
points
 ** 2 , 
axis
 = 1 ) ) . 
astype
 ( 
np
 . 
float32
 ) . 
reshape
 ( ( - 1 , 1 ) )

117 def 
cal_intensity
 ( 
points
 ) :

118 return 
points
 [ : , 3 ] . 
astype
 ( 
np
 . 
float32
 ) . 
reshape
 ( ( - 1 , 1 ) )

119 def 
to_front
 ( 
points
 ) :

120 return 
np
 . 
array
 ( [

121 
np
 . 
arctan2
 ( 
points
 [ : , 1 ] , 
points
 [ : , 0 ] ) / 
cfg
 . 
VELODYNE_ANGULAR_RESOLUTION
 ,

122 
np
 . 
arctan2
 ( 
points
 [ : , 2 ] , 
np
 . 
sqrt
 ( 
points
 [ : , 0 ] ** 2 + 
points
 [ : , 1 ] ** 2 ) )

123 / 
cfg
 . 
VELODYNE_VERTICAL_RESOLUTION

124 ] , 
dtype
 = 
np
 . 
int32
 ) . 
T

127 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 0 ] > 
TOP_X_MIN
 )

128 
lidar
 = 
lidar
 [ 
idx
 ]

129 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 0 ] < 
TOP_X_MAX
 )

130 
lidar
 = 
lidar
 [ 
idx
 ]

132 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 1 ] > 
TOP_Y_MIN
 )

133 
lidar
 = 
lidar
 [ 
idx
 ]

134 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 1 ] < 
TOP_Y_MAX
 )

135 
lidar
 = 
lidar
 [ 
idx
 ]

137 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 2 ] > 
TOP_Z_MIN
 )

138 
lidar
 = 
lidar
 [ 
idx
 ]

139 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 2 ] < 
TOP_Z_MAX
 )

140 
lidar
 = 
lidar
 [ 
idx
 ]

142 
points
 = 
to_front
 ( 
lidar
 )

143 
ind
 = 
np
 . 
where
 ( 
cfg
 . 
FRONT_C_MIN
 < 
points
 [ : , 0 ] )

144 
points
 , 
lidar
 = 
points
 [ 
ind
 ] , 
lidar
 [ 
ind
 ]

145 
ind
 = 
np
 . 
where
 ( 
points
 [ : , 0 ] < 
cfg
 . 
FRONT_C_MAX
 )

146 
points
 , 
lidar
 = 
points
 [ 
ind
 ] , 
lidar
 [ 
ind
 ]

147 
ind
 = 
np
 . 
where
 ( 
cfg
 . 
FRONT_R_MIN
 < 
points
 [ : , 1 ] )

148 
points
 , 
lidar
 = 
points
 [ 
ind
 ] , 
lidar
 [ 
ind
 ]

149 
ind
 = 
np
 . 
where
 ( 
points
 [ : , 1 ] < 
cfg
 . 
FRONT_R_MAX
 )

150 
points
 , 
lidar
 = 
points
 [ 
ind
 ] , 
lidar
 [ 
ind
 ]

152 
points
 [ : , 0 ] += 
int
 ( 
cfg
 . 
FRONT_C_OFFSET
 )

153 
points
 [ : , 1 ] += 
int
 ( 
cfg
 . 
FRONT_R_OFFSET
 )

156 
ind
 = 
np
 . 
where
 ( 0 <= 
points
 [ : , 0 ] )

157 
points
 , 
lidar
 = 
points
 [ 
ind
 ] , 
lidar
 [ 
ind
 ]

158 
ind
 = 
np
 . 
where
 ( 
points
 [ : , 0 ] < 
cfg
 . 
FRONT_WIDTH
 )

159 
points
 , 
lidar
 = 
points
 [ 
ind
 ] , 
lidar
 [ 
ind
 ]

160 
ind
 = 
np
 . 
where
 ( 0 <= 
points
 [ : , 1 ] )

161 
points
 , 
lidar
 = 
points
 [ 
ind
 ] , 
lidar
 [ 
ind
 ]

162 
ind
 = 
np
 . 
where
 ( 
points
 [ : , 1 ] < 
cfg
 . 
FRONT_HEIGHT
 )

163 
points
 , 
lidar
 = 
points
 [ 
ind
 ] , 
lidar
 [ 
ind
 ]

165 
channel
 = 3

166 
front
 = 
np
 . 
zeros
 ( ( 
cfg
 . 
FRONT_WIDTH
 , 
cfg
 . 
FRONT_HEIGHT
 , 
channel
 ) , 
dtype
 = 
np
 . 
float32
 )

167 
weight_mask
 = 
np
 . 
zeros_like
 ( 
front
 [ : , : , 0 ] )

168 def 
_add
 ( 
x
 ) :

169 
weight_mask
 [ 
int
 ( 
x
 [ 0 ] ) , 
int
 ( 
x
 [ 1 ] ) ] += 1

170 def 
_fill
 ( 
x
 ) :

171 
front
 [ 
int
 ( 
x
 [ 0 ] ) , 
int
 ( 
x
 [ 1 ] ) , : ] += 
x
 [ 2 : ]

172 
np
 . 
apply_along_axis
 ( 
_add
 , 1 , 
points
 )

173 
weight_mask
 [ 
weight_mask
 == 0 ] = 1

174 
buf
 = 
np
 . 
hstack
 ( ( 
points
 , 
cal_height
 ( 
lidar
 ) , 
cal_distance
 ( 
lidar
 ) , 
cal_intensity
 ( 
lidar
 ) ) )

175 
np
 . 
apply_along_axis
 ( 
_fill
 , 1 , 
buf
 )

176 
front
 /= 
weight_mask
 [ : , : , 
np
 . 
newaxis
 ]

178 return 
front
 
	}

181 
proprocess
 = 
Preprocess
 ( )

184 def 
	$kitti_label_to_lidar_box3d
 ( 
label
 , 
object_type
 = 'Car' ) :

187 
ret
 = [ ]

188 for 
t
 in [ [ 'Car' , 'Van' ] , [ 'Pedestrian' ] , [ 'Cyclist' ] ] :

189 if 
object_type
 in 
t
 :

190 
category
 = 
t

193 return 
np
 . 
array
 ( [ 
ret
 ] )

195 for 
line
 in 
label
 :

196 
line
 = 
line
 . 
split
 ( )

197 
obj
 = 
line
 [ 0 ]

198 if 
obj
 in 
category
 :

199 
h
 , 
w
 , 
l
 , 
x
 , 
y
 , 
z
 , 
ry
 = [ 
float
 ( 
i
 ) for 
i
 in 
line
 [ 8 : 15 ] ]

200 
h
 , 
w
 , 
l
 , 
x
 , 
y
 , 
z
 , 
rz
 = 
h
 , 
w
 , 
l
 , * 
camera_to_lidar_coords
 ( 
x
 , 
y
 , 
z
 ) , - 
ry
 - 
math
 . 
pi
 / 2

201 
gt_box3d
 = 
box3d_compose
 ( ( 
x
 , 
y
 , 
z
 ) , ( 
h
 , 
w
 , 
l
 ) , ( 0 , 0 , 
rz
 ) )

202 
ret
 . 
append
 ( 
gt_box3d
 )

203 return 
np
 . 
array
 ( [ 
ret
 ] ) 
	}

206 def 
	$filter_center_car
 ( 
lidar
 ) :

207 
idx
 = 
np
 . 
where
 ( 
np
 . 
logical_or
 ( 
numpy
 . 
abs
 ( 
lidar
 [ : , 0 ] ) > 4.7 / 2 , 
numpy
 . 
abs
 ( 
lidar
 [ : , 1 ] ) > 2.1 / 2 ) )

208 
lidar
 = 
lidar
 [ 
idx
 ]

209 return 
lidar
 
	}

212 def 
	$obj_to_gt_boxes3d
 ( 
objs
 ) :

214 
num
 = 
len
 ( 
objs
 )

215 
gt_boxes3d
 = 
np
 . 
zeros
 ( ( 
num
 , 8 , 3 ) , 
dtype
 = 
np
 . 
float32
 )

216 
gt_labels
 = 
np
 . 
zeros
 ( ( 
num
 ) , 
dtype
 = 
np
 . 
int32
 )

218 for 
n
 in 
range
 ( 
num
 ) :

219 
obj
 = 
objs
 [ 
n
 ]

220 
b
 = 
obj
 . 
box

221 
label
 = 0

222 if 
obj
 . 
type
 == 'Van' or 
obj
 . 
type
 == 'Truck' or 
obj
 . 
type
 == 'Car' or 
obj
 . 
type
 == 'Tram' :

223 
label
 = 1

225 
gt_labels
 [ 
n
 ] = 
label

226 
gt_boxes3d
 [ 
n
 ] = 
b

228 return 
gt_boxes3d
 , 
gt_labels
 
	}

230 def 
	$draw_top_image
 ( 
lidar_top
 ) :

231 
top_image
 = 
np
 . 
sum
 ( 
lidar_top
 , 
axis
 = 2 )

232 
top_image
 = 
top_image
 - 
np
 . 
min
 ( 
top_image
 )

233 
divisor
 = 
np
 . 
max
 ( 
top_image
 ) - 
np
 . 
min
 ( 
top_image
 )

234 
top_image
 = ( 
top_image
 / 
divisor
 * 255 )

235 
top_image
 = 
np
 . 
dstack
 ( ( 
top_image
 , 
top_image
 , 
top_image
 ) ) . 
astype
 ( 
np
 . 
uint8
 )

236 return 
top_image
 
	}

238 def 
	$draw_front_image
 ( 
lidar_front
 ) :

240 
front_image
 = 
np
 . 
sum
 ( 
lidar_front
 , 
axis
 = 2 )

241 
front_image
 = 
front_image
 - 
np
 . 
min
 ( 
front_image
 )

242 
divisor
 = 
np
 . 
max
 ( 
front_image
 ) - 
np
 . 
min
 ( 
front_image
 )

243 
front_image
 = ( 
front_image
 / 
divisor
 * 255 )

244 
front_image
 = 
np
 . 
dstack
 ( ( 
front_image
 , 
front_image
 , 
front_image
 ) ) . 
astype
 ( 
np
 . 
uint8
 )

245 return 
front_image
 
	}

247 def 
	$clidar_to_top
 ( 
lidar
 ) :

248 if ( 
cfg
 . 
DATA_SETS_TYPE
 == 'didi' or 
cfg
 . 
DATA_SETS_TYPE
 == 'test' ) :

249 
lidar
 = 
filter_center_car
 ( 
lidar
 )

252 
Xn
 = 
math
 . 
floor
 ( ( 
TOP_X_MAX
 - 
TOP_X_MIN
 ) / 
TOP_X_DIVISION
 )

253 
Yn
 = 
math
 . 
floor
 ( ( 
TOP_Y_MAX
 - 
TOP_Y_MIN
 ) / 
TOP_Y_DIVISION
 )

254 
Zn
 = 
math
 . 
floor
 ( ( 
TOP_Z_MAX
 - 
TOP_Z_MIN
 ) / 
TOP_Z_DIVISION
 )

256 
top_flip
 = 
np
 . 
ones
 ( ( 
Xn
 , 
Yn
 , 
Zn
 + 2 ) , 
dtype
 = 
np
 . 
double
 )

258 
num
 = 
lidar
 . 
shape
 [ 0 ]

262 
SharedLib
 . 
createTopMaps
 ( 
ctypes
 . 
c_void_p
 ( 
lidar
 . 
ctypes
 . 
data
 ) ,

263 
ctypes
 . 
c_int
 ( 
num
 ) ,

264 
ctypes
 . 
c_void_p
 ( 
top_flip
 . 
ctypes
 . 
data
 ) ,

265 
ctypes
 . 
c_float
 ( 
TOP_X_MIN
 ) , 
ctypes
 . 
c_float
 ( 
TOP_X_MAX
 ) ,

266 
ctypes
 . 
c_float
 ( 
TOP_Y_MIN
 ) , 
ctypes
 . 
c_float
 ( 
TOP_Y_MAX
 ) ,

267 
ctypes
 . 
c_float
 ( 
TOP_Z_MIN
 ) , 
ctypes
 . 
c_float
 ( 
TOP_Z_MAX
 ) ,

268 
ctypes
 . 
c_float
 ( 
TOP_X_DIVISION
 ) , 
ctypes
 . 
c_float
 ( 
TOP_Y_DIVISION
 ) ,

269 
ctypes
 . 
c_float
 ( 
TOP_Z_DIVISION
 ) ,

270 
ctypes
 . 
c_int
 ( 
Xn
 ) , 
ctypes
 . 
c_int
 ( 
Yn
 ) , 
ctypes
 . 
c_int
 ( 
Zn
 )

272 
top
 = 
np
 . 
flipud
 ( 
np
 . 
fliplr
 ( 
top_flip
 ) )

273 return 
top
 
	}

278 def 
	$lidar_to_top
 ( 
lidar
 ) :

280 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 0 ] > 
TOP_X_MIN
 )

281 
lidar
 = 
lidar
 [ 
idx
 ]

282 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 0 ] < 
TOP_X_MAX
 )

283 
lidar
 = 
lidar
 [ 
idx
 ]

285 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 1 ] > 
TOP_Y_MIN
 )

286 
lidar
 = 
lidar
 [ 
idx
 ]

287 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 1 ] < 
TOP_Y_MAX
 )

288 
lidar
 = 
lidar
 [ 
idx
 ]

290 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 2 ] > 
TOP_Z_MIN
 )

291 
lidar
 = 
lidar
 [ 
idx
 ]

292 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 2 ] < 
TOP_Z_MAX
 )

293 
lidar
 = 
lidar
 [ 
idx
 ]

295 if ( 
cfg
 . 
DATA_SETS_TYPE
 == 'didi' or 
cfg
 . 
DATA_SETS_TYPE
 == 'test' or 
cfg
 . 
DATA_SETS_TYPE
 == 'didi2' ) :

296 
lidar
 = 
filter_center_car
 ( 
lidar
 )

299 
pxs
 = 
lidar
 [ : , 0 ]

300 
pys
 = 
lidar
 [ : , 1 ]

301 
pzs
 = 
lidar
 [ : , 2 ]

302 
prs
 = 
lidar
 [ : , 3 ]

303 
qxs
 = ( ( 
pxs
 - 
TOP_X_MIN
 ) // 
TOP_X_DIVISION
 ) . 
astype
 ( 
np
 . 
int32
 )

304 
qys
 = ( ( 
pys
 - 
TOP_Y_MIN
 ) // 
TOP_Y_DIVISION
 ) . 
astype
 ( 
np
 . 
int32
 )

306 
qzs
 = ( 
pzs
 - 
TOP_Z_MIN
 ) / 
TOP_Z_DIVISION

307 
quantized
 = 
np
 . 
dstack
 ( ( 
qxs
 , 
qys
 , 
qzs
 , 
prs
 ) ) . 
squeeze
 ( )

309 
X0
 , 
Xn
 = 0 , 
int
 ( ( 
TOP_X_MAX
 - 
TOP_X_MIN
 ) // 
TOP_X_DIVISION
 ) + 1

310 
Y0
 , 
Yn
 = 0 , 
int
 ( ( 
TOP_Y_MAX
 - 
TOP_Y_MIN
 ) // 
TOP_Y_DIVISION
 ) + 1

311 
Z0
 , 
Zn
 = 0 , 
int
 ( ( 
TOP_Z_MAX
 - 
TOP_Z_MIN
 ) / 
TOP_Z_DIVISION
 )

312 
height
 = 
Xn
 - 
X0

313 
width
 = 
Yn
 - 
Y0

314 
channel
 = 
Zn
 - 
Z0
 + 2

316 
top
 = 
np
 . 
zeros
 ( 
shape
 = ( 
height
 , 
width
 , 
channel
 ) , 
dtype
 = 
np
 . 
float32
 )

323 for 
x
 in 
range
 ( 
Xn
 ) :

324 
ix
 = 
np
 . 
where
 ( 
quantized
 [ : , 0 ] == 
x
 )

325 
quantized_x
 = 
quantized
 [ 
ix
 ]

326 if 
len
 ( 
quantized_x
 ) == 0 : continue

327 
yy
 = - 
x

329 for 
y
 in 
range
 ( 
Yn
 ) :

330 
iy
 = 
np
 . 
where
 ( 
quantized_x
 [ : , 1 ] == 
y
 )

331 
quantized_xy
 = 
quantized_x
 [ 
iy
 ]

332 
count
 = 
len
 ( 
quantized_xy
 )

333 if 
count
 == 0 : continue

334 
xx
 = - 
y

336 
top
 [ 
yy
 , 
xx
 , 
Zn
 + 1 ] = 
min
 ( 1 , 
np
 . 
log
 ( 
count
 + 1 ) / 
math
 . 
log
 ( 32 ) )

337 
max_height_point
 = 
np
 . 
argmax
 ( 
quantized_xy
 [ : , 2 ] )

338 
top
 [ 
yy
 , 
xx
 , 
Zn
 ] = 
quantized_xy
 [ 
max_height_point
 , 3 ]

340 for 
z
 in 
range
 ( 
Zn
 ) :

341 
iz
 = 
np
 . 
where
 ( ( 
quantized_xy
 [ : , 2 ] >= 
z
 ) & ( 
quantized_xy
 [ : , 2 ] <= 
z
 + 1 ) )

342 
quantized_xyz
 = 
quantized_xy
 [ 
iz
 ]

343 if 
len
 ( 
quantized_xyz
 ) == 0 : continue

344 
zz
 = 
z

347 
max_height
 = 
max
 ( 0 , 
np
 . 
max
 ( 
quantized_xyz
 [ : , 2 ] ) - 
z
 )

348 
top
 [ 
yy
 , 
xx
 , 
zz
 ] = 
max_height

349 return 
top
 
	}

351 def 
	$lidar_to_top_fast
 ( 
lidar
 ) :

353 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 0 ] > 
TOP_X_MIN
 )

354 
lidar
 = 
lidar
 [ 
idx
 ]

355 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 0 ] < 
TOP_X_MAX
 )

356 
lidar
 = 
lidar
 [ 
idx
 ]

358 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 1 ] > 
TOP_Y_MIN
 )

359 
lidar
 = 
lidar
 [ 
idx
 ]

360 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 1 ] < 
TOP_Y_MAX
 )

361 
lidar
 = 
lidar
 [ 
idx
 ]

363 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 2 ] > 
TOP_Z_MIN
 )

364 
lidar
 = 
lidar
 [ 
idx
 ]

365 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 2 ] < 
TOP_Z_MAX
 )

366 
lidar
 = 
lidar
 [ 
idx
 ]

368 if ( 
cfg
 . 
DATA_SETS_TYPE
 == 'didi' or 
cfg
 . 
DATA_SETS_TYPE
 == 'test' or 
cfg
 . 
DATA_SETS_TYPE
 == 'didi2' ) :

369 
lidar
 = 
filter_center_car
 ( 
lidar
 )

372 
lidar
 [ : , 0 ] = ( ( 
lidar
 [ : , 0 ] - 
TOP_X_MIN
 ) // 
TOP_X_DIVISION
 ) . 
astype
 ( 
np
 . 
int32
 )

373 
lidar
 [ : , 1 ] = ( ( 
lidar
 [ : , 1 ] - 
TOP_Y_MIN
 ) // 
TOP_Y_DIVISION
 ) . 
astype
 ( 
np
 . 
int32
 )

374 
lidar
 [ : , 2 ] = ( ( 
lidar
 [ : , 2 ] - 
TOP_Z_MIN
 ) / 
TOP_Z_DIVISION
 ) . 
astype
 ( 
np
 . 
float32
 )

377 
X0
 , 
Xn
 = 0 , 
int
 ( ( 
TOP_X_MAX
 - 
TOP_X_MIN
 ) // 
TOP_X_DIVISION
 ) + 1

378 
Y0
 , 
Yn
 = 0 , 
int
 ( ( 
TOP_Y_MAX
 - 
TOP_Y_MIN
 ) // 
TOP_Y_DIVISION
 ) + 1

379 
Z0
 , 
Zn
 = 0 , 
int
 ( ( 
TOP_Z_MAX
 - 
TOP_Z_MIN
 ) / 
TOP_Z_DIVISION
 )

380 
height
 = 
Xn
 - 
X0

381 
width
 = 
Yn
 - 
Y0

382 
channel
 = 
Zn
 - 
Z0
 + 2

384 
grid
 = 
np
 . 
zeros
 ( ( 
height
 , 
width
 , 1 ) , 
dtype
 = 
np
 . 
object
 )

385 def 
_fill
 ( 
x
 ) :

386 if 
grid
 [ 
int
 ( 
x
 [ 0 ] ) , 
int
 ( 
x
 [ 1 ] ) , 0 ] == 0 :

387 
grid
 [ 
int
 ( 
x
 [ 0 ] ) , 
int
 ( 
x
 [ 1 ] ) , 0 ] = [ ]

388 
grid
 [ 
int
 ( 
x
 [ 0 ] ) , 
int
 ( 
x
 [ 1 ] ) , 0 ] . 
append
 ( 
x
 )

389 def 
_sort_by_height
 ( 
x
 ) :

390 
x
 = 
x
 [ 0 ]

391 if 
x
 != 0 :

392 
h
 = 
np
 . 
array
 ( [ 
i
 [ 2 ] for 
i
 in 
x
 ] )

393 
grid
 [ 
int
 ( 
x
 [ 0 ] [ 0 ] ) , 
int
 ( 
x
 [ 0 ] [ 1 ] ) , 0 ] = 
list
 ( 
np
 . 
array
 ( 
x
 ) [ 
h
 . 
argsort
 ( 
kind
 = 'heapsort' ) ] )

394 
np
 . 
apply_along_axis
 ( 
_fill
 , 1 , 
lidar
 )

395 
np
 . 
apply_along_axis
 ( 
_sort_by_height
 , 2 , 
grid
 )

398 
top
 = 
np
 . 
zeros
 ( ( 
height
 , 
width
 , 
channel
 ) , 
dtype
 = 
np
 . 
float32
 )

399 def 
_cal_height
 ( 
x
 ) :

400 
x
 = 
x
 [ 0 ]

401 if 
x
 != 0 :

402 
i
 = 0

403 for 
z
 in 
range
 ( 
Zn
 ) :

404 if 
z
 + 1 < 
x
 [ 
i
 ] [ 2 ] : continue

406 while not ( 
x
 [ 
i
 ] [ 2 ] <= 
z
 + 1 and 
x
 [ 
i
 + 1 ] [ 2 ] > 
z
 + 1 ) :

407 
i
 += 1

409 
top
 [ 
int
 ( 
x
 [ 0 ] [ 0 ] ) , 
int
 ( 
x
 [ 0 ] [ 1 ] ) , 
z
 ] = 
max
 ( 
x
 [ - 1 ] [ 2 ] - 
z
 , 0 )

412 
top
 [ 
int
 ( 
x
 [ 0 ] [ 0 ] ) , 
int
 ( 
x
 [ 0 ] [ 1 ] ) , 
z
 ] = 
max
 ( 
x
 [ 
i
 ] [ 2 ] - 
z
 , 0 )

413 
i
 += 1

414 def 
_cal_density
 ( 
x
 ) :

415 
x
 = 
x
 [ 0 ]

416 if 
x
 != 0 :

417 
top
 [ 
int
 ( 
x
 [ 0 ] [ 0 ] ) , 
int
 ( 
x
 [ 0 ] [ 1 ] ) , 
Zn
 + 1 ] = 
min
 ( 1 , 
np
 . 
log
 ( 
len
 ( 
x
 ) + 1 ) / 
np
 . 
log
 ( 32 ) )

418 def 
_cal_intensity
 ( 
x
 ) :

419 
x
 = 
x
 [ 0 ]

420 if 
x
 != 0 :

421 
top
 [ 
int
 ( 
x
 [ 0 ] [ 0 ] ) , 
int
 ( 
x
 [ 0 ] [ 1 ] ) , 
Zn
 ] = 
x
 [ - 1 ] [ 3 ]

422 
np
 . 
apply_along_axis
 ( 
_cal_height
 , 2 , 
grid
 )

423 
np
 . 
apply_along_axis
 ( 
_cal_density
 , 2 , 
grid
 )

424 
np
 . 
apply_along_axis
 ( 
_cal_intensity
 , 2 , 
grid
 )

426 return 
top
 
	}

430 def 
	$get_all_file_names
 ( 
data_seg
 , 
dates
 , 
drivers
 ) :

432 
lidar_dir
 = 
os
 . 
path
 . 
join
 ( 
data_seg
 , "top" )

433 
load_indexs
 = [ ]

434 for 
date
 in 
dates
 :

435 for 
driver
 in 
drivers
 :

437 
file_prefix
 = 
lidar_dir
 + '/' + 
date
 + '_' + 
driver
 + '_*'

438 
driver_files
 = 
glob
 . 
glob
 ( 
file_prefix
 )

439 
name_list
 = [ 
file
 . 
split
 ( '/' ) [ - 1 ] . 
split
 ( '.' ) [ 0 ] for 
file
 in 
driver_files
 ]

440 
load_indexs
 += 
name_list

441 return 
load_indexs
 
	}

444 def 
	$proprecess_rgb
 ( 
save_preprocess_dir
 , 
dataset
 , 
date
 , 
drive
 , 
frames_index
 , 
overwrite
 = False ) :

446 
dataset_dir
 = 
os
 . 
path
 . 
join
 ( 
save_preprocess_dir
 , 'rgb' , 
date
 , 
drive
 )

448 
os
 . 
makedirs
 ( 
dataset_dir
 )

449 
count
 = 0

450 for 
n
 in 
frames_index
 :

451 
path
 = 
os
 . 
path
 . 
join
 ( 
dataset_dir
 , '%05d.png' % 
n
 )

452 if 
overwrite
 == False and 
os
 . 
path
 . 
isfile
 ( 
path
 ) :

453 
count
 += 1

455 
print
 ( 'rgb images={}' . 
format
 ( 
n
 ) )

456 
rgb
 = 
dataset
 . 
rgb
 [ 
count
 ] [ 0 ]

457 
rgb
 = 
proprocess
 . 
rgb
 ( 
rgb
 )

460 
cv2
 . 
imwrite
 ( 
os
 . 
path
 . 
join
 ( 
path
 ) , 
rgb
 )

462 
count
 += 1

463 
print
 ( 'rgb image save done\n' )

465 pass 
	}

468 def 
	$generate_top_view
 ( 
save_preprocess_dir
 , 
dataset
 , 
objects
 , 
date
 , 
drive
 , 
frames_index
 ,

469 
overwrite
 = False , 
dump_image
 = True ) :

471 
dataset_dir
 = 
os
 . 
path
 . 
join
 ( 
save_preprocess_dir
 , 'top' , 
date
 , 
drive
 )

473 
os
 . 
makedirs
 ( 
dataset_dir
 )

475 
count
 = 0

476 
lidars
 = [ ]

477 
pool
 = 
Pool
 ( 3 )

478 for 
n
 in 
frames_index
 :

479 
path
 = 
os
 . 
path
 . 
join
 ( 
dataset_dir
 , '%05d.npy' % 
n
 )

480 if 
overwrite
 == False and 
os
 . 
path
 . 
isfile
 ( 
path
 ) :

481 
count
 += 1

483 
lidars
 . 
append
 ( 
dataset
 . 
velo
 [ 
count
 ] )

484 
count
 += 1

485 if 
cfg
 . 
USE_CLIDAR_TO_TOP
 :

486 
print
 ( 'use clidar_to_top' )

487 
t0
 = 
time
 . 
time
 ( )

488 
tops
 = 
pool
 . 
map
 ( 
clidar_to_top
 , 
lidars
 )

490 
print
 ( 'time = ' , 
time
 . 
time
 ( ) - 
t0
 )

492 
t0
 = 
time
 . 
time
 ( )

493 
tops
 = 
pool
 . 
map
 ( 
lidar_to_top
 , 
lidars
 )

495 
print
 ( 'time = ' , 
time
 . 
time
 ( ) - 
t0
 )

497 
count
 = 0

498 for 
top
 in 
tops
 :

499 
n
 = 
frames_index
 [ 
count
 ]

500 
path
 = 
os
 . 
path
 . 
join
 ( 
dataset_dir
 , '%05d.npy' % 
n
 )

503 
np
 . 
savez_compressed
 ( 
path
 , 
top_view
 = 
top
 )

504 
print
 ( 'top view {} saved' . 
format
 ( 
n
 ) )

505 
count
 += 1

508 if 
dump_image
 :

509 
dataset_dir
 = 
os
 . 
path
 . 
join
 ( 
save_preprocess_dir
 , 'top_image' , 
date
 , 
drive
 )

511 
os
 . 
makedirs
 ( 
dataset_dir
 )

514 
top_images
 = 
pool
 . 
map
 ( 
draw_top_image
 , 
tops
 )

517 
count
 = 0

518 for 
top_image
 in 
top_images
 :

519 
n
 = 
frames_index
 [ 
count
 ]

520 
top_image_path
 = 
os
 . 
path
 . 
join
 ( 
dataset_dir
 , '%05d.png' % 
n
 )

523 if 
objects
 != None :

524 
gt_boxes3d
 , 
gt_labels
 = 
obj_to_gt_boxes3d
 ( 
objects
 [ 
count
 ] )

525 
top_image
 = 
draw_box3d_on_top
 ( 
top_image
 , 
gt_boxes3d
 , 
color
 = ( 0 , 0 , 80 ) )

526 
cv2
 . 
imwrite
 ( 
top_image_path
 , 
top_image
 )

527 
count
 += 1

528 
print
 ( 'top view image {} saved' . 
format
 ( 
n
 ) )

529 
pool
 . 
close
 ( )

530 
pool
 . 
join
 ( )

532 pass 
	}

537 def 
	$preprocess_bbox
 ( 
save_preprocess_dir
 , 
objects
 , 
date
 , 
drive
 , 
frames_index
 , 
overwrite
 = False ) :

540 
bbox_dir
 = 
os
 . 
path
 . 
join
 ( 
save_preprocess_dir
 , 'gt_boxes3d' , 
date
 , 
drive
 )

542 
os
 . 
makedirs
 ( 
bbox_dir
 )

545 
lable_dir
 = 
os
 . 
path
 . 
join
 ( 
save_preprocess_dir
 , 'gt_labels' , 
date
 , 
drive
 )

547 
os
 . 
makedirs
 ( 
lable_dir
 )

550 
count
 = 0

551 for 
n
 in 
frames_index
 :

552 
bbox_path
 = 
os
 . 
path
 . 
join
 ( 
bbox_dir
 , '%05d.npy' % 
n
 )

553 
lable_path
 = 
os
 . 
path
 . 
join
 ( 
lable_dir
 , '%05d.npy' % 
n
 )

554 if 
overwrite
 == False and 
os
 . 
path
 . 
isfile
 ( 
bbox_path
 ) :

555 
count
 += 1

558 if 
overwrite
 == False and 
os
 . 
path
 . 
isfile
 ( 
lable_path
 ) :

559 
count
 += 1

562 
print
 ( 'boxes3d={}' . 
format
 ( 
n
 ) )

564 
obj
 = 
objects
 [ 
count
 ]

565 
gt_boxes3d
 , 
gt_labels
 = 
obj_to_gt_boxes3d
 ( 
obj
 )

567 
np
 . 
save
 ( 
bbox_path
 , 
gt_boxes3d
 )

568 
np
 . 
save
 ( 
lable_path
 , 
gt_labels
 )

569 
count
 += 1

571 pass 
	}

573 def 
	$draw_top_view_image
 ( 
save_preprocess_dir
 , 
objects
 , 
date
 , 
drive
 , 
frames_index
 , 
overwrite
 = False ) :

575 
dataset_dir
 = 
os
 . 
path
 . 
join
 ( 
save_preprocess_dir
 , 'top_image' , 
date
 , 
drive
 )

577 
os
 . 
makedirs
 ( 
dataset_dir
 )

580 
count
 = 0

581 for 
n
 in 
frames_index
 :

582 
top_image_path
 = 
os
 . 
path
 . 
join
 ( 
dataset_dir
 , '%05d.png' % 
n
 )

583 if 
overwrite
 == False and 
os
 . 
path
 . 
isfile
 ( 
top_image_path
 ) :

584 
count
 += 1

587 
print
 ( 'draw top view image ={}' . 
format
 ( 
n
 ) )

589 
top
 = 
np
 . 
load
 ( 
os
 . 
path
 . 
join
 ( 
save_preprocess_dir
 , 'top' , 
date
 , 
drive
 , '%05d.npy.npz' % 
n
 ) )

590 
top
 = 
top
 [ 'top_view' ]

591 
top_image
 = 
draw_top_image
 ( 
top
 )

594 if 
objects
 != None :

595 
gt_boxes3d
 = 
np
 . 
load
 ( 
os
 . 
path
 . 
join
 ( 
save_preprocess_dir
 , 'gt_boxes3d' , 
date
 , 
drive
 , '%05d.npy' % 
n
 ) )

596 
top_image
 = 
draw_box3d_on_top
 ( 
top_image
 , 
gt_boxes3d
 , 
color
 = ( 0 , 0 , 80 ) )

598 
print
 ( 'Not found gt_boxes3d,skip draw bbox on top image' )

600 
cv2
 . 
imwrite
 ( 
top_image_path
 , 
top_image
 )

601 
count
 += 1

602 
print
 ( 'top view image draw done\n' )

604 pass 
	}

606 def 
	$dump_lidar
 ( 
save_preprocess_dir
 , 
dataset
 , 
date
 , 
drive
 , 
frames_index
 , 
overwrite
 = False ) :

608 
dataset_dir
 = 
os
 . 
path
 . 
join
 ( 
save_preprocess_dir
 , 'lidar' , 
date
 , 
drive
 )

610 
os
 . 
makedirs
 ( 
dataset_dir
 )

613 
count
 = 0

614 for 
n
 in 
frames_index
 :

616 
lidar_dump_path
 = 
os
 . 
path
 . 
join
 ( 
dataset_dir
 , '%05d.npy' % 
n
 )

617 if 
overwrite
 == False and 
os
 . 
path
 . 
isfile
 ( 
lidar_dump_path
 ) :

618 
count
 += 1

621 
print
 ( 'lidar data={}' . 
format
 ( 
n
 ) )

622 
lidar
 = 
dataset
 . 
velo
 [ 
count
 ]

623 
np
 . 
save
 ( 
lidar_dump_path
 , 
lidar
 )

624 
count
 += 1

625 
print
 ( 'dump lidar data done\n' )

627 pass 
	}

629 def 
	$dump_bbox_on_camera_image
 ( 
save_preprocess_dir
 , 
dataset
 , 
objects
 , 
date
 , 
drive
 , 
frames_index
 , 
overwrite
 = False ) :

631 
dataset_dir
 = 
os
 . 
path
 . 
join
 ( 
save_preprocess_dir
 , 'gt_box_plot' , 
date
 , 
drive
 )

633 
os
 . 
makedirs
 ( 
dataset_dir
 )

636 
count
 = 0

637 for 
n
 in 
frames_index
 :

638 
print
 ( 'rgb images={}' . 
format
 ( 
n
 ) )

639 
rgb
 = 
dataset
 . 
rgb
 [ 
count
 ] [ 0 ]

640 
rgb
 = ( 
rgb
 * 255 ) . 
astype
 ( 
np
 . 
uint8
 )

641 
rgb
 = 
cv2
 . 
cvtColor
 ( 
rgb
 , 
cv2
 . 
COLOR_RGB2BGR
 )

642 
rgb
 = 
crop_image
 ( 
rgb
 )

644 
objs
 = 
objects
 [ 
count
 ]

645 
gt_boxes3d
 , 
gt_labels
 = 
obj_to_gt_boxes3d
 ( 
objs
 )

646 
img
 = 
draw
 . 
draw_box3d_on_camera
 ( 
rgb
 , 
gt_boxes3d
 )

647 
new_size
 = ( 
img
 . 
shape
 [ 1 ] // 3 , 
img
 . 
shape
 [ 0 ] // 3 )

648 
img
 = 
cv2
 . 
resize
 ( 
img
 , 
new_size
 )

649 
cv2
 . 
imwrite
 ( 
os
 . 
path
 . 
join
 ( 
dataset_dir
 , '%05d.png' % 
n
 ) , 
img
 )

650 
count
 += 1

651 
print
 ( 'gt box image save done\n' )

653 pass 
	}

655 def 
	$crop_image
 ( 
image
 ) :

656 
image_crop
 = 
image
 . 
copy
 ( )

657 
left
 = 
cfg
 . 
IMAGE_CROP_LEFT

658 
right
 = 
cfg
 . 
IMAGE_CROP_RIGHT

659 
top
 = 
cfg
 . 
IMAGE_CROP_TOP

660 
bottom
 = 
cfg
 . 
IMAGE_CROP_BOTTOM

661 
bottom_index
 = - 
bottom
 if 
bottom
 != 0 else None

662 
right_index
 = - 
right
 if 
right
 != 0 else None

663 
image_crop
 = 
image_crop
 [ 
top
 : 
bottom_index
 , 
left
 : 
right_index
 , : ]

664 return 
image_crop
 
	}

666 def 
	$is_evaluation_dataset
 ( 
date
 , 
drive
 ) :

667 if 
date
 == 'Round1Test' or 
date
 == 'test_car' or 
date
 == 'test_ped' :

670 return False 
	}

672 def 
	$data_in_single_driver
 ( 
raw_dir
 , 
date
 , 
drive
 , 
frames_index
 = None ) :

674 if ( 
cfg
 . 
DATA_SETS_TYPE
 == 'didi2' ) :

675 
img_path
 = 
os
 . 
path
 . 
join
 ( 
raw_dir
 , 
date
 , 
drive
 , "image_02" , "data" )

676 elif ( 
cfg
 . 
DATA_SETS_TYPE
 == 'didi' ) :

677 
img_path
 = 
os
 . 
path
 . 
join
 ( 
raw_dir
 , 
date
 , 
drive
 , "image_02" , "data" )

678 elif 
cfg
 . 
DATA_SETS_TYPE
 == 'kitti' :

679 
img_path
 = 
os
 . 
path
 . 
join
 ( 
raw_dir
 , 
date
 , 
date
 + "_drive_" + 
drive
 + "_sync" , "image_02" , "data" )

680 elif ( 
cfg
 . 
DATA_SETS_TYPE
 == 'test' ) :

681 
img_path
 = 
os
 . 
path
 . 
join
 ( 
raw_dir
 , 
date
 , 
drive
 , "image_02" , "data" )

683 raise 
ValueError
 ( 'unexpected type in cfg.DATA_SETS_TYPE item: {}!' . 
format
 ( 
cfg
 . 
DATA_SETS_TYPE
 ) )

685 if 
frames_index
 is None :

686 
nb_frames
 = 
len
 ( 
glob
 . 
glob
 ( 
img_path
 + "/*.png" ) )

687 
frames_index
 = 
range
 ( 
nb_frames
 )

690 if ( 
cfg
 . 
DATA_SETS_TYPE
 == 'test' ) :

691 
max_cache_frames_num
 = 3

693 
max_cache_frames_num
 = 3

694 if 
len
 ( 
frames_index
 ) > 
max_cache_frames_num
 :

695 
frames_idx_chunks
 = [ 
frames_index
 [ 
i
 : 
i
 + 
max_cache_frames_num
 ] for 
i
 in 
range
 ( 0 , 
len
 ( 
frames_index
 ) , 
max_cache_frames_num
 ) ]

697 
frames_idx_chunks
 = [ 
frames_index
 ]

699 for 
i
 , 
frames_index
 in 
enumerate
 ( 
frames_idx_chunks
 ) :

701 
dataset
 = 
pykitti
 . 
raw
 ( 
raw_dir
 , 
date
 , 
drive
 , 
frames_index
 )

704 
tracklet_file
 = 
os
 . 
path
 . 
join
 ( 
dataset
 . 
data_path
 , 'tracklet_labels.xml' )

705 
print
 ( 
tracklet_file
 )

706 if 
os
 . 
path
 . 
isfile
 ( 
tracklet_file
 ) :

707 
objects
 = 
read_objects
 ( 
tracklet_file
 , 
frames_index
 )

708 elif 
is_evaluation_dataset
 ( 
date
 , 
drive
 ) :

709 
objects
 = None

710 
print
 ( "Skip read evaluation_dataset's tracklet_labels file : " )

712 raise 
ValueError
 ( 'read_objects error!!!!!' )

719 
dataset
 . 
load_left_rgb
 ( )

720 
dataset
 . 
load_velo
 ( )

724 
save_preprocess_dir
 = 
cfg
 . 
PREPROCESSING_DATA_SETS_DIR

727 
proprecess_rgb
 ( 
save_preprocess_dir
 , 
dataset
 , 
date
 , 
drive
 , 
frames_index
 , 
overwrite
 = False )

731 
generate_top_view
 ( 
save_preprocess_dir
 , 
dataset
 , 
objects
 , 
date
 , 
drive
 , 
frames_index
 ,

732 
overwrite
 = True , 
dump_image
 = True )

734 if 1 and 
objects
 != None :

735 
preprocess_bbox
 ( 
save_preprocess_dir
 , 
objects
 , 
date
 , 
drive
 , 
frames_index
 , 
overwrite
 = True )

738 
draw_top_view_image
 ( 
save_preprocess_dir
 , 
objects
 , 
date
 , 
drive
 , 
frames_index
 , 
overwrite
 = True )

743 
dump_lidar
 ( 
save_preprocess_dir
 , 
dataset
 , 
date
 , 
drive
 , 
frames_index
 , 
overwrite
 = False )

745 if 1 and 
objects
 != None :

746 
dump_bbox_on_camera_image
 ( 
save_preprocess_dir
 , 
dataset
 , 
objects
 , 
date
 , 
drive
 , 
frames_index
 , 
overwrite
 = True ) 
	}

799 def 
	$preproces
 ( 
mapping
 , 
frames_index
 ) :

801 if 
mapping
 is None :

802 
paths
 = 
glob
 . 
glob
 ( 
os
 . 
path
 . 
join
 ( 
cfg
 . 
RAW_DATA_SETS_DIR
 , '*' ) )

803 
map_key
 = [ 
os
 . 
path
 . 
basename
 ( 
path
 ) for 
path
 in 
paths
 ]

804 
map_value
 = [ 
os
 . 
listdir
 ( 
bag_name
 ) for 
bag_name
 in 
map_key
 ]

805 
mapping
 = { 
k
 : 
v
 for 
k
 , 
v
 in 
zip
 ( 
map_key
 , 
map_value
 ) }

808 for 
key
 in 
mapping
 . 
keys
 ( ) :

809 if 
mapping
 [ 
key
 ] is None :

810 
paths
 = 
glob
 . 
glob
 ( 
os
 . 
path
 . 
join
 ( 
cfg
 . 
RAW_DATA_SETS_DIR
 , 
key
 , '*' ) )

811 if 
len
 ( 
paths
 ) == 0 :

812 raise 
ValueError
 ( 'can not found any file in:{}' . 
format
 ( 
os
 . 
path
 . 
join
 ( 
cfg
 . 
RAW_DATA_SETS_DIR
 , 
key
 , '*' ) ) )

813 
drivers_des
 = [ 
os
 . 
path
 . 
basename
 ( 
path
 ) for 
path
 in 
paths
 ]

815 
drivers_des
 = 
mapping
 [ 
key
 ]

816 for 
driver
 in 
drivers_des
 :

817 
print
 ( 'date {} and driver {}' . 
format
 ( 
key
 , 
driver
 ) )

818 
data_in_single_driver
 ( 
cfg
 . 
RAW_DATA_SETS_DIR
 , 
key
 , 
driver
 , 
frames_index
 ) 
	}

821 if 
__name__
 == '__main__' :

822 
print
 ( '%s: calling main function ... ' % 
os
 . 
path
 . 
basename
 ( 
__file__
 ) )

823 if ( 
cfg
 . 
DATA_SETS_TYPE
 == 'didi' ) :

824 
data_dir
 = { '1' : [ '15' , '10' ] }

825 
data_dir
 = 
OrderedDict
 ( 
data_dir
 )

826 
frames_index
 = None

827 elif ( 
cfg
 . 
DATA_SETS_TYPE
 == 'didi2' ) :

828 
dir_prefix
 = '/home/stu/round12_data/raw/didi'

830 
bag_groups
 = [ 'suburu_pulling_to_left' , 'nissan_following_long'

855 
bag_groups
 = [ 'suburu_pulling_to_left' , 'nissan_following_long'

873 
data_dir
 = 
OrderedDict
 ( [ ( 
bag_group
 , None ) for 
bag_group
 in 
bag_groups
 ] )

874 
print
 ( 'ordered dictionary here: ' , 
data_dir
 )

876 
frames_index
 = None

877 elif 
cfg
 . 
DATA_SETS_TYPE
 == 'kitti' :

878 
data_dir
 = { '2011_09_26' : [ '0001' , '0017' , '0029' , '0052' , '0070' , '0002' , '0018' , '0035' , '0056' , '0079' , '0019'

883 
frames_index
 = None

884 elif 
cfg
 . 
DATA_SETS_TYPE
 == 'test' :

885 
data_dir
 = { '1' : None , '2' : None }

886 
data_dir
 = 
OrderedDict
 ( 
data_dir
 )

887 
frames_index
 = None

889 raise 
ValueError
 ( 'unexpected type in cfg.DATA_SETS_TYPE item: {}!' . 
format
 ( 
cfg
 . 
DATA_SETS_TYPE
 ) )

891 import 
	~time

892 
t0
 = 
time
 . 
time
 ( )

894 
preproces
 ( 
data_dir
 , 
frames_index
 )

896 
print
 ( 'use time : {}' . 
format
 ( 
time
 . 
time
 ( ) - 
t0
 ) )


	@./config.py

15 import 
	~os

16 import 
	~os.path
 as 
osp

17 import 
	~numpy
 as 
np

18 from 
	~time
 import 
strftime
 , 
localtime

19 from 
	~easydict
 import 
EasyDict
 as 
edict

20 import 
	~math

24 
__C
 = 
edict
 ( )

27 
cfg
 = 
__C

28 
__C
 . 
TEST_KEY
 = 11

31 
__C
 . 
LOAD_BEST_PROPOSALS
 = True

32 
__C
 . 
VELODYNE_ANGULAR_RESOLUTION
 = 0.08 / 180 * 
math
 . 
pi

33 
__C
 . 
VELODYNE_VERTICAL_RESOLUTION
 = 0.4 / 180 * 
math
 . 
pi

34 
__C
 . 
VELODYNE_HEIGHT
 = 1.73

35 
__C
 . 
FRONT_R_OFFSET
 = 70

36 
__C
 . 
FRONT_C_OFFSET
 = 750

37 
__C
 . 
FRONT_R_MAX
 = 30

38 
__C
 . 
FRONT_R_MIN
 = - 70

39 
__C
 . 
FRONT_C_MAX
 = 750

40 
__C
 . 
FRONT_C_MIN
 = - 750

41 
__C
 . 
FRONT_WIDTH
 = 1500

42 
__C
 . 
FRONT_HEIGHT
 = 100

43 
__C
 . 
BOX3D_Z_MIN
 = - 2.52

44 
__C
 . 
BOX3D_Z_MAX
 = - 1.02

46 
__C
 . 
USE_FRONT
 = 1

47 
__C
 . 
GPU_AVAILABLE
 = '1'

48 
__C
 . 
GPU_USE_COUNT
 = 1

49 
__C
 . 
GPU_MEMORY_FRACTION
 = 0.8

52 
__C
 . 
ANCHOR_AMOUNT
 = 120000

53 
__C
 . 
REMOVE_THRES
 = 0.0

57 
__C
 . 
USE_GPU_NMS
 = 0

59 
__C
 . 
RPN_NMS_THRESHOLD
 = 0.7

60 
__C
 . 
RCNN_NMS_THRESHOLD
 = 0.75

63 
__C
 . 
USE_HANDCRAFT_FUSION
 = 0

64 
__C
 . 
HIGH_SCORE_THRESHOLD
 = 0.9

65 
__C
 . 
USE_LEARNABLE_FUSION
 = 0

68 
__C
 . 
USE_SIAMESE_FUSION
 = 0

69 
__C
 . 
ROI_ENLARGE_RATIO
 = 1.5

72 
__C
 . 
ROI_POOLING_HEIGHT
 = 6

73 
__C
 . 
ROI_POOLING_WIDTH
 = 6

76 
__C
 . 
POINT_AMOUNT_LIMIT
 = 100000

77 
__C
 . 
VOXEL_ROI_L
 = 0

78 
__C
 . 
VOXEL_ROI_W
 = 0

79 
__C
 . 
VOXEL_ROI_H
 = 0

80 
__C
 . 
USE_CONV3D
 = 0

81 
__C_USE_POINTNET
 = 0

86 
__C
 . 
DATA_SETS_TYPE
 = 'kitti'

89 
__C
 . 
ROOT_DIR
 = 
osp
 . 
abspath
 ( 
osp
 . 
join
 ( 
osp
 . 
dirname
 ( 
__file__
 ) , '..' ) )

91 if 
__C
 . 
DATA_SETS_TYPE
 == 'test' :

92 
__C
 . 
DATA_SETS_DIR
 = 
osp
 . 
abspath
 ( '/home/stu/round12_data_test' )

94 
__C
 . 
DATA_SETS_DIR
 = 
osp
 . 
join
 ( 
__C
 . 
ROOT_DIR
 , 'data' )

96 
__C
 . 
RAW_DATA_SETS_DIR
 = 
osp
 . 
join
 ( 
__C
 . 
DATA_SETS_DIR
 , 'raw' , 
__C
 . 
DATA_SETS_TYPE
 )

97 
__C
 . 
PREPROCESSED_DATA_SETS_DIR
 = 
osp
 . 
join
 ( 
__C
 . 
DATA_SETS_DIR
 , 'preprocessed' , 
__C
 . 
DATA_SETS_TYPE
 )

98 
__C
 . 
PREPROCESSING_DATA_SETS_DIR
 = 
osp
 . 
join
 ( 
__C
 . 
DATA_SETS_DIR
 , 'preprocessing' , 
__C
 . 
DATA_SETS_TYPE
 )

99 
__C
 . 
PREDICTED_XML_DIR
 = 
osp
 . 
join
 ( 
__C
 . 
DATA_SETS_DIR
 , 'predicted' , 
__C
 . 
DATA_SETS_TYPE
 )

101 
__C
 . 
CHECKPOINT_DIR
 = 
osp
 . 
join
 ( 
__C
 . 
ROOT_DIR
 , 'checkpoint' )

102 
__C
 . 
LOG_DIR
 = 
osp
 . 
join
 ( 
__C
 . 
ROOT_DIR
 , 'log' )

104 
__C
 . 
USE_RESNET_AS_TOP_BASENET
 = True

105 
__C
 . 
USE_RESNET_AS_FRONT_BASENET
 = True

107 
__C
 . 
IMAGE_FUSION_DISABLE
 = False

108 
__C
 . 
RGB_BASENET
 = 'resnet'

109 if 
__C
 . 
RGB_BASENET
 == 'xception' :

110 
__C
 . 
USE_IMAGENET_PRE_TRAINED_MODEL
 = True

112 
__C
 . 
USE_IMAGENET_PRE_TRAINED_MODEL
 = False

114 
__C
 . 
TRACKLET_GTBOX_LENGTH_SCALE
 = 1.6

117 if 
__C
 . 
DATA_SETS_TYPE
 == 'didi' or 
__C
 . 
DATA_SETS_TYPE
 == 'test' :

118 
__C
 . 
IMAGE_CROP_LEFT
 = 0

119 
__C
 . 
IMAGE_CROP_RIGHT
 = 0

120 
__C
 . 
IMAGE_CROP_TOP
 = 400

121 
__C
 . 
IMAGE_CROP_BOTTOM
 = 100

122 elif 
__C
 . 
DATA_SETS_TYPE
 == 'didi2' :

123 
__C
 . 
IMAGE_CROP_LEFT
 = 0

124 
__C
 . 
IMAGE_CROP_RIGHT
 = 0

125 
__C
 . 
IMAGE_CROP_TOP
 = 400

126 
__C
 . 
IMAGE_CROP_BOTTOM
 = 100

128 
__C
 . 
IMAGE_CROP_LEFT
 = 0

129 
__C
 . 
IMAGE_CROP_RIGHT
 = 0

130 
__C
 . 
IMAGE_CROP_TOP
 = 0

131 
__C
 . 
IMAGE_CROP_BOTTOM
 = 0

134 if 
__C
 . 
DATA_SETS_TYPE
 == 'test' :

135 
__C
 . 
IMAGE_HEIGHT
 = 1096

136 
__C
 . 
IMAGE_WIDTH
 = 1368

137 elif 
__C
 . 
DATA_SETS_TYPE
 == 'didi' or 
__C
 . 
DATA_SETS_TYPE
 == 'didi2' :

138 
__C
 . 
IMAGE_HEIGHT
 = 1096

139 
__C
 . 
IMAGE_WIDTH
 = 1368

140 elif 
__C
 . 
DATA_SETS_TYPE
 == 'kitti' :

141 
__C
 . 
IMAGE_WIDTH
 = 1242

142 
__C
 . 
IMAGE_HEIGHT
 = 375

146 if 
__C
 . 
DATA_SETS_TYPE
 == 'didi' or 
__C
 . 
DATA_SETS_TYPE
 == 'test' :

147 
TOP_Y_MIN
 = - 10

148 
TOP_Y_MAX
 = + 10

149 
TOP_X_MIN
 = - 45

150 
TOP_X_MAX
 = 45

151 
TOP_Z_MIN
 = - 3.0

152 
TOP_Z_MAX
 = 0.7

154 
TOP_X_DIVISION
 = 0.2

155 
TOP_Y_DIVISION
 = 0.2

156 
TOP_Z_DIVISION
 = 0.3

157 elif 
__C
 . 
DATA_SETS_TYPE
 == 'didi2' :

158 
TOP_Y_MIN
 = - 30

159 
TOP_Y_MAX
 = 30

160 
TOP_X_MIN
 = - 50

161 
TOP_X_MAX
 = 50

162 
TOP_Z_MIN
 = - 3.5

163 
TOP_Z_MAX
 = 0.6

165 
TOP_X_DIVISION
 = 0.2

166 
TOP_Y_DIVISION
 = 0.2

167 
TOP_Z_DIVISION
 = 0.3

168 elif 
__C
 . 
DATA_SETS_TYPE
 == 'kitti' :

169 
TOP_Y_MIN
 = - 30

170 
TOP_Y_MAX
 = + 30

171 
TOP_X_MIN
 = 0

172 
TOP_X_MAX
 = 80

173 
TOP_Z_MIN
 = - 4.2

174 
TOP_Z_MAX
 = 0.8

176 
TOP_X_DIVISION
 = 0.1

177 
TOP_Y_DIVISION
 = 0.1

178 
TOP_Z_DIVISION
 = 0.2

180 raise 
ValueError
 ( 'unexpected type in cfg.DATA_SETS_TYPE item: {}!' . 
format
 ( 
__C
 . 
DATA_SETS_TYPE
 ) )

183 if 
__C
 . 
DATA_SETS_TYPE
 == 'kitti' :

184 
__C
 . 
MATRIX_Mt
 = ( [ [ 2.34773698e-04 , 1.04494074e-02 , 9.99945389e-01 , 0.00000000e+00 ] ,

189 
__C
 . 
MATRIX_Kt
 = ( [ [ 721.5377 , 0. , 0. ] ,

193 
__C
 . 
MATRIX_T_VELO_2_CAM
 = ( [

199 
__C
 . 
MATRIX_R_RECT_0
 = ( [

207 
__C
 . 
TRAINING_TIMER
 = True

208 
__C
 . 
TRACKING_TIMER
 = True

209 
__C
 . 
DATAPY_TIMER
 = False

215 
__C
 . 
USE_CLIDAR_TO_TOP
 = False

217 def 
	$_merge_a_into_b
 ( 
a
 , 
b
 ) :

221 if 
type
 ( 
a
 ) is not 
edict
 :

224 for 
k
 , 
v
 in 
a
 . 
iteritems
 ( ) :

226 if not 
b
 . 
has_key
 ( 
k
 ) :

227 raise 
KeyError
 ( '{} is not a valid config key' . 
format
 ( 
k
 ) )

230 
old_type
 = 
type
 ( 
b
 [ 
k
 ] )

231 if 
old_type
 is not 
type
 ( 
v
 ) :

232 if 
isinstance
 ( 
b
 [ 
k
 ] , 
np
 . 
ndarray
 ) :

233 
v
 = 
np
 . 
array
 ( 
v
 , 
dtype
 = 
b
 [ 
k
 ] . 
dtype
 )

235 raise 
ValueError
 ( ( 'Type mismatch ({} vs. {}) ' 'for config key: {}'

236 ) . 
format
 ( 
type
 ( 
b
 [ 
k
 ] ) ,

237 
type
 ( 
v
 ) , 
k
 ) )

240 if 
type
 ( 
v
 ) is 
edict
 :

242 
_merge_a_into_b
 ( 
a
 [ 
k
 ] , 
b
 [ 
k
 ] )

244 
print
 ( 'Error under config key: {}' . 
format
 ( 
k
 ) )

247 
b
 [ 
k
 ] = 
v
 
	}

249 def 
	$cfg_from_file
 ( 
filename
 ) :

251 import 
	~yaml

252 with 
open
 ( 
filename
 , 'r' ) as 
f
 :

253 
yaml_cfg
 = 
edict
 ( 
yaml
 . 
load
 ( 
f
 ) )

255 
_merge_a_into_b
 ( 
yaml_cfg
 , 
__C
 ) 
	}

257 def 
	$cfg_from_list
 ( 
cfg_list
 ) :

259 from 
	~ast
 import 
literal_eval

260 assert 
len
 ( 
cfg_list
 ) % 2 == 0

261 for 
k
 , 
v
 in 
zip
 ( 
cfg_list
 [ 0 : : 2 ] , 
cfg_list
 [ 1 : : 2 ] ) :

262 
key_list
 = 
k
 . 
split
 ( '.' )

263 
d
 = 
__C

264 for 
subkey
 in 
key_list
 [ : - 1 ] :

265 assert 
d
 . 
has_key
 ( 
subkey
 )

266 
d
 = 
d
 [ 
subkey
 ]

267 
subkey
 = 
key_list
 [ - 1 ]

268 assert 
d
 . 
has_key
 ( 
subkey
 )

270 
value
 = 
literal_eval
 ( 
v
 )

273 
value
 = 
v

274 assert 
type
 ( 
value
 ) == 
type
 ( 
d
 [ 
subkey
 ] ) , 'type {} does not match original type {}'

275 . 
format
 (

276 
type
 ( 
value
 ) , 
type
 ( 
d
 [ 
subkey
 ] ) )

277 
d
 [ 
subkey
 ] = 
value
 
	}

279 if 
__name__
 == '__main__' :

280 
print
 ( '__C.ROOT_DIR = ' + 
__C
 . 
ROOT_DIR
 )

281 
print
 ( '__C.DATA_SETS_DIR = ' + 
__C
 . 
DATA_SETS_DIR
 )

282 
print
 ( '__C.RAW_DATA_SETS_DIR = ' + 
__C
 . 
RAW_DATA_SETS_DIR
 )


	@./test/test.py

1 import 
	~numpy
 as 
np

2 import 
	~matplotlib

3 
matplotlib
 . 
use
 ( 'TkAgg' )

4 import 
	~cv2

5 import 
	~matplotlib.pyplot
 as 
plt

6 from 
	~mpl_toolkits.mplot3d
 import 
Axes3D

7 from 
	~net.common
 import 
MATRIX_Mt
 , 
MATRIX_Kt

8 import 
	~net.processing.boxes3d
 as 
box3d

11 
data_dir
 = '/Users/zengxuefeng/Development/MV3D/src/test/'

13 def 
	$box3d_to_rgb_projections
 ( 
boxes3d
 , 
Mt
 = None , 
Kt
 = None ) :

15 if 
Mt
 is None : 
Mt
 = 
np
 . 
array
 ( 
MATRIX_Mt
 )

16 if 
Kt
 is None : 
Kt
 = 
np
 . 
array
 ( 
MATRIX_Kt
 )

18 
num
 = 
len
 ( 
boxes3d
 )

19 
projections
 = 
np
 . 
zeros
 ( ( 
num
 , 8 , 2 ) , 
dtype
 = 
np
 . 
int32
 )

20 for 
n
 in 
range
 ( 
num
 ) :

22 
box3d
 = 
boxes3d
 [ 
n
 ]

23 
Ps
 = 
np
 . 
hstack
 ( ( 
box3d
 , 
np
 . 
ones
 ( ( 8 , 1 ) ) ) )

24 
Qs
 = 
np
 . 
matmul
 ( 
Ps
 , 
Mt
 )

25 
Qs
 = 
Qs
 [ : , 0 : 3 ]

26 
qs
 = 
np
 . 
matmul
 ( 
Qs
 , 
Kt
 )

27 
zs
 = 
qs
 [ : , 2 ] . 
reshape
 ( 8 , 1 )

28 
qs
 = ( 
qs
 / 
zs
 )

29 
projections
 [ 
n
 ] = 
qs
 [ : , 0 : 2 ]

31 
_Kt
 = ( [ [ 200 , 0. , 0. ] ,

34 
Kt
 = 
np
 . 
array
 ( 
_Kt
 )

35 
box3d
 = 
boxes3d
 [ 
n
 ] . 
copy
 ( )

36 
box3d
 [ : , 0 ] , 
box3d
 [ : , 1 ] , 
box3d
 [ : , 2 ] = 
box3d
 [ : , 1 ] , 
box3d
 [ : , 2 ] , 
box3d
 [ : , 0 ]

37 
Qs
 = 
box3d

38 
qs
 = 
np
 . 
matmul
 ( 
Qs
 , 
Kt
 )

39 
zs
 = 
qs
 [ : , 2 ] . 
reshape
 ( 8 , 1 )

40 
qs
 = ( 
qs
 / 
zs
 )

41 
projections
 [ 
n
 ] = 
qs
 [ : , 0 : 2 ]

42 
print
 ( 
projections
 )

43 return 
projections
 
	}

45 def 
	$draw_boxed3d_to_rgb
 ( 
rgb
 , 
boxes3d
 ) :

46 
projections
 = 
box3d_to_rgb_projections
 ( 
boxes3d
 )

47 
rgb
 = 
box3d
 . 
draw_rgb_projections
 ( 
rgb
 , 
projections
 , 
color
 = ( 255 , 0 , 255 ) , 
thickness
 = 1 )

48 return 
rgb
 
	}

50 def 
	$loadnpy
 ( 
name
 ) :

51 
path
 = 
data_dir
 + 
name

52 
box3d
 = 
np
 . 
load
 ( 
path
 )

54 
print
 ( '{} shape = {}' . 
format
 ( 
name
 , 
box3d
 . 
shape
 ) )

56 return 
box3d
 
	}

58 def 
	$plotBox3d
 ( 
box
 ) :

59 
print
 ( 
box
 . 
shape
 )

60 
fig
 = 
plt
 . 
figure
 ( )

61 
ax
 = 
fig
 . 
add_subplot
 ( 111 , 
projection
 = '3d' )

62 
ax
 . 
scatter
 ( 
box
 [ : , 0 ] , 
box
 [ : , 1 ] , 
box
 [ : , 2 ] )

63 
plt
 . 
axis
 ( 'equal' )

70 
plt
 . 
show
 ( ) 
	}

72 def 
	$main
 ( ) :

73 
boxs
 = 
loadnpy
 ( '2011_09_26_0005_00110.npy' )

74 
len
 ( 
boxs
 )

77 
img
 = 
cv2
 . 
imread
 ( 
data_dir
 + '2011_09_26_0005_00110.png' )

78 
print
 ( 
boxs
 [ 1 : 2 , : , : ] )

79 
img_b
 = 
draw_boxed3d_to_rgb
 ( 
img
 , 
boxs
 [ : , : , : ] )

81 
cv2
 . 
imshow
 ( 'img_b' , 
img_b
 )

82 
cv2
 . 
waitKey
 ( ) 
	}

85 if 
__name__
 == '__main__' :

86 
main
 ( )


	@./test/show_lidar.py

1 import 
	~os

2 
os
 . 
environ
 [ 'HOME' ] = '/root'

4 
SEED
 = 202

8 import 
	~glob

12 import 
	~math

13 import 
	~random

14 import 
	~numpy
 as 
np

15 
random
 . 
seed
 ( 
SEED
 )

16 
np
 . 
random
 . 
seed
 ( 
SEED
 )

18 import 
	~cv2

19 import 
	~mayavi.mlab
 as 
mlab

33 
MM_TOP_VIEW
 = 180 , 0 , 120 , [ 0 , 0 , 0 ]

34 
MM_PER_VIEW1
 = 120 , 30 , 70 , [ 0 , 0 , 0 ]

35 
MM_PER_VIEW2
 = 30 , 45 , 100 , [ 0 , 0 , 0 ]

36 
MM_PER_VIEW3
 = 120 , 30 , 100 , [ 0 , 0 , 0 ]

43 def 
	$draw_shadow_text
 ( 
img
 , 
text
 , 
pt
 , 
fontScale
 , 
color
 , 
thickness
 , 
color1
 = None , 
thickness1
 = None ) :

45 if 
color1
 is None : 
color1
 = ( 0 , 0 , 0 )

46 if 
thickness1
 is None : 
thickness1
 = 
thickness
 + 2

48 
font
 = 
cv2
 . 
FONT_HERSHEY_SIMPLEX

49 
cv2
 . 
putText
 ( 
img
 , 
text
 , 
pt
 , 
font
 , 
fontScale
 , 
color1
 , 
thickness1
 , 
cv2
 . 
LINE_AA
 )

50 
cv2
 . 
putText
 ( 
img
 , 
text
 , 
pt
 , 
font
 , 
fontScale
 , 
color
 , 
thickness
 , 
cv2
 . 
LINE_AA
 ) 
	}

52 def 
	$imshow
 ( 
name
 , 
image
 , 
resize
 = 1 ) :

53 
H
 , 
W
 = 
image
 . 
shape
 [ 0 : 2 ]

54 
cv2
 . 
namedWindow
 ( 
name
 , 
cv2
 . 
WINDOW_NORMAL
 )

55 
cv2
 . 
imshow
 ( 
name
 , 
image
 . 
astype
 ( 
np
 . 
uint8
 ) )

56 
cv2
 . 
resizeWindow
 ( 
name
 , 
round
 ( 
resize
 * 
W
 ) , 
round
 ( 
resize
 * 
H
 ) ) 
	}

59 def 
	$draw_didi_lidar
 ( 
fig
 , 
lidar
 , 
is_grid
 = 1 , 
is_axis
 = 1 ) :

61 
pxs
 = 
lidar
 [ : , 0 ]

62 
pys
 = 
lidar
 [ : , 1 ]

63 
pzs
 = 
lidar
 [ : , 2 ]

64 
prs
 = 
lidar
 [ : , 3 ]

66 
prs
 = 
np
 . 
clip
 ( 
prs
 / 15 , 0 , 1 )

69 if 
is_grid
 :

70 
L
 = 25

71 
dL
 = 5

72 
Z
 = - 2

73 
mlab
 . 
points3d
 ( 0 , 0 , 0 , 
color
 = ( 1 , 1 , 1 ) , 
mode
 = 'sphere' , 
scale_factor
 = 0.2 )

75 for 
y
 in 
np
 . 
arange
 ( - 
L
 , 
L
 + 1 , 
dL
 ) :

76 
x1
 , 
y1
 , 
z1
 = - 
L
 , 
y
 , 
Z

77 
x2
 , 
y2
 , 
z2
 = 
L
 , 
y
 , 
Z

78 
mlab
 . 
plot3d
 ( [ 
x1
 , 
x2
 ] , [ 
y1
 , 
y2
 ] , [ 
z1
 , 
z2
 ] , 
color
 = ( 0.3 , 0.3 , 0.3 ) , 
tube_radius
 = None , 
line_width
 = 1 , 
figure
 = 
fig
 )

80 for 
x
 in 
np
 . 
arange
 ( - 
L
 , 
L
 + 1 , 
dL
 ) :

81 
x1
 , 
y1
 , 
z1
 = 
x
 , - 
L
 , 
Z

82 
x2
 , 
y2
 , 
z2
 = 
x
 , 
L
 , 
Z

83 
mlab
 . 
plot3d
 ( [ 
x1
 , 
x2
 ] , [ 
y1
 , 
y2
 ] , [ 
z1
 , 
z2
 ] , 
color
 = ( 0.3 , 0.3 , 0.3 ) , 
tube_radius
 = None , 
line_width
 = 1 , 
figure
 = 
fig
 )

86 if 
is_axis
 :

87 
axes
 = 
np
 . 
array
 ( [

91 ] , 
dtype
 = 
np
 . 
float64
 )

93 
mlab
 . 
points3d
 ( 0 , 0 , 0 , 
color
 = ( 1 , 1 , 1 ) , 
mode
 = 'sphere' , 
scale_factor
 = 0.2 )

94 
mlab
 . 
plot3d
 ( [ 0 , 
axes
 [ 0 , 0 ] ] , [ 0 , 
axes
 [ 0 , 1 ] ] , [ 0 , 
axes
 [ 0 , 2 ] ] , 
color
 = ( 1 , 0 , 0 ) , 
tube_radius
 = None , 
line_width
 = 2 , 
figure
 = 
fig
 )

95 
mlab
 . 
plot3d
 ( [ 0 , 
axes
 [ 1 , 0 ] ] , [ 0 , 
axes
 [ 1 , 1 ] ] , [ 0 , 
axes
 [ 1 , 2 ] ] , 
color
 = ( 0 , 1 , 0 ) , 
tube_radius
 = None , 
line_width
 = 2 , 
figure
 = 
fig
 )

96 
mlab
 . 
plot3d
 ( [ 0 , 
axes
 [ 2 , 0 ] ] , [ 0 , 
axes
 [ 2 , 1 ] ] , [ 0 , 
axes
 [ 2 , 2 ] ] , 
color
 = ( 0 , 0 , 1 ) , 
tube_radius
 = None , 
line_width
 = 2 , 
figure
 = 
fig
 )

99 
mlab
 . 
points3d
 (

100 
pxs
 , 
pys
 , 
pzs
 , 
prs
 ,

101 
mode
 = 'point' ,

105 
scale_factor
 = 1 ,

106 
figure
 = 
fig
 ) 
	}

116 def 
	$draw_didi_boxes3d
 ( 
fig
 , 
boxes3d
 , 
is_number
 = False , 
color
 = ( 1 , 1 , 1 ) , 
line_width
 = 1 ) :

118 if 
boxes3d
 . 
shape
 == ( 8 , 3 ) : 
boxes3d
 = 
boxes3d
 . 
reshape
 ( 1 , 8 , 3 )

120 
num
 = 
len
 ( 
boxes3d
 )

121 for 
n
 in 
range
 ( 
num
 ) :

122 
b
 = 
boxes3d
 [ 
n
 ]

124 if 
is_number
 :

125 
mlab
 . 
text3d
 ( 
b
 [ 0 , 0 ] , 
b
 [ 0 , 1 ] , 
b
 [ 0 , 2 ] , '%d' % 
n
 , 
scale
 = ( 1 , 1 , 1 ) , 
color
 = 
color
 , 
figure
 = 
fig
 )

126 for 
k
 in 
range
 ( 0 , 4 ) :

129 
i
 , 
j
 = 
k
 , ( 
k
 + 1 ) % 4

130 
mlab
 . 
plot3d
 ( [ 
b
 [ 
i
 , 0 ] , 
b
 [ 
j
 , 0 ] ] , [ 
b
 [ 
i
 , 1 ] , 
b
 [ 
j
 , 1 ] ] , [ 
b
 [ 
i
 , 2 ] , 
b
 [ 
j
 , 2 ] ] , 
color
 = 
color
 , 
tube_radius
 = None , 
line_width
 = 
line_width
 , 
figure
 = 
fig
 )

132 
i
 , 
j
 = 
k
 + 4 , ( 
k
 + 1 ) % 4 + 4

133 
mlab
 . 
plot3d
 ( [ 
b
 [ 
i
 , 0 ] , 
b
 [ 
j
 , 0 ] ] , [ 
b
 [ 
i
 , 1 ] , 
b
 [ 
j
 , 1 ] ] , [ 
b
 [ 
i
 , 2 ] , 
b
 [ 
j
 , 2 ] ] , 
color
 = 
color
 , 
tube_radius
 = None , 
line_width
 = 
line_width
 , 
figure
 = 
fig
 )

135 
i
 , 
j
 = 
k
 , 
k
 + 4

136 
mlab
 . 
plot3d
 ( [ 
b
 [ 
i
 , 0 ] , 
b
 [ 
j
 , 0 ] ] , [ 
b
 [ 
i
 , 1 ] , 
b
 [ 
j
 , 1 ] ] , [ 
b
 [ 
i
 , 2 ] , 
b
 [ 
j
 , 2 ] ] , 
color
 = 
color
 , 
tube_radius
 = None , 
line_width
 = 
line_width
 , 
figure
 = 
fig
 ) 
	}

141 def 
	$dir_to_avi
 ( 
avi_file
 , 
png_dir
 ) :

143 
tmp_dir
 = '~temp_png'

144 
os
 . 
makedirs
 ( 
tmp_dir
 , 
exist_ok
 = True )

146 for 
i
 , 
file
 in 
enumerate
 ( 
sorted
 ( 
glob
 . 
glob
 ( 
png_dir
 + '/*.png' ) ) ) :

147 
name
 = 
os
 . 
path
 . 
basename
 ( 
file
 ) . 
replace
 ( '.png' , '' )

150 
png_file
 = 
png_dir
 + '/' + 
name
 + '.png'

151 
tmp_file
 = 
tmp_dir
 + '/%06d.png' % 
i

152 
img
 = 
cv2
 . 
imread
 ( 
png_file
 , 1 )

153 
draw_shadow_text
 ( 
img
 , 'timestamp=' + 
name
 . 
replace
 ( '_' , ':' ) , ( 5 , 20 ) , 0.5 , ( 225 , 225 , 225 ) , 1 )

154 
imshow
 ( 'img' , 
img
 )

155 
cv2
 . 
waitKey
 ( 1 )

156 
cv2
 . 
imwrite
 ( 
tmp_file
 , 
img
 )

159 
os
 . 
system
 ( 'ffmpeg -y -loglevel 0 -f image2 -r 15 -i %s/%%06d.png -b:v 8000k %s' % ( 
tmp_dir
 , 
avi_file
 ) )

160 
os
 . 
system
 ( 'rm -rf %s' % 
tmp_dir
 ) 
	}

166 def 
	$mark_gt_box3d
 ( 
lidar_dir
 , 
gt_boxes3d_dir
 , 
mark_dir
 ) :

168 
os
 . 
makedirs
 ( 
mark_dir
 , 
exist_ok
 = True )

169 
fig
 = 
mlab
 . 
figure
 ( 
figure
 = None , 
bgcolor
 = ( 0 , 0 , 0 ) , 
fgcolor
 = None , 
engine
 = None , 
size
 = ( 500 , 500 ) )

170 
dummy
 = 
np
 . 
zeros
 ( ( 10 , 10 , 3 ) , 
dtype
 = 
np
 . 
uint8
 )

172 for 
file
 in 
sorted
 ( 
glob
 . 
glob
 ( 
lidar_dir
 + '/*.npy' ) ) :

173 
name
 = 
os
 . 
path
 . 
basename
 ( 
file
 ) . 
replace
 ( '.npy' , '' )

175 
lidar_file
 = 
lidar_dir
 + '/' + 
name
 + '.npy'

176 
boxes3d_file
 = 
gt_boxes3d_dir
 + '/' + 
name
 + '.npy'

177 
lidar
 = 
np
 . 
load
 ( 
lidar_file
 )

178 
boxes3d
 = 
np
 . 
load
 ( 
boxes3d_file
 )

180 
mlab
 . 
clf
 ( 
fig
 )

181 
draw_didi_lidar
 ( 
fig
 , 
lidar
 , 
is_grid
 = 1 , 
is_axis
 = 1 )

182 if 
len
 ( 
boxes3d
 ) != 0 :

183 
draw_didi_boxes3d
 ( 
fig
 , 
boxes3d
 )

185 
azimuth
 , 
elevation
 , 
distance
 , 
focalpoint
 = 
MM_PER_VIEW1

186 
mlab
 . 
view
 ( 
azimuth
 , 
elevation
 , 
distance
 , 
focalpoint
 )

187 
mlab
 . 
show
 ( 1 )

188 
imshow
 ( 'dummy' , 
dummy
 )

189 
cv2
 . 
waitKey
 ( 1 )

191 
mlab
 . 
savefig
 ( 
mark_dir
 + '/' + 
name
 + '.png' , 
figure
 = 
fig
 ) 
	}

199 if 
__name__
 == '__main__' :

200 
print
 ( '%s: calling main function ... ' % 
os
 . 
path
 . 
basename
 ( 
__file__
 ) )

202 
lidar_dir
 = '/root/share/project/didi/data/didi/didi-2/Out/1/15/lidar'

203 
gt_boxes3d_dir
 = '/root/share/project/didi/data/didi/didi-2/Out/1/15/processed/gt_boxes3d'

204 
mark_dir
 = '/root/share/project/didi/data/didi/didi-2/Out/1/15/processed/mark-gt-box3d'

205 
avi_file
 = '/root/share/project/didi/data/didi/didi-2/Out/1/15/processed/mark-gt-box3d.avi'

207 
mark_gt_box3d
 ( 
lidar_dir
 , 
gt_boxes3d_dir
 , 
mark_dir
 )

208 
dir_to_avi
 ( 
avi_file
 , 
mark_dir
 )


	@./test/load_lidar_binary.py

1 import 
	~numpy
 as 
np

2 import 
	~cv2

4 from 
	~kitti_data.pykitti
 import 
utils

5 from 
	~config
 import 
cfg

7 import 
	~data

11 
TOP_Y_MIN
 = - 20

12 
TOP_Y_MAX
 = + 20

13 
TOP_X_MIN
 = 0

14 
TOP_X_MAX
 = 40

15 
TOP_Z_MIN
 = - 2.0

16 
TOP_Z_MAX
 = 0.4

19 
TOP_X_DIVISION
 = 0.1

20 
TOP_Y_DIVISION
 = 0.1

21 
TOP_Z_DIVISION
 = 0.4

24 def 
	$lidar_to_top
 ( 
lidar
 ) :

26 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 0 ] > 
TOP_X_MIN
 )

27 
lidar
 = 
lidar
 [ 
idx
 ]

28 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 0 ] < 
TOP_X_MAX
 )

29 
lidar
 = 
lidar
 [ 
idx
 ]

31 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 1 ] > 
TOP_Y_MIN
 )

32 
lidar
 = 
lidar
 [ 
idx
 ]

33 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 1 ] < 
TOP_Y_MAX
 )

34 
lidar
 = 
lidar
 [ 
idx
 ]

36 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 2 ] > 
TOP_Z_MIN
 )

37 
lidar
 = 
lidar
 [ 
idx
 ]

38 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 2 ] < 
TOP_Z_MAX
 )

39 
lidar
 = 
lidar
 [ 
idx
 ]

42 
pxs
 = 
lidar
 [ : , 0 ]

43 
pys
 = 
lidar
 [ : , 1 ]

44 
pzs
 = 
lidar
 [ : , 2 ]

45 
prs
 = 
lidar
 [ : , 3 ]

46 
qxs
 = ( ( 
pxs
 - 
TOP_X_MIN
 ) // 
TOP_X_DIVISION
 ) . 
astype
 ( 
np
 . 
int32
 )

47 
qys
 = ( ( 
pys
 - 
TOP_Y_MIN
 ) // 
TOP_Y_DIVISION
 ) . 
astype
 ( 
np
 . 
int32
 )

48 
qzs
 = ( ( 
pzs
 - 
TOP_Z_MIN
 ) // 
TOP_Z_DIVISION
 ) . 
astype
 ( 
np
 . 
int32
 )

49 
quantized
 = 
np
 . 
dstack
 ( ( 
qxs
 , 
qys
 , 
qzs
 , 
prs
 ) ) . 
squeeze
 ( )

51 
X0
 , 
Xn
 = 0 , 
int
 ( ( 
TOP_X_MAX
 - 
TOP_X_MIN
 ) // 
TOP_X_DIVISION
 ) + 1

52 
Y0
 , 
Yn
 = 0 , 
int
 ( ( 
TOP_Y_MAX
 - 
TOP_Y_MIN
 ) // 
TOP_Y_DIVISION
 ) + 1

53 
Z0
 , 
Zn
 = 0 , 
int
 ( ( 
TOP_Z_MAX
 - 
TOP_Z_MIN
 ) // 
TOP_Z_DIVISION
 ) + 1

54 
height
 = 
Yn
 - 
Y0

55 
width
 = 
Xn
 - 
X0

56 
channel
 = 
Zn
 - 
Z0
 + 2

57 
print
 ( 'height,width,channel=%d,%d,%d' % ( 
height
 , 
width
 , 
channel
 ) )

58 
top
 = 
np
 . 
zeros
 ( 
shape
 = ( 
height
 , 
width
 , 
channel
 ) , 
dtype
 = 
np
 . 
float32
 )

65 for 
z
 in 
range
 ( 
Zn
 ) :

66 
iz
 = 
np
 . 
where
 ( 
quantized
 [ : , 2 ] == 
z
 )

67 
quantized_z
 = 
quantized
 [ 
iz
 ]

69 for 
y
 in 
range
 ( 
Yn
 ) :

70 
iy
 = 
np
 . 
where
 ( 
quantized_z
 [ : , 1 ] == 
y
 )

71 
quantized_zy
 = 
quantized_z
 [ 
iy
 ]

73 for 
x
 in 
range
 ( 
Xn
 ) :

74 
ix
 = 
np
 . 
where
 ( 
quantized_zy
 [ : , 0 ] == 
x
 )

75 
quantized_zyx
 = 
quantized_zy
 [ 
ix
 ]

76 if 
len
 ( 
quantized_zyx
 ) > 0 :

77 
yy
 , 
xx
 , 
zz
 = - 
x
 , - 
y
 , 
z

80 
max_height
 = 
max
 ( 0 , 
np
 . 
max
 ( 
quantized_zyx
 [ : , 2 ] ) - 
TOP_Z_MIN
 )

81 
top
 [ 
yy
 , 
xx
 , 
zz
 ] = 
max_height

84 
max_intensity
 = 
np
 . 
max
 ( 
quantized_zyx
 [ : , 3 ] )

85 
top
 [ 
yy
 , 
xx
 , 
Zn
 ] = 
max_intensity

88 
count
 = 
len
 ( 
idx
 )

89 
top
 [ 
yy
 , 
xx
 , 
Zn
 + 1 ] += 
count

95 
top
 [ : , : , 
Zn
 + 1 ] = 
np
 . 
log
 ( 
top
 [ : , : , 
Zn
 + 1 ] + 1 ) / 
math
 . 
log
 ( 64 )

98 
top_image
 = 
np
 . 
sum
 ( 
top
 , 
axis
 = 2 )

99 
top_image
 = 
top_image
 - 
np
 . 
min
 ( 
top_image
 )

100 
top_image
 = ( 
top_image
 / 
np
 . 
max
 ( 
top_image
 ) * 255 )

101 
top_image
 = 
np
 . 
dstack
 ( ( 
top_image
 , 
top_image
 , 
top_image
 ) ) . 
astype
 ( 
np
 . 
uint8
 )

105 
top_image
 = 
np
 . 
zeros
 ( ( 
height
 , 
width
 , 3 ) , 
dtype
 = 
np
 . 
float32
 )

107 
num
 = 
len
 ( 
lidar
 )

108 for 
n
 in 
range
 ( 
num
 ) :

109 
x
 , 
y
 = 
qxs
 [ 
n
 ] , 
qys
 [ 
n
 ]

110 if 
x
 >= 0 and 
x
 < 
width
 and 
y
 > 0 and 
y
 < 
height
 :

111 
top_image
 [ 
y
 , 
x
 , : ] += 1

113 
max_value
 = 
np
 . 
max
 ( 
np
 . 
log
 ( 
top_image
 + 0.001 ) )

114 
top_image
 = 
top_image
 / 
max_value
 * 255

115 
top_image
 = 
top_image
 . 
astype
 ( 
dtype
 = 
np
 . 
uint8
 )

118 return 
top
 , 
top_image
 
	}

121 import 
	~matplotlib

122 
matplotlib
 . 
use
 ( 'TkAgg' )

123 import 
	~matplotlib.pyplot
 as 
plt

124 from 
	~mpl_toolkits.mplot3d
 import 
Axes3D

125 def 
	$plot_lidar
 ( 
lidar
 ) :

126 
print
 ( 
lidar
 . 
shape
 )

127 
fig
 = 
plt
 . 
figure
 ( )

128 
ax
 = 
fig
 . 
add_subplot
 ( 111 , 
projection
 = '3d' )

129 for 
i
 in 
range
 ( 
len
 ( 
lidar
 ) ) :

130 
ax
 . 
scatter
 ( 
lidar
 [ 
i
 , 0 ] , 
lidar
 [ 
i
 , 1 ] , 
lidar
 [ 
i
 , 2 ] , 
s
 = 0.01 ,

131 
c
 = [ 0.5 , 0.5 , 0.5 ] )

132 
plt
 . 
axis
 ( 'equal' )

139 
plt
 . 
show
 ( )

142 
lidars
 = 
utils
 . 
load_velo_scans
 ( [ '30.bin' ] )

143 
intensity_max
 = 
np
 . 
max
 ( 
lidars
 [ 0 ] [ : , 3 ] )

145 
print
 ( 'shape: ' + 
str
 ( 
lidars
 [ 0 ] . 
shape
 ) + ' intensity max: ' + 
str
 ( 
intensity_max
 ) )

146 
plot_lidar
 ( 
lidars
 [ 0 ] )

147 
top
 , 
top_image
 = 
data
 . 
lidar_to_top
 ( 
lidars
 [ 0 ] )

148 
cv2
 . 
imwrite
 ( '30.png' , 
top_image
 ) 
	}

151 
top
 = 
np
 . 
load
 ( '1_t_15_00138.npy' )

153 
top_image
 = 
np
 . 
sum
 ( 
top
 , 
axis
 = 2 )

154 
top_image
 = 
top_image
 - 
np
 . 
min
 ( 
top_image
 )

155 
top_image
 = ( 
top_image
 / 
np
 . 
max
 ( 
top_image
 ) * 255 )

156 
top_image
 = 
np
 . 
dstack
 ( ( 
top_image
 , 
top_image
 , 
top_image
 ) ) . 
astype
 ( 
np
 . 
uint8
 )

157 
cv2
 . 
imwrite
 ( 'top_image_1.png' , 
top_image
 )

159 for 
i
 in 
range
 ( 8 ) :

160 
top_image
 = 
top
 [ : , : , 
i
 ]

161 
top_image
 = 
top_image
 - 
np
 . 
min
 ( 
top_image
 )

162 
top_image
 = ( 
top_image
 / 
np
 . 
max
 ( 
top_image
 ) * 255 )

163 
top_image
 = 
np
 . 
dstack
 ( ( 
top_image
 , 
top_image
 , 
top_image
 ) ) . 
astype
 ( 
np
 . 
uint8
 )

164 
cv2
 . 
imwrite
 ( 'top_image_{}.png' . 
format
 ( 
i
 ) , 
top_image
 )

167 import 
	~mayavi.mlab
 as 
mlab

169 from 
	~show_lidar
 import *

171 
lidars
 = 
utils
 . 
load_velo_scans
 ( [ 'kitti_005_0000000000.bin' ] )

172 
lidar
 = 
lidars
 [ 0 ]

173 
intensity_max
 = 
np
 . 
max
 ( 
lidars
 [ 0 ] [ : , 3 ] )

174 
fig
 = 
mlab
 . 
figure
 ( 
figure
 = None , 
bgcolor
 = ( 0 , 0 , 0 ) , 
fgcolor
 = None , 
engine
 = None , 
size
 = ( 500 , 500 ) )

175 
mlab
 . 
clf
 ( 
fig
 )

176 
draw_didi_lidar
 ( 
fig
 , 
lidar
 , 
is_grid
 = 1 , 
is_axis
 = 1 )

177 
mlab
 . 
show
 ( )


	@./mv3d.py

1 import 
	~os

2 import 
	~numpy
 as 
np

4 import 
	~tensorflow
 as 
tf

6 from 
	~sklearn.utils
 import 
shuffle

7 import 
	~glob

8 import 
	~net.utility.draw
 as 
nud

9 import 
	~mv3d_net

10 import 
	~net.blocks
 as 
blocks

11 import 
	~data

12 import 
	~net.processing.boxes3d
 as 
box

13 from 
	~net.rpn_target_op
 import 
make_bases
 , 
make_anchors
 , 
rpn_target

14 from 
	~net.rcnn_target_op
 import 
rcnn_target
 , 
fusion_target

15 from 
	~net.rpn_nms_op
 import 
draw_rpn_proposal

16 from 
	~net.rcnn_nms_op
 import 
rcnn_nms
 , 
draw_rcnn_nms
 , 
draw_rcnn
 , 
draw_box3d_on_image_with_gt
 , 
draw_fusion_target

17 from 
	~net.rpn_target_op
 import 
draw_rpn_gt
 , 
draw_rpn_targets
 , 
draw_rpn_labels

18 from 
	~net.rcnn_target_op
 import 
draw_rcnn_targets
 , 
draw_rcnn_labels

19 from 
	~net.utility.draw
 import 
draw_box3d_on_camera

20 from 
	~net.utility.remove_empty_box
 import 
remove_empty_anchor

21 import 
	~net.utility.file
 as 
utilfile

22 from 
	~config
 import 
cfg

23 import 
	~config

24 from 
	~net.processing.boxes
 import 
non_max_suppress

25 import 
	~utils.batch_loading
 as 
dataset

26 from 
	~utils.timer
 import 
timer

27 from 
	~keras
 import 
backend
 as 
K

28 from 
	~time
 import 
localtime
 , 
strftime

29 import 
	~cv2

30 import 
	~time

31 import 
	~io

32 import 
	~matplotlib.pyplot
 as 
plt

33 from 
	~tensorflow.python
 import 
debug
 as 
tf_debug

34 import 
	~pickle

35 import 
	~subprocess

36 import 
	~sys

37 import 
	~math

43 def 
	$kitti_roi3d_to_inner3d
 ( 
kitti_roi3d
 ) :

46 def 
kitti2inner3d
 ( 
kitti_roi
 ) :

47 
inner_roi
 = 
np
 . 
zeros
 ( ( 8 , 3 ) , 
dtype
 = 
np
 . 
float32
 )

48 
ry
 , 
l
 , 
h
 , 
w
 , 
x
 , 
y
 , 
z
 = 
kitti_roi

51 
rz
 , 
l
 , 
h
 , 
w
 , 
x
 , 
y
 , 
z
 = - 
ry
 , 
w
 , 
h
 , 
l
 , 
z
 , - 
x
 , - 
y

52 
inner_roi
 = 
box
 . 
box3d_compose
 ( ( 
x
 , 
y
 , 
z
 ) , ( 
h
 , 
w
 , 
l
 ) , ( 0 , 0 , 
rz
 ) )

53 return 
inner_roi

55 
rois3d
 = 
np
 . 
zeros
 ( ( 
len
 ( 
kitti_roi3d
 ) , 8 , 3 ) , 
dtype
 = 
np
 . 
float32
 )

56 for 
i
 in 
range
 ( 
len
 ( 
kitti_roi3d
 ) ) :

57 
rois3d
 [ 
i
 ] = 
kitti2inner3d
 ( 
kitti_roi3d
 [ 
i
 ] )

58 return 
rois3d
 
	}

60 def 
	$project_to_top_roi
 ( 
rois3d
 ) :

63 
boxes
 = 
box
 . 
box3d_to_top_box
 ( 
rois3d
 )

64 
batch_inds
 = 
np
 . 
zeros
 ( ( 
len
 ( 
boxes
 ) , 1 ) , 
dtype
 = 
np
 . 
float32
 )

65 
rois
 = 
np
 . 
hstack
 ( ( 
batch_inds
 , 
boxes
 ) )

66 return 
rois
 
	}

68 def 
	$get_top_feature_shape
 ( 
top_shape
 , 
stride
 ) :

69 return ( 
math
 . 
ceil
 ( 
top_shape
 [ 0 ] / 
stride
 ) , 
math
 . 
ceil
 ( 
top_shape
 [ 1 ] / 
stride
 ) ) 
	}

71 def 
	$project_to_roi3d
 ( 
top_rois
 ) :

72 
num
 = 
len
 ( 
top_rois
 )

73 
rois3d
 = 
box
 . 
top_box_to_box3d
 ( 
top_rois
 [ : , 1 : 5 ] )

74 return 
rois3d
 
	}

77 def 
	$project_to_rgb_roi
 ( 
rois3d
 ) :

78 
num
 = 
len
 ( 
rois3d
 )

79 
rois
 = 
np
 . 
zeros
 ( ( 
num
 , 5 ) , 
dtype
 = 
np
 . 
int32
 )

80 
projections
 = 
box
 . 
box3d_to_rgb_box
 ( 
rois3d
 )

81 for 
n
 in 
range
 ( 
num
 ) :

82 
qs
 = 
projections
 [ 
n
 ]

83 
minx
 = 
np
 . 
min
 ( 
qs
 [ : , 0 ] )

84 
maxx
 = 
np
 . 
max
 ( 
qs
 [ : , 0 ] )

85 
miny
 = 
np
 . 
min
 ( 
qs
 [ : , 1 ] )

86 
maxy
 = 
np
 . 
max
 ( 
qs
 [ : , 1 ] )

87 
rois
 [ 
n
 , 1 : 5 ] = 
minx
 , 
miny
 , 
maxx
 , 
maxy

89 return 
rois
 
	}

91 def 
	$project_to_front_roi
 ( 
rois3d
 ) :

93 def 
lidar_to_front
 ( 
point
 ) :

94 
ret
 = [

95 
int
 ( 
math
 . 
atan2
 ( 
point
 [ 1 ] , 
point
 [ 0 ] ) / 
cfg
 . 
VELODYNE_ANGULAR_RESOLUTION
 ) ,

96 
int
 ( 
math
 . 
atan2
 ( 
point
 [ 2 ] , 
math
 . 
sqrt
 ( 
point
 [ 0 ] ** 2 + 
point
 [ 1 ] ** 2 ) )

97 / 
cfg
 . 
VELODYNE_VERTICAL_RESOLUTION
 )

100 
ret
 [ 0 ] = ( 
ret
 [ 0 ] + 
cfg
 . 
FRONT_C_OFFSET
 ) / 2

101 
ret
 [ 1 ] = ( 
ret
 [ 1 ] + 
cfg
 . 
FRONT_R_OFFSET
 ) / 2

102 return 
tuple
 ( 
ret
 )

104 
boxes
 = 
np
 . 
zeros
 ( ( 
len
 ( 
rois3d
 ) , 4 ) , 
dtype
 = 
np
 . 
float32
 )

105 
batch_inds
 = 
np
 . 
zeros
 ( ( 
len
 ( 
rois3d
 ) , 1 ) , 
dtype
 = 
np
 . 
float32
 )

106 for 
index
 in 
range
 ( 
len
 ( 
rois3d
 ) ) :

107 
projection
 = 
np
 . 
array
 ( [ 
lidar_to_front
 ( 
cor
 ) for 
cor
 in 
rois3d
 [ 
index
 ] ] )

108 assert ( 
len
 ( 
projection
 ) == 8 )

109 
c_min
 , 
c_max
 = 
min
 ( 
projection
 [ : , 0 ] ) , 
max
 ( 
projection
 [ : , 0 ] )

110 
r_min
 , 
r_max
 = 
min
 ( 
projection
 [ : , 1 ] ) , 
max
 ( 
projection
 [ : , 1 ] )

111 
boxes
 [ 
index
 , : ] = 
np
 . 
array
 ( [ 
c_min
 , 
r_min
 , 
c_max
 , 
r_max
 ] )

113 
rois
 = 
np
 . 
hstack
 ( ( 
batch_inds
 , 
boxes
 ) )

114 return 
rois
 
	}

117 class 
	cNet
 ( 
object
 ) :

119 def 
	$__init__
 ( 
self
 , 
prefix
 , 
scope_name
 , 
checkpoint_dir
 = None ) :

120 
self
 . 
name
 = 
scope_name

121 
self
 . 
prefix
 = 
prefix

122 
self
 . 
checkpoint_dir
 = 
checkpoint_dir

123 
self
 . 
subnet_checkpoint_dir
 = 
os
 . 
path
 . 
join
 ( 
checkpoint_dir
 , 
scope_name
 )

124 
self
 . 
subnet_checkpoint_name
 = 
scope_name

125 
os
 . 
makedirs
 ( 
self
 . 
subnet_checkpoint_dir
 , 
exist_ok
 = True )

126 
self
 . 
variables
 = 
self
 . 
get_variables
 ( [ 
prefix
 + '/' + 
scope_name
 ] )

127 
self
 . 
saver
 = 
tf
 . 
train
 . 
Saver
 ( 
self
 . 
variables
 , 
max_to_keep
 = 0 ) 
	}

130 def 
	$save_weights
 ( 
self
 , 
sess
 = None , 
step
 = 0 ) :

131 
path
 = 
os
 . 
path
 . 
join
 ( 
self
 . 
subnet_checkpoint_dir
 , 
self
 . 
subnet_checkpoint_name
 )

132 
print
 ( 'Save weigths for {}: {}-{}' . 
format
 ( 
self
 . 
name
 , 
path
 , 
step
 ) )

133 
self
 . 
saver
 . 
save
 ( 
sess
 , 
path
 , 
global_step
 = 
step
 , 
write_meta_graph
 = True if 
step
 == 0 else False ) 
	}

135 def 
	$clean_weights
 ( 
self
 ) :

136 
command
 = 'rm -rf %s' % ( 
os
 . 
path
 . 
join
 ( 
self
 . 
subnet_checkpoint_dir
 ) )

137 
subprocess
 . 
call
 ( 
command
 , 
shell
 = True )

138 
print
 ( 'Clean weights: %s' % 
command
 )

139 
os
 . 
makedirs
 ( 
self
 . 
subnet_checkpoint_dir
 , 
exist_ok
 = True ) 
	}

142 def 
	$load_weights
 ( 
self
 , 
sess
 = None ) :

143 
path
 = 
os
 . 
path
 . 
join
 ( 
self
 . 
subnet_checkpoint_dir
 )

145 if 
tf
 . 
train
 . 
checkpoint_exists
 ( 
path
 ) == False or not 
os
 . 
path
 . 
exists
 ( 
os
 . 
path
 . 
join
 ( 
path
 , 'checkpoint' ) ) :

146 
print
 ( 'Load weights failed for {} at {}, cannot find specified weights, using default initialzied val instead' . 
format
 ( 
self
 . 
name
 , 
path
 ) )

150 assert 
tf
 . 
train
 . 
checkpoint_exists
 ( 
path
 ) == True

151 
self
 . 
saver
 . 
restore
 ( 
sess
 , 
tf
 . 
train
 . 
latest_checkpoint
 ( 
path
 ) )

152 
print
 ( "Load weights for {} success! : {}" . 
format
 ( 
self
 . 
name
 , 
tf
 . 
train
 . 
latest_checkpoint
 ( 
path
 ) ) ) 
	}

155 def 
	$get_variables
 ( 
self
 , 
scope_names
 ) :

156 
variables
 = [ ]

157 for 
scope
 in 
scope_names
 :

158 
variables
 = 
tf
 . 
get_collection
 ( 
tf
 . 
GraphKeys
 . 
GLOBAL_VARIABLES
 , 
scope
 = 
scope
 )

160 
variables
 += 
variables

161 return 
variables
 
	}

164 class 
	cMV3D
 ( 
object
 ) :

166 def 
	$__init__
 ( 
self
 , 
top_shape
 , 
front_shape
 , 
rgb_shape
 , 
debug_mode
 = False , 
log_tag
 = None , 
weigths_dir
 = None ) :

168 
print
 ( 'fuck 0.0!' )

170 
self
 . 
top_rpn_stride
 = None

172 
self
 . 
num_class
 = 2

174 
ratios
 = 
np
 . 
array
 ( [ 0.5 , 1 , 2 ] , 
dtype
 = 
np
 . 
float32
 )

175 
scales
 = 
np
 . 
array
 ( [ 1 , 2 , 3 ] , 
dtype
 = 
np
 . 
float32
 )

184 
self
 . 
bases
 = 
np
 . 
array
 ( [

192 
utilfile
 . 
makedirs
 ( 
cfg
 . 
CHECKPOINT_DIR
 )

193 
self
 . 
log_msg
 = 
utilfile
 . 
Logger
 ( 
cfg
 . 
LOG_DIR
 + '/log.txt' , 
mode
 = 'a' )

194 
self
 . 
track_log
 = 
utilfile
 . 
Logger
 ( 
cfg
 . 
LOG_DIR
 + '/tracking_log.txt' , 
mode
 = 'a' )

196 
self
 . 
gpu_options
 = 
tf
 . 
GPUOptions
 ( 
per_process_gpu_memory_fraction
 = 
cfg
 . 
GPU_MEMORY_FRACTION
 , 
visible_device_list
 = 
cfg
 . 
GPU_AVAILABLE
 )

199 
self
 . 
sess
 = 
tf
 . 
Session
 ( 
config
 = 
tf
 . 
ConfigProto
 (

200 
gpu_options
 = 
self
 . 
gpu_options
 ,

201 
device_count
 = { "GPU"

202 : 
cfg
 . 
GPU_USE_COUNT
 ,

205 
self
 . 
use_pretrain_weights
 = [ ]

207 
print
 ( 'fuck 0.1!' )

208 
self
 . 
build_net
 ( 
top_shape
 , 
front_shape
 , 
rgb_shape
 )

210 
print
 ( 'fuck 0.2!' )

212 
self
 . 
tag
 = 
log_tag

213 
self
 . 
ckpt_dir
 = 
os
 . 
path
 . 
join
 ( 
cfg
 . 
CHECKPOINT_DIR
 , 
log_tag
 ) if 
weigths_dir
 == None else 
weigths_dir

214 
self
 . 
subnet_rpn
 = 
Net
 ( 
prefix
 = 'MV3D' , 
scope_name
 = 
mv3d_net
 . 
top_view_rpn_name
 ,

215 
checkpoint_dir
 = 
self
 . 
ckpt_dir
 )

216 
self
 . 
subnet_imfeatrue
 = 
Net
 ( 
prefix
 = 'MV3D' , 
scope_name
 = 
mv3d_net
 . 
imfeature_net_name
 ,

217 
checkpoint_dir
 = 
self
 . 
ckpt_dir
 )

218 
self
 . 
subnet_frontfeature
 = 
Net
 ( 
prefix
 = 'MV3D' , 
scope_name
 = 
mv3d_net
 . 
frontfeature_net_name
 ,

219 
checkpoint_dir
 = 
self
 . 
ckpt_dir
 )

220 
self
 . 
subnet_fusion
 = 
Net
 ( 
prefix
 = 'MV3D' , 
scope_name
 = 
mv3d_net
 . 
fusion_net_name
 ,

221 
checkpoint_dir
 = 
self
 . 
ckpt_dir
 )

223 
print
 ( 'fuck 0.3!' )

225 
self
 . 
top_rpn_stride
 = 
self
 . 
net
 [ 'top_feature_rpn_stride' ]

226 
top_feature_shape
 = 
get_top_feature_shape
 ( 
top_shape
 , 
self
 . 
top_rpn_stride
 )

228 
self
 . 
top_view_anchors
 , 
self
 . 
anchors_inside_inds
 = 
make_anchors
 ( 
self
 . 
bases
 , 
self
 . 
top_rpn_stride
 , 
top_shape
 [ 0 : 2 ] , 
top_feature_shape
 [ 0 : 2 ] )

229 
self
 . 
anchors_inside_inds
 = 
np
 . 
arange
 ( 0 , 
len
 ( 
self
 . 
top_view_anchors
 ) , 
dtype
 = 
np
 . 
int32
 )

231 
self
 . 
log_subdir
 = None

232 
self
 . 
top_image
 = None

233 
self
 . 
front_image
 = None

234 
self
 . 
time_str
 = None

235 
self
 . 
frame_info
 = None

238 
self
 . 
batch_top_inds
 = None

239 
self
 . 
batch_top_labels
 = None

240 
self
 . 
batch_top_pos_inds
 = None

241 
self
 . 
batch_top_targets
 = None

242 
self
 . 
batch_proposals
 = None

243 
self
 . 
batch_proposal_scores
 = None

244 
self
 . 
batch_gt_top_boxes
 = None

245 
self
 . 
batch_gt_labels
 = None

249 
self
 . 
default_summary_writer
 = None

251 
self
 . 
debug_mode
 = 
debug_mode

254 
self
 . 
tb_dir
 = 
log_tag
 if 
log_tag
 != None else 
strftime
 ( "%Y_%m_%d_%H_%M" , 
localtime
 ( ) )

256 
print
 ( 'fuck 0.4!' ) 
	}

258 def 
	$dump_weigths
 ( 
self
 , 
dir
 ) :

259 
command
 = 'cp %s %s -r' % ( 
self
 . 
ckpt_dir
 , 
dir
 )

260 
os
 . 
system
 ( 
command
 ) 
	}

263 def 
	$gc
 ( 
self
 ) :

264 
self
 . 
log_subdir
 = None

265 
self
 . 
top_image
 = None

266 
self
 . 
front_image
 = None

267 
self
 . 
time_str
 = None

268 
self
 . 
frame_info
 = None 
	}

270 def 
	$predict
 ( 
self
 , 
top_view
 , 
front_view
 , 
rgb_image
 , 
score_threshold
 = 0.75 ) :

271 
self
 . 
lables
 = [ ]

273 
self
 . 
top_view
 = 
top_view

274 
self
 . 
rgb_image
 = 
rgb_image

275 
self
 . 
front_view
 = 
front_view

278 
self
 . 
anchors_inside_inds
 = 
remove_empty_anchor
 ( 
self
 . 
top_view
 [ 0 ] , 
self
 . 
top_view_anchors
 , 
cfg
 . 
REMOVE_THRES
 )

280 
fd1
 = {

281 
self
 . 
net
 [ 'top_view' ] : 
self
 . 
top_view
 ,

282 
self
 . 
net
 [ 'top_anchors' ] : 
self
 . 
top_view_anchors
 ,

283 
self
 . 
net
 [ 'top_inside_inds' ] : 
self
 . 
anchors_inside_inds
 ,

284 
blocks
 . 
IS_TRAIN_PHASE
 : False ,

285 
K
 . 
learning_phase
 ( ) : True

288 
self
 . 
batch_proposals
 , 
self
 . 
batch_proposal_scores
 =

289 
self
 . 
sess
 . 
run
 ( [ 
self
 . 
net
 [ 'proposals' ] , 
self
 . 
net
 [ 'proposal_scores' ] ] , 
fd1
 )

290 
self
 . 
batch_proposal_scores
 = 
np
 . 
reshape
 ( 
self
 . 
batch_proposal_scores
 , ( - 1 ) )

291 
self
 . 
top_rois
 = 
self
 . 
batch_proposals

292 if 
len
 ( 
self
 . 
top_rois
 ) == 0 :

293 return 
np
 . 
zeros
 ( ( 0 , 8 , 3 ) ) , [ ]

295 
self
 . 
rois3d
 = 
project_to_roi3d
 ( 
self
 . 
top_rois
 )

298 
self
 . 
front_rois
 = 
project_to_front_roi
 ( 
self
 . 
rois3d
 )

299 
self
 . 
rgb_rois
 = 
project_to_rgb_roi
 ( 
self
 . 
rois3d
 )

301 
fd2
 = {

302 ** 
fd1
 ,

303 
self
 . 
net
 [ 'front_view' ] : 
self
 . 
front_view
 ,

304 
self
 . 
net
 [ 'rgb_images' ] : 
self
 . 
rgb_image
 ,

306 
self
 . 
net
 [ 'top_rois' ] : 
self
 . 
top_rois
 ,

307 
self
 . 
net
 [ 'front_rois' ] : 
self
 . 
front_rois
 ,

308 
self
 . 
net
 [ 'rgb_rois' ] : 
self
 . 
rgb_rois
 ,

312 
self
 . 
fuse_probs
 , 
self
 . 
fuse_deltas
 ,

313 
self
 . 
fuse_probs_with_rgb
 , 
self
 . 
fuse_deltas_with_rgb
 ,

314 
self
 . 
fuse_probs_without_rgb
 , 
self
 . 
fuse_deltas_without_rgb
 =

315 
self
 . 
sess
 . 
run
 ( [

316 
self
 . 
net
 [ 'fuse_probs' ] , 
self
 . 
net
 [ 'fuse_deltas' ] ,

317 
self
 . 
net
 [ 'fuse_probs_with_rgb' ] , 
self
 . 
net
 [ 'fuse_deltas_with_rgb' ] ,

318 
self
 . 
net
 [ 'fuse_probs_without_rgb' ] , 
self
 . 
net
 [ 'fuse_deltas_without_rgb' ]

319 ] , 
fd2
 )

321 
self
 . 
probs
 , 
self
 . 
boxes3d
 = 
rcnn_nms
 ( 
self
 . 
fuse_probs
 , 
self
 . 
fuse_deltas
 , 
self
 . 
rois3d
 , 
score_threshold
 = 
score_threshold
 )

322 
self
 . 
probs_with_rgb
 , 
self
 . 
boxes3d_with_rgb
 = 
rcnn_nms
 ( 
self
 . 
fuse_probs_with_rgb
 , 
self
 . 
fuse_deltas_with_rgb
 , 
self
 . 
rois3d
 ,

323 
score_threshold
 = 
score_threshold
 )

324 
self
 . 
probs_without_rgb
 , 
self
 . 
boxes3d_without_rgb
 = 
rcnn_nms
 ( 
self
 . 
fuse_probs_without_rgb
 , 
self
 . 
fuse_deltas_without_rgb
 , 
self
 . 
rois3d
 ,

325 
score_threshold
 = 
score_threshold
 )

326 return 
self
 . 
boxes3d
 , 
self
 . 
lables
 , 
self
 . 
probs
 
	}

330 def 
	$predict_for_test
 ( 
self
 , 
top_view
 , 
front_view
 , 
rgb_image
 , 
score_threshold
 = 0.75 , 
gt_boxes3d
 = [ ] ) :

331 
self
 . 
lables
 = [ ]

332 
self
 . 
batch_gt_boxes3d
 = 
gt_boxes3d

333 if 
len
 ( 
gt_boxes3d
 ) > 0 :

334 
self
 . 
batch_gt_top_boxes
 = 
data
 . 
box3d_to_top_box
 ( 
self
 . 
batch_gt_boxes3d
 [ 0 ] )

336 
self
 . 
top_view
 = 
top_view

337 
self
 . 
rgb_image
 = 
rgb_image

338 
self
 . 
front_view
 = 
front_view

341 
self
 . 
anchors_inside_inds
 = 
remove_empty_anchor
 ( 
self
 . 
top_view
 [ 0 ] , 
self
 . 
top_view_anchors
 , 
cfg
 . 
REMOVE_THRES
 )

343 
fd1
 = {

344 
self
 . 
net
 [ 'top_view' ] : 
self
 . 
top_view
 ,

345 
self
 . 
net
 [ 'top_anchors' ] : 
self
 . 
top_view_anchors
 ,

346 
self
 . 
net
 [ 'top_inside_inds' ] : 
self
 . 
anchors_inside_inds
 ,

347 
blocks
 . 
IS_TRAIN_PHASE
 : False ,

348 
K
 . 
learning_phase
 ( ) : True

351 
self
 . 
batch_proposals
 , 
self
 . 
batch_proposal_scores
 =

352 
self
 . 
sess
 . 
run
 ( [ 
self
 . 
net
 [ 'proposals' ] , 
self
 . 
net
 [ 'proposal_scores' ] ] , 
fd1
 )

353 
self
 . 
batch_proposal_scores
 = 
np
 . 
reshape
 ( 
self
 . 
batch_proposal_scores
 , ( - 1 ) )

354 
self
 . 
top_rois
 = 
self
 . 
batch_proposals

355 if 
len
 ( 
self
 . 
top_rois
 ) == 0 :

356 return 
np
 . 
zeros
 ( ( 0 , 8 , 3 ) ) , [ ]

358 
self
 . 
rois3d
 = 
project_to_roi3d
 ( 
self
 . 
top_rois
 )

361 
self
 . 
front_rois
 = 
project_to_front_roi
 ( 
self
 . 
rois3d
 )

362 
self
 . 
rgb_rois
 = 
project_to_rgb_roi
 ( 
self
 . 
rois3d
 )

364 
fd2
 = {

365 ** 
fd1
 ,

366 
self
 . 
net
 [ 'front_view' ] : 
self
 . 
front_view
 ,

367 
self
 . 
net
 [ 'rgb_images' ] : 
self
 . 
rgb_image
 ,

369 
self
 . 
net
 [ 'top_rois' ] : 
self
 . 
top_rois
 ,

370 
self
 . 
net
 [ 'front_rois' ] : 
self
 . 
front_rois
 ,

371 
self
 . 
net
 [ 'rgb_rois' ] : 
self
 . 
rgb_rois
 ,

375 
self
 . 
fuse_probs
 , 
self
 . 
fuse_deltas
 ,

376 
self
 . 
fuse_probs_with_rgb
 , 
self
 . 
fuse_deltas_with_rgb
 ,

377 
self
 . 
fuse_probs_without_rgb
 , 
self
 . 
fuse_deltas_without_rgb
 =

378 
self
 . 
sess
 . 
run
 ( [

379 
self
 . 
net
 [ 'fuse_probs' ] , 
self
 . 
net
 [ 'fuse_deltas' ] ,

380 
self
 . 
net
 [ 'fuse_probs_with_rgb' ] , 
self
 . 
net
 [ 'fuse_deltas_with_rgb' ] ,

381 
self
 . 
net
 [ 'fuse_probs_without_rgb' ] , 
self
 . 
net
 [ 'fuse_deltas_without_rgb' ]

382 ] , 
fd2
 )

384 
self
 . 
probs
 , 
self
 . 
boxes3d
 = 
rcnn_nms
 ( 
self
 . 
fuse_probs
 , 
self
 . 
fuse_deltas
 , 
self
 . 
rois3d
 , 
score_threshold
 = 
score_threshold
 )

385 if 
cfg
 . 
USE_LEARNABLE_FUSION
 or 
cfg
 . 
USE_HANDCRAFT_FUSION
 :

386 
self
 . 
probs_with_rgb
 , 
self
 . 
boxes3d_with_rgb
 = 
rcnn_nms
 ( 
self
 . 
fuse_probs_with_rgb
 , 
self
 . 
fuse_deltas_with_rgb
 , 
self
 . 
rois3d
 ,

387 
score_threshold
 = 
score_threshold
 )

388 
self
 . 
probs_without_rgb
 , 
self
 . 
boxes3d_without_rgb
 = 
rcnn_nms
 ( 
self
 . 
fuse_probs_without_rgb
 , 
self
 . 
fuse_deltas_without_rgb
 , 
self
 . 
rois3d
 ,

389 
score_threshold
 = 
score_threshold
 )

391 return 
self
 . 
boxes3d
 , 
self
 . 
lables
 , 
self
 . 
probs
 
	}

394 def 
	$predict_3dop
 ( 
self
 , 
proposals
 , 
proposal_scores
 , 
top_view
 , 
front_view
 , 
rgb_image
 ) :

397 
self
 . 
lables
 = [ ]

398 
self
 . 
top_view
 , 
self
 . 
front_view
 , 
self
 . 
rgb_image
 = 
top_view
 , 
front_view
 , 
rgb_image

400 
self
 . 
batch_proposals
 , 
self
 . 
batch_proposal_scores
 = 
proposals
 , 
proposal_scores

401 
self
 . 
batch_proposal_scores
 = 
np
 . 
reshape
 ( 
self
 . 
batch_proposal_scores
 , ( - 1 ) )

402 
self
 . 
rois3d
 = 
kitti_roi3d_to_inner3d
 ( 
self
 . 
batch_proposals
 )

403 if 
len
 ( 
self
 . 
rois3d
 ) == 0 :

404 return 
np
 . 
zeros
 ( ( 0 , 8 , 3 ) ) , [ ]

408 
self
 . 
top_rois
 = 
project_to_top_roi
 ( 
self
 . 
rois3d
 )

409 
self
 . 
front_rois
 = 
project_to_front_roi
 ( 
self
 . 
rois3d
 )

410 
self
 . 
rgb_rois
 = 
project_to_rgb_roi
 ( 
self
 . 
rois3d
 )

412 
fd
 = {

413 
self
 . 
net
 [ 'top_view' ] : 
self
 . 
top_view
 [ 
np
 . 
newaxis
 ] ,

414 
self
 . 
net
 [ 'front_view' ] : 
self
 . 
front_view
 [ 
np
 . 
newaxis
 ] ,

415 
self
 . 
net
 [ 'rgb_images' ] : 
self
 . 
rgb_image
 [ 
np
 . 
newaxis
 ] ,

417 
self
 . 
net
 [ 'top_rois' ] : 
self
 . 
top_rois
 ,

418 
self
 . 
net
 [ 'front_rois' ] : 
self
 . 
front_rois
 ,

419 
self
 . 
net
 [ 'rgb_rois' ] : 
self
 . 
rgb_rois
 ,

420 
blocks
 . 
IS_TRAIN_PHASE
 : False ,

421 
K
 . 
learning_phase
 ( ) : True

424 
self
 . 
fuse_probs
 , 
self
 . 
fuse_deltas
 =

425 
self
 . 
sess
 . 
run
 ( [ 
self
 . 
net
 [ 'fuse_probs' ] , 
self
 . 
net
 [ 'fuse_deltas' ] ] , 
fd
 )

427 
self
 . 
probs
 , 
self
 . 
boxes3d
 = 
rcnn_nms
 ( 
self
 . 
fuse_probs
 , 
self
 . 
fuse_deltas
 , 
self
 . 
rois3d
 , 
score_threshold
 = 0.5 )

428 return 
self
 . 
boxes3d
 , 
self
 . 
lables
 
	}

431 def 
	$predict_log
 ( 
self
 , 
log_subdir
 , 
log_rpn
 = False , 
step
 = None , 
scope_name
 = '' , 
gt_boxes3d
 = [ ] ) :

432 
self
 . 
top_image
 = 
data
 . 
draw_top_image
 ( 
self
 . 
top_view
 [ 0 ] )

433 
self
 . 
top_image
 = 
self
 . 
top_image_padding
 ( 
self
 . 
top_image
 )

434 if 
log_rpn
 : 
self
 . 
log_rpn
 ( 
step
 = 
step
 , 
scope_name
 = 
scope_name
 )

435 
self
 . 
log_fusion_net_detail
 ( 
log_subdir
 , 
self
 . 
fuse_probs
 , 
self
 . 
fuse_deltas
 )

438 
text_lables
 = [ 'No.%d class:1 prob: %.4f' % ( 
i
 , 
prob
 ) for 
i
 , 
prob
 in 
enumerate
 ( 
self
 . 
probs
 ) ]

439 
predict_camera_view
 = 
nud
 . 
draw_box3d_on_camera
 ( 
self
 . 
rgb_image
 [ 0 ] , 
self
 . 
boxes3d
 , 
text_lables
 = 
text_lables
 , 
color
 = ( 255 , 0 , 255 ) )

440 
predict_top_view
 = 
data
 . 
draw_box3d_on_top
 ( 
self
 . 
top_image
 , 
self
 . 
boxes3d
 , 
color
 = ( 255 , 0 , 255 ) )

442 if 
cfg
 . 
USE_LEARNABLE_FUSION
 or 
cfg
 . 
USE_HANDCRAFT_FUSION
 :

444 
text_lables
 = [ 'No.%d class:1 prob: %.4f' % ( 
i
 , 
prob
 ) for 
i
 , 
prob
 in 
enumerate
 ( 
self
 . 
probs_without_rgb
 ) ]

445 
predict_camera_view
 = 
nud
 . 
draw_box3d_on_camera
 ( 
predict_camera_view
 , 
self
 . 
boxes3d_without_rgb
 , 
text_lables
 = 
text_lables
 , 
color
 = ( 0 , 255 , 0 ) )

446 
predict_top_view
 = 
data
 . 
draw_box3d_on_top
 ( 
predict_top_view
 , 
self
 . 
boxes3d_without_rgb
 , 
color
 = ( 0 , 255 , 0 ) )

449 
text_lables
 = [ 'No.%d class:1 prob: %.4f' % ( 
i
 , 
prob
 ) for 
i
 , 
prob
 in 
enumerate
 ( 
self
 . 
probs_with_rgb
 ) ]

450 
predict_camera_view
 = 
nud
 . 
draw_box3d_on_camera
 ( 
predict_camera_view
 , 
self
 . 
boxes3d_with_rgb
 , 
text_lables
 = 
text_lables
 , 
color
 = ( 0 , 0 , 255 ) )

451 
predict_top_view
 = 
data
 . 
draw_box3d_on_top
 ( 
predict_top_view
 , 
self
 . 
boxes3d_with_rgb
 , 
color
 = ( 0 , 0 , 255 ) )

455 if 
len
 ( 
gt_boxes3d
 ) > 0 :

456 
predict_top_view
 = 
data
 . 
draw_box3d_on_top
 ( 
predict_top_view
 , 
gt_boxes3d
 , 
color
 = ( 255 , 0 , 0 ) )

457 
predict_camera_view
 = 
draw_box3d_on_camera
 ( 
predict_camera_view
 , 
gt_boxes3d
 , 
color
 = ( 255 , 0 , 0 ) )

459 
new_size
 = ( 
predict_camera_view
 . 
shape
 [ 1 ] // 2 , 
predict_camera_view
 . 
shape
 [ 0 ] // 2 )

460 
predict_camera_view
 = 
cv2
 . 
resize
 ( 
predict_camera_view
 , 
new_size
 )

462 
self
 . 
summary_image
 ( 
predict_camera_view
 , 
scope_name
 + '/predict_camera_view' , 
step
 = 
step
 )

463 
self
 . 
summary_image
 ( 
predict_top_view
 , 
scope_name
 + '/predict_top_view' , 
step
 = 
step
 ) 
	}

466 def 
	$predict_log_for_test
 ( 
self
 , 
log_subdir
 , 
log_rpn
 = False , 
step
 = None , 
scope_name
 = '' , 
gt_boxes3d
 = [ ] ) :

467 
self
 . 
top_image
 = 
data
 . 
draw_top_image
 ( 
self
 . 
top_view
 [ 0 ] )

468 
self
 . 
top_image
 = 
self
 . 
top_image_padding
 ( 
self
 . 
top_image
 )

469 if 
log_rpn
 : 
self
 . 
log_rpn
 ( 
step
 = 
step
 , 
scope_name
 = 
scope_name
 )

470 
self
 . 
log_fusion_net_detail
 ( 
log_subdir
 , 
self
 . 
fuse_probs
 , 
self
 . 
fuse_deltas
 )

471 
text_lables
 = [ 'No.%d class:1 prob: %.4f' % ( 
i
 , 
prob
 ) for 
i
 , 
prob
 in 
enumerate
 ( 
self
 . 
probs
 ) ]

472 
predict_camera_view
 = 
nud
 . 
draw_box3d_on_camera
 ( 
self
 . 
rgb_image
 [ 0 ] , 
self
 . 
boxes3d
 , 
text_lables
 = 
text_lables
 )

474 
predict_top_view
 = 
data
 . 
draw_box3d_on_top
 ( 
self
 . 
top_image
 , 
self
 . 
boxes3d
 )

477 if 
len
 ( 
gt_boxes3d
 ) > 0 :

478 
predict_top_view
 = 
data
 . 
draw_box3d_on_top
 ( 
predict_top_view
 , 
gt_boxes3d
 , 
color
 = ( 255 , 0 , 0 ) )

479 
predict_camera_view
 = 
draw_box3d_on_camera
 ( 
predict_camera_view
 , 
gt_boxes3d
 , 
color
 = ( 255 , 0 , 0 ) )

481 
new_size
 = ( 
predict_camera_view
 . 
shape
 [ 1 ] // 2 , 
predict_camera_view
 . 
shape
 [ 0 ] // 2 )

482 
predict_camera_view
 = 
cv2
 . 
resize
 ( 
predict_camera_view
 , 
new_size
 )

484 
self
 . 
summary_image
 ( 
predict_camera_view
 , 
scope_name
 + '/predict_camera_view' , 
step
 = 0 )

485 
self
 . 
summary_image
 ( 
predict_top_view
 , 
scope_name
 + '/predict_top_view' , 
step
 = 0 )

486 
self
 . 
summary_image
 ( 
predict_top_view
 , 
scope_name
 + '/predict_top_view' , 
step
 = 0 )

487 if 
self
 . 
batch_proposals
 is not None :

488 
rpn_proposal
 = 
draw_rpn_proposal
 ( 
self
 . 
top_image
 , 
self
 . 
batch_proposals
 , 
self
 . 
batch_proposal_scores
 , 
draw_num
 = 20 )

490 
self
 . 
summary_image
 ( 
rpn_proposal
 , 
scope_name
 + '/img_rpn_proposal' , 
step
 = 0 )

491 
self
 . 
summary_image
 ( 
rpn_proposal
 , 
scope_name
 + '/img_rpn_proposal' , 
step
 = 0 ) 
	}

496 def 
	$batch_data_is_invalid
 ( 
self
 , 
train_gt_boxes3d
 ) :

499 for 
i
 in 
range
 ( 
len
 ( 
train_gt_boxes3d
 ) ) :

500 if 
box
 . 
box3d_in_top_view
 ( 
train_gt_boxes3d
 [ 
i
 ] ) :

504 return False 
	}

507 def 
	$build_net
 ( 
self
 , 
top_shape
 , 
front_shape
 , 
rgb_shape
 ) :

508 with 
tf
 . 
variable_scope
 ( 'MV3D' ) :

509 
net
 = 
mv3d_net
 . 
load
 ( 
top_shape
 , 
front_shape
 , 
rgb_shape
 , 
self
 . 
num_class
 , 
len
 ( 
self
 . 
bases
 ) )

510 
self
 . 
net
 = 
net
 
	}

513 def 
	$variables_initializer
 ( 
self
 ) :

516 
self
 . 
sess
 . 
run
 ( 
tf
 . 
global_variables_initializer
 ( ) ,

517 { 
blocks
 . 
IS_TRAIN_PHASE
 : True , 
K
 . 
learning_phase
 ( ) : 1 } ) 
	}

520 def 
	$load_weights
 ( 
self
 , 
weights
 = [ ] ) :

521 for 
name
 in 
weights
 :

522 if 
name
 == 
mv3d_net
 . 
top_view_rpn_name
 :

523 
self
 . 
subnet_rpn
 . 
load_weights
 ( 
self
 . 
sess
 )

525 elif 
name
 == 
mv3d_net
 . 
fusion_net_name
 :

526 
self
 . 
subnet_fusion
 . 
load_weights
 ( 
self
 . 
sess
 )

528 elif 
name
 == 
mv3d_net
 . 
imfeature_net_name
 :

529 
self
 . 
subnet_imfeatrue
 . 
load_weights
 ( 
self
 . 
sess
 )

531 elif 
name
 == 
mv3d_net
 . 
frontfeature_net_name
 :

532 
self
 . 
subnet_frontfeature
 . 
load_weights
 ( 
self
 . 
sess
 )

535 
ValueError
 ( 'unknow weigths name' ) 
	}

537 def 
	$clean_weights
 ( 
self
 , 
weights
 = [ ] ) :

538 for 
name
 in 
weights
 :

539 if 
name
 == 
mv3d_net
 . 
top_view_rpn_name
 :

540 
self
 . 
subnet_rpn
 . 
clean_weights
 ( )

542 elif 
name
 == 
mv3d_net
 . 
fusion_net_name
 :

543 
self
 . 
subnet_fusion
 . 
clean_weights
 ( )

545 elif 
name
 == 
mv3d_net
 . 
imfeature_net_name
 :

546 
self
 . 
subnet_imfeatrue
 . 
clean_weights
 ( )

548 elif 
name
 == 
mv3d_net
 . 
frontfeature_net_name
 :

549 
self
 . 
subnet_frontfeature
 . 
clean_weights
 ( )

552 
ValueError
 ( 'unknow weigths name' ) 
	}

555 def 
	$save_weights
 ( 
self
 , 
weights
 = [ ] , 
step
 = 0 ) :

556 for 
name
 in 
weights
 :

557 if 
name
 == 
mv3d_net
 . 
top_view_rpn_name
 :

558 
self
 . 
subnet_rpn
 . 
save_weights
 ( 
self
 . 
sess
 , 
step
 )

560 elif 
name
 == 
mv3d_net
 . 
fusion_net_name
 :

561 
self
 . 
subnet_fusion
 . 
save_weights
 ( 
self
 . 
sess
 , 
step
 )

563 elif 
name
 == 
mv3d_net
 . 
imfeature_net_name
 :

564 
self
 . 
subnet_imfeatrue
 . 
save_weights
 ( 
self
 . 
sess
 , 
step
 )

566 elif 
name
 == 
mv3d_net
 . 
frontfeature_net_name
 :

567 
self
 . 
subnet_frontfeature
 . 
save_weights
 ( 
self
 . 
sess
 , 
step
 )

570 
ValueError
 ( 'unknow weigths name' ) 
	}

573 def 
	$top_image_padding
 ( 
self
 , 
top_image
 ) :

574 return 
np
 . 
concatenate
 ( ( 
top_image
 , 
np
 . 
zeros_like
 ( 
top_image
 ) * 255 , 
np
 . 
zeros_like
 ( 
top_image
 ) * 255 ) , 1 ) 
	}

577 def 
	$log_rpn
 ( 
self
 , 
step
 = None , 
scope_name
 = '' ) :

579 
top_image
 = 
self
 . 
top_image

580 
subdir
 = 
self
 . 
log_subdir

581 
top_inds
 = 
self
 . 
batch_top_inds

582 
top_labels
 = 
self
 . 
batch_top_labels

583 
top_pos_inds
 = 
self
 . 
batch_top_pos_inds

584 
top_targets
 = 
self
 . 
batch_top_targets

585 
proposals
 = 
self
 . 
batch_proposals

586 
proposal_scores
 = 
self
 . 
batch_proposal_scores

587 
gt_top_boxes
 = 
self
 . 
batch_gt_top_boxes

588 
gt_labels
 = 
self
 . 
batch_gt_labels

590 if 
gt_top_boxes
 is not None :

591 
img_gt
 = 
draw_rpn_gt
 ( 
top_image
 , 
gt_top_boxes
 , 
gt_labels
 )

593 
self
 . 
summary_image
 ( 
img_gt
 , 
scope_name
 + '/img_rpn_gt' , 
step
 = 
step
 )

595 if 
top_inds
 is not None :

596 
img_label
 = 
draw_rpn_labels
 ( 
top_image
 , 
self
 . 
top_view_anchors
 , 
top_inds
 , 
top_labels
 )

598 
cv2
 . 
putText
 ( 
img_label
 , 
self
 . 
anchors_details
 ( ) , ( 0 , 30 ) , 
cv2
 . 
FONT_HERSHEY_SIMPLEX
 , 0.7 , ( 0 , 255 , 100 ) , 1 , 
cv2
 . 
LINE_AA
 )

599 
self
 . 
summary_image
 ( 
img_label
 , 
scope_name
 + '/img_rpn_label' , 
step
 = 
step
 )

601 if 
top_pos_inds
 is not None :

602 
img_target
 = 
draw_rpn_targets
 ( 
top_image
 , 
self
 . 
top_view_anchors
 , 
top_pos_inds
 , 
top_targets
 )

604 
self
 . 
summary_image
 ( 
img_target
 , 
scope_name
 + '/img_rpn_target' , 
step
 = 
step
 )

606 if 
proposals
 is not None :

607 
rpn_proposal
 = 
draw_rpn_proposal
 ( 
top_image
 , 
proposals
 , 
proposal_scores
 , 
draw_num
 = 20 )

609 
self
 . 
summary_image
 ( 
rpn_proposal
 , 
scope_name
 + '/img_rpn_proposal' , 
step
 = 
step
 ) 
	}

613 def 
	$log_fusion_net_detail
 ( 
self
 , 
subdir
 , 
fuse_probs
 , 
fuse_deltas
 ) :

614 
dir
 = 
os
 . 
path
 . 
join
 ( 
cfg
 . 
LOG_DIR
 , 
subdir
 )

615 
os
 . 
makedirs
 ( 
dir
 , 
exist_ok
 = True )

616 with 
open
 ( 
os
 . 
path
 . 
join
 ( 
dir
 , 'fusion_net_detail.txt' ) , 'w' ) as 
info_file
 :

617 
info_file
 . 
write
 ( 'index, fuse_probs, fuse_deltas\n' )

618 for 
i
 , 
prob
 in 
enumerate
 ( 
fuse_probs
 ) :

619 
info_file
 . 
write
 ( '{}, {}, {}\n' . 
format
 ( 
i
 , 
prob
 , 
fuse_deltas
 [ 
i
 ] ) ) 
	}

622 def 
	$summary_image
 ( 
self
 , 
image
 , 
tag
 , 
summary_writer
 = None , 
step
 = None ) :

624 if 
summary_writer
 == None :

625 
summary_writer
 = 
self
 . 
default_summary_writer

627 
im_summaries
 = [ ]

629 
s
 = 
io
 . 
BytesIO
 ( )

630 
plt
 . 
imsave
 ( 
s
 , 
image
 )

633 
img_sum
 = 
tf
 . 
Summary
 . 
Image
 ( 
encoded_image_string
 = 
s
 . 
getvalue
 ( ) ,

634 
height
 = 
image
 . 
shape
 [ 0 ] ,

635 
width
 = 
image
 . 
shape
 [ 1 ] )

637 
im_summaries
 . 
append
 ( 
tf
 . 
Summary
 . 
Value
 ( 
tag
 = 
tag
 , 
image
 = 
img_sum
 ) )

640 
summary
 = 
tf
 . 
Summary
 ( 
value
 = 
im_summaries
 )

641 
summary_writer
 . 
add_summary
 ( 
summary
 , 
step
 ) 
	}

644 def 
	$summary_scalar
 ( 
self
 , 
value
 , 
tag
 , 
summary_writer
 = None , 
step
 = None ) :

654 if 
summary_writer
 == None :

655 
summary_writer
 = 
self
 . 
default_summary_writer

656 
summary
 = 
tf
 . 
Summary
 ( 
value
 = [ 
tf
 . 
Summary
 . 
Value
 ( 
tag
 = 
tag
 ,

657 
simple_value
 = 
value
 ) ] )

658 
summary_writer
 . 
add_summary
 ( 
summary
 , 
step
 ) 
	}

661 class 
	cPredictor
 ( 
MV3D
 ) :

662 def 
	$__init__
 ( 
self
 , 
top_shape
 , 
front_shape
 , 
rgb_shape
 , 
log_tag
 = None , 
weights_tag
 = None , 
weight_name
 = 'default' ) :

663 
weigths_dir
 = 
os
 . 
path
 . 
join
 ( 
cfg
 . 
CHECKPOINT_DIR
 , 
weights_tag
 ) if 
weights_tag
 != None else None

664 
MV3D
 . 
__init__
 ( 
self
 , 
top_shape
 , 
front_shape
 , 
rgb_shape
 , 
log_tag
 = 
log_tag
 , 
weigths_dir
 = 
weigths_dir
 )

665 
self
 . 
variables_initializer
 ( )

666 
self
 . 
load_weights
 ( [ 
mv3d_net
 . 
top_view_rpn_name
 , 
mv3d_net
 . 
imfeature_net_name
 , 
mv3d_net
 . 
fusion_net_name
 , 
mv3d_net
 . 
frontfeature_net_name
 ] )

668 
tb_dir
 = 
os
 . 
path
 . 
join
 ( 
cfg
 . 
LOG_DIR
 , 'tensorboard' , 
self
 . 
tb_dir
 + '_tracking' )

669 if 
os
 . 
path
 . 
isdir
 ( 
tb_dir
 ) :

670 
command
 = 'rm -rf %s' % 
tb_dir

671 
print
 ( '\nClear old summary file: %s' % 
command
 )

672 
os
 . 
system
 ( 
command
 )

673 
self
 . 
default_summary_writer
 = 
tf
 . 
summary
 . 
FileWriter
 ( 
tb_dir
 )

674 
self
 . 
n_log_scope
 = 0

675 
self
 . 
n_max_log_per_scope
 = 10 
	}

678 def 
	$__call__
 ( 
self
 , 
top_view
 , 
front_view
 , 
rgb_image
 , 
nms_threshold
 = 0.5 , 
gt_boxes3d
 = [ ] ) :

679 return 
self
 . 
predict
 ( 
top_view
 , 
front_view
 , 
rgb_image
 , 
score_threshold
 = 
nms_threshold
 , 
gt_boxes3d
 = 
gt_boxes3d
 ) 
	}

681 def 
	$dump_log
 ( 
self
 , 
log_subdir
 , 
n_frame
 ) :

682 
n_start
 = 
n_frame
 - ( 
n_frame
 % ( 
self
 . 
n_max_log_per_scope
 ) )

683 
n_end
 = 
n_start
 + 
self
 . 
n_max_log_per_scope
 - 1

685 
scope_name
 = 'predict_%d_%d' % ( 
n_start
 , 
n_end
 )

686 
self
 . 
predict_log
 ( 
log_subdir
 = 
log_subdir
 , 
log_rpn
 = False , 
step
 = 
n_frame
 , 
scope_name
 = 
scope_name
 , 
gt_boxes3d
 = 
self
 . 
batch_gt_boxes3d
 [ 0 ] ) 
	}

688 class 
	cPredictor_for_test
 ( 
MV3D
 ) :

689 def 
	$__init__
 ( 
self
 , 
top_shape
 , 
front_shape
 , 
rgb_shape
 , 
log_tag
 = None , 
weights_tag
 = None , 
weight_name
 = 'default' ) :

690 
weigths_dir
 = 
os
 . 
path
 . 
join
 ( 
cfg
 . 
CHECKPOINT_DIR
 , 
weights_tag
 ) if 
weights_tag
 != None else None

691 
MV3D
 . 
__init__
 ( 
self
 , 
top_shape
 , 
front_shape
 , 
rgb_shape
 , 
log_tag
 = 
log_tag
 , 
weigths_dir
 = 
weigths_dir
 )

692 
self
 . 
variables_initializer
 ( )

693 
self
 . 
load_weights
 ( [ 
mv3d_net
 . 
top_view_rpn_name
 , 
mv3d_net
 . 
imfeature_net_name
 , 
mv3d_net
 . 
fusion_net_name
 , 
mv3d_net
 . 
frontfeature_net_name
 ] )

695 
tb_dir
 = 
os
 . 
path
 . 
join
 ( 
cfg
 . 
LOG_DIR
 , 'tensorboard' , 
self
 . 
tb_dir
 + '_tracking' )

700 
self
 . 
default_summary_writer
 = 
tf
 . 
summary
 . 
FileWriter
 ( 
tb_dir
 )

701 
self
 . 
n_log_scope
 = 0

702 
self
 . 
n_max_log_per_scope
 = 10 
	}

705 def 
	$__call__
 ( 
self
 , 
top_view
 , 
front_view
 , 
rgb_image
 , 
nms_threshold
 , 
gt_boxes3d
 = [ ] ) :

706 return 
self
 . 
predict_for_test
 ( 
top_view
 , 
front_view
 , 
rgb_image
 , 
score_threshold
 = 
nms_threshold
 , 
gt_boxes3d
 = 
gt_boxes3d
 ) 
	}

708 def 
	$dump_log
 ( 
self
 , 
log_subdir
 , 
n_frame
 ) :

709 
n_start
 = 
n_frame
 - ( 
n_frame
 % ( 
self
 . 
n_max_log_per_scope
 ) )

710 
n_end
 = 
n_start
 + 
self
 . 
n_max_log_per_scope
 - 1

712 
scope_name
 = 'predict'

713 
self
 . 
predict_log_for_test
 ( 
log_subdir
 = 
log_subdir
 , 
log_rpn
 = False , 
step
 = 
n_frame
 , 
scope_name
 = 
scope_name
 , 
gt_boxes3d
 = 
self
 . 
batch_gt_boxes3d
 [ 0 ] ) 
	}

716 class 
	cTrainer
 ( 
MV3D
 ) :

718 def 
	$__init__
 ( 
self
 , 
train_set
 , 
validation_set
 , 
pre_trained_weights
 , 
train_targets
 , 
log_tag
 = None ,

719 
continue_train
 = False , 
batch_size
 = 1 , 
lr
 = 0.001 , 
debug
 = False ) :

720 
print
 ( 'fuck -1!' )

721 
top_shape
 , 
front_shape
 , 
rgb_shape
 = 
train_set
 . 
get_shape
 ( )

722 
print
 ( 'fuck 0!' )

723 
MV3D
 . 
__init__
 ( 
self
 , 
top_shape
 , 
front_shape
 , 
rgb_shape
 , 
log_tag
 = 
log_tag
 )

724 
self
 . 
train_set
 = 
train_set

725 
self
 . 
validation_set
 = 
validation_set

726 
self
 . 
train_target
 = 
train_targets

727 
self
 . 
batch_size
 = 
batch_size

728 
self
 . 
lr
 = 
lr

729 
self
 . 
debug
 = 
debug

731 
self
 . 
train_summary_writer
 = None

732 
self
 . 
val_summary_writer
 = None

733 
self
 . 
tensorboard_dir
 = None

734 
self
 . 
summ
 = None

735 
self
 . 
n_global_step
 = 0

736 
self
 . 
targets_loss
 = 0

737 
self
 . 
targets_loss_sum
 = 0

738 
self
 . 
targets_loss_cur
 = 0

740 
print
 ( 'fuck1!' )

742 
self
 . 
saver
 = 
tf
 . 
train
 . 
Saver
 ( )

743 
print
 ( 'fuck2!' )

745 with 
self
 . 
sess
 . 
as_default
 ( ) :

747 with 
tf
 . 
variable_scope
 ( 'minimize_loss' ) :

750 
self
 . 
learning_rate
 = 
tf
 . 
placeholder
 ( 
tf
 . 
float32
 , 
shape
 = [ ] )

752 
solver
 = 
tf
 . 
train
 . 
AdamOptimizer
 ( 
learning_rate
 = 
self
 . 
lr
 )

753 
self
 . 
do_optimize
 = 
tf
 . 
placeholder
 ( 
tf
 . 
bool
 , 
shape
 = [ ] , 
name
 = 'do_optimize' )

756 
self
 . 
top_cls_loss
 = 
self
 . 
net
 [ 'top_cls_loss' ]

757 
self
 . 
top_cls_loss_sum
 = 0.0

758 
self
 . 
top_cls_loss_cur
 = 
self
 . 
net
 [ 'top_cls_loss_cur' ]

760 
self
 . 
top_reg_loss
 = 
self
 . 
net
 [ 'top_reg_loss' ]

761 
self
 . 
top_reg_loss_sum
 = 0.0

762 
self
 . 
top_reg_loss_cur
 = 
self
 . 
net
 [ 'top_reg_loss_cur' ]

764 
self
 . 
fuse_cls_loss
 = 
self
 . 
net
 [ 'fuse_cls_loss' ]

765 
self
 . 
fuse_cls_loss_sum
 = 0.0

766 
self
 . 
fuse_cls_loss_cur
 = 
self
 . 
net
 [ 'fuse_cls_loss_cur' ]

768 
self
 . 
fuse_reg_loss
 = 
self
 . 
net
 [ 'fuse_reg_loss' ]

769 
self
 . 
fuse_reg_loss_sum
 = 0.0

770 
self
 . 
fuse_reg_loss_cur
 = 
self
 . 
net
 [ 'fuse_reg_loss_cur' ]

772 
train_var_list
 = [ ]

774 assert 
train_targets
 != [ ]

775 for 
target
 in 
train_targets
 :

777 if 
target
 == 
mv3d_net
 . 
top_view_rpn_name
 :

778 
train_var_list
 += 
self
 . 
subnet_rpn
 . 
variables

780 elif 
target
 == 
mv3d_net
 . 
imfeature_net_name
 :

781 
train_var_list
 += 
self
 . 
subnet_imfeatrue
 . 
variables

783 elif 
target
 == 
mv3d_net
 . 
frontfeature_net_name
 :

784 
train_var_list
 += 
self
 . 
subnet_frontfeature
 . 
variables

786 elif 
target
 == 
mv3d_net
 . 
fusion_net_name
 :

787 
train_var_list
 += 
self
 . 
subnet_fusion
 . 
variables

789 
ValueError
 ( 'unknow train_target name' )

792 if 
set
 ( [ 
mv3d_net
 . 
top_view_rpn_name
 ] ) == 
set
 ( 
train_targets
 ) :

793 
w1
 , 
w2
 = 1.0 , 0.5

794 
self
 . 
targets_loss
 = 
w1
 * 
self
 . 
top_cls_loss
 + 
w2
 * 
self
 . 
top_reg_loss

795 
self
 . 
targets_loss_cur
 = 
w1
 * 
self
 . 
top_cls_loss_cur
 + 
w2
 * 
self
 . 
top_reg_loss_cur

797 elif 
set
 ( [ 
mv3d_net
 . 
imfeature_net_name
 ] ) == 
set
 ( 
train_targets
 ) :

798 
w1
 , 
w2
 = 1.0 , 1.0

799 
self
 . 
targets_loss
 = 
w1
 * 
self
 . 
fuse_cls_loss
 + 
w2
 * 
self
 . 
fuse_reg_loss

800 
self
 . 
targets_loss_cur
 = 
w1
 * 
self
 . 
fuse_cls_loss_cur
 + 
w2
 * 
self
 . 
fuse_reg_loss_cur

802 elif 
set
 ( [ 
mv3d_net
 . 
frontfeature_net_name
 ] ) == 
set
 ( 
train_targets
 ) :

803 
w1
 , 
w2
 = 1.0 , 1.0

804 
self
 . 
targets_loss
 = 
w1
 * 
self
 . 
fuse_cls_loss
 + 
w2
 * 
self
 . 
fuse_reg_loss

805 
self
 . 
targets_loss_cur
 = 
w1
 * 
self
 . 
fuse_cls_loss_cur
 + 
w2
 * 
self
 . 
fuse_reg_loss_cur

807 elif 
set
 ( [ 
mv3d_net
 . 
fusion_net_name
 ] ) == 
set
 ( 
train_targets
 ) :

808 
w1
 , 
w2
 = 1.0 , 1.0

809 
self
 . 
targets_loss
 = 
w1
 * 
self
 . 
fuse_cls_loss
 + 
w2
 * 
self
 . 
fuse_reg_loss

810 
self
 . 
targets_loss_cur
 = 
w1
 * 
self
 . 
fuse_cls_loss_cur
 + 
w2
 * 
self
 . 
fuse_reg_loss_cur

812 elif 
set
 ( [ 
mv3d_net
 . 
imfeature_net_name
 , 
mv3d_net
 . 
frontfeature_net_name
 , 
mv3d_net
 . 
fusion_net_name
 ] ) == 
set
 ( 
train_targets
 ) :

813 
w1
 , 
w2
 = 1.0 , 1.0

814 
self
 . 
targets_loss
 = 
w1
 * 
self
 . 
fuse_cls_loss
 + 
w2
 * 
self
 . 
fuse_reg_loss

815 
self
 . 
targets_loss_cur
 = 
w1
 * 
self
 . 
fuse_cls_loss_cur
 + 
w2
 * 
self
 . 
fuse_reg_loss_cur

817 elif 
set
 ( [ 
mv3d_net
 . 
top_view_rpn_name
 , 
mv3d_net
 . 
imfeature_net_name
 , 
mv3d_net
 . 
fusion_net_name
 , 
mv3d_net
 . 
frontfeature_net_name
 ] )

818 == 
set
 ( 
train_targets
 ) :

819 
w1
 , 
w2
 , 
w3
 , 
w4
 , 
w5
 = 1.0 , 1.0 , 0.05 , 1.0 , 0.1

820 
self
 . 
targets_loss
 = 
w1
 * ( 
w2
 * 
self
 . 
top_cls_loss
 + 
w3
 * 
self
 . 
top_reg_loss
 ) +

821 
w4
 * 
self
 . 
fuse_cls_loss
 + 
w5
 * 
self
 . 
fuse_reg_loss

823 
self
 . 
targets_loss_cur
 = 
w1
 * ( 
w2
 * 
self
 . 
top_cls_loss_cur
 + 
w3
 * 
self
 . 
top_reg_loss_cur
 ) +

824 
w4
 * 
self
 . 
fuse_cls_loss_cur
 + 
w5
 * 
self
 . 
fuse_reg_loss_cur

826 
ValueError
 ( 'unknow train_target set' )

828 
tf
 . 
summary
 . 
scalar
 ( 'targets_loss' , 
self
 . 
targets_loss_cur
 )

832 if 
set
 ( [ 
mv3d_net
 . 
top_view_rpn_name
 ] ) == 
set
 ( 
train_targets
 ) :

833 
tf
 . 
summary
 . 
scalar
 ( 'top_cls_loss' , 
self
 . 
top_cls_loss_cur
 )

834 
tf
 . 
summary
 . 
scalar
 ( 'top_reg_loss' , 
self
 . 
top_reg_loss_cur
 )

836 
tf
 . 
summary
 . 
scalar
 ( 'top_cls_loss' , 
self
 . 
top_cls_loss_cur
 )

837 
tf
 . 
summary
 . 
scalar
 ( 'top_reg_loss' , 
self
 . 
top_reg_loss_cur
 )

838 
tf
 . 
summary
 . 
scalar
 ( 'fuse_cls_loss' , 
self
 . 
fuse_cls_loss_cur
 )

839 
tf
 . 
summary
 . 
scalar
 ( 'fuse_reg_loss' , 
self
 . 
fuse_reg_loss_cur
 )

841 
print
 ( 'fuck3!' )

844 
self
 . 
solver_step
 = 
solver
 . 
minimize
 ( 
loss
 = 
self
 . 
targets_loss_cur
 , 
var_list
 = 
train_var_list
 )

846 
print
 ( 'fuck4!' )

849 
train_writer_dir
 = 
os
 . 
path
 . 
join
 ( 
cfg
 . 
LOG_DIR
 , 'tensorboard' , 
self
 . 
tb_dir
 + '_train' )

850 
val_writer_dir
 = 
os
 . 
path
 . 
join
 ( 
cfg
 . 
LOG_DIR
 , 'tensorboard' , 
self
 . 
tb_dir
 + '_val' )

851 if 
continue_train
 == False :

852 if 
os
 . 
path
 . 
isdir
 ( 
train_writer_dir
 ) :

853 
command
 = 'rm -rf %s' % 
train_writer_dir

854 
print
 ( '\nClear old summary file: %s' % 
command
 )

855 
os
 . 
system
 ( 
command
 )

856 if 
os
 . 
path
 . 
isdir
 ( 
val_writer_dir
 ) :

857 
command
 = 'rm -rf %s' % 
val_writer_dir

858 
print
 ( '\nClear old summary file: %s' % 
command
 )

859 
os
 . 
system
 ( 
command
 )

861 
print
 ( 'fuck5!' )

863 
self
 . 
train_summary_writer
 = 
tf
 . 
summary
 . 
FileWriter
 ( 
train_writer_dir
 , 
graph
 = 
tf
 . 
get_default_graph
 ( ) )

864 
self
 . 
val_summary_writer
 = 
tf
 . 
summary
 . 
FileWriter
 ( 
val_writer_dir
 )

866 
print
 ( 'fuck6!' )

867 
summ
 = 
tf
 . 
summary
 . 
merge_all
 ( )

868 
self
 . 
summ
 = 
summ

870 
self
 . 
variables_initializer
 ( )

872 
print
 ( 'fuck7!' )

874 if 
continue_train
 == False :

875 
self
 . 
clean_weights
 ( 
train_targets
 )

877 
self
 . 
load_weights
 ( 
pre_trained_weights
 )

878 if 
continue_train
 : 
self
 . 
load_progress
 ( )

880 
tf
 . 
get_default_graph
 ( ) . 
finalize
 ( )

881 
print
 ( 'fuck8!' ) 
	}

883 def 
	$anchors_details
 ( 
self
 ) :

884 
pos_indes
 = 
self
 . 
batch_top_pos_inds

885 
top_inds
 = 
self
 . 
batch_top_inds

886 return 'anchors: positive= {} total= {}\n' . 
format
 ( 
len
 ( 
pos_indes
 ) , 
len
 ( 
top_inds
 ) ) 
	}

889 def 
	$rpn_poposal_details
 ( 
self
 ) :

891 
top_rois
 = 
self
 . 
batch_top_rois

892 
labels
 = 
self
 . 
batch_fuse_labels

893 
total
 = 
len
 ( 
top_rois
 )

894 
fp
 = 
np
 . 
sum
 ( 
labels
 == 0 )

895 
pos
 = 
total
 - 
fp

896 
info
 = 'RPN proposals: gt_boxes = {} positive= {} total= {}' . 
format
 ( 
len
 ( 
self
 . 
batch_gt_top_boxes
 ) , 
pos
 , 
total
 )

897 return 
info
 
	}

903 def 
	$log_fusion_net_target
 ( 
self
 , 
rgb
 , 
scope_name
 = '' ) :

904 
subdir
 = 
self
 . 
log_subdir

905 
top_image
 = 
self
 . 
top_image

906 
front_image
 = 
self
 . 
front_image

908 
img_rgb_rois
 = 
box
 . 
draw_boxes
 ( 
rgb
 , 
self
 . 
batch_rgb_rois
 [ 
np
 . 
where
 ( 
self
 . 
batch_fuse_labels
 == 0 ) , 1 : 5 ] [ 0 ] ,

909 
color
 = ( 0 , 0 , 255 ) , 
thickness
 = 1 )

910 
img_rgb_rois
 = 
box
 . 
draw_boxes
 ( 
img_rgb_rois
 ,

911 
self
 . 
batch_rgb_rois
 [ 
np
 . 
where
 ( 
self
 . 
batch_fuse_labels
 == 1 ) , 1 : 5 ] [ 0 ] ,

912 
color
 = ( 255 , 255 , 255 ) , 
thickness
 = 3 )

917 
top_img
 , 
cam_img
 , 
front_img
 = 
draw_fusion_target
 ( 
self
 . 
batch_fuse_labels
 , 
self
 . 
batch_fuse_targets
 , 
self
 . 
batch_rois3d
 ,

918 
top_image
 , 
rgb
 , 
front_image
 , [ [ 10 , 20 , 10 ] , [ 0 , 0 , 255 ] , [ 255 , 0 , 0 ] ] )

919 
front_img
 = 
front_img
 . 
transpose
 ( ( 1 , 0 , 2 ) ) [ : : - 1 , : : - 1 , : ]

922 
cv2
 . 
putText
 ( 
cam_img
 , 
self
 . 
rpn_poposal_details
 ( ) , ( 0 , 30 ) , 
cv2
 . 
FONT_HERSHEY_SIMPLEX
 , 0.7 , ( 0 , 255 , 100 ) , 1 , 
cv2
 . 
LINE_AA
 )

923 
cv2
 . 
putText
 ( 
top_img
 , 
self
 . 
rpn_poposal_details
 ( ) , ( 0 , 30 ) , 
cv2
 . 
FONT_HERSHEY_SIMPLEX
 , 0.7 , ( 0 , 255 , 100 ) , 1 , 
cv2
 . 
LINE_AA
 )

927 
self
 . 
summary_image
 ( 
img_rgb_rois
 , 
scope_name
 + '/img_rgb_rois' , 
step
 = 
self
 . 
n_global_step
 )

928 
self
 . 
summary_image
 ( 
cam_img
 , 
scope_name
 + '/fusion_target_rgb' , 
step
 = 
self
 . 
n_global_step
 )

929 
self
 . 
summary_image
 ( 
top_img
 , 
scope_name
 + '/fusion_target_top' , 
step
 = 
self
 . 
n_global_step
 )

930 
self
 . 
summary_image
 ( 
front_img
 , 
scope_name
 + '/fusion_target_front' , 
step
 = 
self
 . 
n_global_step
 ) 
	}

934 def 
	$log_prediction
 ( 
self
 , 
batch_top_view
 , 
batch_front_view
 , 
batch_rgb_images
 ,

935 
batch_gt_labels
 = None , 
batch_gt_boxes3d
 = None , 
print_iou
 = False ,

936 
log_rpn
 = False , 
step
 = None , 
scope_name
 = '' , 
score_threshold
 = 0.75 ) :

937 
boxes3d
 , 
lables
 , 
_
 = 
self
 . 
predict
 ( 
batch_top_view
 , 
batch_front_view
 , 
batch_rgb_images
 , 
score_threshold
 = 
score_threshold
 )

938 
self
 . 
predict_log
 ( 
self
 . 
log_subdir
 , 
log_rpn
 = 
log_rpn
 , 
step
 = 
step
 , 
scope_name
 = 
scope_name
 , 
gt_boxes3d
 = 
batch_gt_boxes3d
 [ 0 ] )

940 if 
type
 ( 
batch_gt_boxes3d
 ) == 
np
 . 
ndarray
 and 
type
 ( 
batch_gt_labels
 ) == 
np
 . 
ndarray
 :

941 
inds
 = 
np
 . 
where
 ( 
batch_gt_labels
 [ 0 ] != 0 )

943 
iou
 = 
box
 . 
boxes3d_score_iou
 ( 
batch_gt_boxes3d
 [ 0 ] [ 
inds
 ] , 
boxes3d
 )

944 
tag
 = 
os
 . 
path
 . 
join
 ( 
scope_name
 , 'IOU' )

945 
self
 . 
summary_scalar
 ( 
value
 = 
iou
 , 
tag
 = 
tag
 , 
step
 = 
self
 . 
n_global_step
 )

946 except 
ValueError
 :

947 
iou
 = - 1

948 
print
 ( "waring :" , 
sys
 . 
exc_info
 ( ) [ 0 ] )

949 if 
print_iou
 : 
self
 . 
log_msg
 . 
write
 ( '\n %s iou: %.5f\n' % ( 
scope_name
 , 
iou
 ) ) 
	}

952 def 
	$log_info
 ( 
self
 , 
subdir
 , 
info
 ) :

953 
dir
 = 
os
 . 
path
 . 
join
 ( 
cfg
 . 
LOG_DIR
 , 
subdir
 )

954 
os
 . 
makedirs
 ( 
dir
 , 
exist_ok
 = True )

955 with 
open
 ( 
os
 . 
path
 . 
join
 ( 
dir
 , 'info.txt' ) , 'w' ) as 
info_file
 :

956 
info_file
 . 
write
 ( 
info
 ) 
	}

958 def 
	$save_progress
 ( 
self
 ) :

959 
print
 ( 'Save progress !' )

960 
path
 = 
os
 . 
path
 . 
join
 ( 
cfg
 . 
LOG_DIR
 , 'train_progress' , 
self
 . 
tag
 , 'progress.data' )

961 
os
 . 
makedirs
 ( 
os
 . 
path
 . 
dirname
 ( 
path
 ) , 
exist_ok
 = True )

962 
pickle
 . 
dump
 ( 
self
 . 
n_global_step
 , 
open
 ( 
path
 , "wb" ) ) 
	}

965 def 
	$load_progress
 ( 
self
 ) :

966 
path
 = 
os
 . 
path
 . 
join
 ( 
cfg
 . 
LOG_DIR
 , 'train_progress' , 
self
 . 
tag
 , 'progress.data' )

967 if 
os
 . 
path
 . 
isfile
 ( 
path
 ) :

968 
self
 . 
n_global_step
 = 
pickle
 . 
load
 ( 
open
 ( 
path
 , 'rb' ) )

969 
print
 ( '\nLoad progress success at {}!' . 
format
 ( 
self
 . 
n_global_step
 ) )

971 
self
 . 
n_global_step
 = 0

972 
print
 ( '\nCan not found progress file!, start at {}' . 
format
 ( 
self
 . 
n_global_step
 ) ) 
	}

975 def 
	$__call__
 ( 
self
 , 
max_iter
 = 1000 , 
train_set
 = None , 
validation_set
 = None ) :

977 
sess
 = 
self
 . 
sess

978 
net
 = 
self
 . 
net

980 with 
sess
 . 
as_default
 ( ) :

986 
validation_step
 = 100

987 
ckpt_save_step
 = 1000

988 
self
 . 
iter_debug
 = 500

989 
summary_step
 = 200

992 if 
cfg
 . 
TRAINING_TIMER
 :

993 
time_it
 = 
timer
 ( )

996 
self
 . 
log_msg
 . 
write
 ( 'iter |  top_cls_loss   reg_loss   |  fuse_cls_loss  reg_loss  total |  \n' )

997 
self
 . 
log_msg
 . 
write
 ( '-------------------------------------------------------------------------------------\n' )

999 
init_step
 = 
self
 . 
n_global_step

1001 for 
iter
 in 
range
 ( 
init_step
 , 
init_step
 + 
max_iter
 ) :

1002 
self
 . 
log_msg
 . 
write
 ( 'Current iterations/Total iterations: {}/{}\n' . 
format
 ( 
iter
 , 
init_step
 + 
max_iter
 ) )

1004 
is_validation
 = False

1005 
summary_it
 = False

1006 
summary_runmeta
 = False

1007 
print_loss
 = False

1008 
log_this_iter
 = False

1009 
do_optimize
 = False

1012 if 
iter
 % 
validation_step
 == 0 : 
summary_it
 , 
is_validation
 , 
print_loss
 = True , True , True

1013 if ( 
iter
 + 1 ) % 
validation_step
 == 0 : 
summary_it
 , 
print_loss
 = True , True

1014 if 
iter
 % 20 == 0 : 
print_loss
 = True

1016 if 1 and 
iter
 % 
summary_step
 == 0 : 
summary_it
 , 
summary_runmeta
 = True , True

1018 if 
iter
 % 
self
 . 
iter_debug
 == 0 or ( 
iter
 + 1 ) % 
self
 . 
iter_debug
 == 0 :

1019 
log_this_iter
 = True

1020 
print
 ( 'Summary log image' )

1021 if 
iter
 % 
self
 . 
iter_debug
 == 0 : 
is_validation
 = False

1022 else : 
is_validation
 = True

1024 
data_set
 = 
self
 . 
validation_set
 if 
is_validation
 else 
self
 . 
train_set

1025 
self
 . 
default_summary_writer
 = 
self
 . 
val_summary_writer
 if 
is_validation
 else 
self
 . 
train_summary_writer

1027 
step_name
 = 'validation' if 
is_validation
 else 'training'

1037 
self
 . 
batch_rgb_images
 , 
self
 . 
batch_top_view
 , 
self
 . 
batch_front_view
 ,

1038 
self
 . 
batch_gt_labels
 , 
self
 . 
batch_gt_boxes3d
 , 
self
 . 
frame_id
 =

1039 
data_set
 . 
load
 ( )

1042 if 
log_this_iter
 :

1043 
self
 . 
time_str
 = 
strftime
 ( "%Y_%m_%d_%H_%M" , 
localtime
 ( ) )

1044 
self
 . 
frame_info
 = 
data_set
 . 
get_frame_info
 ( )

1045 
self
 . 
log_subdir
 = 
step_name
 + '/' + '{}_{}_{}' . 
format
 ( 
self
 . 
tag
 , 
iter
 , 
self
 . 
time_str
 )

1046 
top_image
 = 
data
 . 
draw_top_image
 ( 
self
 . 
batch_top_view
 [ 0 ] )

1047 
self
 . 
top_image
 = 
self
 . 
top_image_padding
 ( 
top_image
 )

1048 
self
 . 
front_image
 = 
data
 . 
draw_front_image
 ( 
self
 . 
batch_front_view
 [ 0 ] )

1052 if not 
iter
 % 
self
 . 
batch_size
 :

1053 
do_optimize
 = True

1056 
t_cls_loss
 , 
t_reg_loss
 , 
f_cls_loss
 , 
f_reg_loss
 =

1057 
self
 . 
fit_iteration
 ( 
self
 . 
batch_rgb_images
 , 
self
 . 
batch_top_view
 , 
self
 . 
batch_front_view
 ,

1058 
self
 . 
batch_gt_labels
 , 
self
 . 
batch_gt_boxes3d
 , 
self
 . 
frame_id
 ,

1059 
is_validation
 = 
is_validation
 , 
summary_it
 = 
summary_it
 ,

1060 
summary_runmeta
 = 
summary_runmeta
 , 
log
 = 
log_this_iter
 , 
do_optimize
 = 
do_optimize
 )

1061 if 
sum
 ( 
np
 . 
isnan
 ( [ 
t_cls_loss
 , 
t_reg_loss
 , 
f_cls_loss
 , 
f_reg_loss
 ] ) ) > 0 :

1062 
print
 ( 'have nan loss!' )

1065 if 
print_loss
 :

1066 
self
 . 
log_msg
 . 
write
 ( '%10s: |  %5d  %0.5f   %0.5f   |   %0.5f   %0.5f \n' %

1067 ( 
step_name
 , 
self
 . 
n_global_step
 , 
t_cls_loss
 , 
t_reg_loss
 , 
f_cls_loss
 , 
f_reg_loss
 ) )

1069 if 
iter
 % 
ckpt_save_step
 == 0 :

1070 
print
 ( 'start save weights' )

1071 
self
 . 
save_weights
 ( 
self
 . 
train_target
 , 
iter
 )

1072 
print
 ( 'Save target at {}' . 
format
 ( 
self
 . 
ckpt_dir
 ) )

1074 if 
cfg
 . 
TRAINING_TIMER
 :

1075 
self
 . 
log_msg
 . 
write
 ( 'It takes %0.2f secs to train %d iterations. \n' %

1076 ( 
time_it
 . 
time_diff_per_n_loops
 ( ) , 
ckpt_save_step
 ) )

1077 
self
 . 
gc
 ( )

1078 
self
 . 
n_global_step
 += 1

1079 except 
KeyboardInterrupt
 :

1080 if 
cfg
 . 
TRAINING_TIMER
 :

1081 
self
 . 
log_msg
 . 
write
 ( 'It takes %0.2f secs to train until now. \n' %

1082 ( 
time_it
 . 
total_time
 ( ) ) )

1084 
self
 . 
save_progress
 ( )

1086 
self
 . 
save_progress
 ( )

1090 if 
cfg
 . 
TRAINING_TIMER
 :

1091 
self
 . 
log_msg
 . 
write
 ( 'It takes %0.2f secs to train the dataset. \n' %

1092 ( 
time_it
 . 
total_time
 ( ) ) )

1093 
self
 . 
save_progress
 ( )

1095 
print
 ( 'Save target at {}' . 
format
 ( 
self
 . 
ckpt_dir
 ) ) 
	}

1101 def 
	$fit_iteration
 ( 
self
 , 
batch_rgb_images
 , 
batch_top_view
 , 
batch_front_view
 ,

1102 
batch_gt_labels
 , 
batch_gt_boxes3d
 , 
frame_id
 , 
is_validation
 = False ,

1103 
summary_it
 = False , 
summary_runmeta
 = False , 
log
 = False , 
do_optimize
 = False ) :

1105 
net
 = 
self
 . 
net

1106 
sess
 = 
self
 . 
sess

1109 
top_cls_loss
 = 
net
 [ 'top_cls_loss' ]

1110 
top_reg_loss
 = 
net
 [ 'top_reg_loss' ]

1111 
fuse_cls_loss
 = 
net
 [ 'fuse_cls_loss' ]

1112 
fuse_reg_loss
 = 
net
 [ 'fuse_reg_loss' ]

1113 
top_cls_loss_cur
 = 
net
 [ 'top_cls_loss_cur' ]

1114 
top_reg_loss_cur
 = 
net
 [ 'top_reg_loss_cur' ]

1115 
fuse_cls_loss_cur
 = 
net
 [ 'fuse_cls_loss_cur' ]

1116 
fuse_reg_loss_cur
 = 
net
 [ 'fuse_reg_loss_cur' ]

1119 
self
 . 
batch_gt_top_boxes
 = 
data
 . 
box3d_to_top_box
 ( 
batch_gt_boxes3d
 [ 0 ] )

1122 
self
 . 
anchors_inside_inds
 = 
remove_empty_anchor
 ( 
batch_top_view
 [ 0 ] , 
self
 . 
top_view_anchors
 , 
cfg
 . 
REMOVE_THRES
 )

1140 
self
 . 
batch_top_inds
 , 
self
 . 
batch_top_pos_inds
 , 
self
 . 
batch_top_labels
 , 
self
 . 
batch_top_targets
 =

1141 
rpn_target
 ( 
self
 . 
top_view_anchors
 , 
self
 . 
anchors_inside_inds
 , 
batch_gt_labels
 [ 0 ] ,

1142 
self
 . 
batch_gt_top_boxes
 )

1144 if 
len
 ( 
self
 . 
batch_top_pos_inds
 ) <= 0 :

1148 if 
set
 ( [ 
mv3d_net
 . 
top_view_rpn_name
 ] ) == 
set
 ( 
self
 . 
train_target
 ) :

1150 
fd1
 = {

1151 
net
 [ 'top_cls_loss_sum' ] : 
self
 . 
top_cls_loss_sum
 ,

1152 
net
 [ 'top_reg_loss_sum' ] : 
self
 . 
top_reg_loss_sum
 ,

1153 
net
 [ 'fuse_cls_loss_sum' ] : 
self
 . 
fuse_cls_loss_sum
 ,

1154 
net
 [ 'fuse_reg_loss_sum' ] : 
self
 . 
fuse_reg_loss_sum
 ,

1156 
net
 [ 'top_view' ] : 
batch_top_view
 ,

1157 
net
 [ 'top_anchors' ] : 
self
 . 
top_view_anchors
 ,

1158 
net
 [ 'top_inside_inds' ] : 
self
 . 
anchors_inside_inds
 ,

1160 
blocks
 . 
IS_TRAIN_PHASE
 : True ,

1161 
K
 . 
learning_phase
 ( ) : 1

1165 
self
 . 
batch_proposals
 , 
self
 . 
batch_proposal_scores
 , 
self
 . 
batch_top_features
 =

1166 
sess
 . 
run
 ( [ 
net
 [ 'proposals' ] , 
net
 [ 'proposal_scores' ] , 
net
 [ 'top_features' ] ] , 
fd1
 )

1168 
fd2
 = {

1169 ** 
fd1
 ,

1170 
net
 [ 'top_inds' ] : 
self
 . 
batch_top_inds
 ,

1171 
net
 [ 'top_pos_inds' ] : 
self
 . 
batch_top_pos_inds
 ,

1172 
net
 [ 'top_labels' ] : 
self
 . 
batch_top_labels
 ,

1173 
net
 [ 'top_targets' ] : 
self
 . 
batch_top_targets
 ,

1175 if 
summary_it
 :

1176 
run_options
 = None

1177 
run_metadata
 = None

1179 if 
is_validation
 :

1180 
t_cls_loss
 , 
t_reg_loss
 , 
tb_sum_val
 =

1181 
sess
 . 
run
 ( [ 
top_cls_loss_cur
 , 
top_reg_loss_cur
 , 
self
 . 
summ
 ] , 
fd2
 )

1182 
self
 . 
val_summary_writer
 . 
add_summary
 ( 
tb_sum_val
 , 
self
 . 
n_global_step
 )

1183 
print
 ( 'added validation summary ' )

1185 if 
summary_runmeta
 :

1186 
run_options
 = 
tf
 . 
RunOptions
 ( 
trace_level
 = 
tf
 . 
RunOptions
 . 
FULL_TRACE
 )

1187 
run_metadata
 = 
tf
 . 
RunMetadata
 ( )

1189 if 
do_optimize
 :

1190 
_
 , 
t_cls_loss
 , 
t_reg_loss
 , 
tb_sum_val
 =

1191 
sess
 . 
run
 ( [ 
self
 . 
solver_step
 , 
top_cls_loss_cur
 , 
top_reg_loss_cur
 ,

1192 
self
 . 
summ
 ] , 
feed_dict
 = 
fd2
 , 
options
 = 
run_options
 , 
run_metadata
 = 
run_metadata
 )

1194 
t_cls_loss
 , 
t_reg_loss
 , 
tb_sum_val
 =

1195 
sess
 . 
run
 ( [ 
top_cls_loss_cur
 , 
top_reg_loss_cur
 ,

1196 
self
 . 
summ
 ] , 
feed_dict
 = 
fd2
 , 
options
 = 
run_options
 , 
run_metadata
 = 
run_metadata
 )

1198 
self
 . 
train_summary_writer
 . 
add_summary
 ( 
tb_sum_val
 , 
self
 . 
n_global_step
 )

1199 
print
 ( 'added training summary ' )

1201 if 
summary_runmeta
 :

1202 
self
 . 
train_summary_writer
 . 
add_run_metadata
 ( 
run_metadata
 , 'step%d' % 
self
 . 
n_global_step
 )

1203 
print
 ( 'added runtime metadata.' )

1206 if 
is_validation
 or not 
do_optimize
 :

1207 
t_cls_loss
 , 
t_reg_loss
 =

1208 
sess
 . 
run
 ( [ 
top_cls_loss_cur
 , 
top_reg_loss_cur
 ] , 
fd2
 )

1210 
_
 , 
t_cls_loss
 , 
t_reg_loss
 =

1211 
sess
 . 
run
 ( [ 
self
 . 
solver_step
 , 
top_cls_loss_cur
 , 
top_reg_loss_cur
 ] ,

1212 
feed_dict
 = 
fd2
 )

1215 if 
do_optimize
 :

1216 
self
 . 
top_cls_loss_sum
 = 
self
 . 
top_reg_loss_sum
 = 
self
 . 
fuse_cls_loss_sum
 = 
self
 . 
fuse_reg_loss_sum
 = 0.0

1218 
self
 . 
top_cls_loss_sum
 += 
t_cls_loss

1219 
self
 . 
top_reg_loss_sum
 += 
t_reg_loss

1220 
self
 . 
fuse_cls_loss_sum
 += 0.0

1221 
self
 . 
fuse_reg_loss_sum
 += 0.0

1223 return 
t_cls_loss
 , 
t_reg_loss
 , 0.0 , 0.0

1227 
fd1
 = {

1228 
net
 [ 'top_cls_loss_sum' ] : 
self
 . 
top_cls_loss_sum
 ,

1229 
net
 [ 'top_reg_loss_sum' ] : 
self
 . 
top_reg_loss_sum
 ,

1230 
net
 [ 'fuse_cls_loss_sum' ] : 
self
 . 
fuse_cls_loss_sum
 ,

1231 
net
 [ 'fuse_reg_loss_sum' ] : 
self
 . 
fuse_reg_loss_sum
 ,

1233 
net
 [ 'top_view' ] : 
batch_top_view
 ,

1234 
net
 [ 'top_anchors' ] : 
self
 . 
top_view_anchors
 ,

1235 
net
 [ 'top_inside_inds' ] : 
self
 . 
anchors_inside_inds
 ,

1237 
blocks
 . 
IS_TRAIN_PHASE
 : True ,

1238 
K
 . 
learning_phase
 ( ) : 1

1241 
self
 . 
batch_proposals
 , 
self
 . 
batch_proposal_scores
 , 
self
 . 
batch_top_features
 =

1242 
sess
 . 
run
 ( [ 
net
 [ 'proposals' ] , 
net
 [ 'proposal_scores' ] , 
net
 [ 'top_features' ] ] , 
fd1
 )

1244 if 
log
 :

1245 
step_name
 = 'validation' if 
is_validation
 else 'train'

1246 
scope_name
 = '%s_iter_%06d' % ( 
step_name
 , 
self
 . 
n_global_step
 - ( 
self
 . 
n_global_step
 % 
self
 . 
iter_debug
 ) )

1247 
self
 . 
log_rpn
 ( 
step
 = 
self
 . 
n_global_step
 , 
scope_name
 = 
scope_name
 )

1252 
self
 . 
batch_top_rois
 , 
self
 . 
batch_fuse_labels
 , 
self
 . 
batch_fuse_targets
 =

1253 
fusion_target
 ( 
self
 . 
batch_proposals
 , 
batch_gt_labels
 [ 0 ] , 
self
 . 
batch_gt_top_boxes
 , 
batch_gt_boxes3d
 [ 0 ] )

1256 if 
len
 ( 
self
 . 
batch_top_rois
 ) <= 0 :

1261 
self
 . 
batch_rois3d
 = 
project_to_roi3d
 ( 
self
 . 
batch_top_rois
 )

1262 
self
 . 
batch_front_rois
 = 
project_to_front_roi
 ( 
self
 . 
batch_rois3d
 )

1263 
self
 . 
batch_rgb_rois
 = 
project_to_rgb_roi
 ( 
self
 . 
batch_rois3d
 )

1265 if 
log
 : 
self
 . 
log_fusion_net_target
 ( 
batch_rgb_images
 [ 0 ] , 
scope_name
 = 
scope_name
 )

1266 if 
log
 :

1267 
log_info_str
 = 'frame info: ' + 
self
 . 
frame_info
 + '\n'

1268 
log_info_str
 += 
self
 . 
anchors_details
 ( )

1269 
log_info_str
 += 
self
 . 
rpn_poposal_details
 ( )

1270 
self
 . 
log_info
 ( 
self
 . 
log_subdir
 , 
log_info_str
 )

1273 
fd2
 = {

1274 ** 
fd1
 ,

1276 
net
 [ 'top_view' ] : 
batch_top_view
 ,

1277 
net
 [ 'front_view' ] : 
batch_front_view
 ,

1278 
net
 [ 'rgb_images' ] : 
batch_rgb_images
 ,

1280 
net
 [ 'top_rois' ] : 
self
 . 
batch_top_rois
 ,

1281 
net
 [ 'front_rois' ] : 
self
 . 
batch_front_rois
 ,

1282 
net
 [ 'rgb_rois' ] : 
self
 . 
batch_rgb_rois
 ,

1284 
net
 [ 'top_inds' ] : 
self
 . 
batch_top_inds
 ,

1285 
net
 [ 'top_pos_inds' ] : 
self
 . 
batch_top_pos_inds
 ,

1286 
net
 [ 'top_labels' ] : 
self
 . 
batch_top_labels
 ,

1287 
net
 [ 'top_targets' ] : 
self
 . 
batch_top_targets
 ,

1289 
net
 [ 'fuse_labels' ] : 
self
 . 
batch_fuse_labels
 ,

1290 
net
 [ 'fuse_targets' ] : 
self
 . 
batch_fuse_targets
 ,

1293 if 
self
 . 
debug_mode
 :

1294 
print
 ( '\n\nstart debug mode\n\n' )

1295 
debug_sess
 = 
tf_debug
 . 
LocalCLIDebugWrapperSession
 ( 
sess
 )

1296 
t_cls_loss
 , 
t_reg_loss
 , 
f_cls_loss
 , 
f_reg_loss
 =

1297 
debug_sess
 . 
run
 ( [ 
top_cls_loss_cur
 , 
top_reg_loss_cur
 , 
fuse_cls_loss_cur
 , 
fuse_reg_loss_cur
 ] , 
fd2
 )

1300 if 
summary_it
 :

1301 
run_options
 = None

1302 
run_metadata
 = None

1304 if 
is_validation
 :

1305 
t_cls_loss
 , 
t_reg_loss
 , 
f_cls_loss
 , 
f_reg_loss
 , 
tb_sum_val
 =

1306 
sess
 . 
run
 ( [ 
top_cls_loss_cur
 , 
top_reg_loss_cur
 , 
fuse_cls_loss_cur
 , 
fuse_reg_loss_cur
 , 
self
 . 
summ
 ] , 
fd2
 )

1307 
self
 . 
val_summary_writer
 . 
add_summary
 ( 
tb_sum_val
 , 
self
 . 
n_global_step
 )

1308 
print
 ( 'added validation  summary ' )

1310 if 
summary_runmeta
 :

1311 
run_options
 = 
tf
 . 
RunOptions
 ( 
trace_level
 = 
tf
 . 
RunOptions
 . 
FULL_TRACE
 )

1312 
run_metadata
 = 
tf
 . 
RunMetadata
 ( )

1314 if 
do_optimize
 :

1315 
_
 , 
t_cls_loss
 , 
t_reg_loss
 , 
f_cls_loss
 , 
f_reg_loss
 , 
tb_sum_val
 =

1316 
sess
 . 
run
 ( [ 
self
 . 
solver_step
 , 
top_cls_loss_cur
 , 
top_reg_loss_cur
 , 
fuse_cls_loss_cur
 , 
fuse_reg_loss_cur
 ,

1317 
self
 . 
summ
 ] , 
feed_dict
 = 
fd2
 , 
options
 = 
run_options
 , 
run_metadata
 = 
run_metadata
 )

1319 
t_cls_loss
 , 
t_reg_loss
 , 
f_cls_loss
 , 
f_reg_loss
 , 
tb_sum_val
 =

1320 
sess
 . 
run
 ( [ 
top_cls_loss_cur
 , 
top_reg_loss_cur
 , 
fuse_cls_loss_cur
 , 
fuse_reg_loss_cur
 ,

1321 
self
 . 
summ
 ] , 
feed_dict
 = 
fd2
 , 
options
 = 
run_options
 , 
run_metadata
 = 
run_metadata
 )

1323 
self
 . 
train_summary_writer
 . 
add_summary
 ( 
tb_sum_val
 , 
self
 . 
n_global_step
 )

1324 
print
 ( 'added training summary ' )

1326 if 
summary_runmeta
 :

1327 
self
 . 
train_summary_writer
 . 
add_run_metadata
 ( 
run_metadata
 , 'step%d' % 
self
 . 
n_global_step
 )

1328 
print
 ( 'added runtime metadata.' )

1331 if 
is_validation
 or not 
do_optimize
 :

1332 
t_cls_loss
 , 
t_reg_loss
 , 
f_cls_loss
 , 
f_reg_loss
 =

1333 
sess
 . 
run
 ( [ 
top_cls_loss_cur
 , 
top_reg_loss_cur
 , 
fuse_cls_loss_cur
 , 
fuse_reg_loss_cur
 ] , 
fd2
 )

1335 
_
 , 
t_cls_loss
 , 
t_reg_loss
 , 
f_cls_loss
 , 
f_reg_loss
 =

1336 
sess
 . 
run
 ( [ 
self
 . 
solver_step
 , 
top_cls_loss_cur
 , 
top_reg_loss_cur
 , 
fuse_cls_loss_cur
 , 
fuse_reg_loss_cur
 ] ,

1337 
feed_dict
 = 
fd2
 )

1338 if 
log
 : 
self
 . 
log_prediction
 ( 
batch_top_view
 , 
batch_front_view
 , 
batch_rgb_images
 ,

1339 
batch_gt_labels
 , 
batch_gt_boxes3d
 ,

1340 
step
 = 
self
 . 
n_global_step
 , 
scope_name
 = 
scope_name
 , 
print_iou
 = True , 
score_threshold
 = 
cfg
 . 
RCNN_NMS_THRESHOLD
 )

1343 if 
do_optimize
 :

1344 
self
 . 
top_cls_loss_sum
 = 
self
 . 
top_reg_loss_sum
 = 
self
 . 
fuse_cls_loss_sum
 = 
self
 . 
fuse_reg_loss_sum
 = 0.0

1346 
self
 . 
top_cls_loss_sum
 += 
t_cls_loss

1347 
self
 . 
top_reg_loss_sum
 += 
t_reg_loss

1348 
self
 . 
fuse_cls_loss_sum
 += 
f_cls_loss

1349 
self
 . 
fuse_reg_loss_sum
 += 
f_reg_loss

1351 return 
t_cls_loss
 , 
t_reg_loss
 , 
f_cls_loss
 , 
f_reg_loss
 
	}

1354 class 
	cTester_3DOP
 ( 
MV3D
 ) :

1355 def 
	$__init__
 ( 
self
 , 
top_shape
 , 
front_shape
 , 
rgb_shape
 , 
weight_dir
 = None , 
log_tag
 = None , 
weights_tag
 = None , 
weights_name
 = 'default' ) :

1357 
self
 . 
weight_dir
 = 
weight_dir

1358 
MV3D
 . 
__init__
 ( 
self
 , 
top_shape
 , 
front_shape
 , 
rgb_shape
 , 
log_tag
 = 
log_tag
 , 
weigths_dir
 = 
self
 . 
weight_dir
 )

1359 
self
 . 
variables_initializer
 ( )

1360 
self
 . 
load_weights
 ( [ 
mv3d_net
 . 
top_view_rpn_name
 , 
mv3d_net
 . 
imfeature_net_name
 , 
mv3d_net
 . 
fusion_net_name
 , 
mv3d_net
 . 
frontfeature_net_name
 ] )

1362 
tb_dir
 = 
os
 . 
path
 . 
join
 ( 
cfg
 . 
LOG_DIR
 , 'tensorboard' , 
self
 . 
tb_dir
 + '_tracking' )

1363 
self
 . 
default_summary_writer
 = 
tf
 . 
summary
 . 
FileWriter
 ( 
tb_dir
 )

1364 
self
 . 
n_log_scope
 = 0

1365 
self
 . 
n_max_log_per_scope
 = 10 
	}

1368 def 
	$__call__
 ( 
self
 , 
proposals
 , 
proposal_scores
 , 
top_view
 , 
front_view
 , 
rgb_image
 ) :

1370 return 
self
 . 
predict_3dop
 ( 
proposals
 , 
proposal_scores
 , 
top_view
 , 
front_view
 , 
rgb_image
 ) 
	}

1372 def 
	$dump_log
 ( 
self
 , 
log_subdir
 , 
n_frame
 ) :

1373 
n_start
 = 
n_frame
 - ( 
n_frame
 % ( 
self
 . 
n_max_log_per_scope
 ) )

1374 
n_end
 = 
n_start
 + 
self
 . 
n_max_log_per_scope
 - 1

1376 
scope_name
 = 'predict_%d_%d' % ( 
n_start
 , 
n_end
 )

1377 
self
 . 
predict_log
 ( 
log_subdir
 = 
log_subdir
 , 
log_rpn
 = True , 
step
 = 
n_frame
 , 
scope_name
 = 
scope_name
 ) 
	}

1380 class 
	cTester_RPN
 ( 
MV3D
 ) :

1381 def 
	$__init__
 ( 
self
 , 
top_shape
 , 
front_shape
 , 
rgb_shape
 , 
weight_dir
 = None , 
log_tag
 = None , 
weights_tag
 = None , 
weights_name
 = 'default' ) :

1383 
self
 . 
weight_dir
 = 
weight_dir

1384 
MV3D
 . 
__init__
 ( 
self
 , 
top_shape
 , 
front_shape
 , 
rgb_shape
 , 
log_tag
 = 
log_tag
 , 
weigths_dir
 = 
self
 . 
weight_dir
 )

1385 
self
 . 
variables_initializer
 ( )

1386 
self
 . 
load_weights
 ( [ 
mv3d_net
 . 
top_view_rpn_name
 , 
mv3d_net
 . 
imfeature_net_name
 , 
mv3d_net
 . 
fusion_net_name
 , 
mv3d_net
 . 
frontfeature_net_name
 ] )

1388 
tb_dir
 = 
os
 . 
path
 . 
join
 ( 
cfg
 . 
LOG_DIR
 , 'tensorboard' , 
self
 . 
tb_dir
 + '_tracking' )

1389 
self
 . 
default_summary_writer
 = 
tf
 . 
summary
 . 
FileWriter
 ( 
tb_dir
 )

1390 
self
 . 
n_log_scope
 = 0

1391 
self
 . 
n_max_log_per_scope
 = 10 
	}

1394 def 
	$__call__
 ( 
self
 , 
top_view
 , 
front_view
 , 
rgb_image
 ) :

1395 
self
 . 
lables
 = [ ]

1397 
self
 . 
top_view
 = 
top_view

1398 
self
 . 
rgb_image
 = 
rgb_image

1399 
self
 . 
front_view
 = 
front_view

1400 
fd1
 = {

1401 
self
 . 
net
 [ 'top_view' ] : 
self
 . 
top_view
 ,

1402 
self
 . 
net
 [ 'top_anchors' ] : 
self
 . 
top_view_anchors
 ,

1403 
self
 . 
net
 [ 'top_inside_inds' ] : 
self
 . 
anchors_inside_inds
 ,

1404 
blocks
 . 
IS_TRAIN_PHASE
 : False ,

1405 
K
 . 
learning_phase
 ( ) : True

1408 
self
 . 
batch_proposals
 , 
self
 . 
batch_proposal_scores
 =

1409 
self
 . 
sess
 . 
run
 ( [ 
self
 . 
net
 [ 'proposals' ] , 
self
 . 
net
 [ 'proposal_scores' ] ] , 
fd1
 )

1410 
self
 . 
batch_proposal_scores
 = 
np
 . 
reshape
 ( 
self
 . 
batch_proposal_scores
 , ( - 1 ) )

1411 
self
 . 
top_rois
 = 
self
 . 
batch_proposals

1412 if 
len
 ( 
self
 . 
top_rois
 ) == 0 :

1413 return 
np
 . 
zeros
 ( ( 0 , 8 , 3 ) ) , [ ]

1415 
self
 . 
rois3d
 = 
project_to_roi3d
 ( 
self
 . 
top_rois
 )

1418 
self
 . 
front_rois
 = 
project_to_front_roi
 ( 
self
 . 
rois3d
 )

1419 
self
 . 
rgb_rois
 = 
project_to_rgb_roi
 ( 
self
 . 
rois3d
 )

1420 return 
self
 . 
rois3d
 , 
self
 . 
rgb_rois
 , 
self
 . 
top_rois
 , 
self
 . 
batch_proposal_scores
 
	}

1422 def 
	$dump_log
 ( 
self
 , 
log_subdir
 , 
n_frame
 ) :

1423 
n_start
 = 
n_frame
 - ( 
n_frame
 % ( 
self
 . 
n_max_log_per_scope
 ) )

1424 
n_end
 = 
n_start
 + 
self
 . 
n_max_log_per_scope
 - 1

1426 
scope_name
 = 'predict_%d_%d' % ( 
n_start
 , 
n_end
 )

1427 
self
 . 
predict_log
 ( 
log_subdir
 = 
log_subdir
 , 
log_rpn
 = True , 
step
 = 
n_frame
 , 
scope_name
 = 
scope_name
 ) 
	}

1429 class 
	cTester_RPN_Target
 ( 
MV3D
 ) :

1430 def 
	$__init__
 ( 
self
 , 
top_shape
 , 
front_shape
 , 
rgb_shape
 , 
weight_dir
 = None , 
log_tag
 = None , 
weights_tag
 = None , 
weights_name
 = 'default' ) :

1432 
self
 . 
top_shape
 = 
top_shape

1433 
self
 . 
weight_dir
 = 
weight_dir

1434 
MV3D
 . 
__init__
 ( 
self
 , 
top_shape
 , 
front_shape
 , 
rgb_shape
 , 
log_tag
 = 
log_tag
 , 
weigths_dir
 = 
self
 . 
weight_dir
 )

1435 
self
 . 
variables_initializer
 ( )

1436 
self
 . 
load_weights
 ( [ 
mv3d_net
 . 
top_view_rpn_name
 , 
mv3d_net
 . 
imfeature_net_name
 , 
mv3d_net
 . 
fusion_net_name
 , 
mv3d_net
 . 
frontfeature_net_name
 ] )

1438 
tb_dir
 = 
os
 . 
path
 . 
join
 ( 
cfg
 . 
LOG_DIR
 , 'tensorboard' , 
self
 . 
tb_dir
 + '_tracking' )

1439 
self
 . 
default_summary_writer
 = 
tf
 . 
summary
 . 
FileWriter
 ( 
tb_dir
 )

1440 
self
 . 
n_log_scope
 = 0

1441 
self
 . 
n_max_log_per_scope
 = 10 
	}

1443 def 
	$anchors_details
 ( 
self
 ) :

1444 
pos_indes
 = 
self
 . 
batch_top_pos_inds

1445 
top_inds
 = 
self
 . 
batch_top_inds

1446 return 'anchors: positive= {} total= {}\n' . 
format
 ( 
len
 ( 
pos_indes
 ) , 
len
 ( 
top_inds
 ) ) 
	}

1448 def 
	$__call__
 ( 
self
 , 
top_view
 , 
front_view
 , 
rgb_image
 , 
bases
 , 
gt_boxes3d
 = [ ] , 
gt_labels
 = [ ] ) :

1449 
self
 . 
lables
 = [ ]

1451 
self
 . 
top_view
 = 
top_view

1452 
self
 . 
rgb_image
 = 
rgb_image

1453 
self
 . 
front_view
 = 
front_view

1455 
self
 . 
bases
 = 
bases

1457 
self
 . 
batch_gt_boxes3d
 = 
gt_boxes3d

1458 
self
 . 
batch_gt_labels
 = 
gt_labels

1459 if 
len
 ( 
gt_boxes3d
 ) > 0 :

1460 
self
 . 
batch_gt_top_boxes
 = 
data
 . 
box3d_to_top_box
 ( 
self
 . 
batch_gt_boxes3d
 [ 0 ] )

1463 
self
 . 
top_rpn_stride
 = 
self
 . 
net
 [ 'top_feature_rpn_stride' ]

1464 
top_feature_shape
 = 
get_top_feature_shape
 ( 
self
 . 
top_shape
 , 
self
 . 
top_rpn_stride
 )

1466 
self
 . 
top_view_anchors
 , 
self
 . 
anchors_inside_inds
 = 
make_anchors
 ( 
self
 . 
bases
 , 
self
 . 
top_rpn_stride
 , 
self
 . 
top_shape
 [ 0 : 2 ] , 
top_feature_shape
 [ 0 : 2 ] )

1467 
self
 . 
anchors_inside_inds
 = 
np
 . 
arange
 ( 0 , 
len
 ( 
self
 . 
top_view_anchors
 ) , 
dtype
 = 
np
 . 
int32
 )

1469 
self
 . 
batch_top_inds
 , 
self
 . 
batch_top_pos_inds
 , 
self
 . 
batch_top_labels
 , 
self
 . 
batch_top_targets
 =

1470 
rpn_target
 ( 
self
 . 
top_view_anchors
 , 
self
 . 
anchors_inside_inds
 , 
self
 . 
batch_gt_labels
 [ 0 ] ,

1471 
self
 . 
batch_gt_top_boxes
 )

1474 
top_image
 = 
data
 . 
draw_top_image
 ( 
self
 . 
top_view
 [ 0 ] )

1475 
top_image
 = 
self
 . 
top_image_padding
 ( 
top_image
 )

1476 
img_label
 = 
draw_rpn_labels
 ( 
top_image
 , 
self
 . 
top_view_anchors
 , 
self
 . 
batch_top_inds
 , 
self
 . 
batch_top_labels
 )

1477 
cv2
 . 
putText
 ( 
img_label
 , 
self
 . 
anchors_details
 ( ) , ( 0 , 30 ) , 
cv2
 . 
FONT_HERSHEY_SIMPLEX
 , 0.7 , ( 0 , 255 , 100 ) , 1 , 
cv2
 . 
LINE_AA
 )

1478 
self
 . 
summary_image
 ( 
img_label
 , 'test_rpn_target/img_rpn_label' , 
step
 = 0 )

1480 
img_gt
 = 
draw_rpn_gt
 ( 
top_image
 , 
self
 . 
batch_gt_top_boxes
 , 
self
 . 
batch_gt_labels
 )

1481 
self
 . 
summary_image
 ( 
img_gt
 , 'test_rpn_target/img_rpn_gt' , 
step
 = 0 )

1482 
self
 . 
summary_image
 ( 
img_gt
 , 'test_rpn_target/img_rpn_gt' , 
step
 = 0 )

1484 return 
len
 ( 
self
 . 
batch_top_inds
 ) , 
len
 ( 
self
 . 
batch_top_pos_inds
 ) 
	}


	@./raw_data.py

1 from 
	~typing
 import 
List
 , 
Tuple

2 import 
	~config

3 from 
	~config
 import 
cfg

4 import 
	~os

5 import 
	~numpy
 as 
np

6 import 
	~glob

7 import 
	~cv2

9 from 
	~kitti_data.pykitti.tracklet
 import 
parseXML
 , 
TRUNC_IN_IMAGE
 , 
TRUNC_TRUNCATED

11 import 
	~math

12 from 
	~config
 import 
cfg

13 from 
	~data
 import 
is_evaluation_dataset

16 class 
	cRawData
 ( 
object
 ) :

17 def 
	$__init__
 ( 
self
 ) :

18 pass 
	}

20 def 
	$get_synced_nframe
 ( 
self
 , 
dir_tag
 : 
str
 ) -> 
int
 :

21 
name
 = 
dir_tag
 . 
split
 ( '/' )

22 
path
 = 
os
 . 
path
 . 
join
 ( 
cfg
 . 
RAW_DATA_SETS_DIR
 , 
name
 [ 0 ] , 
name
 [ 1 ] , 'image_02' , 'data' , '*' )

23 return 
len
 ( 
glob
 . 
glob
 ( 
path
 ) ) 
	}

26 class 
	cImage
 ( 
RawData
 ) :

28 def 
	$__init__
 ( 
self
 , 
prefix
 : 
dict
 = None ) :

29 
RawData
 . 
__init__
 ( 
self
 )

30 
self
 . 
prefix
 = 
prefix

31 
self
 . 
files_path_mapping
 = 
self
 . 
get_paths_mapping
 ( ) 
	}

34 def 
	$load
 ( 
self
 , 
frame_tag
 : 
str
 ) -> 
np
 . 
ndarray
 :

35 return 
cv2
 . 
imread
 ( 
self
 . 
files_path_mapping
 [ 
frame_tag
 ] ) 
	}

37 def 
	$get_tags
 ( 
self
 ) -> [ 
str
 ] :

38 
tags
 = [ 
tag
 for 
tag
 in 
self
 . 
files_path_mapping
 ]

39 
tags
 . 
sort
 ( )

40 return 
tags
 
	}

44 def 
	$get_paths_mapping
 ( 
self
 ) :

45 
raw_dir
 = 
cfg
 . 
RAW_DATA_SETS_DIR

46 
mapping
 = { }

51 for 
dir1
 in 
glob
 . 
glob
 ( 
os
 . 
path
 . 
join
 ( 
raw_dir
 , '*' ) ) :

52 
name1
 = 
os
 . 
path
 . 
basename
 ( 
dir1
 )

53 if 
self
 . 
prefix
 is not None and 
name1
 not in 
self
 . 
prefix
 . 
keys
 ( ) :

57 for 
dir2
 in 
glob
 . 
glob
 ( 
os
 . 
path
 . 
join
 ( 
dir1
 , '*' ) ) :

59 
name2
 = 
os
 . 
path
 . 
basename
 ( 
dir2
 )

60 if 
name2
 . 
split
 ( '_' ) [ - 2 ] not in 
self
 . 
prefix
 [ 
name1
 ] :

64 
files_path
 = 
glob
 . 
glob
 ( 
os
 . 
path
 . 
join
 ( 
dir2
 , 'image_02' , 'data' , '*' ) )

65 
files_path
 . 
sort
 ( )

66 for 
i
 , 
file_path
 in 
enumerate
 ( 
files_path
 ) :

67 
key
 = '%s/%s/%05d' % ( 
name1
 , 
name2
 , 
i
 )

68 
mapping
 [ 
key
 ] = 
file_path

70 return 
mapping
 
	}

78 class 
	cTracklet
 ( 
RawData
 ) :

80 def 
	$__init__
 ( 
self
 , 
prefix
 : 
dict
 ) :

81 
RawData
 . 
__init__
 ( 
self
 )

82 
self
 . 
prefix
 = 
prefix

83 
self
 . 
frames_object
 = 
self
 . 
get_frames_objects
 ( ) 
	}

86 def 
	$load
 ( 
self
 , 
frame_tag
 : 
str
 ) :

87 
objs
 = 
self
 . 
frames_object
 [ 
frame_tag
 ]

89 return 
objs
 
	}

91 def 
	$get_tags
 ( 
self
 ) -> [ 
str
 ] :

92 
tags
 = [ 
tag
 for 
tag
 in 
self
 . 
frames_object
 ]

93 
tags
 . 
sort
 ( )

94 return 
tags
 
	}

96 def 
	$frame_tag_to_path
 ( 
self
 ) :

97 pass 
	}

99 def 
	$get_frames_objects
 ( 
self
 ) :

100 
raw_dir
 = 
cfg
 . 
RAW_DATA_SETS_DIR

101 
frames_objects
 = { }

104 for 
dir1
 in 
glob
 . 
glob
 ( 
os
 . 
path
 . 
join
 ( 
raw_dir
 , '*' ) ) :

105 
name1
 = 
os
 . 
path
 . 
basename
 ( 
dir1
 )

106 if 
self
 . 
prefix
 is not None and 
name1
 not in 
self
 . 
prefix
 . 
keys
 ( ) :

110 for 
dir2
 in 
glob
 . 
glob
 ( 
os
 . 
path
 . 
join
 ( 
dir1
 , '*' ) ) :

112 
name2
 = 
os
 . 
path
 . 
basename
 ( 
dir2
 )

113 if 
name2
 . 
split
 ( '_' ) [ - 2 ] not in 
self
 . 
prefix
 [ 
name1
 ] :

116 
dir_tag
 = '%s/%s' % ( 
name1
 , 
name2
 )

117 
nframe
 = 
self
 . 
get_synced_nframe
 ( 
dir_tag
 )

120 
tracklet_file
 = 
os
 . 
path
 . 
join
 ( 
dir2
 , 'tracklet_labels.xml' )

121 if 
os
 . 
path
 . 
isfile
 ( 
tracklet_file
 ) == False : continue

122 
one_frame_objects
 = 
read_objects
 ( 
tracklet_file
 , 
range
 ( 
nframe
 ) )

124 for 
i
 , 
objects
 in 
enumerate
 ( 
one_frame_objects
 ) :

125 
frame_tag
 = '%s/%05d' % ( 
dir_tag
 , 
i
 )

126 
frames_objects
 [ 
frame_tag
 ] = 
objects

128 return 
frames_objects
 
	}

131 class 
	cLidar
 ( 
RawData
 ) :

132 def 
	$__init__
 ( 
self
 , 
prefix
 : 
dict
 ) :

133 
RawData
 . 
__init__
 ( 
self
 )

134 
self
 . 
prefix
 = 
prefix

135 
self
 . 
files_path_mapping
 = 
self
 . 
get_paths_mapping
 ( ) 
	}

137 def 
	$load
 ( 
self
 , 
frame_tag
 : 
str
 ) -> 
np
 . 
dtype
 :

138 
lidar
 = 
np
 . 
fromfile
 ( 
self
 . 
files_path_mapping
 [ 
frame_tag
 ] , 
np
 . 
float32
 )

139 return 
lidar
 . 
reshape
 ( ( - 1 , 4 ) ) 
	}

141 def 
	$get_tags
 ( 
self
 ) -> [ 
str
 ] :

142 
tags
 = [ 
tag
 for 
tag
 in 
self
 . 
files_path_mapping
 ]

143 
tags
 . 
sort
 ( )

144 return 
tags
 
	}

146 def 
	$get_paths_mapping
 ( 
self
 ) :

147 
raw_dir
 = 
cfg
 . 
RAW_DATA_SETS_DIR

148 
mapping
 = { }

151 for 
dir1
 in 
glob
 . 
glob
 ( 
os
 . 
path
 . 
join
 ( 
raw_dir
 , '*' ) ) :

152 
name1
 = 
os
 . 
path
 . 
basename
 ( 
dir1
 )

153 if 
self
 . 
prefix
 is not None and 
name1
 not in 
self
 . 
prefix
 . 
keys
 ( ) :

157 for 
dir2
 in 
glob
 . 
glob
 ( 
os
 . 
path
 . 
join
 ( 
dir1
 , '*' ) ) :

158 
name2
 = 
os
 . 
path
 . 
basename
 ( 
dir2
 )

159 if 
name2
 . 
split
 ( '_' ) [ - 2 ] not in 
self
 . 
prefix
 [ 
name1
 ] :

163 
files_path
 = 
glob
 . 
glob
 ( 
os
 . 
path
 . 
join
 ( 
dir2
 , 'velodyne_points' , 'data' , '*' ) )

164 
files_path
 . 
sort
 ( )

165 for 
i
 , 
file_path
 in 
enumerate
 ( 
files_path
 ) :

166 
key
 = '%s/%s/%05d' % ( 
name1
 , 
name2
 , 
i
 )

167 
mapping
 [ 
key
 ] = 
file_path

169 return 
mapping
 
	}

173 def 
	$read_objects
 ( 
tracklet_file
 , 
frames_index
 ) :

174 
objects
 = [ ]

176 for 
n
 in 
frames_index
 : 
objects
 . 
append
 ( [ ] )

179 
tracklets
 = 
parseXML
 ( 
tracklet_file
 )

180 
num
 = 
len
 ( 
tracklets
 )

182 for 
n
 in 
range
 ( 
num
 ) :

183 
tracklet
 = 
tracklets
 [ 
n
 ]

186 
h
 , 
w
 , 
l
 = 
tracklet
 . 
size

189 
start_frame
 = 
tracklet
 . 
firstFrame

190 
end_frame
 = 
tracklet
 . 
firstFrame
 + 
tracklet
 . 
nFrames

192 
object_in_frames_index
 = [ 
i
 for 
i
 in 
frames_index
 if 
i
 in 
range
 ( 
start_frame
 , 
end_frame
 ) ]

193 
object_in_tracklet_index
 = [ 
i
 - 
start_frame
 for 
i
 in 
object_in_frames_index
 ]

195 for 
i
 in 
object_in_tracklet_index
 :

196 
translation
 = 
tracklet
 . 
trans
 [ 
i
 ]

197 
rotation
 = 
tracklet
 . 
rots
 [ 
i
 ]

198 
state
 = 
tracklet
 . 
states
 [ 
i
 ]

199 
occlusion
 = 
tracklet
 . 
occs
 [ 
i
 ]

200 
truncation
 = 
tracklet
 . 
truncs
 [ 
i
 ]

203 if 
cfg
 . 
DATA_SETS_TYPE
 == 'kitti' :

206 if 
truncation
 not in ( 
TRUNC_IN_IMAGE
 , 
TRUNC_TRUNCATED
 ) :

209 elif 
cfg
 . 
DATA_SETS_TYPE
 == 'didi2' :

212 elif 
cfg
 . 
DATA_SETS_TYPE
 == 'didi' :

215 elif 
cfg
 . 
DATA_SETS_TYPE
 == 'test' :

218 raise 
ValueError
 ( 'unexpected type in cfg.DATA_SETS_TYPE :{}!' . 
format
 ( 
cfg
 . 
DATA_SETS_TYPE
 ) )

221 
o
 = 
type
 ( '' , ( ) , { } ) ( )

222 
o
 . 
type
 = 
tracklet
 . 
objectType

223 
o
 . 
tracklet_id
 = 
n

225 
o
 . 
translation
 = 
translation

226 
o
 . 
rotation
 = 
rotation

227 
o
 . 
size
 = 
tracklet
 . 
size

229 
objects
 [ 
frames_index
 . 
index
 ( 
i
 + 
start_frame
 ) ] . 
append
 ( 
o
 )

231 return 
objects
 
	}

234 if 
__name__
 == '__main__' :

235 import 
	~data

236 import 
	~net.utility.draw
 as 
draw

237 from 
	~sklearn.utils
 import 
shuffle

239 
preprocess
 = 
data
 . 
Preprocess
 ( )

241 
raw_img
 = 
Image
 ( )

242 
raw_tracklet
 = 
Tracklet
 ( )

243 
raw_lidar
 = 
Lidar
 ( )

245 
tags
 = 
shuffle
 ( 
raw_tracklet
 . 
get_tags
 ( ) )

248 
os
 . 
makedirs
 ( 
os
 . 
path
 . 
join
 ( 
config
 . 
cfg
 . 
LOG_DIR
 , 'test' , 'rgb' ) , 
exist_ok
 = True )

249 
os
 . 
makedirs
 ( 
os
 . 
path
 . 
join
 ( 
config
 . 
cfg
 . 
LOG_DIR
 , 'test' , 'top' ) , 
exist_ok
 = True )

250 for 
one_frame_tag
 in 
tags
 :

253 
objs
 = 
raw_tracklet
 . 
load
 ( 
one_frame_tag
 )

254 
rgb
 = 
raw_img
 . 
load
 ( 
one_frame_tag
 )

255 
lidar
 = 
raw_lidar
 . 
load
 ( 
one_frame_tag
 )

258 
rgb
 = 
preprocess
 . 
rgb
 ( 
rgb
 )

259 
top
 = 
preprocess
 . 
lidar_to_top
 ( 
lidar
 )

260 
boxes3d
 = [ 
preprocess
 . 
bbox3d
 ( 
obj
 ) for 
obj
 in 
objs
 ]

261 
labels
 = [ 
preprocess
 . 
label
 ( 
obj
 ) for 
obj
 in 
objs
 ]

265 
img
 = 
draw
 . 
draw_box3d_on_camera
 ( 
rgb
 , 
boxes3d
 )

266 
new_size
 = ( 
img
 . 
shape
 [ 1 ] // 3 , 
img
 . 
shape
 [ 0 ] // 3 )

267 
img
 = 
cv2
 . 
resize
 ( 
img
 , 
new_size
 )

268 
path
 = 
os
 . 
path
 . 
join
 ( 
config
 . 
cfg
 . 
LOG_DIR
 , 'test' , 'rgb' , '%s.png' % 
one_frame_tag
 . 
replace
 ( '/' , '_' ) )

269 
cv2
 . 
imwrite
 ( 
path
 , 
img
 )

270 
print
 ( 'write %s finished' % 
path
 )

273 
path
 = 
os
 . 
path
 . 
join
 ( 
config
 . 
cfg
 . 
LOG_DIR
 , 'test' , 'top' , '%s.png' % 
one_frame_tag
 . 
replace
 ( '/' , '_' ) )

274 
top_image
 = 
data
 . 
draw_top_image
 ( 
top
 )

275 
top_image
 = 
data
 . 
draw_box3d_on_top
 ( 
top_image
 , 
boxes3d
 , 
color
 = ( 0 , 0 , 80 ) )

276 
cv2
 . 
imwrite
 ( 
path
 , 
top_image
 )

277 
print
 ( 'write %s finished' % 
path
 )


	@./task.py

1 import 
	~os

2 import 
	~time

3 import 
	~argparse

4 import 
	~subprocess

7 def 
	$run_task
 ( 
command
 , 
time_threshold
 = None ) :

8 
print
 ( '\nStart run:\n"%s"\n' % ( 
command
 ) )

9 
delta_time
 = 0

11 
try_max
 = 3

12 
try_count
 = 0

13 if 
time_threshold
 != None :

14 while 
delta_time
 < 
time_threshold
 and 
try_count
 <= 
try_max
 :

15 
start_time
 = 
time
 . 
time
 ( )

16 
os
 . 
system
 ( 
command
 )

17 
delta_time
 = 
time
 . 
time
 ( ) - 
start_time

18 
print
 ( '\n\n{} finished ,detal time : {} retry: {}' . 
format
 ( 
command
 , 
delta_time
 , 
try_count
 ) )

19 
time
 . 
sleep
 ( 2 )

20 
try_count
 += 1

22 
exit_code
 = 
subprocess
 . 
call
 ( 
command
 , 
shell
 = True )

23 if 
exit_code
 != 0 : 
exit
 ( 
exit_code
 ) 
	}

25 class 
	cTask
 ( 
object
 ) :

27 def 
	$__init__
 ( 
self
 , 
fast_test
 = False , 
tag
 = 'unknown_tag' ) :

28 
self
 . 
fast_test
 = 
fast_test

29 
self
 . 
tag
 = 
tag
 
	}

31 def 
	$train_rpn
 ( 
self
 ) :

32 
iter
 = lambda 
i
 : 
i
 if 
self
 . 
fast_test
 == False else 1

34 
run_task
 ( 'python train.py -w "" -t "top_view_rpn" -i %d ' '-n %s'

35 % ( 
iter
 ( 500 ) , 
self
 . 
tag
 ) )

37 for 
i
 in 
range
 ( 
iter
 ( 10 ) ) :

38 
run_task
 ( 'python train.py -w "top_view_rpn" -t "top_view_rpn" -i %d ' ' -n %s -c True'

39 % ( 
iter
 ( 2000 ) , 
tag
 ) )

40 
run_task
 ( 'python tracking.py -n %s_%d -w "%s" -t %s' % ( 
tag
 , 
i
 , 
tag
 , 
self
 . 
fast_test
 ) ) 
	}

44 def 
	$train_img_and_fusion
 ( 
self
 ) :

46 
iter
 = lambda 
i
 : 
i
 if 
self
 . 
fast_test
 == False else 1

48 
run_task
 ( 'python train.py -w "top_view_rpn" -t "image_feature,fusion" -i %d ' '-n %s'

49 % ( 
iter
 ( 2000 ) , 
self
 . 
tag
 ) )

51 for 
i
 in 
range
 ( 
iter
 ( 5 ) ) :

52 
run_task
 ( 'python train.py -w "top_view_rpn,image_feature,fusion" -t "image_feature,fusion" -i %d ' ' -n %s -c True'

53 % ( 
iter
 ( 2500 ) , 
tag
 ) )

54 
run_task
 ( 'python tracking.py -n %s_%d -w "%s" -t %s' % ( 
tag
 , 
i
 , 
tag
 , 
self
 . 
fast_test
 ) ) 
	}

56 def 
	$str2bool
 ( 
v
 : 
str
 ) :

57 if 
v
 . 
lower
 ( ) in ( 'true' ) :

59 elif 
v
 . 
lower
 ( ) in ( 'false' ) :

62 raise 
argparse
 . 
ArgumentTypeError
 ( 'Boolean value expected.' ) 
	}

65 if 
__name__
 == '__main__' :

66 
parser
 = 
argparse
 . 
ArgumentParser
 ( 
description
 = 'tracking' )

67 
parser
 . 
add_argument
 ( '-n' , '--tag' , 
type
 = 
str
 , 
nargs
 = '?' , 
default
 = 'unknown_tag' ,

68 
help
 = 'set log tag' )

69 
parser
 . 
add_argument
 ( '-t' , '--fast_test' , 
type
 = 
str2bool
 , 
nargs
 = '?' , 
default
 = False ,

70 
help
 = 'fast test mode' )

71 
args
 = 
parser
 . 
parse_args
 ( )

73 
print
 ( '\n\n{}\n\n' . 
format
 ( 
args
 ) )

74 
fast_test
 = 
bool
 ( 
args
 . 
fast_test
 )

75 
tag
 = 
args
 . 
tag

76 if 
tag
 == 'unknow_tag' :

77 
tag
 = 
input
 ( 'Enter log tag : ' )

78 
print
 ( '\nSet log tag :"%s" ok !!\n' % 
tag
 )

81 
Task
 ( 
tag
 = 
tag
 , 
fast_test
 = 
args
 . 
fast_test
 ) . 
train_rpn
 ( )


	@./mv3d_net.py

1 from 
	~net.utility.file
 import *

2 from 
	~net.blocks
 import *

3 from 
	~net.rpn_nms_op
 import 
tf_rpn_nms

4 from 
	~net.roipooling_op
 import 
roi_pool
 as 
tf_roipooling

5 from 
	~config
 import 
cfg

6 from 
	~net.resnet
 import 
ResnetBuilder

22 import 
	~numpy
 as 
np

24 
top_view_rpn_name
 = 'top_view_rpn'

25 
imfeature_net_name
 = 'image_feature'

26 
frontfeature_net_name
 = 'front_feature'

27 
fusion_net_name
 = 'fusion'

28 
conv3d_net_name
 = 'conv3d_for_regress'

31 def 
	$top_feature_net
 ( 
input
 , 
anchors
 , 
inds_inside
 , 
num_bases
 , 
nms_thresh
 ) :

40 
stride
 = 1.

44 with 
tf
 . 
variable_scope
 ( 'top-block-1' ) as 
scope
 :

45 
block
 = 
conv2d_bn_relu
 ( 
input
 , 
num_kernels
 = 32 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '1' )

46 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 32 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '2' )

47 
block
 = 
maxpool
 ( 
block
 , 
kernel_size
 = ( 2 , 2 ) , 
stride
 = [ 1 , 2 , 2 , 1 ] , 
padding
 = 'SAME' , 
name
 = '4' )

48 
stride
 *= 2

50 with 
tf
 . 
variable_scope
 ( 'top-block-2' ) as 
scope
 :

51 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 64 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '1' )

52 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 64 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '2' )

53 
block
 = 
maxpool
 ( 
block
 , 
kernel_size
 = ( 2 , 2 ) , 
stride
 = [ 1 , 2 , 2 , 1 ] , 
padding
 = 'SAME' , 
name
 = '4' )

54 
stride
 *= 2

56 with 
tf
 . 
variable_scope
 ( 'top-block-3' ) as 
scope
 :

57 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 128 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '1' )

58 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 128 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '2' )

59 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 128 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '3' )

60 
block
 = 
maxpool
 ( 
block
 , 
kernel_size
 = ( 2 , 2 ) , 
stride
 = [ 1 , 2 , 2 , 1 ] , 
padding
 = 'SAME' , 
name
 = '4' )

61 
stride
 *= 2

63 with 
tf
 . 
variable_scope
 ( 'top-block-4' ) as 
scope
 :

64 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 128 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '1' )

65 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 128 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '2' )

66 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 128 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '3' )

69 with 
tf
 . 
variable_scope
 ( 'top-for-rpn' ) as 
scope
 :

70 
up
 = 
upsample2d
 ( 
block
 , 
factor
 = 2 , 
has_bias
 = True , 
trainable
 = True , 
name
 = '1' )

71 
top_rpn_stride
 = 
stride
 / 2

72 
up
 = 
conv2d_bn_relu
 ( 
up
 , 
num_kernels
 = 128 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '2' )

73 
scores
 = 
conv2d
 ( 
up
 , 
num_kernels
 = 2 * 
num_bases
 , 
kernel_size
 = ( 1 , 1 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = 'score' )

74 
probs
 = 
tf
 . 
nn
 . 
softmax
 ( 
tf
 . 
reshape
 ( 
scores
 , [ - 1 , 2 ] ) , 
name
 = 'prob' )

75 
deltas
 = 
conv2d
 ( 
up
 , 
num_kernels
 = 4 * 
num_bases
 , 
kernel_size
 = ( 1 , 1 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = 'delta' )

77 with 
tf
 . 
variable_scope
 ( 'top-for-rcnn' ) as 
scope
 :

78 
block
 = 
upsample2d
 ( 
block
 , 
factor
 = 4 , 
has_bias
 = True , 
trainable
 = True , 
name
 = '1' )

79 
top_rcnn_stride
 = 
stride
 / 4

82 with 
tf
 . 
variable_scope
 ( 'top-nms' ) as 
scope
 :

83 
batch_size
 , 
img_height
 , 
img_width
 , 
img_channel
 = 
input
 . 
get_shape
 ( ) . 
as_list
 ( )

84 
img_scale
 = 1

85 
rois
 , 
roi_scores
 = 
tf_rpn_nms
 ( 
probs
 , 
deltas
 , 
anchors
 , 
inds_inside
 ,

86 
top_rpn_stride
 , 
img_width
 , 
img_height
 , 
img_scale
 ,

87 
nms_thresh
 = 
nms_thresh
 , 
min_size
 = 
top_rpn_stride
 ,

88 
name
 = 'nms' )

89 
feature
 = 
block

91 
print
 ( 'top: rpn_scale=%f, rpn_stride=%d, rcnn_scale:%f, rcnn_stride=%d' % ( 1. / 
top_rpn_stride
 , 
top_rpn_stride
 , 1. / 
top_rcnn_stride
 , 
top_rcnn_stride
 ) )

92 return 
feature
 , 
scores
 , 
probs
 , 
deltas
 , 
rois
 , 
roi_scores
 , 
top_rpn_stride
 , 
top_rcnn_stride
 
	}

95 def 
	$top_feature_net_r
 ( 
input
 , 
anchors
 , 
inds_inside
 , 
num_bases
 , 
nms_thresh
 ) :

104 
stride
 = 1.

107 
batch_size
 , 
img_height
 , 
img_width
 , 
img_channel
 = 
input
 . 
get_shape
 ( ) . 
as_list
 ( )

109 with 
tf
 . 
variable_scope
 ( 'feature-extract-resnet' ) as 
scope
 :

110 
print
 ( 'build_resnet' )

111 
block
 = 
ResnetBuilder
 . 
resnet_tiny
 ( 
input
 )

118 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 128 , 
kernel_size
 = ( 1 , 1 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '2' )

119 
stride
 = 8

122 with 
tf
 . 
variable_scope
 ( 'predict-for-rpn' ) as 
scope
 :

123 
up
 = 
upsample2d
 ( 
block
 , 
factor
 = 2 , 
has_bias
 = True , 
trainable
 = True , 
name
 = '1' )

124 
top_rpn_stride
 = 
stride
 / 2

125 
up
 = 
conv2d_bn_relu
 ( 
up
 , 
num_kernels
 = 128 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '2' )

126 
scores
 = 
conv2d
 ( 
up
 , 
num_kernels
 = 2 * 
num_bases
 , 
kernel_size
 = ( 1 , 1 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = 'score' )

127 
probs
 = 
tf
 . 
nn
 . 
softmax
 ( 
tf
 . 
reshape
 ( 
scores
 , [ - 1 , 2 ] ) , 
name
 = 'prob' )

128 
deltas
 = 
conv2d
 ( 
up
 , 
num_kernels
 = 4 * 
num_bases
 , 
kernel_size
 = ( 1 , 1 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = 'delta' )

130 with 
tf
 . 
variable_scope
 ( 'for-rcnn' ) as 
scope
 :

131 
block
 = 
upsample2d
 ( 
block
 , 
factor
 = 4 , 
has_bias
 = True , 
trainable
 = True , 
name
 = '1' )

132 
top_rcnn_stride
 = 
stride
 / 4

135 with 
tf
 . 
variable_scope
 ( 'NMS' ) as 
scope
 :

136 
img_scale
 = 1

137 
rois
 , 
roi_scores
 = 
tf_rpn_nms
 ( 
probs
 , 
deltas
 , 
anchors
 , 
inds_inside
 ,

138 
top_rpn_stride
 , 
img_width
 , 
img_height
 , 
img_scale
 ,

139 
nms_thresh
 = 
nms_thresh
 , 
min_size
 = 
top_rpn_stride
 ,

140 
name
 = 'nms' )

142 
feature
 = 
block

144 
print
 ( 'top: rpn_scale=%f, rpn_stride=%d, rcnn_scale:%f, rcnn_stride=%d' % ( 1. / 
top_rpn_stride
 , 
top_rpn_stride
 , 1. / 
top_rcnn_stride
 , 
top_rcnn_stride
 ) )

145 return 
feature
 , 
scores
 , 
probs
 , 
deltas
 , 
rois
 , 
roi_scores
 , 
top_rpn_stride
 , 
top_rcnn_stride
 
	}

210 def 
	$rgb_feature_net
 ( 
input
 ) :

212 
stride
 = 1.

216 with 
tf
 . 
variable_scope
 ( 'rgb-block-1' ) as 
scope
 :

217 
block
 = 
conv2d_bn_relu
 ( 
input
 , 
num_kernels
 = 32 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '1' )

218 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 32 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '2' )

219 
block
 = 
maxpool
 ( 
block
 , 
kernel_size
 = ( 2 , 2 ) , 
stride
 = [ 1 , 2 , 2 , 1 ] , 
padding
 = 'SAME' , 
name
 = '4' )

220 
stride
 *= 2

222 with 
tf
 . 
variable_scope
 ( 'rgb-block-2' ) as 
scope
 :

223 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 64 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '1' )

224 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 64 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '2' )

225 
block
 = 
maxpool
 ( 
block
 , 
kernel_size
 = ( 2 , 2 ) , 
stride
 = [ 1 , 2 , 2 , 1 ] , 
padding
 = 'SAME' , 
name
 = '4' )

226 
stride
 *= 2

228 with 
tf
 . 
variable_scope
 ( 'rgb-block-3' ) as 
scope
 :

229 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 128 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '1' )

230 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 128 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '2' )

231 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 128 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '3' )

232 
block
 = 
maxpool
 ( 
block
 , 
kernel_size
 = ( 2 , 2 ) , 
stride
 = [ 1 , 2 , 2 , 1 ] , 
padding
 = 'SAME' , 
name
 = '4' )

233 
stride
 *= 2

235 with 
tf
 . 
variable_scope
 ( 'rgb-block-4' ) as 
scope
 :

236 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 128 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '1' )

237 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 128 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '2' )

238 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 128 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '3' )

240 with 
tf
 . 
variable_scope
 ( 'rgb-block-5' ) as 
scope
 :

241 
block
 = 
upsample2d
 ( 
block
 , 
factor
 = 2 , 
has_bias
 = True , 
trainable
 = True , 
name
 = '1' )

242 
stride
 /= 2

244 
feature
 = 
block

247 
print
 ( 'rgb : scale=%f, stride=%d' % ( 1. / 
stride
 , 
stride
 ) )

248 return 
feature
 , 
stride
 
	}

250 def 
	$rgb_feature_net_r
 ( 
input
 ) :

255 
batch_size
 , 
img_height
 , 
img_width
 , 
img_channel
 = 
input
 . 
get_shape
 ( ) . 
as_list
 ( )

257 with 
tf
 . 
variable_scope
 ( 'resnet-block-1' ) as 
scope
 :

258 
print
 ( 'build_resnet' )

259 
block
 = 
ResnetBuilder
 . 
resnet_tiny
 ( 
input
 )

260 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 128 , 
kernel_size
 = ( 1 , 1 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '2' )

261 
stride
 = 8

263 with 
tf
 . 
variable_scope
 ( 'resnet-block-2' ) as 
scope
 :

264 
block
 = 
upsample2d
 ( 
block
 , 
factor
 = 2 , 
has_bias
 = True , 
trainable
 = True , 
name
 = '1' )

265 
stride
 /= 2

267 
feature
 = 
block

269 
print
 ( 'rgb : scale=%f, stride=%d' % ( 1. / 
stride
 , 
stride
 ) )

270 return 
feature
 , 
stride
 
	}

273 def 
	$rgb_feature_net_x
 ( 
input
 ) :

383 return None , 8 
	}

386 def 
	$front_feature_net
 ( 
input
 ) :

387 
stride
 = 1.

390 with 
tf
 . 
variable_scope
 ( 'feature_extraction' ) :

391 if not 
cfg
 . 
USE_FRONT
 :

392 
tmp
 = 
tf
 . 
Variable
 ( 
tf
 . 
random_normal
 ( 
shape
 = [ 1 ] ) , 
name
 = 'tmp' )

393 return None , 
stride

394 with 
tf
 . 
variable_scope
 ( 'front-block-1' ) as 
scope
 :

395 
block
 = 
conv2d_bn_relu
 ( 
input
 , 
num_kernels
 = 32 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '1' )

396 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 32 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '2' )

397 
block
 = 
maxpool
 ( 
block
 , 
kernel_size
 = ( 2 , 2 ) , 
stride
 = [ 1 , 2 , 2 , 1 ] , 
padding
 = 'SAME' , 
name
 = '4' )

398 
stride
 *= 2

400 with 
tf
 . 
variable_scope
 ( 'front-block-2' ) as 
scope
 :

401 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 64 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '1' )

402 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 64 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '2' )

403 
block
 = 
maxpool
 ( 
block
 , 
kernel_size
 = ( 2 , 2 ) , 
stride
 = [ 1 , 2 , 2 , 1 ] , 
padding
 = 'SAME' , 
name
 = '4' )

404 
stride
 *= 2

406 with 
tf
 . 
variable_scope
 ( 'front-block-3' ) as 
scope
 :

407 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 128 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '1' )

408 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 128 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '2' )

409 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 128 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '3' )

410 
block
 = 
maxpool
 ( 
block
 , 
kernel_size
 = ( 2 , 2 ) , 
stride
 = [ 1 , 2 , 2 , 1 ] , 
padding
 = 'SAME' , 
name
 = '4' )

411 
stride
 *= 2

413 with 
tf
 . 
variable_scope
 ( 'front-block-4' ) as 
scope
 :

414 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 128 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '1' )

415 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 128 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '2' )

416 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 128 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '3' )

418 with 
tf
 . 
variable_scope
 ( 'front-block-5' ) as 
scope
 :

419 
block
 = 
upsample2d
 ( 
block
 , 
factor
 = 4 , 
has_bias
 = True , 
trainable
 = True , 
name
 = '1' )

420 
stride
 /= 4

422 
feature
 = 
block

424 
print
 ( 'front: scale=%f, stride=%d' % ( 1. / 
stride
 , 
stride
 ) )

425 return 
feature
 , 
stride
 
	}

428 def 
	$front_feature_net_r
 ( 
input
 ) :

429 
stride
 = 1.

432 
batch_size
 , 
img_height
 , 
img_width
 , 
img_channel
 = 
input
 . 
get_shape
 ( ) . 
as_list
 ( )

434 with 
tf
 . 
variable_scope
 ( 'feature_extraction' ) :

435 if not 
cfg
 . 
USE_FRONT
 :

436 
tmp
 = 
tf
 . 
Variable
 ( 
tf
 . 
random_normal
 ( 
shape
 = [ 1 ] ) , 
name
 = 'tmp' )

437 return None , 
stride

438 with 
tf
 . 
variable_scope
 ( 'front-feature-extract-resnet' ) as 
scope
 :

439 
print
 ( 'build_resnet' )

440 
block
 = 
ResnetBuilder
 . 
resnet_tiny
 ( 
input
 )

447 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 128 , 
kernel_size
 = ( 1 , 1 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = '2' )

448 
stride
 = 8

450 with 
tf
 . 
variable_scope
 ( 'front-block-upsample' ) as 
scope
 :

451 
block
 = 
upsample2d
 ( 
block
 , 
factor
 = 4 , 
has_bias
 = True , 
trainable
 = True , 
name
 = '1' )

452 
stride
 /= 4

454 
feature
 = 
block

456 
print
 ( 'front: scale=%f, stride=%d' % ( 1. / 
stride
 , 
stride
 ) )

457 return 
feature
 , 
stride
 
	}

475 def 
	$fusion_net
 ( 
feature_list
 , 
num_class
 , 
out_shape
 = ( 8 , 3 ) ) :

477 with 
tf
 . 
variable_scope
 ( 'fuse-net' ) as 
scope
 :

478 
num
 = 
len
 ( 
feature_list
 )

479 
feature_names
 = [ 'top' , 'front' , 'rgb' ] if 
cfg
 . 
USE_FRONT
 else [ 'top' , 'rgb' ]

480 
roi_features_list
 = [ ]

481 
ctx_roi_features_list
 = [ ]

482 for 
n
 in 
range
 ( 
num
 ) :

483 
feature
 = 
feature_list
 [ 
n
 ] [ 0 ]

484 
roi
 = 
feature_list
 [ 
n
 ] [ 1 ]

485 
pool_height
 = 
feature_list
 [ 
n
 ] [ 2 ]

486 
pool_width
 = 
feature_list
 [ 
n
 ] [ 3 ]

487 
pool_scale
 = 
feature_list
 [ 
n
 ] [ 4 ]

488 if ( 
pool_height
 == 0 or 
pool_width
 == 0 ) : continue

490 with 
tf
 . 
variable_scope
 ( 
feature_names
 [ 
n
 ] + '-roi-pooling' ) :

491 
roi_features
 , 
roi_idxs
 = 
tf_roipooling
 ( 
feature
 , 
roi
 , 
pool_height
 , 
pool_width
 ,

492 
pool_scale
 , 
name
 = '%s-roi_pooling' % 
feature_names
 [ 
n
 ] )

493 with 
tf
 . 
variable_scope
 ( 
feature_names
 [ 
n
 ] + '-feature-conv' ) :

495 with 
tf
 . 
variable_scope
 ( 'block1' ) as 
scope
 :

496 
block
 = 
conv2d_bn_relu
 ( 
roi_features
 , 
num_kernels
 = 128 , 
kernel_size
 = ( 3 , 3 ) ,

497 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = 
feature_names
 [ 
n
 ] + '_conv_1' )

498 
residual
 = 
block

500 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 128 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] ,

501 
padding
 = 'SAME' , 
name
 = 
feature_names
 [ 
n
 ] + '_conv_2' ) + 
residual

503 
block
 = 
avgpool
 ( 
block
 , 
kernel_size
 = ( 2 , 2 ) , 
stride
 = [ 1 , 2 , 2 , 1 ] ,

504 
padding
 = 'SAME' , 
name
 = 
feature_names
 [ 
n
 ] + '_max_pool' )

505 with 
tf
 . 
variable_scope
 ( 'block2' ) as 
scope
 :

507 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 256 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' ,

508 
name
 = 
feature_names
 [ 
n
 ] + '_conv_1' )

509 
residual
 = 
block

510 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 256 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' ,

511 
name
 = 
feature_names
 [ 
n
 ] + '_conv_2' ) + 
residual

513 
block
 = 
avgpool
 ( 
block
 , 
kernel_size
 = ( 2 , 2 ) , 
stride
 = [ 1 , 2 , 2 , 1 ] ,

514 
padding
 = 'SAME' , 
name
 = 
feature_names
 [ 
n
 ] + '_max_pool' )

515 with 
tf
 . 
variable_scope
 ( 'block3' ) as 
scope
 :

517 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 512 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' ,

518 
name
 = 
feature_names
 [ 
n
 ] + '_conv_1' )

519 
residual
 = 
block

520 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 512 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' ,

521 
name
 = 
feature_names
 [ 
n
 ] + '_conv_2' ) + 
residual

523 
block
 = 
avgpool
 ( 
block
 , 
kernel_size
 = ( 2 , 2 ) , 
stride
 = [ 1 , 2 , 2 , 1 ] ,

524 
padding
 = 'SAME' , 
name
 = 
feature_names
 [ 
n
 ] + '_max_pool' )

526 
roi_features
 = 
flatten
 ( 
block
 )

529 
roi_features_list
 . 
append
 ( 
roi_features
 )

531 if 
cfg
 . 
USE_SIAMESE_FUSION
 :

532 def 
enlarge_roi
 ( 
roi
 , 
ratio
 ) :

534 
roi_T
 = 
tf
 . 
transpose
 ( 
roi
 )

535 
x1
 = 
tf
 . 
gather
 ( 
roi_T
 , 1 )

536 
y1
 = 
tf
 . 
gather
 ( 
roi_T
 , 2 )

537 
x2
 = 
tf
 . 
gather
 ( 
roi_T
 , 3 )

538 
y2
 = 
tf
 . 
gather
 ( 
roi_T
 , 4 )

539 
center_x
 , 
center_y
 = ( 
x1
 + 
x2
 ) // 2 , ( 
y1
 + 
y2
 ) // 2

540 
width
 , 
height
 = 
x2
 - 
x1
 , 
y2
 - 
y1

541 
new_width
 , 
new_height
 = 
tf
 . 
to_float
 ( 
width
 ) * 
ratio
 , 
tf
 . 
to_float
 ( 
height
 ) * 
ratio

542 return 
tf
 . 
stack
 ( [

543 
tf
 . 
zeros_like
 ( 
roi
 [ : , 0 ] ) ,

544 
center_x
 - 
new_width
 / 2. ,

545 
center_y
 - 
new_height
 / 2. ,

546 
center_x
 + 
new_width
 / 2. ,

547 
center_y
 + 
new_height
 / 2.

548 ] , 
axis
 = 1 )

551 
ctx_pool_height
 , 
ctx_pool_width
 = 
pool_height
 , 
pool_width

552 
ctx_roi
 = 
enlarge_roi
 ( 
roi
 , 
cfg
 . 
ROI_ENLARGE_RATIO
 )

553 with 
tf
 . 
variable_scope
 ( 
feature_names
 [ 
n
 ] + '-roi-pooling-ctx' ) :

554 
ctx_roi_features
 , 
ctx_roi_idxs
 = 
tf_roipooling
 ( 
feature
 , 
ctx_roi
 , 
ctx_pool_height
 , 
ctx_pool_width
 ,

555 
pool_scale
 , 
name
 = '%s-roi_pooling-ctx' % 
feature_names
 [ 
n
 ] )

556 with 
tf
 . 
variable_scope
 ( 
feature_names
 [ 
n
 ] + '-feature-conv-ctx' ) :

558 with 
tf
 . 
variable_scope
 ( 'block1-ctx' ) as 
scope
 :

559 
block
 = 
conv2d_bn_relu
 ( 
ctx_roi_features
 , 
num_kernels
 = 128 , 
kernel_size
 = ( 3 , 3 ) ,

560 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = 
feature_names
 [ 
n
 ] + '_conv_1-ctx' )

561 
residual
 = 
block

563 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 128 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] ,

564 
padding
 = 'SAME' , 
name
 = 
feature_names
 [ 
n
 ] + '_conv_2-ctx' ) + 
residual

566 
block
 = 
avgpool
 ( 
block
 , 
kernel_size
 = ( 2 , 2 ) , 
stride
 = [ 1 , 2 , 2 , 1 ] ,

567 
padding
 = 'SAME' , 
name
 = 
feature_names
 [ 
n
 ] + '_max_pool-ctx' )

568 with 
tf
 . 
variable_scope
 ( 'block2-ctx' ) as 
scope
 :

570 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 256 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' ,

571 
name
 = 
feature_names
 [ 
n
 ] + '_conv_1-ctx' )

572 
residual
 = 
block

573 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 256 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' ,

574 
name
 = 
feature_names
 [ 
n
 ] + '_conv_2-ctx' ) + 
residual

576 
block
 = 
avgpool
 ( 
block
 , 
kernel_size
 = ( 2 , 2 ) , 
stride
 = [ 1 , 2 , 2 , 1 ] ,

577 
padding
 = 'SAME' , 
name
 = 
feature_names
 [ 
n
 ] + '_max_pool-ctx' )

578 with 
tf
 . 
variable_scope
 ( 'block3-ctx' ) as 
scope
 :

580 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 512 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' ,

581 
name
 = 
feature_names
 [ 
n
 ] + '_conv_1-ctx' )

582 
residual
 = 
block

583 
block
 = 
conv2d_bn_relu
 ( 
block
 , 
num_kernels
 = 512 , 
kernel_size
 = ( 3 , 3 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' ,

584 
name
 = 
feature_names
 [ 
n
 ] + '_conv_2-ctx' ) + 
residual

586 
block
 = 
avgpool
 ( 
block
 , 
kernel_size
 = ( 2 , 2 ) , 
stride
 = [ 1 , 2 , 2 , 1 ] ,

587 
padding
 = 'SAME' , 
name
 = 
feature_names
 [ 
n
 ] + '_max_pool-ctx' )

588 
ctx_roi_features
 = 
flatten
 ( 
block
 )

591 
ctx_roi_features_list
 . 
append
 ( 
ctx_roi_features
 )

593 if 
cfg
 . 
USE_SIAMESE_FUSION
 :

595 
roi_feature_list
 = 
concat
 ( [ 
roi_features_list
 , 
ctx_roi_features_list
 ] , 
axis
 = 2 , 
name
 = 'concat_ctx_roi_feature' )

597 with 
tf
 . 
variable_scope
 ( 'rois-without-rgb-feature-concat' ) :

598 
block_without_rgb
 = 
concat
 ( 
roi_features_list
 [ 0 : 2 ] if 
cfg
 . 
USE_FRONT
 else 
roi_features_list
 [ 0 ] , 
axis
 = 1 , 
name
 = 'concat_without_rgb' )

600 with 
tf
 . 
variable_scope
 ( 'fusion-without-rgb-feature-fc' ) :

601 
block_without_rgb
 = 
linear_bn_relu
 ( 
block_without_rgb
 , 
num_hiddens
 = 512 , 
name
 = '1' )

602 
block_without_rgb
 = 
linear_bn_relu
 ( 
block_without_rgb
 , 
num_hiddens
 = 512 , 
name
 = '2' )

603 if 
cfg
 . 
USE_SIAMESE_FUSION
 :

604 
block_without_rgb
 = 
linear_bn_relu
 ( 
block_without_rgb
 , 
num_hiddens
 = 512 , 
name
 = '3' )

606 with 
tf
 . 
variable_scope
 ( 'rois-all-feature-concat' ) :

607 
block
 = 
concat
 ( 
roi_features_list
 , 
axis
 = 1 , 
name
 = 'concat' )

609 with 
tf
 . 
variable_scope
 ( 'fusion-feature-fc' ) :

610 
print
 ( '\nUse fusion-feature-2fc' )

611 
block
 = 
linear_bn_relu
 ( 
block
 , 
num_hiddens
 = 512 , 
name
 = '1' )

612 
block
 = 
linear_bn_relu
 ( 
block
 , 
num_hiddens
 = 512 , 
name
 = '2' )

613 if 
cfg
 . 
USE_SIAMESE_FUSION
 :

614 
block
 = 
linear_bn_relu
 ( 
block
 , 
num_hiddens
 = 512 , 
name
 = '3' )

616 return 
block_without_rgb
 , 
block
 
	}

619 def 
	$fuse_loss
 ( 
scores
 , 
deltas
 , 
rcnn_labels
 , 
rcnn_targets
 ) :

621 def 
modified_smooth_l1
 ( 
deltas
 , 
targets
 , 
sigma
 = 3.0 ) :

627 
sigma2
 = 
sigma
 * 
sigma

628 
diffs
 = 
tf
 . 
subtract
 ( 
deltas
 , 
targets
 )

629 
smooth_l1_signs
 = 
tf
 . 
cast
 ( 
tf
 . 
less
 ( 
tf
 . 
abs
 ( 
diffs
 ) , 1.0 / 
sigma2
 ) , 
tf
 . 
float32
 )

631 
smooth_l1_option1
 = 
tf
 . 
multiply
 ( 
diffs
 , 
diffs
 ) * 0.5 * 
sigma2

632 
smooth_l1_option2
 = 
tf
 . 
abs
 ( 
diffs
 ) - 0.5 / 
sigma2

633 
smooth_l1_add
 = 
tf
 . 
multiply
 ( 
smooth_l1_option1
 , 
smooth_l1_signs
 ) + 
tf
 . 
multiply
 ( 
smooth_l1_option2
 , 1 - 
smooth_l1_signs
 )

634 
smooth_l1
 = 
smooth_l1_add

636 return 
smooth_l1

639 
_
 , 
num_class
 = 
scores
 . 
get_shape
 ( ) . 
as_list
 ( )

640 
dim
 = 
np
 . 
prod
 ( 
deltas
 . 
get_shape
 ( ) . 
as_list
 ( ) [ 1 : ] ) // 
num_class

642 with 
tf
 . 
variable_scope
 ( 'get_scores' ) :

643 
rcnn_scores
 = 
tf
 . 
reshape
 ( 
scores
 , [ - 1 , 
num_class
 ] , 
name
 = 'rcnn_scores' )

644 
pos_inds
 = 
tf
 . 
where
 ( 
tf
 . 
not_equal
 ( 
rcnn_labels
 , 0 ) , 
name
 = 'pos_inds' )

645 
rcnn_cls_loss_pos
 = 
tf
 . 
reduce_mean
 ( 
tf
 . 
nn
 . 
sparse_softmax_cross_entropy_with_logits
 (

646 
logits
 = 
tf
 . 
gather
 ( 
rcnn_scores
 , 
pos_inds
 ) , 
labels
 = 
tf
 . 
gather
 ( 
rcnn_labels
 , 
pos_inds
 ) ) )

647 
rcnn_cls_loss_all
 = 
tf
 . 
reduce_mean
 ( 
tf
 . 
nn
 . 
sparse_softmax_cross_entropy_with_logits
 (

648 
logits
 = 
rcnn_scores
 , 
labels
 = 
rcnn_labels
 ) )

649 
rcnn_cls_loss
 = 
tf
 . 
add
 ( 
tf
 . 
multiply
 ( 
rcnn_cls_loss_pos
 , 2.0 - 1.0 ) , 
tf
 . 
multiply
 ( 
rcnn_cls_loss_all
 , 1.0 ) )

651 with 
tf
 . 
variable_scope
 ( 'get_detals' ) :

652 
num
 = 
tf
 . 
identity
 ( 
tf
 . 
shape
 ( 
deltas
 ) [ 0 ] , 'num' )

653 
idx
 = 
tf
 . 
identity
 ( 
tf
 . 
range
 ( 
num
 ) * 
num_class
 + 
rcnn_labels
 , 
name
 = 'idx' )

654 
deltas1
 = 
tf
 . 
reshape
 ( 
deltas
 , [ - 1 , 
dim
 ] , 
name
 = 'deltas1' )

655 
rcnn_deltas_with_fp
 = 
tf
 . 
gather
 ( 
deltas1
 , 
idx
 , 
name
 = 'rcnn_deltas_with_fp' )

656 
rcnn_targets_with_fp
 = 
tf
 . 
reshape
 ( 
rcnn_targets
 , [ - 1 , 
dim
 ] , 
name
 = 'rcnn_targets_with_fp' )

659 
fp_idxs
 = 
tf
 . 
where
 ( 
tf
 . 
not_equal
 ( 
rcnn_labels
 , 0 ) , 
name
 = 'fp_idxs' )

660 
rcnn_deltas_no_fp
 = 
tf
 . 
gather
 ( 
rcnn_deltas_with_fp
 , 
fp_idxs
 , 
name
 = 'rcnn_deltas_no_fp' )

661 
rcnn_targets_no_fp
 = 
tf
 . 
gather
 ( 
rcnn_targets_with_fp
 , 
fp_idxs
 , 
name
 = 'rcnn_targets_no_fp' )

663 with 
tf
 . 
variable_scope
 ( 'modified_smooth_l1' ) :

664 
rcnn_smooth_l1
 = 
modified_smooth_l1
 ( 
rcnn_deltas_no_fp
 , 
rcnn_targets_no_fp
 , 
sigma
 = 3.0 )

666 
rcnn_reg_loss
 = 
tf
 . 
reduce_mean
 ( 
tf
 . 
reduce_sum
 ( 
rcnn_smooth_l1
 , 
axis
 = 1 ) )

671 return 
rcnn_cls_loss
 , 
rcnn_reg_loss
 
	}

673 def 
	$rpn_loss
 ( 
scores
 , 
deltas
 , 
inds
 , 
pos_inds
 , 
rpn_labels
 , 
rpn_targets
 ) :

675 def 
modified_smooth_l1
 ( 
box_preds
 , 
box_targets
 , 
sigma
 = 2.0 ) :

681 
sigma2
 = 
sigma
 * 
sigma

682 
diffs
 = 
tf
 . 
subtract
 ( 
box_preds
 , 
box_targets
 )

683 
smooth_l1_signs
 = 
tf
 . 
cast
 ( 
tf
 . 
less
 ( 
tf
 . 
abs
 ( 
diffs
 ) , 1.0 / 
sigma2
 ) , 
tf
 . 
float32
 )

685 
smooth_l1_option1
 = 
tf
 . 
multiply
 ( 
diffs
 , 
diffs
 ) * 0.5 * 
sigma2

686 
smooth_l1_option2
 = 
tf
 . 
abs
 ( 
diffs
 ) - 0. / 
sigma2

687 
smooth_l1_add
 = 
tf
 . 
multiply
 ( 
smooth_l1_option1
 , 
smooth_l1_signs
 ) + 
tf
 . 
multiply
 ( 
smooth_l1_option2
 , 1 - 
smooth_l1_signs
 )

688 
smooth_l1
 = 
smooth_l1_add

690 return 
smooth_l1

692 
scores1
 = 
tf
 . 
reshape
 ( 
scores
 , [ - 1 , 2 ] )

693 
rpn_scores
 = 
tf
 . 
gather
 ( 
scores1
 , 
inds
 )

695 
rpn_scores_pos
 = 
tf
 . 
gather
 ( 
scores1
 , 
pos_inds
 )

696 
rpn_labels_pos
 = 
tf
 . 
ones_like
 ( 
pos_inds
 )

698 
rpn_cls_loss_pos
 = 
tf
 . 
reduce_mean
 ( 
tf
 . 
nn
 . 
sparse_softmax_cross_entropy_with_logits
 ( 
logits
 = 
rpn_scores_pos
 , 
labels
 = 
rpn_labels_pos
 ) )

699 
rpn_cls_loss_all
 = 
tf
 . 
reduce_mean
 ( 
tf
 . 
nn
 . 
sparse_softmax_cross_entropy_with_logits
 ( 
logits
 = 
rpn_scores
 , 
labels
 = 
rpn_labels
 ) )

700 
rpn_cls_loss
 = 
tf
 . 
add
 ( 
tf
 . 
multiply
 ( 
rpn_cls_loss_pos
 , 2.0 - 1.0 ) , 
tf
 . 
multiply
 ( 
rpn_cls_loss_all
 , 1.0 ) )

702 
deltas1
 = 
tf
 . 
reshape
 ( 
deltas
 , [ - 1 , 4 ] )

703 
rpn_deltas
 = 
tf
 . 
gather
 ( 
deltas1
 , 
pos_inds
 )

705 with 
tf
 . 
variable_scope
 ( 'modified_smooth_l1' ) :

706 
rpn_smooth_l1
 = 
modified_smooth_l1
 ( 
rpn_deltas
 , 
rpn_targets
 , 
sigma
 = 3.0 )

708 
rpn_reg_loss
 = 
tf
 . 
reduce_mean
 ( 
tf
 . 
reduce_sum
 ( 
rpn_smooth_l1
 , 
axis
 = 1 ) )

713 return 
rpn_cls_loss
 , 
rpn_reg_loss
 
	}

715 def 
	$remove_empty_anchor
 ( 
top_view
 , 
top_anchors
 , 
top_inside_inds
 ) :

720 def 
cond
 ( 
no_empty_inds
 , 
index
 ) :

721 nonlocal 
top_view
 , 
top_anchors

722 return 
tf
 . 
less
 ( 
index
 , 
cfg
 . 
ANCHOR_AMOUNT
 )

724 def 
body
 ( 
no_empty_inds
 , 
index
 ) :

725 nonlocal 
top_view
 , 
top_anchors

727 
x1
 = 
top_anchors
 [ 
index
 ] [ 0 ]

728 
y1
 = 
top_anchors
 [ 
index
 ] [ 1 ]

729 
x2
 = 
top_anchors
 [ 
index
 ] [ 2 ]

730 
y2
 = 
top_anchors
 [ 
index
 ] [ 3 ]

731 
res
 = 
tf
 . 
reduce_sum
 ( 
top_view
 [ : , 
x1
 : 
x2
 , 
y1
 : 
y2
 , : ] )

732 
no_empty_inds
 = 
tf
 . 
cond
 (

733 
tf
 . 
less_equal
 ( 
res
 , 0. ) ,

734 lambda : 
no_empty_inds
 ,

735 lambda : 
tf
 . 
concat
 ( [ 
no_empty_inds
 , 
index
 * 
tf
 . 
ones
 ( 1 , 
dtype
 = 
tf
 . 
int32
 ) ] , 
axis
 = 0 ) ,

737 
index
 = 
tf
 . 
add
 ( 
index
 , 1 )

738 return 
no_empty_inds
 , 
index

740 
index
 = 
tf
 . 
constant
 ( 0 )

741 
top_no_empty_inds
 = 
tf
 . 
zeros
 ( 1 , 
dtype
 = 
tf
 . 
int32
 )

742 
top_no_empty_inds
 , 
_
 = 
tf
 . 
while_loop
 (

743 
cond
 ,

744 
body
 ,

745 [ 
top_no_empty_inds
 , 
index
 ] ,

746 
shape_invariants
 = [ 
tf
 . 
TensorShape
 ( [ None ] ) , 
index
 . 
get_shape
 ( ) ] ,

747 
parallel_iterations
 = 512 ,

748 
back_prop
 = False ,

749 
name
 = 'remove_empty_anchor'

751 
top_no_empty_inds
 = 
top_no_empty_inds
 [ 1 : ]

752 return 
top_no_empty_inds
 
	}

755 def 
	$load
 ( 
top_shape
 , 
front_shape
 , 
rgb_shape
 , 
num_class
 , 
len_bases
 ) :

757 
out_shape
 = ( 8 , 3 )

758 
stride
 = 8

761 
top_cls_loss_sum
 = 
tf
 . 
placeholder
 ( 
shape
 = [ ] , 
dtype
 = 
tf
 . 
float32
 , 
name
 = 'top_cls_loss_sum' )

762 
top_reg_loss_sum
 = 
tf
 . 
placeholder
 ( 
shape
 = [ ] , 
dtype
 = 
tf
 . 
float32
 , 
name
 = 'top_reg_loss_sum' )

763 
fuse_cls_loss_sum
 = 
tf
 . 
placeholder
 ( 
shape
 = [ ] , 
dtype
 = 
tf
 . 
float32
 , 
name
 = 'fuse_cls_loss_sum' )

764 
fuse_reg_loss_sum
 = 
tf
 . 
placeholder
 ( 
shape
 = [ ] , 
dtype
 = 
tf
 . 
float32
 , 
name
 = 'fuse_reg_loss_sum' )

766 
top_anchors
 = 
tf
 . 
placeholder
 ( 
shape
 = [ None , 4 ] , 
dtype
 = 
tf
 . 
int32
 , 
name
 = 'anchors' )

767 
top_inside_inds
 = 
tf
 . 
placeholder
 ( 
shape
 = [ None ] , 
dtype
 = 
tf
 . 
int32
 , 
name
 = 'inside_inds' )

769 
top_view
 = 
tf
 . 
placeholder
 ( 
shape
 = [ None , * 
top_shape
 ] , 
dtype
 = 
tf
 . 
float32
 , 
name
 = 'top' )

770 
front_view
 = 
tf
 . 
placeholder
 ( 
shape
 = [ None , * 
front_shape
 ] , 
dtype
 = 
tf
 . 
float32
 , 
name
 = 'front' )

771 
rgb_images
 = 
tf
 . 
placeholder
 ( 
shape
 = [ None , * 
rgb_shape
 ] , 
dtype
 = 
tf
 . 
float32
 , 
name
 = 'rgb' )

772 
top_rois
 = 
tf
 . 
placeholder
 ( 
shape
 = [ None , 5 ] , 
dtype
 = 
tf
 . 
float32
 , 
name
 = 'top_rois' )

773 
front_rois
 = 
tf
 . 
placeholder
 ( 
shape
 = [ None , 5 ] , 
dtype
 = 
tf
 . 
float32
 , 
name
 = 'front_rois' )

774 
rgb_rois
 = 
tf
 . 
placeholder
 ( 
shape
 = [ None , 5 ] , 
dtype
 = 
tf
 . 
float32
 , 
name
 = 'rgb_rois' )

777 
raw_lidar
 = 
tf
 . 
placeholder
 ( 
shape
 = [ None , 
cfg
 . 
POINT_AMOUNT_LIMIT
 , 4 ] , 
dtype
 = 
tf
 . 
float32
 , 
name
 = 'raw_lidar' )

778 
point_cloud_rois
 = 
tf
 . 
placeholder
 ( 
shape
 = [ None , None , 
cfg
 . 
POINT_AMOUNT_LIMIT
 , 4 ] , 
dtype
 = 
tf
 . 
float32
 , 
name
 = 'point_cloud_rois' )

779 
voxel_rois
 = 
tf
 . 
placeholder
 ( 
shape
 = [ None , None , 
cfg
 . 
VOXEL_ROI_L
 , 
cfg
 . 
VOXEL_ROI_W
 , 
cfg
 . 
VOXEL_ROI_H
 ] , 
dtype
 = 
tf
 . 
float32
 , 
name
 = 'voxel_rois' )

781 with 
tf
 . 
variable_scope
 ( 
top_view_rpn_name
 ) :

783 if 
cfg
 . 
USE_RESNET_AS_TOP_BASENET
 == True :

784 
top_features
 , 
top_scores
 , 
top_probs
 , 
top_deltas
 , 
proposals
 , 
proposal_scores
 , 
top_feature_rpn_stride
 , 
top_feature_rcnn_stride
 =

785 
top_feature_net_r
 ( 
top_view
 , 
top_anchors
 , 
top_inside_inds
 , 
len_bases
 , 
cfg
 . 
RPN_NMS_THRESHOLD
 )

787 
top_features
 , 
top_scores
 , 
top_probs
 , 
top_deltas
 , 
proposals
 , 
proposal_scores
 , 
top_feature_rpn_stride
 , 
top_feature_rcnn_stride
 =

788 
top_feature_net
 ( 
top_view
 , 
top_anchors
 , 
top_inside_inds
 , 
len_bases
 , 
cfg
 . 
RPN_NMS_THRESHOLD
 )

790 with 
tf
 . 
variable_scope
 ( 'loss' ) :

792 
top_inds
 = 
tf
 . 
placeholder
 ( 
shape
 = [ None ] , 
dtype
 = 
tf
 . 
int32
 , 
name
 = 'top_ind' )

793 
top_pos_inds
 = 
tf
 . 
placeholder
 ( 
shape
 = [ None ] , 
dtype
 = 
tf
 . 
int32
 , 
name
 = 'top_pos_ind' )

794 
top_labels
 = 
tf
 . 
placeholder
 ( 
shape
 = [ None ] , 
dtype
 = 
tf
 . 
int32
 , 
name
 = 'top_label' )

795 
top_targets
 = 
tf
 . 
placeholder
 ( 
shape
 = [ None , 4 ] , 
dtype
 = 
tf
 . 
float32
 , 
name
 = 'top_target' )

796 
top_cls_loss_cur
 , 
top_reg_loss_cur
 = 
rpn_loss
 ( 
top_scores
 , 
top_deltas
 , 
top_inds
 , 
top_pos_inds
 ,

797 
top_labels
 , 
top_targets
 )

805 with 
tf
 . 
variable_scope
 ( 
imfeature_net_name
 ) as 
scope
 :

806 if 
cfg
 . 
RGB_BASENET
 == 'resnet' :

807 
rgb_features
 , 
rgb_stride
 = 
rgb_feature_net_r
 ( 
rgb_images
 )

808 elif 
cfg
 . 
RGB_BASENET
 == 'xception' :

809 
rgb_features
 , 
rgb_stride
 = 
rgb_feature_net_x
 ( 
rgb_images
 )

810 elif 
cfg
 . 
RGB_BASENET
 == 'VGG' :

811 
rgb_features
 , 
rgb_stride
 = 
rgb_feature_net
 ( 
rgb_images
 )

813 with 
tf
 . 
variable_scope
 ( 
frontfeature_net_name
 ) as 
scope
 :

814 if 
cfg
 . 
USE_RESNET_AS_FRONT_BASENET
 :

815 
front_features
 , 
front_stride
 = 
front_feature_net_r
 ( 
front_view
 )

817 
front_features
 , 
front_stride
 = 
front_feature_net
 ( 
front_view
 )

823 with 
tf
 . 
variable_scope
 ( 
fusion_net_name
 ) as 
scope
 :

824 if 
cfg
 . 
IMAGE_FUSION_DISABLE
 == True :

825 
fuse_output_without_rgb
 , 
fuse_output_with_rgb
 = 
fusion_net
 (

826 ( [ 
top_features
 , 
top_rois
 , 
cfg
 . 
ROI_POOLING_HEIGHT
 , 
cfg
 . 
ROI_POOLING_WIDTH
 , 1. / 
top_feature_rcnn_stride
 ] ,

827 [ 
front_features
 , 
front_rois
 , 0 , 0 , 1. / 
front_stride
 ] ,

828 [ 
rgb_features
 , 
rgb_rois
 * 0 , 
cfg
 . 
ROI_POOLING_HEIGHT
 , 
cfg
 . 
ROI_POOLING_WIDTH
 , 1. / 
rgb_stride
 ] , ) ,

829 
num_class
 , 
out_shape
 )

830 
print
 ( '\n\n!!!! disable image fusion\n\n' )

834 
fuse_output_without_rgb
 , 
fuse_output_with_rgb
 = 
fusion_net
 (

835 ( [ 
top_features
 , 
top_rois
 * 0 , 
cfg
 . 
ROI_POOLING_HEIGHT
 , 
cfg
 . 
ROI_POOLING_WIDTH
 , 1. / 
top_feature_rcnn_stride
 ] ,

836 [ 
front_features
 , 
front_rois
 , 
cfg
 . 
ROI_POOLING_HEIGHT
 , 0 , 1. / 
front_stride
 ] ,

837 [ 
rgb_features
 , 
rgb_rois
 , 
cfg
 . 
ROI_POOLING_HEIGHT
 , 
cfg
 . 
ROI_POOLING_WIDTH
 , 1. / 
rgb_stride
 ] , ) ,

838 
num_class
 , 
out_shape
 )

839 
print
 ( '\n\n!!!! disable top view fusion\n\n' )

842 if 
cfg
 . 
USE_FRONT
 :

843 
fuse_output_without_rgb
 , 
fuse_output_with_rgb
 = 
fusion_net
 (

844 ( [ 
top_features
 , 
top_rois
 , 
cfg
 . 
ROI_POOLING_HEIGHT
 , 
cfg
 . 
ROI_POOLING_WIDTH
 , 1. / 
top_feature_rcnn_stride
 ] ,

845 [ 
front_features
 , 
front_rois
 , 
cfg
 . 
ROI_POOLING_HEIGHT
 , 
cfg
 . 
ROI_POOLING_WIDTH
 , 1. / 
front_stride
 ] ,

846 [ 
rgb_features
 , 
rgb_rois
 , 
cfg
 . 
ROI_POOLING_HEIGHT
 , 
cfg
 . 
ROI_POOLING_WIDTH
 , 1. / 
rgb_stride
 ] , ) ,

847 
num_class
 , 
out_shape
 )

849 
fuse_output_without_rgb
 , 
fuse_output_with_rgb
 = 
fusion_net
 (

850 ( [ 
top_features
 , 
top_rois
 , 
cfg
 . 
ROI_POOLING_HEIGHT
 , 
cfg
 . 
ROI_POOLING_WIDTH
 , 1. / 
top_feature_rcnn_stride
 ] ,

851 [ 
rgb_features
 , 
rgb_rois
 , 
cfg
 . 
ROI_POOLING_HEIGHT
 , 
cfg
 . 
ROI_POOLING_WIDTH
 , 1. / 
rgb_stride
 ] , ) ,

852 
num_class
 , 
out_shape
 )

856 if 
cfg
 . 
USE_HANDCRAFT_FUSION
 or 
cfg
 . 
USE_LEARNABLE_FUSION
 :

857 with 
tf
 . 
variable_scope
 ( 'predict-without-rgb' ) :

858 
dim
 = 
np
 . 
product
 ( [ * 
out_shape
 ] )

859 
fuse_scores_without_rgb
 = 
linear
 ( 
fuse_output_without_rgb
 , 
num_hiddens
 = 
num_class
 , 
name
 = 'score' )

860 
fuse_probs_without_rgb
 = 
tf
 . 
nn
 . 
softmax
 ( 
fuse_scores_without_rgb
 , 
name
 = 'prob' )

861 
fuse_deltas_without_rgb
 = 
linear_bn_relu
 ( 
fuse_output_without_rgb
 , 
num_hiddens
 = 256 , 
name
 = 'box_1' )

862 
fuse_deltas_without_rgb
 = 
linear_bn_relu
 ( 
fuse_output_without_rgb
 , 
num_hiddens
 = 256 , 
name
 = 'box_2' )

863 
fuse_deltas_without_rgb
 = 
linear
 ( 
fuse_output_without_rgb
 , 
num_hiddens
 = 
dim
 * 
num_class
 , 
name
 = 'box_3' )

864 
fuse_deltas_without_rgb
 = 
tf
 . 
reshape
 ( 
fuse_deltas_without_rgb
 , ( - 1 , 
num_class
 , * 
out_shape
 ) )

866 with 
tf
 . 
variable_scope
 ( 'predict-with-rgb' ) as 
scope
 :

867 
dim
 = 
np
 . 
product
 ( [ * 
out_shape
 ] )

870 
fuse_scores_with_rgb
 = 
linear
 ( 
fuse_output_with_rgb
 , 
num_hiddens
 = 
num_class
 , 
name
 = 'score' )

871 
fuse_probs_with_rgb
 = 
tf
 . 
nn
 . 
softmax
 ( 
fuse_scores_with_rgb
 , 
name
 = 'prob' )

872 
fuse_deltas_with_rgb
 = 
linear_bn_relu
 ( 
fuse_output_with_rgb
 , 
num_hiddens
 = 256 , 
name
 = 'box_1' )

873 
fuse_deltas_with_rgb
 = 
linear_bn_relu
 ( 
fuse_output_with_rgb
 , 
num_hiddens
 = 256 , 
name
 = 'box_2' )

874 
fuse_deltas_with_rgb
 = 
linear
 ( 
fuse_output_with_rgb
 , 
num_hiddens
 = 
dim
 * 
num_class
 , 
name
 = 'box_3' )

875 
fuse_deltas_with_rgb
 = 
tf
 . 
reshape
 ( 
fuse_deltas_with_rgb
 , ( - 1 , 
num_class
 , * 
out_shape
 ) )

884 with 
tf
 . 
variable_scope
 ( 'predict-fuse' ) as 
scope
 :

885 
dim
 = 
np
 . 
product
 ( [ * 
out_shape
 ] )

886 if 
cfg
 . 
USE_HANDCRAFT_FUSION
 :

887 
max_op_mask
 = 
tf
 . 
logical_or
 (

888 
cfg
 . 
HIGH_SCORE_THRESHOLD
 < 
fuse_probs_with_rgb
 ,

889 
cfg
 . 
HIGH_SCORE_THRESHOLD
 < 
fuse_probs_without_rgb

891 
max_mask
 = 
fuse_probs_with_rgb
 > 
fuse_probs_without_rgb

893 
fuse_probs
 = 
tf
 . 
map_fn
 ( lambda 
x
 : 
tf
 . 
cond
 (

894 
max_op_mask
 [ 
x
 ] ,

895 lambda : 
tf
 . 
cond
 (

896 
max_mask
 [ 
x
 ] ,

897 lambda : 
fuse_probs_with_rgb
 [ 
x
 ] ,

898 lambda : 
fuse_probs_without_rgb
 [ 
x
 ]

900 lambda : 
tf
 . 
reduce_mean
 ( [ 
fuse_probs_with_rgb
 [ 
x
 ] , 
fuse_probs_without_rgb
 [ 
x
 ] ] , 
axis
 = 0 ) ,

901 ) , 
tf
 . 
range
 ( 
fuse_scores_with_rgb
 . 
shape
 [ 0 ] ) , 
dtype
 = 
tf
 . 
float32
 )

905 
fuse_scores
 = 
tf
 . 
map_fn
 ( lambda 
x
 : 
tf
 . 
cond
 (

906 
max_op_mask
 [ 
x
 ] ,

907 lambda : 
tf
 . 
cond
 (

908 
max_mask
 [ 
x
 ] ,

909 lambda : 
fuse_scores_with_rgb
 [ 
x
 ] ,

910 lambda : 
fuse_scores_without_rgb
 [ 
x
 ]

912 lambda : 
tf
 . 
reduce_mean
 ( [ 
fuse_probs_with_rgb
 [ 
x
 ] , 
fuse_probs_without_rgb
 [ 
x
 ] ] , 
axis
 = 0 ) *

913 
tf
 . 
sqrt
 (

914 
tf
 . 
multiply
 (

915 
tf
 . 
reduce_sum
 (

916 
tf
 . 
div
 ( 
fuse_scores_with_rgb
 [ 
x
 ] , 
fuse_probs_with_rgb
 [ 
x
 ] )

918 
tf
 . 
reduce_sum
 (

919 
tf
 . 
div
 ( 
fuse_scores_without_rgb
 [ 
x
 ] , 
fuse_probs_without_rgb
 [ 
x
 ] )

923 ) , 
tf
 . 
range
 ( 
fuse_scores_with_rgb
 . 
shape
 [ 0 ] ) , 
dtype
 = 
tf
 . 
float32
 )

925 
fuse_deltas
 = 
tf
 . 
map_fn
 ( lambda 
x
 : 
tf
 . 
cond
 (

926 
max_op_mask
 [ 
x
 ] ,

927 lambda : 
tf
 . 
cond
 (

928 
max_mask
 [ 
x
 ] ,

929 lambda : 
fuse_deltas_with_rgb
 [ 
x
 ] ,

930 lambda : 
fuse_deltas_without_rgb
 [ 
x
 ]

932 lambda : 
tf
 . 
reduce_mean
 ( [ 
fuse_deltas_with_rgb
 [ 
x
 ] , 
fuse_deltas_without_rgb
 [ 
x
 ] ] , 
axis
 = 0 ) ,

933 ) , 
tf
 . 
range
 ( 
fuse_scores_with_rgb
 . 
shape
 [ 0 ] ) , 
dtype
 = 
tf
 . 
float32
 )

934 
fuse_deltas
 = 
tf
 . 
reshape
 ( 
fuse_deltas
 , ( - 1 , 
num_class
 , * 
out_shape
 ) )

935 elif 
cfg
 . 
USE_LEARNABLE_FUSION
 :

936 
fuse_scores
 = 
linear
 ( 
concat
 ( [ 
fuse_scores_with_rgb
 , 
fuse_scores_without_rgb
 ] , 
axis
 = 1 ) , 
num_hiddens
 = 
num_class
 , 
name
 = 'fuse_scores' )

937 
fuse_probs
 = 
linear
 ( 
concat
 ( [ 
fuse_probs_with_rgb
 , 
fuse_probs_without_rgb
 ] , 
axis
 = 1 ) , 
num_hiddens
 = 
num_class
 , 
name
 = 'fuse_probs' )

938 
fuse_deltas
 = 
linear_bn_relu
 ( 
concat
 ( [

939 
tf
 . 
reshape
 ( 
fuse_deltas_with_rgb
 , ( - 1 , 
dim
 * 
num_class
 ) ) ,

940 
tf
 . 
reshape
 ( 
fuse_deltas_without_rgb
 , ( - 1 , 
dim
 * 
num_class
 ) )

941 ] , 
axis
 = 1 ) , 
num_hiddens
 = 
dim
 * 
num_class
 , 
name
 = 'fuse_deltas' )

942 
fuse_deltas
 = 
tf
 . 
reshape
 ( 
fuse_deltas
 , ( - 1 , 
num_class
 , * 
out_shape
 ) )

944 
fuse_scores
 = 
fuse_scores_without_rgb
 = 
fuse_scores_with_rgb

945 
fuse_probs
 = 
fuse_probs_without_rgb
 = 
fuse_probs_with_rgb

946 
fuse_deltas
 = 
fuse_deltas_without_rgb
 = 
fuse_deltas_with_rgb

948 with 
tf
 . 
variable_scope
 ( 'loss' ) as 
scope
 :

949 
fuse_labels
 = 
tf
 . 
placeholder
 ( 
shape
 = [ None ] , 
dtype
 = 
tf
 . 
int32
 , 
name
 = 'fuse_label' )

950 
fuse_targets
 = 
tf
 . 
placeholder
 ( 
shape
 = [ None , * 
out_shape
 ] , 
dtype
 = 
tf
 . 
float32
 , 
name
 = 'fuse_target' )

953 with 
tf
 . 
variable_scope
 ( 'loss-fuse' ) :

954 
fuse_cls_loss_cur
 , 
fuse_reg_loss_cur
 = 
fuse_loss
 ( 
fuse_scores
 , 
fuse_deltas
 , 
fuse_labels
 , 
fuse_targets
 )

956 if 
cfg
 . 
USE_HANDCRAFT_FUSION
 or 
cfg
 . 
USE_LEARNABLE_FUSION
 :

957 with 
tf
 . 
variable_scope
 ( 'loss-with-rgb' ) :

958 
fuse_cls_loss_with_rgb
 , 
fuse_reg_loss_with_rgb
 = 
fuse_loss
 ( 
fuse_scores_with_rgb
 , 
fuse_deltas_with_rgb
 , 
fuse_labels
 , 
fuse_targets
 )

960 with 
tf
 . 
variable_scope
 ( 'loss-without-rgb' ) :

961 
fuse_cls_loss_without_rgb
 , 
fuse_reg_loss_without_rgb
 = 
fuse_loss
 ( 
fuse_scores_without_rgb
 , 
fuse_deltas_without_rgb
 , 
fuse_labels
 , 
fuse_targets
 )

963 
fuse_cls_loss_with_rgb
 = 
fuse_cls_loss_without_rgb
 = 
fuse_cls_loss_cur

964 
fuse_reg_loss_with_rgb
 = 
fuse_reg_loss_without_rgb
 = 
fuse_reg_loss_cur

967 with 
tf
 . 
variable_scope
 ( 'loss' ) as 
scope
 :

969 
top_cls_loss
 = 
tf
 . 
add
 ( 
top_cls_loss_cur
 , 
top_cls_loss_sum
 )

970 
top_reg_loss
 = 
tf
 . 
add
 ( 
top_reg_loss_cur
 , 
top_reg_loss_sum
 )

971 
fuse_cls_loss
 = 
tf
 . 
add
 ( 
fuse_cls_loss_cur
 , 
fuse_cls_loss_sum
 )

972 
fuse_reg_loss
 = 
tf
 . 
add
 ( 
fuse_reg_loss_cur
 , 
fuse_reg_loss_sum
 )

996 : 
top_cls_loss_sum
 , 'top_reg_loss_sum'

997 : 
top_reg_loss_sum
 , 'fuse_cls_loss_sum'

998 : 
fuse_cls_loss_sum
 , 'fuse_reg_loss_sum'

999 : 
fuse_reg_loss_sum
 , 'top_cls_loss_cur'

1001 : 
top_cls_loss_cur
 , 'top_reg_loss_cur'

1002 : 
top_reg_loss_cur
 , 'fuse_cls_loss_cur'

1003 : 
fuse_cls_loss_cur
 , 'fuse_reg_loss_cur'

1004 : 
fuse_reg_loss_cur
 , 'top_anchors'

1006 : 
top_anchors
 , 'top_inside_inds'

1007 : 
top_inside_inds
 , 'top_view'

1008 : 
top_view
 , 'front_view'

1009 : 
front_view
 , 'rgb_images'

1010 : 
rgb_images
 , 'top_rois'

1011 : 
top_rois
 , 'front_rois'

1012 : 
front_rois
 , 'rgb_rois'

1013 : 
rgb_rois
 , 'top_cls_loss'

1016 : 
top_cls_loss
 , 'top_reg_loss'

1017 : 
top_reg_loss
 , 'fuse_cls_loss'

1018 : 
fuse_cls_loss
 , 'fuse_reg_loss'

1019 : 
fuse_reg_loss
 , 'fuse_cls_loss_with_rgb'

1020 : 
fuse_cls_loss_with_rgb
 , 'fuse_reg_loss_with_rgb'

1021 : 
fuse_reg_loss_with_rgb
 , 'fuse_cls_loss_without_rgb'

1022 : 
fuse_cls_loss_without_rgb
 , 'fuse_reg_loss_without_rgb'

1023 : 
fuse_reg_loss_without_rgb
 , 'top_features'

1025 : 
top_features
 , 'top_scores'

1026 : 
top_scores
 , 'top_probs'

1027 : 
top_probs
 , 'top_deltas'

1028 : 
top_deltas
 , 'proposals'

1029 : 
proposals
 , 'proposal_scores'

1030 : 
proposal_scores
 , 'top_inds'

1032 : 
top_inds
 , 'top_pos_inds'

1033 : 
top_pos_inds
 , 'top_labels'

1035 : 
top_labels
 , 'top_targets'

1036 : 
top_targets
 , 'fuse_labels'

1038 : 
fuse_labels
 , 'fuse_targets'

1039 : 
fuse_targets
 , 'fuse_probs'

1041 : 
fuse_probs
 , 'fuse_scores'

1042 : 
fuse_scores
 , 'fuse_deltas'

1043 : 
fuse_deltas
 , 'fuse_probs_with_rgb'

1045 : 
fuse_probs_with_rgb
 , 'fuse_scores_with_rgb'

1046 : 
fuse_scores_with_rgb
 , 'fuse_deltas_with_rgb'

1047 : 
fuse_deltas_with_rgb
 , 'fuse_probs_without_rgb'

1049 : 
fuse_probs_without_rgb
 , 'fuse_scores_without_rgb'

1050 : 
fuse_scores_without_rgb
 , 'fuse_deltas_without_rgb'

1051 : 
fuse_deltas_without_rgb
 , 'top_feature_rpn_stride'

1053 : 
top_feature_rpn_stride

1055 } 
	}

1057 def 
	$test_roi_pooling
 ( ) :

1058 import 
	~numpy
 as 
np

1059 
rgb_images
 = 
tf
 . 
placeholder
 ( 
shape
 = [ None , * ( 375 , 1242 , 3 ) ] , 
dtype
 = 
tf
 . 
float32
 , 
name
 = 'rgb_images' )

1060 
rgb_rois
 = 
tf
 . 
placeholder
 ( 
shape
 = [ None , 5 ] , 
dtype
 = 
tf
 . 
float32
 , 
name
 = 'rgb_rois' )

1061 
res
 = 
tf_roipooling
 ( 
rgb_images
 , 
rgb_rois
 , 100 , 200 , 1 )

1062 
sess
 = 
tf
 . 
Session
 ( )

1063 with 
sess
 . 
as_default
 ( ) :

1064 
ret
 = 
sess
 . 
run
 ( 
res
 , 
feed_dict
 = {

1065 
rgb_images
 : 
np
 . 
ones
 ( ( 1 , 375 , 1242 , 3 ) ) ,

1066 
rgb_rois
 : 
np
 . 
ones
 ( ( 1 , 5 ) ) ,

1068 
print
 ( 
ret
 ) 
	}

1070 def 
	$test_nms
 ( ) :

1071 import 
	~numpy
 as 
np
 
	}

1073 if 
__name__
 == '__main__' :

1074 
test_roi_pooling
 ( )


	@./train_data_render.py

1 import 
	~mv3d
 as 
mod

2 import 
	~glob

3 from 
	~config
 import *

4 import 
	~utils.batch_loading
 as 
ub

5 import 
	~cv2

6 import 
	~numpy
 as 
np

7 import 
	~net.utility.draw
 as 
draw

8 import 
	~skvideo.io

9 import 
	~data

10 from 
	~config
 import 
cfg

11 from 
	~config
 import 
TOP_X_MAX
 , 
TOP_X_MIN
 , 
TOP_Y_MAX
 , 
TOP_Z_MIN
 , 
TOP_Z_MAX
 ,

12 
TOP_Y_MIN
 , 
TOP_X_DIVISION
 , 
TOP_Y_DIVISION
 , 
TOP_Z_DIVISION

14 
dataset_dir
 = 
cfg
 . 
PREPROCESSED_DATA_SETS_DIR

16 
training_dataset
 = { '1'

27 
cameraMatrix
 = 
np
 . 
array
 ( [ [ 1384.621562 , 0.000000 , 625.888005 ] ,

31 
cameraDist
 = 
np
 . 
array
 ( [ - 0.152089 , 0.270168 , 0.003143 , - 0.005640 , 0.000000 ] )

33 def 
	$filter_center_car
 ( 
lidar
 ) :

34 
lidar
 = 
lidar
 [ 
np
 . 
logical_or
 ( 
np
 . 
abs
 ( 
lidar
 [ : , 0 ] ) > 4.7 / 2 , 
np
 . 
abs
 ( 
lidar
 [ : , 1 ] ) > 2.1 / 2 ) ]

35 return 
lidar
 
	}

39 def 
	$lidar_to_top
 ( 
lidar
 ) :

40 
lidar
 = 
lidar
 [ 
lidar
 [ : , 0 ] > 
TOP_X_MIN
 ]

41 
lidar
 = 
lidar
 [ 
lidar
 [ : , 0 ] < 
TOP_X_MAX
 ]

42 
lidar
 = 
lidar
 [ 
lidar
 [ : , 1 ] > 
TOP_Y_MIN
 ]

43 
lidar
 = 
lidar
 [ 
lidar
 [ : , 1 ] < 
TOP_Y_MAX
 ]

44 
lidar
 = 
lidar
 [ 
lidar
 [ : , 2 ] > - 4 ]

45 
lidar
 = 
lidar
 [ 
lidar
 [ : , 2 ] < 1 ]

46 
lidar
 = 
filter_center_car
 ( 
lidar
 )

48 
quantized
 = ( 
lidar
 - [ 
TOP_X_MIN
 , 
TOP_Y_MIN
 , - 8 , 0 ] ) / [ 
TOP_X_DIVISION
 , 
TOP_Y_DIVISION
 , 1. , 1 ]

50 
X0
 , 
Xn
 = 0 , 
int
 ( ( 
TOP_X_MAX
 - 
TOP_X_MIN
 ) // 
TOP_X_DIVISION
 ) + 1

51 
Y0
 , 
Yn
 = 0 , 
int
 ( ( 
TOP_Y_MAX
 - 
TOP_Y_MIN
 ) // 
TOP_Y_DIVISION
 ) + 1

53 
height
 = 
Xn
 - 
X0

54 
width
 = 
Yn
 - 
Y0

56 
grid
 = [ [ [ ] for 
y
 in 
range
 ( 
width
 ) ] for 
x
 in 
range
 ( 
height
 ) ]

57 
top
 = 
np
 . 
zeros
 ( 
shape
 = ( 
height
 , 
width
 ) , 
dtype
 = 
np
 . 
float32
 )

59 for 
i
 in 
range
 ( 
len
 ( 
quantized
 ) ) :

60 
grid
 [ 
int
 ( 
quantized
 [ 
i
 ] [ 0 ] ) ] [ 
int
 ( 
quantized
 [ 
i
 ] [ 1 ] ) ] . 
append
 ( 
quantized
 [ 
i
 ] [ 2 ] )

62 for 
x
 in 
range
 ( 
height
 ) :

63 for 
y
 in 
range
 ( 
width
 ) :

64 if 
len
 ( 
grid
 [ 
x
 ] [ 
y
 ] ) > 0 :

65 
top
 [ 
height
 - 
x
 - 1 ] [ 
width
 - 
y
 - 1 ] = 
max
 ( 
grid
 [ 
x
 ] [ 
y
 ] )

66 return 
top
 
	}

70 def 
	$lidar_to_front
 ( 
lidar
 ) :

71 
lidar
 = 
lidar
 [ 
lidar
 [ : , 0 ] > 0 ]

72 
lidar
 = 
lidar
 [ 
lidar
 [ : , 0 ] < 100 ]

73 
lidar
 = 
lidar
 [ 
lidar
 [ : , 1 ] > 
TOP_Y_MIN
 ]

74 
lidar
 = 
lidar
 [ 
lidar
 [ : , 1 ] < 
TOP_Y_MAX
 ]

75 
lidar
 = 
lidar
 [ 
lidar
 [ : , 2 ] > - 4. ]

76 
lidar
 = 
lidar
 [ 
lidar
 [ : , 2 ] < 1. ]

77 
lidar
 = 
filter_center_car
 ( 
lidar
 )

79 
y_division
 = 0.1

80 
z_division
 = 0.1

82 
quantized
 = ( 
lidar
 - [ 0 , 
TOP_Y_MIN
 , - 4. , 0 ] ) / [ 1 , 
y_division
 , 
z_division
 , 1 ]

84 
Y0
 , 
Yn
 = 0 , 
int
 ( ( 
TOP_Y_MAX
 - 
TOP_Y_MIN
 ) // 
y_division
 ) + 1

85 
Z0
 , 
Zn
 = 0 , 
int
 ( ( 1. - ( - 4. ) ) // 
z_division
 ) + 1

86 
height
 = 
Zn
 - 
Z0

87 
width
 = 
Yn
 - 
Y0

88 
grid
 = [ [ [ ] for 
y
 in 
range
 ( 
width
 ) ] for 
z
 in 
range
 ( 
height
 ) ]

89 
front
 = 
np
 . 
zeros
 ( 
shape
 = ( 
height
 , 
width
 ) , 
dtype
 = 
np
 . 
float32
 )

93 for 
i
 in 
range
 ( 
len
 ( 
quantized
 ) ) :

94 
grid
 [ 
int
 ( 
quantized
 [ 
i
 ] [ 2 ] ) ] [ 
int
 ( 
quantized
 [ 
i
 ] [ 1 ] ) ] . 
append
 ( 
quantized
 [ 
i
 ] [ 0 ] )

96 for 
z
 in 
range
 ( 
height
 ) :

97 for 
y
 in 
range
 ( 
width
 ) :

98 if 
len
 ( 
grid
 [ 
z
 ] [ 
y
 ] ) > 0 :

100 
front
 [ 
height
 - 
z
 - 1 ] [ 
width
 - 
y
 - 1 ] = 
min
 ( 
grid
 [ 
z
 ] [ 
y
 ] )

101 return 
front
 
	}

103 def 
	$draw_top_image
 ( 
top
 ) :

104 
top_binary
 = 
np
 . 
zeros_like
 ( 
top
 )

105 
top_binary
 [ 
top
 > 0 ] = 255

106 return 
np
 . 
dstack
 ( ( 
top_binary
 , 
top_binary
 , 
top_binary
 ) ) . 
astype
 ( 
np
 . 
uint8
 ) 
	}

109 def 
	$draw_front_image
 ( 
top
 ) :

110 
top_binary
 = 
np
 . 
zeros_like
 ( 
top
 )

111 
top_binary
 [ 
top
 > 0 ] = 255

112 return 
np
 . 
dstack
 ( ( 
top_binary
 , 
top_binary
 , 
top_binary
 ) ) . 
astype
 ( 
np
 . 
uint8
 ) 
	}

115 def 
	$train_data_render
 ( 
gt_boxes3d_dir
 , 
gt_labels_dir
 , 
rgb_dir
 , 
top_dir
 , 
lidar_dir
 , 
save_video_name
 ) :

116 
files
 = 
glob
 . 
glob
 ( 
os
 . 
path
 . 
join
 ( 
gt_boxes3d_dir
 , "*.npy" ) )

117 
files_count
 = 
len
 ( 
files
 )

119 
vid_in
 = 
skvideo
 . 
io
 . 
FFmpegWriter
 ( 
os
 . 
path
 . 
join
 ( 
cfg
 . 
LOG_DIR
 , 
save_video_name
 ) )

120 for 
i
 in 
range
 ( 
files_count
 ) :

121 
name
 = "{:05}" . 
format
 ( 
i
 )

122 
gt_boxes3d_file
 = 
os
 . 
path
 . 
join
 ( 
gt_boxes3d_dir
 , 
name
 + '.npy' )

123 
gt_labels_file
 = 
os
 . 
path
 . 
join
 ( 
gt_labels_dir
 , 
name
 + '.npy' )

124 
rgb_file
 = 
os
 . 
path
 . 
join
 ( 
rgb_dir
 , 
name
 + '.png' )

125 
top_file
 = 
os
 . 
path
 . 
join
 ( 
top_dir
 , 
name
 + '.npy' )

126 
lidar_file
 = 
os
 . 
path
 . 
join
 ( 
lidar_dir
 , 
name
 + ".npy" )

128 
boxes3d
 = 
np
 . 
load
 ( 
gt_boxes3d_file
 )

129 
rgb_image
 = 
cv2
 . 
imread
 ( 
rgb_file
 )

130 
rgb_image
 = 
cv2
 . 
cvtColor
 ( 
rgb_image
 , 
cv2
 . 
COLOR_BGR2RGB
 )

132 
rgb_image_undistort
 = 
cv2
 . 
undistort
 ( 
rgb_image
 , 
cameraMatrix
 , 
cameraDist
 , None , 
cameraMatrix
 )

135 
lidar
 = 
np
 . 
load
 ( 
lidar_file
 )

136 
top
 = 
lidar_to_top
 ( 
lidar
 )

137 
top_image
 = 
draw_top_image
 ( 
top
 )

138 
front
 = 
lidar_to_front
 ( 
lidar
 )

139 
front_image
 = 
draw_front_image
 ( 
front
 )

141 
lidar_to_top
 ( 
lidar
 )

142 if 
len
 ( 
boxes3d
 ) > 0 :

143 
rgb_image
 = 
draw
 . 
draw_box3d_on_camera
 ( 
rgb_image
 , 
boxes3d
 , 
color
 = ( 0 , 0 , 255 ) , 
thickness
 = 1 )

145 
top_image_boxed
 = 
data
 . 
draw_box3d_on_top
 ( 
top_image
 , 
boxes3d
 [ : , : , : ] , 
color
 = ( 255 , 255 , 0 ) , 
thickness
 = 1 )

148 
new_image
 = 
np
 . 
concatenate
 ( ( 
top_image
 , 
top_image_boxed
 ) , 
axis
 = 1 )

149 
new_image
 = 
np
 . 
concatenate
 ( ( 
front_image
 , 
new_image
 ) , 
axis
 = 0 )

150 
rgb_image
 = 
cv2
 . 
resize
 ( 
rgb_image
 , ( 
int
 ( 
new_image
 . 
shape
 [ 0 ] * 
rgb_image
 . 
shape
 [ 1 ] / 
rgb_image
 . 
shape
 [ 0 ] ) , 
new_image
 . 
shape
 [ 0 ] ) )

151 
new_image
 = 
np
 . 
concatenate
 ( ( 
new_image
 , 
rgb_image
 ) , 
axis
 = 1 )

152 
vid_in
 . 
writeFrame
 ( 
new_image
 )

154 
vid_in
 . 
close
 ( )

156 pass 
	}

158 if 
__name__
 == '__main__' :

159 
data_dir
 = 
cfg
 . 
PREPROCESSED_DATA_SETS_DIR

160 
output_dir
 = 
cfg
 . 
LOG_DIR

161 
frames_index
 = None

163 
dataset_loader
 = 
ub
 . 
batch_loading
 ( 
cfg
 . 
PREPROCESSED_DATA_SETS_DIR
 , { 'Round1Test' : [ '19_f2' ] , } , 
is_testset
 = True )

165 for 
major
 , 
minors
 in 
training_dataset
 . 
items
 ( ) :

166 for 
minor
 in 
minors
 :

167 
gt_boxes3d_dir
 = 
os
 . 
path
 . 
join
 ( 
data_dir
 , "gt_boxes3d" , 
major
 , 
minor
 )

168 
gt_labels_dir
 = 
os
 . 
path
 . 
join
 ( 
data_dir
 , "gt_lables" , 
major
 , 
minor
 )

169 
rgb_dir
 = 
os
 . 
path
 . 
join
 ( 
data_dir
 , "rgb" , 
major
 , 
minor
 )

170 
top_dir
 = 
os
 . 
path
 . 
join
 ( 
data_dir
 , "top" , 
major
 , 
minor
 )

171 
lidar_dir
 = 
os
 . 
path
 . 
join
 ( 
data_dir
 , "lidar" , 
major
 , 
minor
 )

172 
output_file
 = 
os
 . 
path
 . 
join
 ( 
output_dir
 , "{}__{}.mp4" . 
format
 ( 
major
 , 
minor
 ) )

173 
print
 ( "output_file: " + 
output_file
 )

174 
train_data_render
 ( 
gt_boxes3d_dir
 , 
gt_labels_dir
 , 
rgb_dir
 , 
top_dir
 , 
lidar_dir
 , 
output_file
 )

176 
print
 ( "Completed" )


	@./test_remove_empty_box.py

1 import 
	~argparse

2 import 
	~mv3d

3 import 
	~mv3d_net

4 from 
	~utils.batch_loading
 import 
BatchLoading3

5 from 
	~config
 import *

6 import 
	~tensorflow
 as 
tf

7 from 
	~net.utility.remove_empty_box
 import 
remove_empty_anchor

9 if 
__name__
 == '__main__' :

10 
parser
 = 
argparse
 . 
ArgumentParser
 ( 
description
 = 'training' )

12 
all
 = '%s,%s,%s,%s' % ( 
mv3d_net
 . 
top_view_rpn_name
 , 
mv3d_net
 . 
imfeature_net_name
 , 
mv3d_net
 . 
fusion_net_name
 , 
mv3d_net
 . 
frontfeature_net_name
 )

14 
parser
 . 
add_argument
 ( '-w' , '--weights' , 
type
 = 
str
 , 
nargs
 = '?' , 
default
 = 
all
 ,

15 
help
 = 'use pre trained weights example: -w "%s" ' % ( 
all
 ) )

17 
parser
 . 
add_argument
 ( '-t' , '--targets' , 
type
 = 
str
 , 
nargs
 = '?' , 
default
 = 
all
 ,

18 
help
 = 'train targets example: -w "%s" ' % ( 
all
 ) )

20 
parser
 . 
add_argument
 ( '-i' , '--max_iter' , 
type
 = 
int
 , 
nargs
 = '?' , 
default
 = 1000 ,

21 
help
 = 'max count of train iter' )

23 
parser
 . 
add_argument
 ( '-n' , '--tag' , 
type
 = 
str
 , 
nargs
 = '?' , 
default
 = 'unknown_tag' ,

24 
help
 = 'set log tag' )

26 
parser
 . 
add_argument
 ( '-c' , '--continue_train' , 
action
 = 'store_true' , 
default
 = False ,

27 
help
 = 'set continue train flag' )

29 
parser
 . 
add_argument
 ( '-b' , '--batch-size' , 
type
 = 
int
 , 
nargs
 = '?' , 
default
 = 1 ,

30 
help
 = 'set continue train flag' )

32 
parser
 . 
add_argument
 ( '-l' , '--lr' , 
type
 = 
float
 , 
nargs
 = '?' , 
default
 = 0.001 ,

33 
help
 = 'set learning rate' )

35 
args
 = 
parser
 . 
parse_args
 ( )

37 
training_dataset
 = { '2011_09_26'

45 
validation_dataset
 = { '2011_09_26'

50 
tag
 = 
args
 . 
tag

51 if 
tag
 == 'unknown_tag' :

52 
tag
 = 
input
 ( 'Enter log tag : ' )

53 
print
 ( '\nSet log tag :"%s" ok !!\n' % 
tag
 )

55 
max_iter
 = 
args
 . 
max_iter

56 
weights
 = [ ]

57 if 
args
 . 
weights
 != '' :

58 
weights
 = 
args
 . 
weights
 . 
split
 ( ',' )

60 
targets
 = [ ]

61 if 
args
 . 
targets
 != '' :

62 
targets
 = 
args
 . 
targets
 . 
split
 ( ',' )

65 import 
	~time

66 import 
	~random

67 import 
	~numpy
 as 
np

68 with 
BatchLoading3
 ( 
tags
 = 
training_dataset
 , 
require_shuffle
 = True , 
use_precal_view
 = True , 
queue_size
 = 1 , 
use_multi_process_num
 = 0 ) as 
training
 :

69 with 
BatchLoading3
 ( 
tags
 = 
validation_dataset
 , 
require_shuffle
 = False , 
use_precal_view
 = True , 
queue_size
 = 1 , 
use_multi_process_num
 = 0 ) as 
validation
 :

70 
print
 ( 'loading graph' )

71 
train
 = 
mv3d
 . 
Trainer
 ( 
train_set
 = 
training
 , 
validation_set
 = 
validation
 ,

72 
pre_trained_weights
 = 
weights
 , 
train_targets
 = 
targets
 , 
log_tag
 = 
tag
 ,

73 
continue_train
 = 
args
 . 
continue_train
 , 
batch_size
 = 
args
 . 
batch_size
 , 
lr
 = 
args
 . 
lr
 )

74 
print
 ( 'end loading graph' )

75 
train
 ( 
max_iter
 = 2 )

76 
a
 = 120000

77 
anchors
 = 
np
 . 
hstack
 ( [

78 0 * 
np
 . 
ones
 ( ( 
a
 , 1 ) ) ,

79 0 * 
np
 . 
ones
 ( ( 
a
 , 1 ) ) ,

80 40 * 
np
 . 
ones
 ( ( 
a
 , 1 ) ) ,

81 16 * 
np
 . 
ones
 ( ( 
a
 , 1 ) )

82 ] ) . 
astype
 ( 
np
 . 
int32
 )

83 for 
i
 , 
j
 in 
enumerate
 ( 
anchors
 ) :

84 
l
 = 
random
 . 
randint
 ( 0 , 900 )

85 
anchors
 [ 
i
 ] += 
l

88 
view
 = 0.01 * 
np
 . 
random
 . 
randn
 ( 800 , 600 , 27 ) . 
astype
 ( 
np
 . 
float32
 )

89 
t
 = 
time
 . 
time
 ( )

90 
index
 = 
remove_empty_anchor
 ( 
view
 , 
anchors
 , 0 )

91 
print
 ( 'done, {}' . 
format
 ( 
time
 . 
time
 ( ) - 
t
 ) )

92 
print
 ( 
index
 )

93 
print
 ( 
len
 ( 
index
 ) )

94 
train
 ( 
max_iter
 = 1000 )


	@./tracking.py

1 import 
	~mv3d

2 from 
	~data
 import 
draw_top_image
 , 
draw_box3d_on_top

3 from 
	~net.utility.draw
 import 
imsave
 , 
draw_box3d_on_camera
 , 
draw_box3d_on_camera

4 from 
	~net.processing.boxes3d
 import 
boxes3d_decompose

5 from 
	~tracklets.Tracklet_saver
 import 
Tracklet_saver

6 import 
	~argparse

7 import 
	~os

8 import 
	~config

9 from 
	~config
 import 
cfg

10 import 
	~time

11 import 
	~utils.batch_loading
 as 
ub

12 import 
	~cv2

13 import 
	~numpy
 as 
np

14 import 
	~net.utility.draw
 as 
draw

15 import 
	~skvideo.io

16 from 
	~utils.timer
 import 
timer

17 from 
	~time
 import 
localtime
 , 
strftime

18 from 
	~utils.batch_loading
 import 
BatchLoading2
 as 
BatchLoading

19 from 
	~utils.training_validation_data_splitter
 import 
get_test_tags

21 
log_subdir
 = 
os
 . 
path
 . 
join
 ( 'tracking' , 
strftime
 ( "%Y_%m_%d_%H_%M_%S" , 
localtime
 ( ) ) )

22 
log_dir
 = 
os
 . 
path
 . 
join
 ( 
cfg
 . 
LOG_DIR
 , 
log_subdir
 )

24 
fast_test
 = False

27 def 
	$pred_and_save
 ( 
tracklet_pred_dir
 , 
dataset
 , 
generate_video
 = False ,

28 
frame_offset
 = 16 , 
log_tag
 = None , 
weights_tag
 = None ) :

30 
tracklet
 = 
Tracklet_saver
 ( 
tracklet_pred_dir
 )

31 
os
 . 
makedirs
 ( 
os
 . 
path
 . 
join
 ( 
log_dir
 , 'image' ) , 
exist_ok
 = True )

33 
top_shape
 , 
front_shape
 , 
rgb_shape
 = 
dataset
 . 
get_shape
 ( )

34 
predict
 = 
mv3d
 . 
Predictor
 ( 
top_shape
 , 
front_shape
 , 
rgb_shape
 , 
log_tag
 = 
log_tag
 , 
weights_tag
 = 
weights_tag
 )

36 if 
generate_video
 :

37 
vid_in
 = 
skvideo
 . 
io
 . 
FFmpegWriter
 ( 
os
 . 
path
 . 
join
 ( 
log_dir
 , 'output.mp4' ) )

40 
timer_step
 = 100

41 if 
cfg
 . 
TRACKING_TIMER
 :

42 
time_it
 = 
timer
 ( )

44 
frame_num
 = 0

45 for 
i
 in 
range
 ( 
dataset
 . 
size
 if 
fast_test
 == False else 
frame_offset
 + 1 ) :

47 
rgb
 , 
top
 , 
front
 , 
_
 , 
_
 , 
_
 = 
dataset
 . 
load
 ( )

49 
frame_num
 = 
i
 - 
frame_offset

50 if 
frame_num
 < 0 :

53 
boxes3d
 , 
probs
 = 
predict
 ( 
top
 , 
front
 , 
rgb
 )

54 
predict
 . 
dump_log
 ( 
log_subdir
 = 
log_subdir
 , 
n_frame
 = 
i
 )

57 if 
cfg
 . 
TRACKING_TIMER
 and 
i
 % 
timer_step
 == 0 and 
i
 != 0 :

58 
predict
 . 
track_log
 . 
write
 ( 'It takes %0.2f secs for inferring %d frames. \n' %

59 ( 
time_it
 . 
time_diff_per_n_loops
 ( ) , 
timer_step
 ) )

62 
top_image
 = 
draw_top_image
 ( 
top
 [ 0 ] )

63 
rgb_image
 = 
rgb
 [ 0 ]

65 if 
len
 ( 
boxes3d
 ) != 0 :

66 
top_image
 = 
draw_box3d_on_top
 ( 
top_image
 , 
boxes3d
 [ : , : , : ] , 
color
 = ( 80 , 80 , 0 ) , 
thickness
 = 3 )

67 
rgb_image
 = 
draw_box3d_on_camera
 ( 
rgb_image
 , 
boxes3d
 [ : , : , : ] , 
color
 = ( 0 , 0 , 80 ) , 
thickness
 = 3 )

68 
translation
 , 
size
 , 
rotation
 = 
boxes3d_decompose
 ( 
boxes3d
 [ : , : , : ] )

70 
size
 [ : , 1 : 3 ] = 
size
 [ : , 1 : 3 ] / 
cfg
 . 
TRACKLET_GTBOX_LENGTH_SCALE

72 for 
j
 in 
range
 ( 
len
 ( 
translation
 ) ) :

73 if 0 < 
translation
 [ 
j
 , 1 ] < 8 :

74 
tracklet
 . 
add_tracklet
 ( 
frame_num
 , 
size
 [ 
j
 ] , 
translation
 [ 
j
 ] , 
rotation
 [ 
j
 ] )

75 
resize_scale
 = 
top_image
 . 
shape
 [ 0 ] / 
rgb_image
 . 
shape
 [ 0 ]

76 
rgb_image
 = 
cv2
 . 
resize
 ( 
rgb_image
 , ( 
int
 ( 
rgb_image
 . 
shape
 [ 1 ] * 
resize_scale
 ) , 
top_image
 . 
shape
 [ 0 ] ) )

77 
rgb_image
 = 
cv2
 . 
cvtColor
 ( 
rgb_image
 , 
cv2
 . 
COLOR_BGR2RGB
 )

78 
new_image
 = 
np
 . 
concatenate
 ( ( 
top_image
 , 
rgb_image
 ) , 
axis
 = 1 )

79 
cv2
 . 
imwrite
 ( 
os
 . 
path
 . 
join
 ( 
log_dir
 , 'image' , '%5d_image.jpg' % 
i
 ) , 
new_image
 )

81 if 
generate_video
 :

82 
vid_in
 . 
writeFrame
 ( 
new_image
 )

83 
vid_in
 . 
close
 ( )

85 
tracklet
 . 
write_tracklet
 ( )

86 
predict
 . 
dump_weigths
 ( 
os
 . 
path
 . 
join
 ( 
log_dir
 , 'pretrained_model' ) )

88 if 
cfg
 . 
TRACKING_TIMER
 :

89 
predict
 . 
log_msg
 . 
write
 ( 'It takes %0.2f secs for inferring the whole test dataset. \n' %

90 ( 
time_it
 . 
total_time
 ( ) ) )

92 
print
 ( "tracklet file named tracklet_labels.xml is written successfully." )

93 return 
tracklet
 . 
path
 
	}

96 def 
	$str2bool
 ( 
v
 ) :

97 if 
v
 . 
lower
 ( ) in ( 'true' ) :

99 elif 
v
 . 
lower
 ( ) in ( 'false' ) :

102 raise 
argparse
 . 
ArgumentTypeError
 ( 'Boolean value expected.' ) 
	}

105 from 
	~tracklets.evaluate_tracklets
 import 
tracklet_score

107 if 
__name__
 == '__main__' :

109 
parser
 = 
argparse
 . 
ArgumentParser
 ( 
description
 = 'tracking' )

110 
parser
 . 
add_argument
 ( '-n' , '--tag' , 
type
 = 
str
 , 
nargs
 = '?' , 
default
 = 'unknown_tag' ,

111 
help
 = 'set log tag' )

112 
parser
 . 
add_argument
 ( '-w' , '--weights' , 
type
 = 
str
 , 
nargs
 = '?' , 
default
 = '' ,

113 
help
 = 'set weigths tag name' )

114 
parser
 . 
add_argument
 ( '-t' , '--fast_test' , 
type
 = 
str2bool
 , 
nargs
 = '?' , 
default
 = False ,

115 
help
 = 'set fast_test model' )

116 
args
 = 
parser
 . 
parse_args
 ( )

118 
print
 ( '\n\n{}\n\n' . 
format
 ( 
args
 ) )

119 
tag
 = 
args
 . 
tag

120 if 
tag
 == 'unknow_tag' :

121 
tag
 = 
input
 ( 'Enter log tag : ' )

122 
print
 ( '\nSet log tag :"%s" ok !!\n' % 
tag
 )

123 
weights_tag
 = 
args
 . 
weights
 if 
args
 . 
weights
 != '' else None

125 
fast_test
 = 
args
 . 
fast_test

127 
tracklet_pred_dir
 = 
os
 . 
path
 . 
join
 ( 
log_dir
 , 'tracklet' )

128 
os
 . 
makedirs
 ( 
tracklet_pred_dir
 , 
exist_ok
 = True )

132 
frame_offset
 = 0

133 
dataset_loader
 = None

135 if 
config
 . 
cfg
 . 
DATA_SETS_TYPE
 == 'didi2' :

136 
if_score
 = False

138 
dataset
 = { 'nissan_brief' : [ 'nissan06' ] }

141 
car
 = '3'

142 
data
 = '7'

143 
dataset
 = {

144 
car
 : [ 
data
 ]

149 
gt_tracklet_file
 = 
os
 . 
path
 . 
join
 ( 
cfg
 . 
RAW_DATA_SETS_DIR
 , 
car
 , 
data
 , 'tracklet_labels.xml' )

151 
test_key_list
 = [ 'nissan_pulling_away' , 'nissan_pulling_up_to_it'

154 
test_key_full_path_list
 = [ 
os
 . 
path
 . 
join
 ( 
cfg
 . 
RAW_DATA_SETS_DIR
 , 
key
 ) for 
key
 in 
test_key_list
 ]

155 
test_value_list
 = [ 
os
 . 
listdir
 ( 
value
 ) [ 0 ] for 
value
 in 
test_key_full_path_list
 ]

157 
test_bags
 = [ 
k
 + '/' + 
v
 for 
k
 , 
v
 in 
zip
 ( 
test_key_list
 , 
test_value_list
 ) ]

160 elif 
config
 . 
cfg
 . 
DATA_SETS_TYPE
 == 'didi' :

161 
if_score
 = True

163 
dataset
 = { 'Round1Test' : [ '19_f2' ] }

166 
car
 = '3'

167 
data
 = '7'

168 
dataset
 = {

169 
car
 : [ 
data
 ]

174 
gt_tracklet_file
 = 
os
 . 
path
 . 
join
 ( 
cfg
 . 
RAW_DATA_SETS_DIR
 , 
car
 , 
data
 , 'tracklet_labels.xml' )

176 elif 
config
 . 
cfg
 . 
DATA_SETS_TYPE
 == 'kitti' :

177 
if_score
 = False

178 
car
 = '2011_09_26'

179 
data
 = '0013'

180 
dataset
 = {

181 
car
 : [ 
data
 ]

186 
gt_tracklet_file
 = 
os
 . 
path
 . 
join
 ( 
cfg
 . 
RAW_DATA_SETS_DIR
 , 
car
 , 
car
 + '_drive_' + 
data
 + '_sync' , 'tracklet_labels.xml'

189 
test_tags
 = 
get_test_tags
 ( 
test_bags
 )

191 with 
BatchLoading
 ( 
test_bags
 , 
test_tags
 , 
require_shuffle
 = False , 
is_testset
 = True ) as 
dataset_loader
 :

195 
print
 ( "tracklet_pred_dir: " + 
tracklet_pred_dir
 )

196 
pred_file
 = 
pred_and_save
 ( 
tracklet_pred_dir
 , 
dataset_loader
 ,

197 
frame_offset
 = 0 , 
log_tag
 = 
tag
 , 
weights_tag
 = 
weights_tag
 )

199 if 
if_score
 :

200 
tracklet_score
 ( 
pred_file
 = 
pred_file
 , 
gt_file
 = 
gt_tracklet_file
 , 
output_dir
 = 
tracklet_pred_dir
 )

201 
print
 ( "scores are save under {} directory." . 
format
 ( 
tracklet_pred_dir
 ) )

203 
print
 ( "Completed" )


	@./UKF_Python_to_C++/samplePython.py


	@./net/processing/boxes3d.py

1 import 
	~math

2 import 
	~numpy
 as 
np

3 import 
	~cv2

4 import 
	~net.processing.projection
 as 
proj

5 from 
	~shapely.geometry
 import 
Polygon

6 from 
	~config
 import 
TOP_X_MAX
 , 
TOP_X_MIN
 , 
TOP_Y_MAX
 , 
TOP_Z_MIN
 , 
TOP_Z_MAX
 ,

7 
TOP_Y_MIN
 , 
TOP_X_DIVISION
 , 
TOP_Y_DIVISION
 , 
TOP_Z_DIVISION

8 from 
	~config
 import 
cfg

9 import 
	~numpy.linalg

12 def 
	$top_to_lidar_coords
 ( 
xx
 , 
yy
 ) :

13 
X0
 , 
Xn
 = 0 , 
int
 ( ( 
TOP_X_MAX
 - 
TOP_X_MIN
 ) // 
TOP_X_DIVISION
 ) + 1

14 
Y0
 , 
Yn
 = 0 , 
int
 ( ( 
TOP_Y_MAX
 - 
TOP_Y_MIN
 ) // 
TOP_Y_DIVISION
 ) + 1

15 
y
 = 
Yn
 * 
TOP_Y_DIVISION
 - ( 
xx
 + 0.5 ) * 
TOP_Y_DIVISION
 + 
TOP_Y_MIN

16 
x
 = 
Xn
 * 
TOP_X_DIVISION
 - ( 
yy
 + 0.5 ) * 
TOP_X_DIVISION
 + 
TOP_X_MIN

18 return 
x
 , 
y
 
	}

21 def 
	$lidar_to_top_coords
 ( 
x
 , 
y
 , 
z
 = None ) :

22 
X0
 , 
Xn
 = 0 , 
int
 ( ( 
TOP_X_MAX
 - 
TOP_X_MIN
 ) // 
TOP_X_DIVISION
 ) + 1

23 
Y0
 , 
Yn
 = 0 , 
int
 ( ( 
TOP_Y_MAX
 - 
TOP_Y_MIN
 ) // 
TOP_Y_DIVISION
 ) + 1

24 
xx
 = 
Yn
 - 
int
 ( ( 
y
 - 
TOP_Y_MIN
 ) // 
TOP_Y_DIVISION
 )

25 
yy
 = 
Xn
 - 
int
 ( ( 
x
 - 
TOP_X_MIN
 ) // 
TOP_X_DIVISION
 )

27 return 
xx
 , 
yy
 
	}

29 def 
	$lidar_to_front_coords
 ( 
x
 , 
y
 , 
z
 ) :

30 
ret
 = [

31 
int
 ( 
math
 . 
atan2
 ( 
y
 , 
x
 ) / 
cfg
 . 
VELODYNE_ANGULAR_RESOLUTION
 ) ,

32 
int
 ( 
math
 . 
atan2
 ( 
z
 , 
math
 . 
sqrt
 ( 
x
 ** 2 + 
y
 ** 2 ) )

33 / 
cfg
 . 
VELODYNE_VERTICAL_RESOLUTION
 )

36 
ret
 [ 0 ] = ( 
ret
 [ 0 ] + 
cfg
 . 
FRONT_C_OFFSET
 ) / 2

37 
ret
 [ 1 ] = ( 
ret
 [ 1 ] + 
cfg
 . 
FRONT_R_OFFSET
 ) / 2

38 return 
tuple
 ( 
ret
 ) 
	}

40 def 
	$top_box_to_box3d
 ( 
boxes
 ) :

42 
num
 = 
len
 ( 
boxes
 )

43 
boxes3d
 = 
np
 . 
zeros
 ( ( 
num
 , 8 , 3 ) , 
dtype
 = 
np
 . 
float32
 )

44 for 
n
 in 
range
 ( 
num
 ) :

45 
x1
 , 
y1
 , 
x2
 , 
y2
 = 
boxes
 [ 
n
 ]

47 
points
 = [ ( 
x1
 , 
y1
 ) , ( 
x1
 , 
y2
 ) , ( 
x2
 , 
y2
 ) , ( 
x2
 , 
y1
 ) ]

48 for 
k
 in 
range
 ( 4 ) :

49 
xx
 , 
yy
 = 
points
 [ 
k
 ]

50 
x
 , 
y
 = 
top_to_lidar_coords
 ( 
xx
 , 
yy
 )

51 
boxes3d
 [ 
n
 , 
k
 , : ] = 
x
 , 
y
 , 
cfg
 . 
BOX3D_Z_MIN

52 
boxes3d
 [ 
n
 , 4 + 
k
 , : ] = 
x
 , 
y
 , 
cfg
 . 
BOX3D_Z_MAX

54 return 
boxes3d
 
	}

56 def 
	$lidar_to_camera_coords
 ( 
x
 , 
y
 , 
z
 ) :

57 if ( 
cfg
 . 
DATA_SETS_TYPE
 == 'kitti' ) :

58 
ret
 = 
np
 . 
array
 ( [ 
x
 , 
y
 , 
z
 , 1 ] )

59 
ret
 = 
np
 . 
matmul
 ( 
np
 . 
array
 ( 
cfg
 . 
MATRIX_T_VELO_2_CAM
 ) , 
ret
 )

60 
ret
 = 
np
 . 
matmul
 ( 
np
 . 
array
 ( 
cfg
 . 
MATRIX_R_RECT_0
 ) , 
ret
 )

61 
ret
 = 
ret
 [ 0 : 3 ]

62 return 
ret
 
	}

64 def 
	$camera_to_lidar_coords
 ( 
x
 , 
y
 , 
z
 ) :

65 if ( 
cfg
 . 
DATA_SETS_TYPE
 == 'kitti' ) :

66 
ret
 = 
np
 . 
array
 ( [ 
x
 , 
y
 , 
z
 , 1 ] )

67 
ret
 = 
np
 . 
matmul
 ( 
np
 . 
linalg
 . 
inv
 ( 
np
 . 
array
 ( 
cfg
 . 
MATRIX_R_RECT_0
 ) ) , 
ret
 )

68 
ret
 = 
np
 . 
matmul
 ( 
np
 . 
linalg
 . 
inv
 ( 
np
 . 
array
 ( 
cfg
 . 
MATRIX_T_VELO_2_CAM
 ) ) , 
ret
 )

69 
ret
 = 
ret
 [ 0 : 3 ]

70 return 
ret
 
	}

72 def 
	$box3d_in_top_view
 ( 
boxes3d
 ) :

74 for 
i
 in 
range
 ( 8 ) :

75 if 
TOP_X_MIN
 <= 
boxes3d
 [ 
i
 , 0 ] <= 
TOP_X_MAX
 and 
TOP_Y_MIN
 <= 
boxes3d
 [ 
i
 , 1 ] <= 
TOP_Y_MAX
 :

79 return True 
	}

81 def 
	$box3d_to_top_box
 ( 
boxes3d
 ) :

83 
num
 = 
len
 ( 
boxes3d
 )

84 
boxes
 = 
np
 . 
zeros
 ( ( 
num
 , 4 ) , 
dtype
 = 
np
 . 
float32
 )

86 for 
n
 in 
range
 ( 
num
 ) :

87 
b
 = 
boxes3d
 [ 
n
 ]

89 
x0
 = 
b
 [ 0 , 0 ]

90 
y0
 = 
b
 [ 0 , 1 ]

91 
x1
 = 
b
 [ 1 , 0 ]

92 
y1
 = 
b
 [ 1 , 1 ]

93 
x2
 = 
b
 [ 2 , 0 ]

94 
y2
 = 
b
 [ 2 , 1 ]

95 
x3
 = 
b
 [ 3 , 0 ]

96 
y3
 = 
b
 [ 3 , 1 ]

97 
u0
 , 
v0
 = 
lidar_to_top_coords
 ( 
x0
 , 
y0
 )

98 
u1
 , 
v1
 = 
lidar_to_top_coords
 ( 
x1
 , 
y1
 )

99 
u2
 , 
v2
 = 
lidar_to_top_coords
 ( 
x2
 , 
y2
 )

100 
u3
 , 
v3
 = 
lidar_to_top_coords
 ( 
x3
 , 
y3
 )

102 
umin
 = 
min
 ( 
u0
 , 
u1
 , 
u2
 , 
u3
 )

103 
umax
 = 
max
 ( 
u0
 , 
u1
 , 
u2
 , 
u3
 )

104 
vmin
 = 
min
 ( 
v0
 , 
v1
 , 
v2
 , 
v3
 )

105 
vmax
 = 
max
 ( 
v0
 , 
v1
 , 
v2
 , 
v3
 )

107 
boxes
 [ 
n
 ] = 
np
 . 
array
 ( [ 
umin
 , 
vmin
 , 
umax
 , 
vmax
 ] )

109 return 
boxes
 
	}

111 def 
	$convert_points_to_croped_image
 ( 
img_points
 ) :

112 
img_points
 = 
img_points
 . 
copy
 ( )

114 
left
 = 
cfg
 . 
IMAGE_CROP_LEFT

115 
right
 = 
cfg
 . 
IMAGE_CROP_RIGHT

116 
top
 = 
cfg
 . 
IMAGE_CROP_TOP

117 
bottom
 = 
cfg
 . 
IMAGE_CROP_BOTTOM

119 
croped_img_h
 = 
proj
 . 
image_height
 - 
top
 - 
bottom

120 
croped_img_w
 = 
proj
 . 
image_width
 - 
left
 - 
right

123 
img_points
 [ : , 1 ] -= 
top

124 
mask
 = 
img_points
 [ : , 1 ] < 0

125 
img_points
 [ 
mask
 , 1 ] = 0

126 
out_range_mask
 = 
mask

128 
mask
 = 
img_points
 [ : , 1 ] >= 
croped_img_h

129 
img_points
 [ 
mask
 , 1 ] = 
croped_img_h
 - 1

130 
out_range_mask
 = 
np
 . 
logical_or
 ( 
out_range_mask
 , 
mask
 )

132 
img_points
 [ : , 0 ] -= 
left

133 
mask
 = 
img_points
 [ : , 0 ] < 0

134 
img_points
 [ 
mask
 , 0 ] = 0

135 
out_range_mask
 = 
np
 . 
logical_or
 ( 
out_range_mask
 , 
mask
 )

137 
mask
 = 
img_points
 [ : , 0 ] >= 
croped_img_w

138 
img_points
 [ 
mask
 , 0 ] = 
croped_img_w
 - 1

139 
out_range_mask
 = 
np
 . 
logical_or
 ( 
out_range_mask
 , 
mask
 )

141 return 
img_points
 , 
out_range_mask
 
	}

145 def 
	$box3d_to_rgb_box
 ( 
boxes3d
 , 
Mt
 = None , 
Kt
 = None ) :

146 if ( 
cfg
 . 
DATA_SETS_TYPE
 == 'kitti' ) :

147 if 
Mt
 is None : 
Mt
 = 
np
 . 
array
 ( 
cfg
 . 
MATRIX_Mt
 )

148 if 
Kt
 is None : 
Kt
 = 
np
 . 
array
 ( 
cfg
 . 
MATRIX_Kt
 )

150 
num
 = 
len
 ( 
boxes3d
 )

151 
projections
 = 
np
 . 
zeros
 ( ( 
num
 , 8 , 2 ) , 
dtype
 = 
np
 . 
int32
 )

152 for 
n
 in 
range
 ( 
num
 ) :

153 
box3d
 = 
boxes3d
 [ 
n
 ]

154 
Ps
 = 
np
 . 
hstack
 ( ( 
box3d
 , 
np
 . 
ones
 ( ( 8 , 1 ) ) ) )

155 
Qs
 = 
np
 . 
matmul
 ( 
Ps
 , 
Mt
 )

156 
Qs
 = 
Qs
 [ : , 0 : 3 ]

157 
qs
 = 
np
 . 
matmul
 ( 
Qs
 , 
Kt
 )

158 
zs
 = 
qs
 [ : , 2 ] . 
reshape
 ( 8 , 1 )

159 
qs
 = ( 
qs
 / 
zs
 )

160 
projections
 [ 
n
 ] = 
qs
 [ : , 0 : 2 ]

161 return 
projections

164 
num
 = 
len
 ( 
boxes3d
 )

165 
projections
 = 
np
 . 
zeros
 ( ( 
num
 , 8 , 2 ) , 
dtype
 = 
np
 . 
int32
 )

166 for 
n
 in 
range
 ( 
num
 ) :

167 
box3d
 = 
boxes3d
 [ 
n
 ] . 
copy
 ( )

168 if 
np
 . 
sum
 ( 
box3d
 [ : , 0 ] > 0 ) > 0 :

169 
box2d
 = 
box3d_to_rgb_projection_cv2
 ( 
box3d
 )

170 
box2d
 , 
out_range
 = 
convert_points_to_croped_image
 ( 
box2d
 )

171 if 
np
 . 
sum
 ( 
out_range
 == False ) >= 2 :

172 
projections
 [ 
n
 ] = 
box2d

173 return 
projections
 
	}

175 def 
	$box3d_to_camera_box3d
 ( 
boxes3d
 ) :

176 if ( 
cfg
 . 
DATA_SETS_TYPE
 == 'kitti' ) :

177 
num
 = 
len
 ( 
boxes3d
 )

178 
projections
 = 
np
 . 
zeros
 ( ( 
num
 , 8 , 3 ) , 
dtype
 = 
np
 . 
float32
 )

179 for 
n
 in 
range
 ( 
num
 ) :

180 
box3d
 = 
boxes3d
 [ 
n
 ]

181 
ret
 = 
np
 . 
hstack
 ( ( 
box3d
 , 
np
 . 
ones
 ( ( 8 , 1 ) ) ) )

182 
ret
 = 
np
 . 
matmul
 ( 
ret
 , 
np
 . 
array
 ( 
cfg
 . 
MATRIX_T_VELO_2_CAM
 ) . 
T
 )

183 
ret
 = 
np
 . 
matmul
 ( 
ret
 , 
np
 . 
array
 ( 
cfg
 . 
MATRIX_R_RECT_0
 ) . 
T
 )

184 
projections
 [ 
n
 ] = 
ret
 [ : , 0 : 3 ]

185 return 
projections
 
	}

187 def 
	$box3d_to_top_projections
 ( 
boxes3d
 ) :

189 
num
 = 
len
 ( 
boxes3d
 )

190 
projections
 = 
np
 . 
zeros
 ( ( 
num
 , 4 , 2 ) , 
dtype
 = 
np
 . 
float32
 )

191 for 
n
 in 
range
 ( 
num
 ) :

192 
b
 = 
boxes3d
 [ 
n
 ]

193 
x0
 = 
b
 [ 0 , 0 ]

194 
y0
 = 
b
 [ 0 , 1 ]

195 
x1
 = 
b
 [ 1 , 0 ]

196 
y1
 = 
b
 [ 1 , 1 ]

197 
x2
 = 
b
 [ 2 , 0 ]

198 
y2
 = 
b
 [ 2 , 1 ]

199 
x3
 = 
b
 [ 3 , 0 ]

200 
y3
 = 
b
 [ 3 , 1 ]

201 
u0
 , 
v0
 = 
lidar_to_top_coords
 ( 
x0
 , 
y0
 )

202 
u1
 , 
v1
 = 
lidar_to_top_coords
 ( 
x1
 , 
y1
 )

203 
u2
 , 
v2
 = 
lidar_to_top_coords
 ( 
x2
 , 
y2
 )

204 
u3
 , 
v3
 = 
lidar_to_top_coords
 ( 
x3
 , 
y3
 )

205 
projections
 [ 
n
 ] = 
np
 . 
array
 ( [ [ 
u0
 , 
v0
 ] , [ 
u1
 , 
v1
 ] , [ 
u2
 , 
v2
 ] , [ 
u3
 , 
v3
 ] ] )

207 return 
projections
 
	}

210 def 
	$draw_rgb_projections
 ( 
image
 , 
projections
 , 
color
 = ( 255 , 0 , 255 ) , 
thickness
 = 2 , 
darker
 = 1.0 ) :

212 
img
 = ( 
image
 . 
copy
 ( ) * 
darker
 ) . 
astype
 ( 
np
 . 
uint8
 )

213 
num
 = 
len
 ( 
projections
 )

214 for 
n
 in 
range
 ( 
num
 ) :

215 
qs
 = 
projections
 [ 
n
 ]

216 for 
k
 in 
range
 ( 0 , 4 ) :

218 
i
 , 
j
 = 
k
 , ( 
k
 + 1 ) % 4

219 
cv2
 . 
line
 ( 
img
 , ( 
qs
 [ 
i
 , 0 ] , 
qs
 [ 
i
 , 1 ] ) , ( 
qs
 [ 
j
 , 0 ] , 
qs
 [ 
j
 , 1 ] ) , 
color
 , 
thickness
 , 
cv2
 . 
LINE_AA
 )

221 
i
 , 
j
 = 
k
 + 4 , ( 
k
 + 1 ) % 4 + 4

222 
cv2
 . 
line
 ( 
img
 , ( 
qs
 [ 
i
 , 0 ] , 
qs
 [ 
i
 , 1 ] ) , ( 
qs
 [ 
j
 , 0 ] , 
qs
 [ 
j
 , 1 ] ) , 
color
 , 
thickness
 , 
cv2
 . 
LINE_AA
 )

224 
i
 , 
j
 = 
k
 , 
k
 + 4

225 
cv2
 . 
line
 ( 
img
 , ( 
qs
 [ 
i
 , 0 ] , 
qs
 [ 
i
 , 1 ] ) , ( 
qs
 [ 
j
 , 0 ] , 
qs
 [ 
j
 , 1 ] ) , 
color
 , 
thickness
 , 
cv2
 . 
LINE_AA
 )

227 return 
img
 
	}

230 def 
	$draw_box3d_on_top
 ( 
image
 , 
boxes3d
 , 
color
 = ( 255 , 255 , 255 ) , 
thickness
 = 1 ) :

232 
img
 = 
image
 . 
copy
 ( )

233 
num
 = 
len
 ( 
boxes3d
 )

234 for 
n
 in 
range
 ( 
num
 ) :

235 
b
 = 
boxes3d
 [ 
n
 ]

236 
x0
 = 
b
 [ 0 , 0 ]

237 
y0
 = 
b
 [ 0 , 1 ]

238 
x1
 = 
b
 [ 1 , 0 ]

239 
y1
 = 
b
 [ 1 , 1 ]

240 
x2
 = 
b
 [ 2 , 0 ]

241 
y2
 = 
b
 [ 2 , 1 ]

242 
x3
 = 
b
 [ 3 , 0 ]

243 
y3
 = 
b
 [ 3 , 1 ]

244 
u0
 , 
v0
 = 
lidar_to_top_coords
 ( 
x0
 , 
y0
 )

245 
u1
 , 
v1
 = 
lidar_to_top_coords
 ( 
x1
 , 
y1
 )

246 
u2
 , 
v2
 = 
lidar_to_top_coords
 ( 
x2
 , 
y2
 )

247 
u3
 , 
v3
 = 
lidar_to_top_coords
 ( 
x3
 , 
y3
 )

248 
cv2
 . 
line
 ( 
img
 , ( 
u0
 , 
v0
 ) , ( 
u1
 , 
v1
 ) , 
color
 , 
thickness
 , 
cv2
 . 
LINE_AA
 )

249 
cv2
 . 
line
 ( 
img
 , ( 
u1
 , 
v1
 ) , ( 
u2
 , 
v2
 ) , 
color
 , 
thickness
 , 
cv2
 . 
LINE_AA
 )

250 
cv2
 . 
line
 ( 
img
 , ( 
u2
 , 
v2
 ) , ( 
u3
 , 
v3
 ) , 
color
 , 
thickness
 , 
cv2
 . 
LINE_AA
 )

251 
cv2
 . 
line
 ( 
img
 , ( 
u3
 , 
v3
 ) , ( 
u0
 , 
v0
 ) , 
color
 , 
thickness
 , 
cv2
 . 
LINE_AA
 )

253 return 
img
 
	}

255 def 
	$draw_box3d_on_front
 ( 
image
 , 
boxes3d
 , 
color
 = ( 255 , 255 , 255 ) , 
thickness
 = 1 ) :

256 
img
 = 
image
 . 
copy
 ( )

257 for 
index
 in 
range
 ( 
len
 ( 
boxes3d
 ) ) :

258 
projection
 = 
np
 . 
array
 ( [ 
lidar_to_front_coords
 ( * 
cor
 ) for 
cor
 in 
boxes3d
 [ 
index
 ] ] )

259 assert ( 
len
 ( 
projection
 ) == 8 )

260 
c_min
 , 
c_max
 = 
int
 ( 
min
 ( 
projection
 [ : , 0 ] ) ) , 
int
 ( 
max
 ( 
projection
 [ : , 0 ] ) )

261 
r_min
 , 
r_max
 = 
int
 ( 
min
 ( 
projection
 [ : , 1 ] ) ) , 
int
 ( 
max
 ( 
projection
 [ : , 1 ] ) )

264 
cv2
 . 
line
 ( 
img
 , ( 
r_min
 , 
c_min
 ) , ( 
r_min
 , 
c_max
 ) , 
color
 , 
thickness
 , 
cv2
 . 
LINE_AA
 )

265 
cv2
 . 
line
 ( 
img
 , ( 
r_min
 , 
c_max
 ) , ( 
r_max
 , 
c_max
 ) , 
color
 , 
thickness
 , 
cv2
 . 
LINE_AA
 )

266 
cv2
 . 
line
 ( 
img
 , ( 
r_max
 , 
c_max
 ) , ( 
r_max
 , 
c_min
 ) , 
color
 , 
thickness
 , 
cv2
 . 
LINE_AA
 )

267 
cv2
 . 
line
 ( 
img
 , ( 
r_max
 , 
c_min
 ) , ( 
r_min
 , 
c_min
 ) , 
color
 , 
thickness
 , 
cv2
 . 
LINE_AA
 )

270 return 
img
 
	}

272 def 
	$draw_boxes
 ( 
image
 , 
boxes
 , 
color
 = ( 0 , 255 , 255 ) , 
thickness
 = 1 , 
darken
 = 1.0 ) :

274 
img
 = ( 
image
 . 
copy
 ( ) * 
darken
 ) . 
astype
 ( 
np
 . 
uint8
 )

275 
num
 = 
len
 ( 
boxes
 )

276 for 
n
 in 
range
 ( 
num
 ) :

277 
b
 = 
boxes
 [ 
n
 ]

278 
cv2
 . 
rectangle
 ( 
img
 , ( 
b
 [ 0 ] , 
b
 [ 1 ] ) , ( 
b
 [ 2 ] , 
b
 [ 3 ] ) , 
color
 , 
thickness
 )

280 return 
img
 
	}

285 def 
	$box3d_transform0
 ( 
et_boxes3d
 , 
gt_boxes3d
 ) :

287 
et_centers
 = 
np
 . 
sum
 ( 
et_boxes3d
 , 
axis
 = 1 , 
keepdims
 = True ) / 8

288 
et_scales
 = 10

289 
deltas
 = ( 
et_boxes3d
 - 
gt_boxes3d
 ) / 
et_scales

290 return 
deltas
 
	}

293 def 
	$box3d_transform_inv0
 ( 
et_boxes3d
 , 
deltas
 ) :

295 
et_centers
 = 
np
 . 
sum
 ( 
et_boxes3d
 , 
axis
 = 1 , 
keepdims
 = True ) / 8

296 
et_scales
 = 10

297 
boxes3d
 = - 
deltas
 * 
et_scales
 + 
et_boxes3d

299 return 
boxes3d
 
	}

301 def 
	$box3d_transform
 ( 
et_boxes3d
 , 
gt_boxes3d
 ) :

303 
num
 = 
len
 ( 
et_boxes3d
 )

304 
deltas
 = 
np
 . 
zeros
 ( ( 
num
 , 8 , 3 ) , 
dtype
 = 
np
 . 
float32
 )

305 for 
n
 in 
range
 ( 
num
 ) :

306 
e
 = 
et_boxes3d
 [ 
n
 ]

307 
center
 = 
np
 . 
sum
 ( 
e
 , 
axis
 = 0 , 
keepdims
 = True ) / 8

308 
scale
 = ( 
np
 . 
sum
 ( ( 
e
 - 
center
 ) ** 2 ) / 8 ) ** 0.5

310 
g
 = 
gt_boxes3d
 [ 
n
 ]

311 
deltas
 [ 
n
 ] = ( 
g
 - 
e
 ) / 
scale

312 return 
deltas
 
	}

315 def 
	$box3d_transform_inv
 ( 
et_boxes3d
 , 
deltas
 ) :

317 
num
 = 
len
 ( 
et_boxes3d
 )

318 
boxes3d
 = 
np
 . 
zeros
 ( ( 
num
 , 8 , 3 ) , 
dtype
 = 
np
 . 
float32
 )

319 for 
n
 in 
range
 ( 
num
 ) :

320 
e
 = 
et_boxes3d
 [ 
n
 ]

321 
center
 = 
np
 . 
sum
 ( 
e
 , 
axis
 = 0 , 
keepdims
 = True ) / 8

322 
scale
 = ( 
np
 . 
sum
 ( ( 
e
 - 
center
 ) ** 2 ) / 8 ) ** 0.5

324 
d
 = 
deltas
 [ 
n
 ]

325 
boxes3d
 [ 
n
 ] = 
e
 + 
scale
 * 
d

327 return 
boxes3d
 
	}

331 def 
	$regularise_box3d
 ( 
boxes3d
 ) :

333 
num
 = 
len
 ( 
boxes3d
 )

334 
reg_boxes3d
 = 
np
 . 
zeros
 ( ( 
num
 , 8 , 3 ) , 
dtype
 = 
np
 . 
float32
 )

335 for 
n
 in 
range
 ( 
num
 ) :

336 
b
 = 
boxes3d
 [ 
n
 ]

338 
dis
 = 0

339 
corners
 = 
np
 . 
zeros
 ( ( 4 , 3 ) , 
dtype
 = 
np
 . 
float32
 )

340 for 
k
 in 
range
 ( 0 , 4 ) :

342 
i
 , 
j
 = 
k
 , 
k
 + 4

343 
dis
 += 
np
 . 
sum
 ( ( 
b
 [ 
i
 ] - 
b
 [ 
j
 ] ) ** 2 ) ** 0.5

344 
corners
 [ 
k
 ] = ( 
b
 [ 
i
 ] + 
b
 [ 
j
 ] ) / 2

346 
dis
 = 
dis
 / 4

347 
b
 = 
reg_boxes3d
 [ 
n
 ]

348 for 
k
 in 
range
 ( 0 , 4 ) :

349 
i
 , 
j
 = 
k
 , 
k
 + 4

350 
b
 [ 
i
 ] = 
corners
 [ 
k
 ] - 
dis
 / 2 * 
np
 . 
array
 ( [ 0 , 0 , 1 ] )

351 
b
 [ 
j
 ] = 
corners
 [ 
k
 ] + 
dis
 / 2 * 
np
 . 
array
 ( [ 0 , 0 , 1 ] )

353 return 
reg_boxes3d
 
	}

355 def 
	$boxes3d_decompose
 ( 
boxes3d
 ) :

358 if 
cfg
 . 
DATA_SETS_TYPE
 == 'didi2' or 
cfg
 . 
DATA_SETS_TYPE
 == 'didi' or 
cfg
 . 
DATA_SETS_TYPE
 == 'test' :

359 
T_x
 = 
np
 . 
sum
 ( 
boxes3d
 [ : , 0 : 8 , 0 ] , 1 ) / 8.0

360 
T_y
 = 
np
 . 
sum
 ( 
boxes3d
 [ : , 0 : 8 , 1 ] , 1 ) / 8.0

361 
T_z
 = 
np
 . 
sum
 ( 
boxes3d
 [ : , 0 : 8 , 2 ] , 1 ) / 8.0

362 elif 
cfg
 . 
DATA_SETS_TYPE
 == 'kitti' :

363 
T_x
 = 
np
 . 
sum
 ( 
boxes3d
 [ : , 0 : 4 , 0 ] , 1 ) / 4.0

364 
T_y
 = 
np
 . 
sum
 ( 
boxes3d
 [ : , 0 : 4 , 1 ] , 1 ) / 4.0

365 
T_z
 = 
np
 . 
sum
 ( 
boxes3d
 [ : , 0 : 4 , 2 ] , 1 ) / 4.0

367 
Points0
 = 
boxes3d
 [ : , 0 , 0 : 2 ]

368 
Points1
 = 
boxes3d
 [ : , 1 , 0 : 2 ]

369 
Points2
 = 
boxes3d
 [ : , 2 , 0 : 2 ]

371 
dis1
 = 
np
 . 
sum
 ( ( 
Points0
 - 
Points1
 ) ** 2 , 1 ) ** 0.5

372 
dis2
 = 
np
 . 
sum
 ( ( 
Points1
 - 
Points2
 ) ** 2 , 1 ) ** 0.5

374 
dis1_is_max
 = 
dis1
 > 
dis2

377 
L
 = 
np
 . 
maximum
 ( 
dis1
 , 
dis2
 )

378 
W
 = 
np
 . 
minimum
 ( 
dis1
 , 
dis2
 )

379 
H
 = 
np
 . 
sum
 ( ( 
boxes3d
 [ : , 0 , 0 : 3 ] - 
boxes3d
 [ : , 4 , 0 : 3 ] ) ** 2 , 1 ) ** 0.5

382 
yaw
 = lambda 
p1
 , 
p2
 , 
dis
 : 
math
 . 
atan2
 ( 
p2
 [ 1 ] - 
p1
 [ 1 ] , 
p2
 [ 0 ] - 
p1
 [ 0 ] )

383 
R_x
 = 
np
 . 
zeros
 ( 
len
 ( 
boxes3d
 ) )

384 
R_y
 = 
np
 . 
zeros
 ( 
len
 ( 
boxes3d
 ) )

385 
R_z
 = [ 
yaw
 ( 
Points0
 [ 
i
 ] , 
Points1
 [ 
i
 ] , 
dis1
 [ 
i
 ] ) if 
is_max
 else 
yaw
 ( 
Points1
 [ 
i
 ] , 
Points2
 [ 
i
 ] , 
dis2
 [ 
i
 ] )

386 for 
is_max
 , 
i
 in 
zip
 ( 
dis1_is_max
 , 
range
 ( 
len
 ( 
dis1_is_max
 ) ) ) ]

387 
R_z
 = 
np
 . 
array
 ( 
R_z
 )

389 
translation
 = 
np
 . 
c_
 [ 
T_x
 , 
T_y
 , 
T_z
 ]

390 
size
 = 
np
 . 
c_
 [ 
H
 , 
W
 , 
L
 ]

391 
rotation
 = 
np
 . 
c_
 [ 
R_x
 , 
R_y
 , 
R_z
 ]

392 return 
translation
 , 
size
 , 
rotation
 
	}

395 def 
	$box3d_compose
 ( 
translation
 , 
size
 , 
rotation
 ) :

400 
h
 , 
w
 , 
l
 = 
size
 [ 0 ] , 
size
 [ 1 ] , 
size
 [ 2 ]

401 if 
cfg
 . 
DATA_SETS_TYPE
 == 'didi' or 
cfg
 . 
DATA_SETS_TYPE
 == 'test' :

402 
h
 , 
w
 = 
h
 * 1.1 , 
l

403 
trackletBox
 = 
np
 . 
array
 ( [

404 [ - 
l
 / 2 , - 
l
 / 2 , 
l
 / 2 , 
l
 / 2 , - 
l
 / 2 , - 
l
 / 2 , 
l
 / 2 , 
l
 / 2 ] ,

405 [ 
w
 / 2 , - 
w
 / 2 , - 
w
 / 2 , 
w
 / 2 , 
w
 / 2 , - 
w
 / 2 , - 
w
 / 2 , 
w
 / 2 ] ,

406 [ - 
h
 / 2 , - 
h
 / 2 , - 
h
 / 2 , - 
h
 / 2 , 
h
 / 2 , 
h
 / 2 , 
h
 / 2 , 
h
 / 2 ] ] )

407 elif 
cfg
 . 
DATA_SETS_TYPE
 == 'kitti' :

408 
trackletBox
 = 
np
 . 
array
 ( [

409 [ - 
l
 / 2 , - 
l
 / 2 , 
l
 / 2 , 
l
 / 2 , - 
l
 / 2 , - 
l
 / 2 , 
l
 / 2 , 
l
 / 2 ] ,

410 [ 
w
 / 2 , - 
w
 / 2 , - 
w
 / 2 , 
w
 / 2 , 
w
 / 2 , - 
w
 / 2 , - 
w
 / 2 , 
w
 / 2 ] ,

411 [ 0.0 , 0.0 , 0.0 , 0.0 , 
h
 , 
h
 , 
h
 , 
h
 ] ] )

412 elif 
cfg
 . 
DATA_SETS_TYPE
 == 'didi2' :

413 
h
 , 
w
 = 1.5 * 
h
 , 1.7 * 
w

414 
trackletBox
 = 
np
 . 
array
 ( [

415 [ - 
l
 / 2 , - 
l
 / 2 , 
l
 / 2 , 
l
 / 2 , - 
l
 / 2 , - 
l
 / 2 , 
l
 / 2 , 
l
 / 2 ] ,

416 [ 
w
 / 2 , - 
w
 / 2 , - 
w
 / 2 , 
w
 / 2 , 
w
 / 2 , - 
w
 / 2 , - 
w
 / 2 , 
w
 / 2 ] ,

417 [ - 
h
 / 2 , - 
h
 / 2 , - 
h
 / 2 , - 
h
 / 2 , 
h
 / 2 , 
h
 / 2 , 
h
 / 2 , 
h
 / 2 ] ] )

419 raise 
ValueError
 ( 'unexpected type in cfg.DATA_SETS_TYPE :{}!' . 
format
 ( 
cfg
 . 
DATA_SETS_TYPE
 ) )

423 
yaw
 = 
rotation
 [ 2 ]

425 
rotMat
 = 
np
 . 
array
 ( [

426 [ 
np
 . 
cos
 ( 
yaw
 ) , - 
np
 . 
sin
 ( 
yaw
 ) , 0.0 ] ,

427 [ 
np
 . 
sin
 ( 
yaw
 ) , 
np
 . 
cos
 ( 
yaw
 ) , 0.0 ] ,

429 
cornerPosInVelo
 = 
np
 . 
dot
 ( 
rotMat
 , 
trackletBox
 ) + 
np
 . 
tile
 ( 
translation
 , ( 8 , 1 ) ) . 
T

432 
box3d
 = 
cornerPosInVelo
 . 
transpose
 ( )

434 return 
box3d
 
	}

438 import 
	~cv2

441 def 
	$project_point
 ( 
point
 , 
cameraMat
 , 
cameraExtrinsicMat
 , 
distCoeff
 ) :

442 
cameraXYZ
 = 
cameraExtrinsicMat
 [ 0 : 3 , 0 : 3 ] . 
dot
 ( 
point
 . 
transpose
 ( ) ) + 
cameraExtrinsicMat
 [ 0 : 3 , 3 ]

443 
x1
 = 
cameraXYZ
 [ 0 ] / 
cameraXYZ
 [ 2 ]

444 
y1
 = 
cameraXYZ
 [ 1 ] / 
cameraXYZ
 [ 2 ]

445 
r2
 = 
x1
 * 
x1
 + 
y1
 * 
y1

446 
factor
 = 1 + 
distCoeff
 [ 0 ] * 
r2
 + 
distCoeff
 [ 1 ] * ( 
r2
 ** 2 ) + 
distCoeff
 [ 4 ] * ( 
r2
 ** 3 )

447 
x2
 = 
x1
 * 
factor
 + 2 * 
distCoeff
 [ 2 ] * 
x1
 * 
y1
 + 
distCoeff
 [ 3 ] * ( 
r2
 + 2 * 
x1
 * 
x1
 )

448 
y2
 = 
y1
 * 
factor
 + 
distCoeff
 [ 2 ] * ( 
r2
 + 2 * 
y1
 * 
y1
 ) + 2 * 
distCoeff
 [ 3 ] * 
x1
 * 
y1

449 
u
 = 
cameraMat
 [ 0 ] [ 0 ] * 
x2
 + 
cameraMat
 [ 0 ] [ 2 ]

450 
v
 = 
cameraMat
 [ 1 ] [ 1 ] * 
y2
 + 
cameraMat
 [ 1 ] [ 2 ]

451 return [ 
u
 , 
v
 ] 
	}

453 def 
	$box3d_to_rgb_projection_cv2
 ( 
points
 ) :

474 
projMat
 = 
np
 . 
matrix
 ( [ [ 6.24391515e+02 , - 1.35999541e+03 , - 3.47685065e+01 , - 8.19238784e+02 ] ,

477 
imagePoints
 = [ ]

478 for 
pt
 in 
points
 :

479 
X
 = 
projMat
 * 
np
 . 
matrix
 ( 
list
 ( 
pt
 ) + [ 1 ] ) . 
T

480 
X
 = 
np
 . 
array
 ( 
X
 [ : 2 , 0 ] / 
X
 [ 2 , 0 ] ) . 
flatten
 ( )

481 
imagePoints
 . 
append
 ( 
X
 )

482 
imagePoints
 = 
np
 . 
array
 ( 
imagePoints
 )

484 return 
imagePoints
 . 
astype
 ( 
np
 . 
int
 ) 
	}

487 def 
	$box3d_intersection
 ( 
box_a
 , 
box_b
 ) :

496 
min_h_a
 = 
np
 . 
min
 ( 
box_a
 [ 2 ] )

497 
max_h_a
 = 
np
 . 
max
 ( 
box_a
 [ 2 ] )

498 
min_h_b
 = 
np
 . 
min
 ( 
box_b
 [ 2 ] )

499 
max_h_b
 = 
np
 . 
max
 ( 
box_b
 [ 2 ] )

500 
max_of_min
 = 
np
 . 
max
 ( [ 
min_h_a
 , 
min_h_b
 ] )

501 
min_of_max
 = 
np
 . 
min
 ( [ 
max_h_a
 , 
max_h_b
 ] )

502 
z_intersection
 = 
np
 . 
max
 ( [ 0 , 
min_of_max
 - 
max_of_min
 ] )

503 if 
z_intersection
 == 0 :

507 
xy_poly_a
 = 
Polygon
 ( 
zip
 ( * 
box_a
 [ 0 : 2 , 0 : 4 ] ) )

508 
xy_poly_b
 = 
Polygon
 ( 
zip
 ( * 
box_b
 [ 0 : 2 , 0 : 4 ] ) )

509 
xy_intersection
 = 
xy_poly_a
 . 
intersection
 ( 
xy_poly_b
 ) . 
area

510 if 
xy_intersection
 == 0 :

513 return 
z_intersection
 * 
xy_intersection
 
	}

516 def 
	$boxes3d_score_iou
 ( 
gt_boxes3d
 , 
pre_boxes3d
 ) :

517 
n_pre_box
 = 
pre_boxes3d
 . 
shape
 [ 0 ]

518 if 
n_pre_box
 == 0 : return 0.

519 
n_gt_box
 = 
gt_boxes3d
 . 
shape
 [ 0 ]

521 
_
 , 
gt_size
 , 
_
 = 
boxes3d_decompose
 ( 
gt_boxes3d
 )

522 
gt_vol
 = 
np
 . 
sum
 ( 
np
 . 
prod
 ( 
gt_size
 , 1 ) )

524 
_
 , 
pre_size
 , 
_
 = 
boxes3d_decompose
 ( 
pre_boxes3d
 )

525 
pre_vol
 = 
np
 . 
sum
 ( 
np
 . 
prod
 ( 
pre_size
 , 1 ) )

527 
inters
 = 
np
 . 
zeros
 ( ( 
n_gt_box
 , 
n_pre_box
 ) )

529 for 
j
 in 
range
 ( 
n_gt_box
 ) :

530 for 
i
 in 
range
 ( 
n_pre_box
 ) :

532 
inters
 [ 
j
 , 
i
 ] = 
box3d_intersection
 ( 
gt_boxes3d
 [ 
j
 ] . 
T
 , 
pre_boxes3d
 [ 
i
 ] . 
T
 )

534 raise 
ValueError
 ( 'Invalid box' )

536 
inter
 = 
np
 . 
sum
 ( 
np
 . 
max
 ( 
inters
 , 1 ) )

537 
union
 = 
gt_vol
 + 
pre_vol
 - 
inter

539 
iou
 = 
inter
 / 
union

540 return 
iou
 
	}

545 if 
__name__
 == '__main__' :

548 
gt_boxes3d
 = 
np
 . 
load
 ( 'gt_boxes3d_135.npy' )

549 
translation
 , 
size
 , 
rotation
 = 
boxes3d_decompose
 ( 
gt_boxes3d
 [ 0 ] )

550 
print
 ( 
translation
 , 
size
 , 
rotation
 )

553 
gt_box3d_trans
 = 
np
 . 
array
 ( [

558 
gt_box3d_size
 = 
np
 . 
array
 ( [

563 
gt_box3d_rota
 = 
np
 . 
array
 ( [

569 
pre_box3d_trans
 = 
np
 . 
array
 ( [

574 
pre_box3d_size
 = 
np
 . 
array
 ( [

579 
pre_box3d_rota
 = 
np
 . 
array
 ( [

585 
n_box
 = 
gt_box3d_trans
 . 
shape
 [ 0 ]

586 
gt_boxes3d
 = [ ]

587 for 
i
 in 
range
 ( 
n_box
 ) :

588 
gt_boxes3d
 . 
append
 ( 
box3d_compose
 ( 
gt_box3d_trans
 [ 
i
 ] , 
gt_box3d_size
 [ 
i
 ] , 
gt_box3d_rota
 [ 
i
 ] ) )

589 
gt_boxes3d
 = 
np
 . 
array
 ( 
gt_boxes3d
 )

591 
n_box
 = 
pre_box3d_trans
 . 
shape
 [ 0 ]

592 
pre_boxes3d
 = [ ]

593 for 
i
 in 
range
 ( 
n_box
 ) :

594 
pre_boxes3d
 . 
append
 ( 
box3d_compose
 ( 
pre_box3d_trans
 [ 
i
 ] , 
pre_box3d_size
 [ 
i
 ] , 
pre_box3d_rota
 [ 
i
 ] ) )

595 
pre_boxes3d
 = 
np
 . 
array
 ( 
pre_boxes3d
 )

597 
iou
 = 
boxes3d_score_iou
 ( 
gt_boxes3d
 , 
pre_boxes3d
 )

598 
print
 ( 'iou = {}' . 
format
 ( 
iou
 ) )

600 
iou
 = 
boxes3d_score_iou
 ( 
gt_boxes3d
 , 
pre_boxes3d
 [ 0 : 1 , : , : ] )

601 
print
 ( 'iou = {}' . 
format
 ( 
iou
 ) )


	@./net/processing/__init__.py


	@./net/processing/projection.py

1 import 
	~numpy
 as 
np

2 import 
	~math

3 from 
	~config
 import 
cfg

5 
image_height
 = 
cfg
 . 
IMAGE_HEIGHT

6 
image_width
 = 
cfg
 . 
IMAGE_WIDTH

9 
P
 = 
np
 . 
array
 ( [ [ 1362.184692 , 0.0 , 620.575531 ] , [ 0.0 , 1372.305786 , 561.873133 ] , [ 0.0 , 0.0 , 1.0 ] ] )

12 
ry
 = 5.2 / 180.0 * 
math
 . 
pi

13 
ry_M
 = 
np
 . 
array
 ( [ [ 
math
 . 
cos
 ( 
ry
 ) , 0. , 
math
 . 
sin
 ( 
ry
 ) ] , [ 0.0 , 1.0 , 0. ] , [ - 
math
 . 
sin
 ( 
ry
 ) , 0.0 , 
math
 . 
cos
 ( 
ry
 ) ] ] )

15 
rz
 = - 1.2 / 180.0 * 
math
 . 
pi

16 
rz_M
 = 
np
 . 
array
 ( [ [ 
math
 . 
cos
 ( 
rz
 ) , - 
math
 . 
sin
 ( 
rz
 ) , 0 ] , [ 
math
 . 
sin
 ( 
rz
 ) , 
math
 . 
cos
 ( 
rz
 ) , 0. ] , [ 0 , 0.0 , 1 ] ] )

18 
R_axis
 = 
np
 . 
array
 ( [ [ 0.0 , - 1.0 , 0.0 ] , [ 0.0 , 0.0 , 1.0 ] , [ 1.0 , 0.0 , 0.0 ] ] )

19 
cameraMatrix_in
 = 
np
 . 
array
 ( [ [ 1384.621562 , 0.000000 , 625.888005 ] ,

24 def 
	$distortion_correct
 ( 
points
 ) :

25 
kc
 = [ - 0.152089 , 0.270168 , 0.003143 , - 0.005640 , 0.000000 ]

27 
n_points_x
 = 
points
 [ : , 0 ] / 
points
 [ : , 2 ]

28 
n_points_y
 = 
points
 [ : , 1 ] / 
points
 [ : , 2 ]

29 
n_points
 = [ ]

30 for 
i
 in 
range
 ( 
len
 ( 
n_points_x
 ) ) :

31 
x
 = 
n_points_x
 [ 
i
 ]

32 
y
 = 
n_points_y
 [ 
i
 ]

33 
r
 = 
math
 . 
sqrt
 ( 
x
 ** 2 + 
y
 ** 2 )

34 
coeff1
 = 1 + 
kc
 [ 0 ] * ( 
r
 ** 2 ) + 
kc
 [ 1 ] * ( 
r
 ** 4 ) + 
kc
 [ 4 ] * ( 
r
 ** 6 )

35 
d_x
 = 2 * 
kc
 [ 2 ] * 
x
 * 
y
 + 
kc
 [ 3 ] * ( 
r
 ** 2 + 2 * ( 
x
 ** 2 ) )

36 
d_y
 = 
kc
 [ 2 ] * ( 
r
 ** 2 + 2 * ( 
y
 ** 2 ) ) + 2 * 
kc
 [ 3 ] * 
x
 * 
y

37 
i_x
 = 
coeff1
 * 
x
 + 
d_x

38 
i_y
 = 
coeff1
 * 
y
 + 
d_y

39 
n_points
 . 
append
 ( [ 
i_x
 , 
i_y
 , 1 ] )

40 return 
n_points
 
	}

44 def 
	$project_cam
 ( 
points
 ) :

45 
p_tmp
 = 
np
 . 
dot
 ( 
ry_M
 , 
points
 . 
T
 )

46 
p_tmp
 = 
np
 . 
dot
 ( 
rz_M
 , 
p_tmp
 )

47 
p_tmp
 = 
np
 . 
dot
 ( 
R_axis
 , 
p_tmp
 )

48 
points
 = 
distortion_correct
 ( 
p_tmp
 . 
T
 )

49 
p_tmp
 = 
np
 . 
array
 ( 
points
 )

50 
p_cam
 = 
np
 . 
dot
 ( 
P
 , 
p_tmp
 . 
T
 )

51 
p_cam
 [ 0 , : ] = 
p_cam
 [ 0 , : ] / 
p_cam
 [ 2 , : ]

52 
p_cam
 [ 1 , : ] = 
p_cam
 [ 1 , : ] / 
p_cam
 [ 2 , : ]

53 
p_col
 = 
p_cam
 [ 0 , : ]

54 
mask_col
 = 
p_col
 > 0

55 
p_cam
 = 
p_cam
 [ : , 
mask_col
 ]

56 
p_col
 = 
p_col
 [ 
mask_col
 ]

57 
mask_col
 = 
p_col
 < 
image_width

58 
p_col
 = 
p_col
 [ 
mask_col
 ]

59 
p_cam
 = 
p_cam
 [ : , 
mask_col
 ]

60 
p_row
 = 
p_cam
 [ 1 , : ]

61 
mask_row
 = 
p_row
 > 0

62 
p_cam
 = 
p_cam
 [ : , 
mask_row
 ]

63 
p_row
 = 
p_row
 [ 
mask_row
 ]

64 
mask_row
 = 
p_row
 < 
image_height

65 
p_cam
 = 
p_cam
 [ : , 
mask_row
 ]

66 
pixels_cam
 = 
p_cam
 . 
T

67 if 
len
 ( 
pixels_cam
 ) != 8 :

68 return 
np
 . 
zeros
 ( ( 8 , 2 ) )

71 
pixels_cam
 [ : , 1 ] = 
image_height
 - 
pixels_cam
 [ : , 1 ]

76 
pixels_cam
 = [ [ 
int
 ( 
round
 ( 
p
 [ 0 ] ) ) , 
int
 ( 
round
 ( 
p
 [ 1 ] ) ) ] for 
p
 in 
pixels_cam
 ]

77 
pixels_cam
 = 
np
 . 
array
 ( 
pixels_cam
 )

80 return 
pixels_cam
 
	}

86 def 
	$scale_to_255
 ( 
a
 , 
min
 , 
max
 , 
dtype
 = 
np
 . 
uint8
 ) :

90 return ( ( ( 
a
 - 
min
 ) / 
float
 ( 
max
 - 
min
 ) ) * 255 ) . 
astype
 ( 
dtype
 ) 
	}

96 def 
	$point_cloud_to_panorama
 ( 
points
 ,

97 
v_res
 = 0.42 ,

98 
h_res
 = 0.35 ,

99 
v_fov
 = ( - 24.9 , 2.0 ) ,

100 
d_range
 = ( 0 , 100 ) ,

101 
y_fudge
 = 3

130 
x_points
 = 
points
 [ : , 0 ]

131 
y_points
 = 
points
 [ : , 1 ]

132 
z_points
 = 
points
 [ : , 2 ]

133 
r_points
 = 
points
 [ : , 3 ]

134 
d_points
 = 
np
 . 
sqrt
 ( 
x_points
 ** 2 + 
y_points
 ** 2 )

141 
v_fov_total
 = - 
v_fov
 [ 0 ] + 
v_fov
 [ 1 ]

144 
v_res_rad
 = 
v_res
 * ( 
np
 . 
pi
 / 180 )

145 
h_res_rad
 = 
h_res
 * ( 
np
 . 
pi
 / 180 )

148 
x_img
 = 
np
 . 
arctan2
 ( 
y_points
 , 
x_points
 ) / 
h_res_rad

149 
y_img
 = - ( 
np
 . 
arctan2
 ( 
z_points
 , 
d_points
 ) / 
v_res_rad
 )

152 
d_plane
 = ( 
v_fov_total
 / 
v_res
 ) / ( 
v_fov_total
 * ( 
np
 . 
pi
 / 180 ) )

153 
h_below
 = 
d_plane
 * 
np
 . 
tan
 ( - 
v_fov
 [ 0 ] * ( 
np
 . 
pi
 / 180 ) )

154 
h_above
 = 
d_plane
 * 
np
 . 
tan
 ( 
v_fov
 [ 1 ] * ( 
np
 . 
pi
 / 180 ) )

155 
y_max
 = 
int
 ( 
np
 . 
ceil
 ( 
h_below
 + 
h_above
 + 
y_fudge
 ) )

158 
x_min
 = - 360.0 / 
h_res
 / 2

159 
x_img
 = 
np
 . 
trunc
 ( - 
x_img
 - 
x_min
 ) . 
astype
 ( 
np
 . 
int32
 )

160 
x_max
 = 
int
 ( 
np
 . 
ceil
 ( 360.0 / 
h_res
 ) )

162 
y_min
 = - ( ( 
v_fov
 [ 1 ] / 
v_res
 ) + 
y_fudge
 )

163 
y_img
 = 
np
 . 
trunc
 ( 
y_img
 - 
y_min
 ) . 
astype
 ( 
np
 . 
int32
 )

166 
d_points
 = 
np
 . 
clip
 ( 
d_points
 , 
a_min
 = 
d_range
 [ 0 ] , 
a_max
 = 
d_range
 [ 1 ] )

169 
img
 = 
np
 . 
zeros
 ( [ 
y_max
 + 1 , 
x_max
 + 1 ] , 
dtype
 = 
np
 . 
uint8
 )

170 
img
 [ 
y_img
 , 
x_img
 ] = 
scale_to_255
 ( 
d_points
 , 
min
 = 
d_range
 [ 0 ] , 
max
 = 
d_range
 [ 1 ] )

172 return 
img
 
	}


	@./net/processing/boxes.py

1 from 
	~net.configuration
 import 
CFG

2 from 
	~net.lib.utils.bbox
 import 
bbox_overlaps
 , 
box_vote

3 from 
	~config
 import *

5 if 
cfg
 . 
USE_GPU_NMS
 :

6 from 
	~net.lib.nms.gpu_nms
 import 
gpu_nms
 as 
nms

8 from 
	~net.lib.nms.cpu_nms
 import 
cpu_nms
 as 
nms

9 import 
	~numpy
 as 
np

15 def 
	$clip_boxes
 ( 
boxes
 , 
width
 , 
height
 ) :

19 
boxes
 [ : , 0 : : 4 ] = 
np
 . 
maximum
 ( 
np
 . 
minimum
 ( 
boxes
 [ : , 0 : : 4 ] , 
width
 - 1 ) , 0 )

21 
boxes
 [ : , 1 : : 4 ] = 
np
 . 
maximum
 ( 
np
 . 
minimum
 ( 
boxes
 [ : , 1 : : 4 ] , 
height
 - 1 ) , 0 )

23 
boxes
 [ : , 2 : : 4 ] = 
np
 . 
maximum
 ( 
np
 . 
minimum
 ( 
boxes
 [ : , 2 : : 4 ] , 
width
 - 1 ) , 0 )

25 
boxes
 [ : , 3 : : 4 ] = 
np
 . 
maximum
 ( 
np
 . 
minimum
 ( 
boxes
 [ : , 3 : : 4 ] , 
height
 - 1 ) , 0 )

26 return 
boxes
 
	}

32 def 
	$box_transform
 ( 
et_boxes
 , 
gt_boxes
 ) :

33 
et_ws
 = 
et_boxes
 [ : , 2 ] - 
et_boxes
 [ : , 0 ] + 1.0

34 
et_hs
 = 
et_boxes
 [ : , 3 ] - 
et_boxes
 [ : , 1 ] + 1.0

35 
et_cxs
 = 
et_boxes
 [ : , 0 ] + 0.5 * 
et_ws

36 
et_cys
 = 
et_boxes
 [ : , 1 ] + 0.5 * 
et_hs

38 
gt_ws
 = 
gt_boxes
 [ : , 2 ] - 
gt_boxes
 [ : , 0 ] + 1.0

39 
gt_hs
 = 
gt_boxes
 [ : , 3 ] - 
gt_boxes
 [ : , 1 ] + 1.0

40 
gt_cxs
 = 
gt_boxes
 [ : , 0 ] + 0.5 * 
gt_ws

41 
gt_cys
 = 
gt_boxes
 [ : , 1 ] + 0.5 * 
gt_hs

43 
dxs
 = ( 
gt_cxs
 - 
et_cxs
 ) / 
et_ws

44 
dys
 = ( 
gt_cys
 - 
et_cys
 ) / 
et_hs

45 
dws
 = 
np
 . 
log
 ( 
gt_ws
 / 
et_ws
 )

46 
dhs
 = 
np
 . 
log
 ( 
gt_hs
 / 
et_hs
 )

48 
deltas
 = 
np
 . 
vstack
 ( ( 
dxs
 , 
dys
 , 
dws
 , 
dhs
 ) ) . 
transpose
 ( )

49 return 
deltas
 
	}

53 def 
	$box_transform_inv
 ( 
et_boxes
 , 
deltas
 ) :

55 
num
 = 
len
 ( 
et_boxes
 )

56 
boxes
 = 
np
 . 
zeros
 ( ( 
num
 , 4 ) , 
dtype
 = 
np
 . 
float32
 )

57 if 
num
 == 0 : return 
boxes

59 
et_ws
 = 
et_boxes
 [ : , 2 ] - 
et_boxes
 [ : , 0 ] + 1.0

60 
et_hs
 = 
et_boxes
 [ : , 3 ] - 
et_boxes
 [ : , 1 ] + 1.0

61 
et_cxs
 = 
et_boxes
 [ : , 0 ] + 0.5 * 
et_ws

62 
et_cys
 = 
et_boxes
 [ : , 1 ] + 0.5 * 
et_hs

64 
et_ws
 = 
et_ws
 [ : , 
np
 . 
newaxis
 ]

65 
et_hs
 = 
et_hs
 [ : , 
np
 . 
newaxis
 ]

66 
et_cxs
 = 
et_cxs
 [ : , 
np
 . 
newaxis
 ]

67 
et_cys
 = 
et_cys
 [ : , 
np
 . 
newaxis
 ]

69 
dxs
 = 
deltas
 [ : , 0 : : 4 ]

70 
dys
 = 
deltas
 [ : , 1 : : 4 ]

71 
dws
 = 
deltas
 [ : , 2 : : 4 ]

72 
dhs
 = 
deltas
 [ : , 3 : : 4 ]

74 
cxs
 = 
dxs
 * 
et_ws
 + 
et_cxs

75 
cys
 = 
dys
 * 
et_hs
 + 
et_cys

76 
ws
 = 
np
 . 
exp
 ( 
dws
 ) * 
et_ws

77 
hs
 = 
np
 . 
exp
 ( 
dhs
 ) * 
et_hs

79 
boxes
 [ : , 0 : : 4 ] = 
cxs
 - 0.5 * 
ws

80 
boxes
 [ : , 1 : : 4 ] = 
cys
 - 0.5 * 
hs

81 
boxes
 [ : , 2 : : 4 ] = 
cxs
 + 0.5 * 
ws

82 
boxes
 [ : , 3 : : 4 ] = 
cys
 + 0.5 * 
hs

84 return 
boxes
 
	}

87 def 
	$non_max_suppress
 ( 
boxes
 , 
scores
 , 
num_classes
 ,

88 
nms_after_thesh
 = 
CFG
 . 
TEST
 . 
RCNN_NMS_AFTER
 ,

89 
nms_before_score_thesh
 = 0.05 ,

90 
is_box_vote
 = False ,

91 
max_per_image
 = 100 ) :

98 
nms_boxes
 = [ [ ] for 
_
 in 
range
 ( 
num_classes
 ) ]

99 for 
j
 in 
range
 ( 1 , 
num_classes
 ) :

100 
inds
 = 
np
 . 
where
 ( 
scores
 [ : , 
j
 ] > 
nms_before_score_thesh
 ) [ 0 ]

102 
cls_scores
 = 
scores
 [ 
inds
 , 
j
 ]

103 
cls_boxes
 = 
boxes
 [ 
inds
 , 
j
 * 4 : ( 
j
 + 1 ) * 4 ]

104 
print
 ( 
cls_scores
 , 
cls_boxes
 )

105 
cls_dets
 = 
np
 . 
hstack
 ( ( 
cls_boxes
 , 
cls_scores
 [ : , 
np
 . 
newaxis
 ] ) ) . 
astype
 ( 
np
 . 
float32
 , 
copy
 = False )

108 if 
len
 ( 
inds
 ) > 0 :

109 
keep
 = 
nms
 ( 
cls_dets
 , 
nms_after_thesh
 )

110 
dets_NMSed
 = 
cls_dets
 [ 
keep
 , : ]

111 if 
is_box_vote
 :

112 
cls_dets
 = 
box_vote
 ( 
dets_NMSed
 , 
cls_dets
 )

114 
cls_dets
 = 
dets_NMSed

116 
nms_boxes
 [ 
j
 ] = 
cls_dets

120 if 
max_per_image
 > 0 :

121 
image_scores
 = 
np
 . 
hstack
 ( [ 
nms_boxes
 [ 
j
 ] [ : , - 1 ] for 
j
 in 
range
 ( 1 , 
num_classes
 ) ] )

122 if 
len
 ( 
image_scores
 ) > 
max_per_image
 :

123 
image_thresh
 = 
np
 . 
sort
 ( 
image_scores
 ) [ - 
max_per_image
 ]

124 for 
j
 in 
range
 ( 1 , 
num_classes
 ) :

125 
keep
 = 
np
 . 
where
 ( 
nms_boxes
 [ 
j
 ] [ : , - 1 ] >= 
image_thresh
 ) [ 0 ]

126 
nms_boxes
 [ 
j
 ] = 
nms_boxes
 [ 
j
 ] [ 
keep
 , : ]

128 return 
nms_boxes
 
	}

131 def 
	$remove_empty_anchors
 ( 
top_view
 , 
anchors
 , 
inside_inds
 ) :

136 return 
inside_inds
 
	}


	@./net/resnet.py

1 from 
	~__future__
 import 
division

2 import 
	~os

3 
os
 . 
environ
 [ 'DISPLAY' ] = ':0'

5 import 
	~six

6 from 
	~keras.models
 import 
Model

7 from 
	~keras.layers
 import (

8 
Input
 ,

9 
Activation
 ,

10 
Dense
 ,

11 
Flatten

13 from 
	~keras.layers.convolutional
 import (

14 
Conv2D
 ,

15 
MaxPooling2D
 ,

16 
AveragePooling2D

18 from 
	~keras.layers.merge
 import 
add

19 from 
	~keras.layers.normalization
 import 
BatchNormalization

20 from 
	~keras.regularizers
 import 
l2

21 from 
	~keras
 import 
backend
 as 
K

24 def 
	$_bn_relu
 ( 
input
 ) :

27 
norm
 = 
BatchNormalization
 ( 
axis
 = 
CHANNEL_AXIS
 ) ( 
input
 )

28 return 
Activation
 ( "relu" ) ( 
norm
 ) 
	}

31 def 
	$_conv_bn_relu
 ( ** 
conv_params
 ) :

34 
filters
 = 
conv_params
 [ "filters" ]

35 
kernel_size
 = 
conv_params
 [ "kernel_size" ]

36 
strides
 = 
conv_params
 . 
setdefault
 ( "strides" , ( 1 , 1 ) )

37 
kernel_initializer
 = 
conv_params
 . 
setdefault
 ( "kernel_initializer" , "he_normal" )

38 
padding
 = 
conv_params
 . 
setdefault
 ( "padding" , "same" )

39 
kernel_regularizer
 = 
conv_params
 . 
setdefault
 ( "kernel_regularizer" , 
l2
 ( 1.e-4 ) )

41 def 
f
 ( 
input
 ) :

42 
conv
 = 
Conv2D
 ( 
filters
 = 
filters
 , 
kernel_size
 = 
kernel_size
 ,

43 
strides
 = 
strides
 , 
padding
 = 
padding
 ,

44 
kernel_initializer
 = 
kernel_initializer
 ,

45 
kernel_regularizer
 = 
kernel_regularizer
 ) ( 
input
 )

46 return 
_bn_relu
 ( 
conv
 )

48 return 
f
 
	}

51 def 
	$_bn_relu_conv
 ( ** 
conv_params
 ) :

55 
filters
 = 
conv_params
 [ "filters" ]

56 
kernel_size
 = 
conv_params
 [ "kernel_size" ]

57 
strides
 = 
conv_params
 . 
setdefault
 ( "strides" , ( 1 , 1 ) )

58 
kernel_initializer
 = 
conv_params
 . 
setdefault
 ( "kernel_initializer" , "he_normal" )

59 
padding
 = 
conv_params
 . 
setdefault
 ( "padding" , "same" )

60 
kernel_regularizer
 = 
conv_params
 . 
setdefault
 ( "kernel_regularizer" , 
l2
 ( 1.e-4 ) )

62 def 
f
 ( 
input
 ) :

63 
activation
 = 
_bn_relu
 ( 
input
 )

64 return 
Conv2D
 ( 
filters
 = 
filters
 , 
kernel_size
 = 
kernel_size
 ,

65 
strides
 = 
strides
 , 
padding
 = 
padding
 ,

66 
kernel_initializer
 = 
kernel_initializer
 ,

67 
kernel_regularizer
 = 
kernel_regularizer
 ) ( 
activation
 )

69 return 
f
 
	}

72 def 
	$_shortcut
 ( 
input
 , 
residual
 ) :

78 
input_shape
 = 
K
 . 
int_shape
 ( 
input
 )

79 
residual_shape
 = 
K
 . 
int_shape
 ( 
residual
 )

80 
stride_width
 = 
int
 ( 
round
 ( 
input_shape
 [ 
ROW_AXIS
 ] / 
residual_shape
 [ 
ROW_AXIS
 ] ) )

81 
stride_height
 = 
int
 ( 
round
 ( 
input_shape
 [ 
COL_AXIS
 ] / 
residual_shape
 [ 
COL_AXIS
 ] ) )

82 
equal_channels
 = 
input_shape
 [ 
CHANNEL_AXIS
 ] == 
residual_shape
 [ 
CHANNEL_AXIS
 ]

84 
shortcut
 = 
input

86 if 
stride_width
 > 1 or 
stride_height
 > 1 or not 
equal_channels
 :

87 
shortcut
 = 
Conv2D
 ( 
filters
 = 
residual_shape
 [ 
CHANNEL_AXIS
 ] ,

88 
kernel_size
 = ( 1 , 1 ) ,

89 
strides
 = ( 
stride_width
 , 
stride_height
 ) ,

90 
padding
 = "valid" ,

91 
kernel_initializer
 = "he_normal" ,

92 
kernel_regularizer
 = 
l2
 ( 0.0001 ) ) ( 
input
 )

94 return 
add
 ( [ 
shortcut
 , 
residual
 ] ) 
	}

97 def 
	$_residual_block
 ( 
block_function
 , 
filters
 , 
repetitions
 , 
is_first_layer
 = False ) :

100 def 
f
 ( 
input
 ) :

101 for 
i
 in 
range
 ( 
repetitions
 ) :

102 
init_strides
 = ( 1 , 1 )

103 if 
i
 == 0 and not 
is_first_layer
 :

104 
init_strides
 = ( 2 , 2 )

105 
input
 = 
block_function
 ( 
filters
 = 
filters
 , 
init_strides
 = 
init_strides
 ,

106 
is_first_block_of_first_layer
 = ( 
is_first_layer
 and 
i
 == 0 ) ) ( 
input
 )

107 return 
input

109 return 
f
 
	}

112 def 
	$basic_block
 ( 
filters
 , 
init_strides
 = ( 1 , 1 ) , 
is_first_block_of_first_layer
 = False ) :

116 def 
f
 ( 
input
 ) :

118 if 
is_first_block_of_first_layer
 :

120 
conv1
 = 
Conv2D
 ( 
filters
 = 
filters
 , 
kernel_size
 = ( 3 , 3 ) ,

121 
strides
 = 
init_strides
 ,

122 
padding
 = "same" ,

123 
kernel_initializer
 = "he_normal" ,

124 
kernel_regularizer
 = 
l2
 ( 1e-4 ) ) ( 
input
 )

126 
conv1
 = 
_bn_relu_conv
 ( 
filters
 = 
filters
 , 
kernel_size
 = ( 3 , 3 ) ,

127 
strides
 = 
init_strides
 ) ( 
input
 )

129 
residual
 = 
_bn_relu_conv
 ( 
filters
 = 
filters
 , 
kernel_size
 = ( 3 , 3 ) ) ( 
conv1
 )

130 return 
_shortcut
 ( 
input
 , 
residual
 )

132 return 
f
 
	}

135 def 
	$bottleneck
 ( 
filters
 , 
init_strides
 = ( 1 , 1 ) , 
is_first_block_of_first_layer
 = False ) :

142 def 
f
 ( 
input
 ) :

144 if 
is_first_block_of_first_layer
 :

146 
conv_1_1
 = 
Conv2D
 ( 
filters
 = 
filters
 , 
kernel_size
 = ( 1 , 1 ) ,

147 
strides
 = 
init_strides
 ,

148 
padding
 = "same" ,

149 
kernel_initializer
 = "he_normal" ,

150 
kernel_regularizer
 = 
l2
 ( 1e-4 ) ) ( 
input
 )

152 
conv_1_1
 = 
_bn_relu_conv
 ( 
filters
 = 
filters
 , 
kernel_size
 = ( 3 , 3 ) ,

153 
strides
 = 
init_strides
 ) ( 
input
 )

155 
conv_3_3
 = 
_bn_relu_conv
 ( 
filters
 = 
filters
 , 
kernel_size
 = ( 3 , 3 ) ) ( 
conv_1_1
 )

156 
residual
 = 
_bn_relu_conv
 ( 
filters
 = 
filters
 * 4 , 
kernel_size
 = ( 1 , 1 ) ) ( 
conv_3_3
 )

157 return 
_shortcut
 ( 
input
 , 
residual
 )

159 return 
f
 
	}

162 def 
	$_handle_dim_ordering
 ( ) :

163 global 
	gROW_AXIS

164 global 
	gCOL_AXIS

165 global 
	gCHANNEL_AXIS

166 if 
K
 . 
image_dim_ordering
 ( ) == 'tf' :

167 
ROW_AXIS
 = 1

168 
COL_AXIS
 = 2

169 
CHANNEL_AXIS
 = 3

171 
CHANNEL_AXIS
 = 1

172 
ROW_AXIS
 = 2

173 
COL_AXIS
 = 3 
	}

176 def 
	$_get_block
 ( 
identifier
 ) :

177 if 
isinstance
 ( 
identifier
 , 
six
 . 
string_types
 ) :

178 
res
 = 
globals
 ( ) . 
get
 ( 
identifier
 )

179 if not 
res
 :

180 raise 
ValueError
 ( 'Invalid {}' . 
format
 ( 
identifier
 ) )

181 return 
res

182 return 
identifier
 
	}

185 class 
	cResnetBuilder
 ( 
object
 ) :

186 @ 
	`staticmethod

187 def 
	$build
 ( 
input_shape
 , 
num_outputs
 , 
block_fn
 , 
repetitions
 ) :

201 
_handle_dim_ordering
 ( )

202 if 
len
 ( 
input_shape
 ) != 3 :

203 raise 
Exception
 ( "Input shape should be a tuple (nb_channels, nb_rows, nb_cols)" )

206 if 
K
 . 
image_dim_ordering
 ( ) == 'tf' :

207 
input_shape
 = ( 
input_shape
 [ 1 ] , 
input_shape
 [ 2 ] , 
input_shape
 [ 0 ] )

210 
block_fn
 = 
_get_block
 ( 
block_fn
 )

213 
input
 = 
Input
 ( 
shape
 = 
input_shape
 )

214 
conv1
 = 
_conv_bn_relu
 ( 
filters
 = 64 , 
kernel_size
 = ( 7 , 7 ) , 
strides
 = ( 2 , 2 ) ) ( 
input
 )

215 
pool1
 = 
MaxPooling2D
 ( 
pool_size
 = ( 3 , 3 ) , 
strides
 = ( 2 , 2 ) , 
padding
 = "same" ) ( 
conv1
 )

217 
block
 = 
pool1

218 
filters
 = 64

219 for 
i
 , 
r
 in 
enumerate
 ( 
repetitions
 ) :

220 
block
 = 
_residual_block
 ( 
block_fn
 , 
filters
 = 
filters
 , 
repetitions
 = 
r
 , 
is_first_layer
 = ( 
i
 == 0 ) ) ( 
block
 )

221 
filters
 *= 2

224 
block
 = 
_bn_relu
 ( 
block
 )

227 
block_shape
 = 
K
 . 
int_shape
 ( 
block
 )

228 
pool2
 = 
AveragePooling2D
 ( 
pool_size
 = ( 
block_shape
 [ 
ROW_AXIS
 ] , 
block_shape
 [ 
COL_AXIS
 ] ) ,

229 
strides
 = ( 1 , 1 ) ) ( 
block
 )

230 
flatten1
 = 
Flatten
 ( ) ( 
pool2
 )

231 
dense
 = 
Dense
 ( 
units
 = 
num_outputs
 , 
kernel_initializer
 = "he_normal" ,

232 
activation
 = "softmax" ) ( 
flatten1
 )

234 
model
 = 
Model
 ( 
inputs
 = 
input
 , 
outputs
 = 
dense
 )

235 return 
model
 
	}

237 @ 
	`staticmethod

238 def 
	$build_tiny
 ( 
input
 , 
block_fn
 , 
repetitions
 ) :

240 
_handle_dim_ordering
 ( )

241 
block_fn
 = 
_get_block
 ( 
block_fn
 )

242 
conv1
 = 
_conv_bn_relu
 ( 
filters
 = 64 , 
kernel_size
 = ( 7 , 7 ) , 
strides
 = ( 2 , 2 ) ) ( 
input
 )

243 
pool1
 = 
MaxPooling2D
 ( 
pool_size
 = ( 3 , 3 ) , 
strides
 = ( 2 , 2 ) , 
padding
 = "same" ) ( 
conv1
 )

245 
block
 = 
pool1

246 
filters
 = 64

247 for 
i
 , 
r
 in 
enumerate
 ( 
repetitions
 ) :

248 
block
 = 
_residual_block
 ( 
block_fn
 , 
filters
 = 
filters
 , 
repetitions
 = 
r
 , 
is_first_layer
 = ( 
i
 == 0 ) ) ( 
block
 )

249 
filters
 *= 2

251 return 
block
 
	}

253 @ 
	`staticmethod

254 def 
	$build_resnet_18
 ( 
input_shape
 , 
num_outputs
 ) :

255 return 
ResnetBuilder
 . 
build
 ( 
input_shape
 , 
num_outputs
 , 
basic_block
 , [ 2 , 2 , 2 , 2 ] ) 
	}

257 @ 
	`staticmethod

258 def 
	$resnet_tiny
 ( 
input
 ) :

259 return 
ResnetBuilder
 . 
build_tiny
 ( 
input
 , 
bottleneck
 , [ 3 , 4 ] ) 
	}

261 @ 
	`staticmethod

262 def 
	$build_resnet_34
 ( 
input_shape
 , 
num_outputs
 ) :

263 return 
ResnetBuilder
 . 
build
 ( 
input_shape
 , 
num_outputs
 , 
basic_block
 , [ 3 , 4 , 6 , 3 ] ) 
	}

265 @ 
	`staticmethod

266 def 
	$build_resnet_50
 ( 
input_shape
 , 
num_outputs
 ) :

267 return 
ResnetBuilder
 . 
build
 ( 
input_shape
 , 
num_outputs
 , 
bottleneck
 , [ 3 , 4 , 6 , 3 ] ) 
	}

269 @ 
	`staticmethod

270 def 
	$build_resnet_101
 ( 
input_shape
 , 
num_outputs
 ) :

271 return 
ResnetBuilder
 . 
build
 ( 
input_shape
 , 
num_outputs
 , 
bottleneck
 , [ 3 , 4 , 23 , 3 ] ) 
	}

273 @ 
	`staticmethod

274 def 
	$build_resnet_152
 ( 
input_shape
 , 
num_outputs
 ) :

275 return 
ResnetBuilder
 . 
build
 ( 
input_shape
 , 
num_outputs
 , 
bottleneck
 , [ 3 , 8 , 36 , 3 ] ) 
	}

277 if 
__name__
 == '__main__' :

278 import 
	~tensorflow
 as 
tf
 """\n    TensorShape([Dimension(None), Dimension(57), Dimension(13), Dimension(128)])\n    input.shape\n    TensorShape([Dimension(None), Dimension(450), Dimension(100), Dimension(10)])\n\n    """

285 
x
 = 
tf
 . 
placeholder
 ( 'float32' , [ None , 450 , 100 , 10 ] )

286 
resnet
 = 
ResnetBuilder
 . 
build_resnet_50
 ( [ 10 , 450 , 100 ] , 10 )

287 
print
 ( 
resnet
 . 
summary
 ( ) )

288 
input
 = 
resnet
 . 
get_layer
 ( 'input_1' ) . 
input

289 
output
 = 
resnet
 . 
get_layer
 ( 'add_7' ) . 
output

290 
resnet_f
 = 
Model
 ( 
inputs
 = 
input
 , 
outputs
 = 
output
 )

292 
print
 ( 
resnet_f
 ( 
x
 ) )


	@./net/configuration.py

1 from 
	~easydict
 import *

2 import 
	~numpy
 as 
np

3 import 
	~simplejson
 as 
jason

8 
CFG
 = 
EasyDict
 ( )

11 
CFG
 . 
TRAIN
 = 
EasyDict
 ( )

14 
CFG
 . 
TRAIN
 . 
IMS_PER_BATCH
 = 1

17 
CFG
 . 
TRAIN
 . 
RPN_BATCHSIZE
 = 256

18 
CFG
 . 
TRAIN
 . 
RPN_FG_FRACTION
 = 0.25

19 
CFG
 . 
TRAIN
 . 
RPN_FG_THRESH_LO
 = 0.7

20 
CFG
 . 
TRAIN
 . 
RPN_BG_THRESH_HI
 = 0.5

22 
CFG
 . 
TRAIN
 . 
RPN_NMS_THRESHOLD
 = 0.5

23 
CFG
 . 
TRAIN
 . 
RPN_NMS_MIN_SIZE
 = 8

24 
CFG
 . 
TRAIN
 . 
RPN_NMS_PRE_TOPN
 = 10

25 
CFG
 . 
TRAIN
 . 
RPN_NMS_POST_TOPN
 = 10

29 
CFG
 . 
TRAIN
 . 
RCNN_BATCH_SIZE
 = 128

30 
CFG
 . 
TRAIN
 . 
RCNN_FG_FRACTION
 = 0.25

31 
CFG
 . 
TRAIN
 . 
RCNN_BG_THRESH_HI
 = 0.01

32 
CFG
 . 
TRAIN
 . 
RCNN_BG_THRESH_LO
 = 0

33 
CFG
 . 
TRAIN
 . 
RCNN_FG_THRESH_LO
 = 0.5

34 
CFG
 . 
TRAIN
 . 
RCNN_box_NORMALIZE_STDS
 = ( 0.1 , 0.1 , 0.2 , 0.2 )

38 
CFG
 . 
TEST
 = 
EasyDict
 ( )

40 
CFG
 . 
TEST
 . 
RCNN_NMS_AFTER
 = 0.3

41 
CFG
 . 
TEST
 . 
RCNN_box_NORMALIZE_STDS
 = 
CFG
 . 
TRAIN
 . 
RCNN_box_NORMALIZE_STDS

42 
CFG
 . 
TEST
 . 
USE_box_VOTE
 = 1

46 def 
	$merge_a_into_b
 ( 
a
 , 
b
 ) :

51 if 
type
 ( 
a
 ) is not 
EasyDict
 :

54 for 
k
 , 
v
 in 
a
 . 
iteritems
 ( ) :

56 if not 
b
 . 
has_key
 ( 
k
 ) :

57 raise 
KeyError
 ( '{} is not a valid config key' . 
format
 ( 
k
 ) )

60 
old_type
 = 
type
 ( 
b
 [ 
k
 ] )

61 if 
old_type
 is not 
type
 ( 
v
 ) :

62 if 
isinstance
 ( 
b
 [ 
k
 ] , 
np
 . 
ndarray
 ) :

63 
v
 = 
np
 . 
array
 ( 
v
 , 
dtype
 = 
b
 [ 
k
 ] . 
dtype
 )

65 raise 
ValueError
 ( ( 'Type mismatch ({} vs. {}) ' 'for config key: {}'

66 ) . 
format
 ( 
type
 ( 
b
 [ 
k
 ] ) , 
type
 ( 
v
 ) , 
k
 ) )

69 if 
type
 ( 
v
 ) is 
EasyDict
 :

71 
merge_a_into_b
 ( 
a
 [ 
k
 ] , 
b
 [ 
k
 ] )

73 
print
 ( 'Error under config key: {}' . 
format
 ( 
k
 ) )

76 
b
 [ 
k
 ] = 
v
 
	}

79 def 
	$read_cfg
 ( 
file
 ) :

82 with 
open
 ( 
file
 , 'r' ) as 
f
 :

83 
cfg
 = 
EasyDict
 ( 
jason
 . 
load
 ( 
f
 ) )

86 
merge_a_into_b
 ( 
cfg
 , 
CFG
 ) 
	}

89 def 
	$write_cfg
 ( 
file
 ) :

91 with 
open
 ( 
file
 , 'w' ) as 
f
 :

92 
jason
 . 
dump
 ( 
CFG
 , 
f
 , 
indent
 = 4 ) 
	}


	@./net/roipooling_op/roi_pooling_op.py

1 import 
	~tensorflow
 as 
tf

2 import 
	~os.path
 as 
osp

4 
filename
 = 
osp
 . 
join
 ( 
osp
 . 
dirname
 ( 
__file__
 ) , 'roi_pooling.so' )

5 
_roi_pooling_module
 = 
tf
 . 
load_op_library
 ( 
filename
 )

6 
roi_pool
 = 
_roi_pooling_module
 . 
roi_pool

7 
roi_pool_grad
 = 
_roi_pooling_module
 . 
roi_pool_grad


	@./net/roipooling_op/__init__.py

8 import 
	~tensorflow
 as 
tf

9 import 
	~os

10 from 
	~tensorflow.python.framework
 import 
ops

12 
print
 ( 'running init code of roi pooling' )

13 
filename
 = 
os
 . 
path
 . 
join
 ( 
os
 . 
path
 . 
dirname
 ( 
__file__
 ) , 'roi_pooling.so' )

14 
print
 ( "file name is here: " , 
filename
 )

15 
_roi_pooling_module
 = 
tf
 . 
load_op_library
 ( 
filename
 )

16 
roi_pool
 = 
_roi_pooling_module
 . 
roi_pool

17 
roi_pool_grad
 = 
_roi_pooling_module
 . 
roi_pool_grad

22 @ 
ops
 . 
	`RegisterGradient
 ( "RoiPool" )

23 def 
	$_roi_pool_grad
 ( 
op
 , 
grad
 , 
_
 ) :

32 
data
 = 
op
 . 
inputs
 [ 0 ]

33 
rois
 = 
op
 . 
inputs
 [ 1 ]

34 
argmax
 = 
op
 . 
outputs
 [ 1 ]

35 
height
 = 
op
 . 
get_attr
 ( 'pooled_height' )

36 
width
 = 
op
 . 
get_attr
 ( 'pooled_width' )

37 
scale
 = 
op
 . 
get_attr
 ( 'spatial_scale' )

40 
data_grad
 = 
roi_pool_grad
 ( 
data
 , 
rois
 , 
argmax
 , 
grad
 , 
height
 , 
width
 , 
scale
 )

42 return [ 
data_grad
 , None ] 
	}


	@./net/roipooling_op/roi_pooling_op_grad.py

1 import 
	~tensorflow
 as 
tf

2 from 
	~tensorflow.python.framework
 import 
ops

3 import 
	~roi_pooling_op

5 @ 
ops
 . 
	`RegisterGradient
 ( "RoiPool" )

6 def 
	$_roi_pool_grad
 ( 
op
 , 
grad
 , 
_
 ) :

15 
data
 = 
op
 . 
inputs
 [ 0 ]

16 
rois
 = 
op
 . 
inputs
 [ 1 ]

17 
argmax
 = 
op
 . 
outputs
 [ 1 ]

18 
pooled_height
 = 
op
 . 
get_attr
 ( 'pooled_height' )

19 
pooled_width
 = 
op
 . 
get_attr
 ( 'pooled_width' )

20 
spatial_scale
 = 
op
 . 
get_attr
 ( 'spatial_scale' )

23 
data_grad
 = 
roi_pooling_op
 . 
roi_pool_grad
 ( 
data
 , 
rois
 , 
argmax
 , 
grad
 , 
pooled_height
 , 
pooled_width
 , 
spatial_scale
 )

25 return [ 
data_grad
 , None ] 
	}


	@./net/roipooling_op/roi_pooling_op_test.py

1 import 
	~os

4 import 
	~tensorflow
 as 
tf

5 import 
	~numpy
 as 
np

6 import 
	~os

7 import 
	~net.roipooling_op
 as 
roip

10 def 
	$weight_variable
 ( 
shape
 ) :

11 
initial
 = 
tf
 . 
truncated_normal
 ( 
shape
 , 
stddev
 = 0.1 )

12 return 
tf
 . 
Variable
 ( 
initial
 ) 
	}

14 def 
	$conv2d
 ( 
x
 , 
W
 ) :

15 return 
tf
 . 
nn
 . 
conv2d
 ( 
x
 , 
W
 , 
strides
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' ) 
	}

19 if 
__name__
 == '__main__' :

20 
print
 ( '%s: calling main function ... ' % 
os
 . 
path
 . 
basename
 ( 
__file__
 ) )

21 
sess
 = 
tf
 . 
Session
 ( )

22 with 
sess
 . 
as_default
 ( ) :

24 
data_array
 = 
np
 . 
random
 . 
rand
 ( 32 , 100 , 100 , 3 )

25 
data
 = 
tf
 . 
convert_to_tensor
 ( 
data_array
 , 
dtype
 = 
tf
 . 
float32
 )

27 
rois
 = 
tf
 . 
convert_to_tensor
 ( [ [ 0 , 10 , 10 , 20 , 20 ] , [ 31 , 300 , 300 , 400 , 400 ] ] , 
dtype
 = 
tf
 . 
float32
 )

30 
W
 = 
weight_variable
 ( [ 3 , 3 , 3 , 1 ] )

31 
h
 = 
conv2d
 ( 
data
 , 
W
 )

32 
y
 , 
argmax
 = 
roip
 . 
roi_pool
 ( 
h
 , 
rois
 , 6 , 6 , 1.0 / 3 )

36 
y_hat
 = 
tf
 . 
convert_to_tensor
 ( 
np
 . 
ones
 ( ( 2 , 6 , 6 , 1 ) ) , 
dtype
 = 
tf
 . 
float32
 )

37 
loss
 = 
tf
 . 
reduce_mean
 ( 
tf
 . 
square
 ( 
y
 - 
y_hat
 ) )

38 
optimizer
 = 
tf
 . 
train
 . 
GradientDescentOptimizer
 ( 
learning_rate
 = 0.008 )

39 
optimizer_step
 = 
optimizer
 . 
minimize
 ( 
loss
 )

42 
print
 ( '-----------------------------' )

43 
print
 ( 'y_hat, y, argmax' )

44 
print
 ( 
y_hat
 , 
y
 , 
argmax
 )

49 
sess
 . 
run
 ( 
tf
 . 
global_variables_initializer
 ( ) )

51 for 
iter
 in 
range
 ( 500 ) :

52 
print
 ( "sth" )

53 
_
 , 
ls
 = 
sess
 . 
run
 ( [ 
optimizer_step
 , 
loss
 ] )

56 
print
 ( '-----------------------------' )

57 
print
 ( 'iter=%d,  loss=%f' % ( 
iter
 , 
ls
 ) )

62 
print
 ( '' )

64 
weights
 = 
sess
 . 
run
 ( 
W
 )

65 
estimates
 = 
sess
 . 
run
 ( 
y
 )

66 
features
 = 
sess
 . 
run
 ( 
h
 )

67 
print
 ( 'weights:\n' , 
weights
 )

68 
print
 ( 'estimates:\n' , 
estimates
 )

69 
print
 ( 'features:\n' , 
features
 )


	@./net/rpn_nms_op.py

1 from 
	~net.utility.draw
 import *

3 from 
	~net.processing.boxes
 import *

4 from 
	~net.rpn_target_op
 import 
make_bases
 , 
make_anchors

5 import 
	~tensorflow
 as 
tf

17 def 
	$draw_rpn_deltal_apply
 ( 
image
 , 
probs
 , 
deltas
 , 
anchors
 , 
inside_inds
 , 
threshold
 = 0.75 , 
darker
 = 0.7 ) :

22 
img_rpn
 = 
image
 . 
copy
 ( ) * 
darker

23 
probs
 = 
probs
 . 
reshape
 ( - 1 , 2 )

24 
probs
 = 
probs
 [ : , 1 ]

26 
deltas
 = 
deltas
 . 
reshape
 ( - 1 , 4 )

27 
inds
 = 
np
 . 
argsort
 ( 
probs
 ) [ : : - 1 ]

29 
num_anchors
 = 
len
 ( 
anchors
 )

30 
insides
 = 
np
 . 
zeros
 ( ( 
num_anchors
 ) , 
dtype
 = 
np
 . 
int32
 )

31 
insides
 [ 
inside_inds
 ] = 1

32 for 
j
 in 
range
 ( 100 ) :

33 
i
 = 
inds
 [ 
j
 ]

34 if 
insides
 [ 
i
 ] == 0 :

37 
a
 = 
anchors
 [ 
i
 ]

38 
t
 = 
deltas
 [ 
i
 ]

39 
b
 = 
box_transform_inv
 ( 
a
 . 
reshape
 ( 1 , 4 ) , 
t
 . 
reshape
 ( 1 , 4 ) )

41 
b
 = 
b
 . 
reshape
 ( - 1 )

42 
s
 = 
probs
 [ 
i
 ]

43 if 
s
 < 
threshold
 :

46 
v
 = 
s
 * 255

47 
cv2
 . 
rectangle
 ( 
img_rpn
 , ( 
a
 [ 0 ] , 
a
 [ 1 ] ) , ( 
a
 [ 2 ] , 
a
 [ 3 ] ) , ( 0 , 0 , 
v
 ) , 1 )

48 
cv2
 . 
rectangle
 ( 
img_rpn
 , ( 
b
 [ 0 ] , 
b
 [ 1 ] ) , ( 
b
 [ 2 ] , 
b
 [ 3 ] ) , ( 0 , 
v
 , 
v
 ) , 1 )

50 return 
img_rpn
 
	}

53 def 
	$draw_rpn_proposal
 ( 
image
 , 
rois
 , 
roi_scores
 , 
darker
 = 0.75 , 
draw_num
 = 100 ) :

54 
img_rpn_nms
 = 
image
 . 
copy
 ( ) * 
darker

56 
scores
 = 
roi_scores

57 
inds
 = 
np
 . 
argsort
 ( 
scores
 )

59 
num
 = 
len
 ( 
inds
 )

60 for 
n
 in 
range
 ( 0 , 
num
 ) :

61 
i
 = 
inds
 [ 
n
 ]

62 
box
 = 
rois
 [ 
i
 , 1 : 5 ] . 
astype
 ( 
np
 . 
int
 )

63 
v
 = 254 * ( 1 - 
roi_scores
 [ 
i
 ] ) + 1

64 
color
 = ( 0 , 
v
 , 
v
 )

65 
cv2
 . 
rectangle
 ( 
img_rpn_nms
 , ( 
box
 [ 0 ] , 
box
 [ 1 ] ) , ( 
box
 [ 2 ] , 
box
 [ 3 ] ) , 
color
 , 1 )

67 return 
img_rpn_nms
 
	}

70 def 
	$filter_boxes
 ( 
boxes
 , 
min_size
 ) :

72 
ws
 = 
boxes
 [ : , 2 ] - 
boxes
 [ : , 0 ] + 1

73 
hs
 = 
boxes
 [ : , 3 ] - 
boxes
 [ : , 1 ] + 1

74 
keep
 = 
np
 . 
where
 ( ( 
ws
 >= 
min_size
 ) & ( 
hs
 >= 
min_size
 ) ) [ 0 ]

75 return 
keep
 
	}

79 def 
	$rpn_nms_generator
 (

80 
stride
 , 
img_width
 , 
img_height
 , 
img_scale
 = 1 ,

81 
nms_thresh
 = 
CFG
 . 
TRAIN
 . 
RPN_NMS_THRESHOLD
 ,

82 
min_size
 = 
CFG
 . 
TRAIN
 . 
RPN_NMS_MIN_SIZE
 ,

83 
nms_pre_topn
 = 
CFG
 . 
TRAIN
 . 
RPN_NMS_PRE_TOPN
 ,

84 
nms_post_topn
 = 
CFG
 . 
TRAIN
 . 
RPN_NMS_POST_TOPN
 ) :

87 def 
rpn_nms
 ( 
scores
 , 
deltas
 , 
anchors
 , 
inside_inds
 ) :

91 
scores
 = 
scores
 . 
reshape
 ( ( - 1 , 2 , 1 ) )

92 
scores
 = 
scores
 [ : , 1 , : ]

93 
deltas
 = 
deltas
 . 
reshape
 ( ( - 1 , 4 ) )

95 
scores
 = 
scores
 [ 
inside_inds
 ]

96 
deltas
 = 
deltas
 [ 
inside_inds
 ]

97 
anchors
 = 
anchors
 [ 
inside_inds
 ]

100 
proposals
 = 
box_transform_inv
 ( 
anchors
 , 
deltas
 )

103 
proposals
 = 
clip_boxes
 ( 
proposals
 , 
img_width
 , 
img_height
 )

107 
keep
 = 
filter_boxes
 ( 
proposals
 , 
min_size
 * 
img_scale
 )

108 
proposals
 = 
proposals
 [ 
keep
 , : ]

109 
scores
 = 
scores
 [ 
keep
 ]

113 
order
 = 
scores
 . 
ravel
 ( ) . 
argsort
 ( ) [ : : - 1 ]

114 if 
nms_pre_topn
 > 0 :

115 
order
 = 
order
 [ : 
nms_pre_topn
 ]

116 
proposals
 = 
proposals
 [ 
order
 , : ]

117 
scores
 = 
scores
 [ 
order
 ]

123 
keep
 = 
nms
 ( 
np
 . 
hstack
 ( ( 
proposals
 , 
scores
 ) ) , 
nms_thresh
 )

124 if 
nms_post_topn
 > 0 :

125 
keep
 = 
keep
 [ : 
nms_post_topn
 ]

126 
proposals
 = 
proposals
 [ 
keep
 , : ]

127 
scores
 = 
scores
 [ 
keep
 ]

132 
roi_scores
 = 
scores
 . 
squeeze
 ( )

134 
num_proposals
 = 
len
 ( 
proposals
 )

135 
batch_inds
 = 
np
 . 
zeros
 ( ( 
num_proposals
 , 1 ) , 
dtype
 = 
np
 . 
float32
 )

136 
rois
 = 
np
 . 
hstack
 ( ( 
batch_inds
 , 
proposals
 ) )

138 return 
rois
 , 
roi_scores

139 return 
rpn_nms
 
	}

143 def 
	$tf_rpn_nms
 (

144 
scores
 , 
deltas
 , 
anchors
 , 
inside_inds
 ,

145 
stride
 , 
img_width
 , 
img_height
 , 
img_scale
 ,

146 
nms_thresh
 , 
min_size
 , 
nms_pre_topn
 = 
CFG
 . 
TRAIN
 . 
RPN_NMS_PRE_TOPN
 ,

147 
nms_post_topn
 = 
CFG
 . 
TRAIN
 . 
RPN_NMS_POST_TOPN
 , 
name
 = 'rpn_mns' ) :

152 
rpn_nms
 = 
rpn_nms_generator
 ( 
stride
 , 
img_width
 , 
img_height
 , 
img_scale
 , 
nms_thresh
 , 
min_size
 , 
nms_pre_topn
 , 
nms_post_topn
 )

154 
tf
 . 
py_func
 (

155 
rpn_nms
 ,

156 [ 
scores
 , 
deltas
 , 
anchors
 , 
inside_inds
 ] ,

157 [ 
tf
 . 
float32
 , 
tf
 . 
float32
 ] ,

158 
name
 = 
name
 ) 
	}

161 if 
__name__
 == '__main__' :

162 
print
 ( '\"%s\" running main function ...' % 
os
 . 
path
 . 
basename
 ( 
__file__
 ) )

164 
bases
 = 
make_bases
 (

165 
base_size
 = 16 ,

168 
ratios
 = [ 0.5 , 1 , 2 ] ,

169 
scales
 = 2 ** 
np
 . 
arange
 ( 3 , 4 ) )

170 
num_bases
 = 
len
 ( 
bases
 )

171 
stride
 = 16

172 
image_shape
 = ( 480 , 640 , 3 )

173 
feature_shape
 = ( 480 // 
stride
 , 640 // 
stride
 , 64 )

174 
anchors
 , 
inside_inds
 = 
make_anchors
 ( 
bases
 , 
stride
 , 
image_shape
 [ 0 : 2 ] , 
feature_shape
 [ 0 : 2 ] )

176 
img_height
 , 
img_width
 , 
_
 = 
image_shape

177 
H
 , 
W
 , 
_
 = 
feature_shape

178 
scores
 = 
np
 . 
random
 . 
uniform
 ( 0 , 255 , 
size
 = ( 1 , 
H
 , 
W
 , 
num_bases
 * 2 ) ) . 
astype
 ( 
np
 . 
float32
 )

179 
deltas
 = 
np
 . 
random
 . 
uniform
 ( 0 , 1 , 
size
 = ( 1 , 
H
 , 
W
 , 
num_bases
 * 4 ) ) . 
astype
 ( 
np
 . 
float32
 )

181 
rpn_nms
 = 
rpn_nms_generator
 ( 
stride
 , 
img_width
 , 
img_height
 )

182 
rois
 , 
roi_scores
 = 
rpn_nms
 ( 
scores
 , 
deltas
 , 
anchors
 , 
inside_inds
 )

184 
print
 ( 'sucess!' )


	@./net/__init__.py


	@./net/rcnn_nms_op.py

1 from 
	~net.configuration
 import *

2 from 
	~net.processing.boxes
 import *

3 from 
	~net.processing.boxes3d
 import *

4 from 
	~net.utility.draw
 import *

5 import 
	~numpy
 as 
np

6 from 
	~data
 import 
box3d_to_top_box
 , 
box3d_to_rgb_box

10 def 
	$draw_rcnn
 ( 
image
 , 
probs
 , 
deltas
 , 
rois
 , 
rois3d
 , 
threshold
 = 0.8 ) :

12 
img_rcnn
 = 
image
 . 
copy
 ( )

13 
cls
 = 1

14 
probs
 = 
probs
 [ : , 
cls
 ]

15 
idx
 = 
np
 . 
where
 ( 
probs
 > 
threshold
 ) [ 0 ]

18 
rois
 = 
rois
 [ 
idx
 ]

19 
rois3d
 = 
rois3d
 [ 
idx
 ]

20 
deltas
 = 
deltas
 [ 
idx
 , 
cls
 ]

22 
num
 = 
len
 ( 
rois
 )

23 for 
n
 in 
range
 ( 
num
 ) :

24 
a
 = 
rois
 [ 
n
 , 1 : 5 ]

25 
cv2
 . 
rectangle
 ( 
img_rcnn
 , ( 
a
 [ 0 ] , 
a
 [ 1 ] ) , ( 
a
 [ 2 ] , 
a
 [ 3 ] ) , ( 255 , 0 , 255 ) , 1 )

28 if 
deltas
 . 
shape
 [ 1 : ] == ( 4 , ) :

29 
boxes
 = 
box_transform_inv
 ( 
rois
 [ : , 1 : 5 ] , 
deltas
 )

32 if 
deltas
 . 
shape
 [ 1 : ] == ( 8 , 3 ) :

33 
boxes3d
 = 
box3d_transform_inv
 ( 
rois3d
 , 
deltas
 )

34 
boxes3d
 = 
regularise_box3d
 ( 
boxes3d
 )

35 
img_rcnn
 = 
draw_box3d_on_top
 ( 
img_rcnn
 , 
boxes3d
 )

37 return 
img_rcnn
 
	}

41 def 
	$draw_rcnn_nms
 ( 
rgb
 , 
boxes3d
 , 
probs
 = None ) :

43 
img_rcnn_nms
 = 
rgb
 . 
copy
 ( )

44 
projections
 = 
box3d_to_rgb_box
 ( 
boxes3d
 )

45 
img_rcnn_nms
 = 
draw_rgb_projections
 ( 
img_rcnn_nms
 , 
projections
 , 
color
 = ( 255 , 0 , 255 ) , 
thickness
 = 1 )

47 return 
img_rcnn_nms
 
	}

49 def 
	$draw_box3d_on_image_with_gt
 ( 
rgb
 , 
boxes3d
 , 
gt_boxes3d
 ) :

51 
img_rcnn_nms
 = 
rgb
 . 
copy
 ( )

52 
projections
 = 
box3d_to_rgb_box
 ( 
boxes3d
 )

53 
img_rcnn_nms
 = 
draw_rgb_projections
 ( 
img_rcnn_nms
 , 
projections
 , 
color
 = ( 255 , 0 , 255 ) , 
thickness
 = 1 )

55 
projections_gt
 = 
box3d_to_rgb_box
 ( 
gt_boxes3d
 )

56 
img_rcnn_nms
 = 
draw_rgb_projections
 ( 
img_rcnn_nms
 , 
projections_gt
 , 
color
 = ( 255 , 255 , 255 ) , 
thickness
 = 1 )

58 return 
img_rcnn_nms
 
	}

62 def 
	$rcnn_nms
 ( 
probs
 , 
deltas
 , 
rois3d
 , 
score_threshold
 = 0.75 , 
nms_threshold
 = 0.001 ) :

65 
cls
 = 1

66 
probs
 = 
probs
 [ : , 
cls
 ]

67 
idx
 = 
np
 . 
where
 ( 
probs
 > 
score_threshold
 ) [ 0 ]

70 
rois3d
 = 
rois3d
 [ 
idx
 ]

71 
deltas
 = 
deltas
 [ 
idx
 , 
cls
 ]

72 
probs
 = 
probs
 [ 
idx
 ]

75 if 
deltas
 . 
shape
 [ 1 : ] == ( 8 , 3 ) :

76 
boxes3d
 = 
box3d_transform_inv
 ( 
rois3d
 , 
deltas
 )

77 
boxes3d
 = 
regularise_box3d
 ( 
boxes3d
 )

78 
boxes
 = 
box3d_to_top_box
 ( 
boxes3d
 )

80 
dets
 = 
np
 . 
c_
 [ 
boxes
 , 
probs
 ]

83 
keep
 = 
nms
 ( 
dets
 , 
nms_threshold
 )

84 return 
probs
 [ 
keep
 ] , 
boxes3d
 [ 
keep
 ] 
	}

87 def 
	$draw_fusion_target
 ( 
labels
 , 
deltas
 , 
rois3d
 , 
top_img
 , 
cam_img
 , 
front_img
 , 
class_color
 ) :

89 
boxes3d
 = 
box3d_transform_inv
 ( 
rois3d
 , 
deltas
 )

90 
boxes3d
 = 
regularise_box3d
 ( 
boxes3d
 )

91 
gt_boxes3d
 = 
boxes3d
 [ 
labels
 != 0 ]

92 
raw_boxes3d
 = 
rois3d

94 for 
i
 , 
label
 in 
enumerate
 ( 
labels
 ) :

96 
color
 = 
class_color
 [ 1 ] if 
label
 else 
class_color
 [ 0 ]

97 
top_img
 = 
draw_box3d_on_top
 ( 
top_img
 , 
raw_boxes3d
 [ 
i
 : 
i
 + 1 , : , : ] , ( 
color
 [ 0 ] , 
color
 [ 1 ] , 
color
 [ 2 ] ) )

98 
cam_img
 = 
draw_box3d_on_camera
 ( 
cam_img
 , 
raw_boxes3d
 [ 
i
 : 
i
 + 1 , : , : ] , ( 
color
 [ 0 ] , 
color
 [ 1 ] , 
color
 [ 2 ] ) )

99 
front_img
 = 
draw_box3d_on_front
 ( 
front_img
 , 
raw_boxes3d
 [ 
i
 : 
i
 + 1 , : , : ] , ( 
color
 [ 0 ] , 
color
 [ 1 ] , 
color
 [ 2 ] ) )

101 for 
box
 in 
gt_boxes3d
 :

102 
color
 = 
class_color
 [ 2 ]

103 
top_img
 = 
draw_box3d_on_top
 ( 
top_img
 , 
box
 [ 
np
 . 
newaxis
 , : , : ] , ( 
color
 [ 0 ] , 
color
 [ 1 ] , 
color
 [ 2 ] ) )

104 
cam_img
 = 
draw_box3d_on_camera
 ( 
cam_img
 , 
box
 [ 
np
 . 
newaxis
 , : , : ] , ( 
color
 [ 0 ] , 
color
 [ 1 ] , 
color
 [ 2 ] ) )

105 
front_img
 = 
draw_box3d_on_front
 ( 
front_img
 , 
box
 [ 
np
 . 
newaxis
 , : , : ] , ( 
color
 [ 0 ] , 
color
 [ 1 ] , 
color
 [ 2 ] ) )

107 return 
top_img
 , 
cam_img
 , 
front_img
 
	}


	@./net/rpn_target_op.py

1 from 
	~net.configuration
 import *

2 import 
	~net.processing.boxes
 as 
boxes

3 from 
	~net.lib.utils.bbox
 import 
bbox_overlaps
 as 
box_overlaps

4 from 
	~net.blocks
 import *

5 from 
	~net.utility.draw
 import *

9 def 
	$convert_w_h_cx_cy
 ( 
base
 ) :

12 
w
 = 
base
 [ 2 ] - 
base
 [ 0 ] + 1

13 
h
 = 
base
 [ 3 ] - 
base
 [ 1 ] + 1

14 
cx
 = 
base
 [ 0 ] + 0.5 * ( 
w
 - 1 )

15 
cy
 = 
base
 [ 1 ] + 0.5 * ( 
h
 - 1 )

16 return 
w
 , 
h
 , 
cx
 , 
cy
 
	}

19 def 
	$make_bases_given_ws_hs
 ( 
ws
 , 
hs
 , 
cx
 , 
cy
 ) :

22 
ws
 = 
ws
 [ : , 
np
 . 
newaxis
 ]

23 
hs
 = 
hs
 [ : , 
np
 . 
newaxis
 ]

24 
bases
 = 
np
 . 
hstack
 ( ( 
cx
 - 0.5 * ( 
ws
 - 1 ) ,

25 
cy
 - 0.5 * ( 
hs
 - 1 ) ,

26 
cx
 + 0.5 * ( 
ws
 - 1 ) ,

27 
cy
 + 0.5 * ( 
hs
 - 1 ) ) )

28 return 
bases
 
	}

31 def 
	$make_bases_given_ratios
 ( 
base
 , 
ratios
 ) :

34 
w
 , 
h
 , 
cx
 , 
cy
 = 
convert_w_h_cx_cy
 ( 
base
 )

35 
size
 = 
w
 * 
h

36 
size_ratios
 = 
size
 / 
ratios

37 
ws
 = 
np
 . 
round
 ( 
np
 . 
sqrt
 ( 
size_ratios
 ) )

38 
hs
 = 
np
 . 
round
 ( 
ws
 * 
ratios
 )

39 
bases
 = 
make_bases_given_ws_hs
 ( 
ws
 , 
hs
 , 
cx
 , 
cy
 )

40 return 
bases
 
	}

43 def 
	$make_bases_given_scales
 ( 
base
 , 
scales
 ) :

46 
w
 , 
h
 , 
cx
 , 
cy
 = 
convert_w_h_cx_cy
 ( 
base
 )

47 
ws
 = 
w
 * 
scales

48 
hs
 = 
h
 * 
scales

49 
bases
 = 
make_bases_given_ws_hs
 ( 
ws
 , 
hs
 , 
cx
 , 
cy
 )

50 return 
bases
 
	}

53 def 
	$make_bases
 (

54 
base_size
 = 16 ,

55 
ratios
 = [ 0.5 , 1 , 2 ] ,

56 
scales
 = 2 ** 
np
 . 
arange
 ( 3 , 6 ) ) :

60 
base
 = 
np
 . 
array
 ( [ 1 , 1 , 
base_size
 , 
base_size
 ] ) - 1

61 
ratio_bases
 = 
make_bases_given_ratios
 ( 
base
 , 
ratios
 )

62 
bases
 = 
np
 . 
vstack
 (

63 [ 
make_bases_given_scales
 ( 
ratio_bases
 [ 
i
 , : ] , 
scales
 ) for 
i
 in 
range
 ( 
ratio_bases
 . 
shape
 [ 0 ] ) ] )

64 return 
bases
 
	}

86 def 
	$make_anchors
 ( 
bases
 , 
stride
 , 
image_shape
 , 
feature_shape
 , 
allowed_border
 = 0 ) :

92 
H
 , 
W
 = 
feature_shape

93 
img_height
 , 
img_width
 = 
image_shape

96 
shift_x
 = 
np
 . 
arange
 ( 0 , 
W
 ) * 
stride

97 
shift_y
 = 
np
 . 
arange
 ( 0 , 
H
 ) * 
stride

98 
shift_x
 , 
shift_y
 = 
np
 . 
meshgrid
 ( 
shift_x
 , 
shift_y
 )

99 
shifts
 = 
np
 . 
vstack
 ( ( 
shift_x
 . 
ravel
 ( ) , 
shift_y
 . 
ravel
 ( ) , 
shift_x
 . 
ravel
 ( ) , 
shift_y
 . 
ravel
 ( ) ) ) . 
transpose
 ( )

101 
B
 = 
len
 ( 
bases
 )

102 
HW
 = 
len
 ( 
shifts
 )

103 
anchors
 = ( 
bases
 . 
reshape
 ( ( 1 , 
B
 , 4 ) ) + 
shifts
 . 
reshape
 ( ( 1 , 
HW
 , 4 ) ) . 
transpose
 ( ( 1 , 0 , 2 ) ) )

104 
anchors
 = 
anchors
 . 
reshape
 ( ( 
HW
 * 
B
 , 4 ) ) . 
astype
 ( 
np
 . 
int32
 )

105 
num_anchors
 = 
int
 ( 
HW
 * 
B
 )

108 
inside_inds
 = 
np
 . 
where
 (

109 ( 
anchors
 [ : , 0 ] >= - 
allowed_border
 ) &

110 ( 
anchors
 [ : , 1 ] >= - 
allowed_border
 ) &

111 ( 
anchors
 [ : , 2 ] < 
img_width
 + 
allowed_border
 ) &

112 ( 
anchors
 [ : , 3 ] < 
img_height
 + 
allowed_border
 )

113 ) [ 0 ] . 
astype
 ( 
np
 . 
int32
 )

115 return 
anchors
 , 
inside_inds
 
	}

120 def 
	$rpn_target
 ( 
anchors
 , 
inside_inds
 , 
gt_labels
 , 
gt_boxes
 ) :

138 
inside_anchors
 = 
anchors
 [ 
inside_inds
 , : ]

141 
labels
 = 
np
 . 
empty
 ( ( 
len
 ( 
inside_inds
 ) , ) , 
dtype
 = 
np
 . 
int32
 )

142 
labels
 . 
fill
 ( - 1 )

145 
overlaps
 = 
box_overlaps
 (

146 
np
 . 
ascontiguousarray
 ( 
inside_anchors
 , 
dtype
 = 
np
 . 
float
 ) ,

147 
np
 . 
ascontiguousarray
 ( 
gt_boxes
 , 
dtype
 = 
np
 . 
float
 ) )

149 
argmax_overlaps
 = 
overlaps
 . 
argmax
 ( 
axis
 = 1 )

150 
max_overlaps
 = 
overlaps
 [ 
np
 . 
arange
 ( 
len
 ( 
inside_inds
 ) ) , 
argmax_overlaps
 ]

151 
gt_argmax_overlaps
 = 
overlaps
 . 
argmax
 ( 
axis
 = 0 )

152 
gt_max_overlaps
 = 
overlaps
 [ 
gt_argmax_overlaps
 , 
np
 . 
arange
 ( 
overlaps
 . 
shape
 [ 1 ] ) ]

154 
tmp
 = [ ]

155 for 
ele
 in 
gt_max_overlaps
 :

156 if 
ele
 != 0 :

157 
tmp
 . 
append
 ( 
ele
 )

158 
gt_max_overlaps
 = 
np
 . 
array
 ( 
tmp
 )

160 
gt_argmax_overlaps
 = 
np
 . 
where
 ( 
overlaps
 == 
gt_max_overlaps
 ) [ 0 ]

162 
labels
 [ 
max_overlaps
 < 
CFG
 . 
TRAIN
 . 
RPN_BG_THRESH_HI
 ] = 0

163 
labels
 [ 
gt_argmax_overlaps
 ] = 1

164 
labels
 [ 
max_overlaps
 >= 
CFG
 . 
TRAIN
 . 
RPN_FG_THRESH_LO
 ] = 1

169 
num_fg
 = 
int
 ( 
CFG
 . 
TRAIN
 . 
RPN_FG_FRACTION
 * 
CFG
 . 
TRAIN
 . 
RPN_BATCHSIZE
 )

170 
fg_inds
 = 
np
 . 
where
 ( 
labels
 == 1 ) [ 0 ]

171 if 
len
 ( 
fg_inds
 ) > 
num_fg
 :

172 
disable_inds
 = 
np
 . 
random
 . 
choice
 ( 
fg_inds
 , 
size
 = ( 
len
 ( 
fg_inds
 ) - 
num_fg
 ) , 
replace
 = False )

173 
labels
 [ 
disable_inds
 ] = - 1

176 
num_bg
 = 
int
 ( 
CFG
 . 
TRAIN
 . 
RPN_BATCHSIZE
 - 
np
 . 
sum
 ( 
labels
 == 1 ) )

177 
bg_inds
 = 
np
 . 
where
 ( 
labels
 == 0 ) [ 0 ]

178 if 
len
 ( 
bg_inds
 ) > 
num_bg
 :

179 
disable_inds
 = 
np
 . 
random
 . 
choice
 ( 
bg_inds
 , 
size
 = ( 
len
 ( 
bg_inds
 ) - 
num_bg
 ) , 
replace
 = False )

180 
labels
 [ 
disable_inds
 ] = - 1

182 
idx_label
 = 
np
 . 
where
 ( 
labels
 != - 1 ) [ 0 ]

183 
idx_target
 = 
np
 . 
where
 ( 
labels
 == 1 ) [ 0 ]

185 
pos_neg_inds
 = 
inside_inds
 [ 
idx_label
 ]

186 
labels
 = 
labels
 [ 
idx_label
 ]

188 
pos_inds
 = 
inside_inds
 [ 
idx_target
 ]

189 
pos_anchors
 = 
inside_anchors
 [ 
idx_target
 ]

190 
pos_gt_boxes
 = ( 
gt_boxes
 [ 
argmax_overlaps
 ] ) [ 
idx_target
 ]

191 
targets
 = 
boxes
 . 
box_transform
 ( 
pos_anchors
 , 
pos_gt_boxes
 )

193 return 
pos_neg_inds
 , 
pos_inds
 , 
labels
 , 
targets
 
	}

209 def 
	$draw_rpn_gt
 ( 
image
 , 
gt_boxes
 , 
gt_labels
 = None ) :

213 
gt_labels
 = 
gt_labels
 [ 0 ]

215 
img_gt
 = 
image
 . 
copy
 ( )

216 
num
 = 
len
 ( 
gt_boxes
 )

217 for 
n
 in 
range
 ( 
num
 ) :

218 
b
 = 
gt_boxes
 [ 
n
 ]

219 
u0
 , 
v0
 = 
b
 [ 0 ] , 
b
 [ 1 ]

220 
u1
 , 
v1
 = 
b
 [ 2 ] , 
b
 [ 3 ]

221 
thickness
 = 1

222 if 
gt_labels
 [ 
n
 ] == 1 :

223 
color
 = ( 255 , 0 , 0 )

224 
cv2
 . 
line
 ( 
img_gt
 , ( 
u0
 , 
v0
 ) , ( 
u0
 , 
v1
 ) , 
color
 , 
thickness
 , 
cv2
 . 
LINE_AA
 )

225 
cv2
 . 
line
 ( 
img_gt
 , ( 
u0
 , 
v1
 ) , ( 
u1
 , 
v1
 ) , 
color
 , 
thickness
 , 
cv2
 . 
LINE_AA
 )

226 
cv2
 . 
line
 ( 
img_gt
 , ( 
u1
 , 
v1
 ) , ( 
u1
 , 
v0
 ) , 
color
 , 
thickness
 , 
cv2
 . 
LINE_AA
 )

227 
cv2
 . 
line
 ( 
img_gt
 , ( 
u1
 , 
v0
 ) , ( 
u0
 , 
v0
 ) , 
color
 , 
thickness
 , 
cv2
 . 
LINE_AA
 )

228 elif 
gt_labels
 [ 
n
 ] == 0 :

229 
color
 = ( 0 , 255 , 255 )

230 
cv2
 . 
line
 ( 
img_gt
 , ( 
u0
 , 
v0
 ) , ( 
u0
 , 
v1
 ) , 
color
 , 
thickness
 , 
cv2
 . 
LINE_AA
 )

231 
cv2
 . 
line
 ( 
img_gt
 , ( 
u0
 , 
v1
 ) , ( 
u1
 , 
v1
 ) , 
color
 , 
thickness
 , 
cv2
 . 
LINE_AA
 )

232 
cv2
 . 
line
 ( 
img_gt
 , ( 
u1
 , 
v1
 ) , ( 
u1
 , 
v0
 ) , 
color
 , 
thickness
 , 
cv2
 . 
LINE_AA
 )

233 
cv2
 . 
line
 ( 
img_gt
 , ( 
u1
 , 
v0
 ) , ( 
u0
 , 
v0
 ) , 
color
 , 
thickness
 , 
cv2
 . 
LINE_AA
 )

235 return 
img_gt
 
	}

237 def 
	$draw_rpn_labels
 ( 
image
 , 
anchors
 , 
inds
 , 
labels
 ) :

239 
is_print
 = 0

247 
num_anchors
 = 
len
 ( 
anchors
 )

248 
labels
 = 
labels
 . 
reshape
 ( - 1 )

250 
fg_label_inds
 = 
inds
 [ 
np
 . 
where
 ( 
labels
 == 1 ) [ 0 ] ]

251 
bg_label_inds
 = 
inds
 [ 
np
 . 
where
 ( 
labels
 == 0 ) [ 0 ] ]

252 
num_pos_label
 = 
len
 ( 
fg_label_inds
 )

253 
num_neg_label
 = 
len
 ( 
bg_label_inds
 )

254 if 
is_print
 : 
print
 ( 'rpn label : num_pos=%d num_neg=%d,  all = %d' % ( 
num_pos_label
 , 
num_neg_label
 , 
num_pos_label
 + 
num_neg_label
 ) )

256 
img_label
 = 
image
 . 
copy
 ( )

257 for 
i
 in 
bg_label_inds
 :

258 
a
 = 
anchors
 [ 
i
 ]

259 
cv2
 . 
rectangle
 ( 
img_label
 , ( 
a
 [ 0 ] , 
a
 [ 1 ] ) , ( 
a
 [ 2 ] , 
a
 [ 3 ] ) , ( 32 , 32 , 32 ) , 1 )

260 
cv2
 . 
circle
 ( 
img_label
 , ( 
a
 [ 0 ] , 
a
 [ 1 ] ) , 2 , ( 32 , 32 , 32 ) , - 1 )

262 for 
i
 in 
fg_label_inds
 :

263 
a
 = 
anchors
 [ 
i
 ]

264 
cv2
 . 
rectangle
 ( 
img_label
 , ( 
a
 [ 0 ] , 
a
 [ 1 ] ) , ( 
a
 [ 2 ] , 
a
 [ 3 ] ) , ( 0 , 0 , 255 ) , 1 )

265 
cv2
 . 
circle
 ( 
img_label
 , ( 
a
 [ 0 ] , 
a
 [ 1 ] ) , 2 , ( 0 , 0 , 255 ) , - 1 )

267 return 
img_label
 
	}

272 def 
	$draw_rpn_targets
 ( 
image
 , 
anchors
 , 
pos_inds
 , 
targets
 ) :

273 
is_print
 = 0

276 
fg_target_inds
 = 
pos_inds

277 
num_pos_target
 = 
len
 ( 
fg_target_inds
 )

278 if 
is_print
 : 
print
 ( 'rpn target : num_pos=%d' % ( 
num_pos_target
 ) )

280 
img_target
 = 
image
 . 
copy
 ( )

281 for 
n
 , 
i
 in 
enumerate
 ( 
fg_target_inds
 ) :

282 
a
 = 
anchors
 [ 
i
 ]

283 
t
 = 
targets
 [ 
n
 ]

284 
b
 = 
boxes
 . 
box_transform_inv
 ( 
a
 . 
reshape
 ( 1 , 4 ) , 
t
 . 
reshape
 ( 1 , 4 ) )

285 
b
 = 
b
 . 
reshape
 ( - 1 ) . 
astype
 ( 
np
 . 
int32
 )

287 
cv2
 . 
rectangle
 ( 
img_target
 , ( 
a
 [ 0 ] , 
a
 [ 1 ] ) , ( 
a
 [ 2 ] , 
a
 [ 3 ] ) , ( 0 , 0 , 255 ) , 1 )

288 
cv2
 . 
rectangle
 ( 
img_target
 , ( 
b
 [ 0 ] , 
b
 [ 1 ] ) , ( 
b
 [ 2 ] , 
b
 [ 3 ] ) , ( 0 , 255 , 255 ) , 1 )

289 return 
img_target
 
	}

415 if 
__name__
 == '__main__' :

416 
print
 ( '\"%s\" running main function ...' % 
os
 . 
path
 . 
basename
 ( 
__file__
 ) )

418 
test_op
 ( )


	@./net/blocks.py

5 import 
	~tensorflow
 as 
tf

6 import 
	~numpy
 as 
np

12 
IS_TRAIN_PHASE
 = 
tf
 . 
placeholder
 ( 
dtype
 = 
tf
 . 
bool
 , 
name
 = 'is_train_phase' )

16 def 
	$print_macs_to_file
 ( 
log
 = None ) :

21 if 
log
 is not None :

22 
log
 . 
write
 ( 'MAC for conv layers : \n' )

23 
log
 . 
write
 ( 'MAC  param_size  :   name           (op)    params   out    in \n' )

24 
log
 . 
write
 ( '----------------------------------------------------------------\n' )

27 
all
 = 0

28 
all_param_size
 = 0

29 
all_mac
 = 0

31 
ops
 = 
tf
 . 
Graph
 . 
get_operations
 ( 
tf
 . 
get_default_graph
 ( ) )

32 for 
op
 in 
ops
 :

33 if 
hasattr
 ( 
op
 . 
op_def
 , 'name' ) :

34 
op_name
 = 
op
 . 
op_def
 . 
name

35 if 
op_name
 == 'Conv2D' :

49 
g
 = 1

50 assert ( 
op
 . 
inputs
 [ 1 ] . 
name
 == 
op
 . 
name
 + '_weight/read:0' )

51 
inum
 , 
ih
 , 
iw
 , 
ic
 = 
op
 . 
inputs
 [ 0 ] . 
get_shape
 ( ) . 
as_list
 ( )

52 
onum
 , 
oh
 , 
ow
 , 
oc
 = 
op
 . 
outputs
 [ 0 ] . 
get_shape
 ( ) . 
as_list
 ( )

53 
h
 , 
w
 , 
ki
 , 
ko
 = 
op
 . 
inputs
 [ 1 ] . 
get_shape
 ( ) . 
as_list
 ( )

54 assert ( 
ic
 == 
ki
 )

55 assert ( 
oc
 == 
ko
 )

58 
name
 = 
op
 . 
name

59 
input_name
 = 
op
 . 
inputs
 [ 0 ] . 
name

60 
output_name
 = 
op
 . 
outputs
 [ 0 ] . 
name

62 
mac
 = 
w
 * 
h
 * 
ic
 * 
oc
 * 
oh
 * 
ow
 / 1000000. / 
g

63 
param_size
 = 
oc
 * 
h
 * 
w
 * 
ic
 / 1000000.

66 
all_param_size
 += 
param_size

67 
all_mac
 += 
mac

68 
all
 += 1

70 if 
log
 is not None :

71 
log
 . 
write
 ( '%10.1f  %5.2f  :  %-26s (%s)   %4d  %dx%dx%4d   %-30s %3d, %3d, %4d,   %-30s %3d, %3d, %5d\n' %

72 ( 
mac
 , 
param_size
 , 
name
 , 'Conv2D' , 
oc
 , 
h
 , 
w
 , 
ic
 , 
output_name
 , 
oh
 , 
ow
 , 
oc
 , 
input_name
 , 
ih
 , 
iw
 , 
ic
 ) )

76 
print
 ( 'error in shape?' )

79 if 
op_name
 == 'MatMul' :

87 
inum
 , 
ic
 = 
op
 . 
inputs
 [ 0 ] . 
get_shape
 ( ) . 
as_list
 ( )

88 
onum
 , 
oc
 = 
op
 . 
outputs
 [ 0 ] . 
get_shape
 ( ) . 
as_list
 ( )

90 
name
 = 
op
 . 
name

91 
input_name
 = 
op
 . 
inputs
 [ 0 ] . 
name

92 
output_name
 = 
op
 . 
outputs
 [ 0 ] . 
name

94 
mac
 = 
ic
 * 
oc
 / 1000000. / 
g

95 
param_size
 = 
oc
 * 
ic
 / 1000000.

97 
all_param_size
 += 
param_size

98 
all_mac
 += 
mac

99 
all
 += 1

101 if 
log
 is not None :

102 
log
 . 
write
 ( '%10.1f  %5.2f  :  %-26s (%s)   %4d  %dx%dx%3d   %-30s %3d, %3d, %4d,   %-30s %3d, %3d, %5d\n' %

103 ( 
mac
 , 
param_size
 , 
name
 , 'Conv2D' , 
oc
 , 1 , 1 , 
ic
 , 
output_name
 , 1 , 1 , 
oc
 , 
input_name
 , 1 , 1 , 
ic
 ) )

104 if 
log
 is not None :

105 
log
 . 
write
 ( '\n' )

106 
log
 . 
write
 ( 'summary : \n' )

107 
log
 . 
write
 ( 'num of conv     = %d\n' % 
all
 )

108 
log
 . 
write
 ( 'all mac         = %.1f (M)\n' % 
all_mac
 )

109 
log
 . 
write
 ( 'all param_size  = %.1f (M)\n' % 
all_param_size
 )

111 return 
all
 , 
all_mac
 , 
all_param_size
 
	}

116 def 
	$l2_regulariser
 ( 
decay
 ) :

118 
variables
 = 
tf
 . 
get_collection
 ( 
tf
 . 
GraphKeys
 . 
GLOBAL_VARIABLES
 )

119 for 
v
 in 
variables
 :

120 
name
 = 
v
 . 
name

121 if 'weight' in 
name
 :

122 
l2
 = 
decay
 * 
tf
 . 
nn
 . 
l2_loss
 ( 
v
 )

123 
tf
 . 
add_to_collection
 ( 'losses' , 
l2
 )

124 elif 'bias' in 
name
 :

126 elif 'beta' in 
name
 :

128 elif 'gamma' in 
name
 :

130 elif 'moving_mean' in 
name
 :

132 elif 'moving_variance' in 
name
 :

134 elif 'moments' in 
name
 :

139 raise 
Exception
 ( 'unknown variable type: %s ?' % 
name
 )

142 
l2_loss
 = 
tf
 . 
add_n
 ( 
tf
 . 
get_collection
 ( 'losses' ) )

143 return 
l2_loss
 
	}

150 def 
	$conv2d
 ( 
input
 , 
num_kernels
 = 1 , 
kernel_size
 = ( 1 , 1 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
has_bias
 = True , 
name
 = 'conv' ) :

152 
input_shape
 = 
input
 . 
get_shape
 ( ) . 
as_list
 ( )

153 assert 
len
 ( 
input_shape
 ) == 4

154 
C
 = 
input_shape
 [ 3 ]

155 
H
 = 
kernel_size
 [ 0 ]

156 
W
 = 
kernel_size
 [ 1 ]

157 
K
 = 
num_kernels

160 
w
 = 
tf
 . 
get_variable
 ( 
name
 = 
name
 + '_weight' , 
shape
 = [ 
H
 , 
W
 , 
C
 , 
K
 ] , 
initializer
 = 
tf
 . 
truncated_normal_initializer
 ( 
stddev
 = 0.1 ) )

161 
conv
 = 
tf
 . 
nn
 . 
conv2d
 ( 
input
 , 
w
 , 
strides
 = 
stride
 , 
padding
 = 
padding
 , 
name
 = 
name
 )

162 if 
has_bias
 :

163 
b
 = 
tf
 . 
get_variable
 ( 
name
 = 
name
 + '_bias' , 
shape
 = [ 
K
 ] , 
initializer
 = 
tf
 . 
constant_initializer
 ( 0.0 ) )

164 
conv
 = 
conv
 + 
b

166 return 
conv
 
	}

169 def 
	$relu
 ( 
input
 , 
name
 = 'relu' ) :

170 
act
 = 
tf
 . 
nn
 . 
relu
 ( 
input
 , 
name
 = 
name
 )

171 return 
act
 
	}

174 def 
	$dropout
 ( 
input
 , 
keep
 = 1.0 , 
name
 = 'drop' ) :

176 
drop
 = 
tf
 . 
cond
 ( 
IS_TRAIN_PHASE
 ,

177 lambda : 
tf
 . 
nn
 . 
dropout
 ( 
input
 , 
keep
 ) ,

178 lambda : 
tf
 . 
nn
 . 
dropout
 ( 
input
 , 1 ) )

179 return 
drop
 
	}

184 def 
	$bn
 ( 
input
 , 
decay
 = 0.9 , 
eps
 = 1e-5 , 
name
 = 'bn' ) :

185 with 
tf
 . 
variable_scope
 ( 
name
 ) as 
scope
 :

186 
bn
 = 
tf
 . 
cond
 ( 
IS_TRAIN_PHASE
 ,

187 lambda : 
tf
 . 
contrib
 . 
layers
 . 
batch_norm
 ( 
input
 , 
decay
 = 
decay
 , 
epsilon
 = 
eps
 , 
center
 = True , 
scale
 = True ,

188 
is_training
 = 1 , 
reuse
 = None ,

189 
updates_collections
 = None , 
scope
 = 
scope
 ) ,

190 lambda : 
tf
 . 
contrib
 . 
layers
 . 
batch_norm
 ( 
input
 , 
decay
 = 
decay
 , 
epsilon
 = 
eps
 , 
center
 = True , 
scale
 = True ,

191 
is_training
 = 0 , 
reuse
 = True ,

192 
updates_collections
 = None , 
scope
 = 
scope
 ) )

194 return 
bn
 
	}

197 def 
	$maxpool
 ( 
input
 , 
kernel_size
 = ( 1 , 1 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = 'max' ) :

198 
H
 = 
kernel_size
 [ 0 ]

199 
W
 = 
kernel_size
 [ 1 ]

200 
pool
 = 
tf
 . 
nn
 . 
max_pool
 ( 
input
 , 
ksize
 = [ 1 , 
H
 , 
W
 , 1 ] , 
strides
 = 
stride
 , 
padding
 = 
padding
 , 
name
 = 
name
 )

201 return 
pool
 
	}

203 def 
	$avgpool
 ( 
input
 , 
kernel_size
 = ( 1 , 1 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
has_bias
 = True , 
is_global_pool
 = False , 
name
 = 'avg' ) :

205 if 
is_global_pool
 == True :

206 
input_shape
 = 
input
 . 
get_shape
 ( ) . 
as_list
 ( )

207 assert 
len
 ( 
input_shape
 ) == 4

208 
H
 = 
input_shape
 [ 1 ]

209 
W
 = 
input_shape
 [ 2 ]

211 
pool
 = 
tf
 . 
nn
 . 
avg_pool
 ( 
input
 , 
ksize
 = [ 1 , 
H
 , 
W
 , 1 ] , 
strides
 = [ 1 , 
H
 , 
W
 , 1 ] , 
padding
 = 'VALID' , 
name
 = 
name
 )

212 
pool
 = 
flatten
 ( 
pool
 )

215 
H
 = 
kernel_size
 [ 0 ]

216 
W
 = 
kernel_size
 [ 1 ]

217 
pool
 = 
tf
 . 
nn
 . 
avg_pool
 ( 
input
 , 
ksize
 = [ 1 , 
H
 , 
W
 , 1 ] , 
strides
 = 
stride
 , 
padding
 = 
padding
 , 
name
 = 
name
 )

219 return 
pool
 
	}

222 def 
	$concat
 ( 
input
 , 
axis
 = 3 , 
name
 = 'cat' ) :

223 
cat
 = 
tf
 . 
concat
 ( 
axis
 = 
axis
 , 
values
 = 
input
 , 
name
 = 
name
 )

224 return 
cat
 
	}

226 def 
	$flatten
 ( 
input
 , 
name
 = 'flat' ) :

227 
input_shape
 = 
input
 . 
get_shape
 ( ) . 
as_list
 ( )

228 
dim
 = 
np
 . 
prod
 ( 
input_shape
 [ 1 : ] )

229 
flat
 = 
tf
 . 
reshape
 ( 
input
 , [ - 1 , 
dim
 ] , 
name
 = 
name
 )

230 return 
flat
 
	}

232 def 
	$linear
 ( 
input
 , 
num_hiddens
 = 1 , 
has_bias
 = True , 
name
 = 'linear' ) :

233 
input_shape
 = 
input
 . 
get_shape
 ( ) . 
as_list
 ( )

234 assert 
len
 ( 
input_shape
 ) == 2

236 
C
 = 
input_shape
 [ 1 ]

237 
K
 = 
num_hiddens

239 
w
 = 
tf
 . 
get_variable
 ( 
name
 = 
name
 + '_weight' , 
shape
 = [ 
C
 , 
K
 ] , 
initializer
 = 
tf
 . 
truncated_normal_initializer
 ( 
stddev
 = 0.1 ) )

240 
dense
 = 
tf
 . 
matmul
 ( 
input
 , 
w
 , 
name
 = 
name
 )

241 if 
has_bias
 :

242 
b
 = 
tf
 . 
get_variable
 ( 
name
 = 
name
 + '_bias' , 
shape
 = [ 
K
 ] , 
initializer
 = 
tf
 . 
constant_initializer
 ( 0.0 ) )

243 
dense
 = 
dense
 + 
b

245 return 
dense
 
	}

254 def 
	$upsample2d
 ( 
input
 , 
factor
 = 2 , 
has_bias
 = True , 
trainable
 = True , 
name
 = 'upsample2d' ) :

256 def 
make_upsample_filter
 ( 
size
 ) :

260 
factor
 = ( 
size
 + 1 ) // 2

261 if 
size
 % 2 == 1 :

262 
center
 = 
factor
 - 1

264 
center
 = 
factor
 - 0.5

265 
og
 = 
np
 . 
ogrid
 [ : 
size
 , : 
size
 ]

266 return ( 1 - 
abs
 ( 
og
 [ 0 ] - 
center
 ) / 
factor
 ) *

267 ( 1 - 
abs
 ( 
og
 [ 1 ] - 
center
 ) / 
factor
 )

269 
input_shape
 = 
input
 . 
get_shape
 ( ) . 
as_list
 ( )

270 assert 
len
 ( 
input_shape
 ) == 4

271 
N
 = 
input_shape
 [ 0 ]

272 
H
 = 
input_shape
 [ 1 ]

273 
W
 = 
input_shape
 [ 2 ]

274 
C
 = 
input_shape
 [ 3 ]

275 
K
 = 
C

277 
size
 = 2 * 
factor
 - 
factor
 % 2

278 
filter
 = 
make_upsample_filter
 ( 
size
 )

279 
weights
 = 
np
 . 
zeros
 ( 
shape
 = ( 
size
 , 
size
 , 
C
 , 
K
 ) , 
dtype
 = 
np
 . 
float32
 )

280 for 
c
 in 
range
 ( 
C
 ) :

281 
weights
 [ : , : , 
c
 , 
c
 ] = 
filter

282 
init
 = 
tf
 . 
constant_initializer
 ( 
value
 = 
weights
 , 
dtype
 = 
tf
 . 
float32
 )

285 
output_shape
 = 
tf
 . 
stack
 ( [ 
tf
 . 
shape
 ( 
input
 ) [ 0 ] , 
tf
 . 
shape
 ( 
input
 ) [ 1 ] * 
factor
 , 
tf
 . 
shape
 ( 
input
 ) [ 2 ] * 
factor
 , 
tf
 . 
shape
 ( 
input
 ) [ 3 ] ] )

286 
w
 = 
tf
 . 
get_variable
 ( 
name
 = 
name
 + '_weight' , 
shape
 = [ 
size
 , 
size
 , 
C
 , 
K
 ] , 
initializer
 = 
init
 , 
trainable
 = 
trainable
 )

287 
deconv
 = 
tf
 . 
nn
 . 
conv2d_transpose
 ( 
name
 = 
name
 , 
value
 = 
input
 , 
filter
 = 
w
 , 
output_shape
 = 
output_shape
 , 
strides
 = [ 1 , 
factor
 , 
factor
 , 1 ] , 
padding
 = 'SAME' )

289 if 
has_bias
 :

290 
b
 = 
tf
 . 
get_variable
 ( 
name
 = 
name
 + '_bias' , 
shape
 = [ 
K
 ] , 
initializer
 = 
tf
 . 
constant_initializer
 ( 0.0 ) )

291 
deconv
 = 
deconv
 + 
b

293 return 
deconv
 
	}

296 def 
	$conv2d_bn_relu
 ( 
input
 , 
num_kernels
 = 1 , 
kernel_size
 = ( 1 , 1 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = 'conv' ) :

297 with 
tf
 . 
variable_scope
 ( 
name
 ) as 
scope
 :

298 
block
 = 
conv2d
 ( 
input
 , 
num_kernels
 = 
num_kernels
 , 
kernel_size
 = 
kernel_size
 , 
stride
 = 
stride
 , 
padding
 = 
padding
 , 
has_bias
 = False )

299 
block
 = 
bn
 ( 
block
 )

300 
block
 = 
relu
 ( 
block
 )

301 return 
block
 
	}

303 def 
	$conv2d_relu
 ( 
input
 , 
num_kernels
 = 1 , 
kernel_size
 = ( 1 , 1 ) , 
stride
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' , 
name
 = 'conv' ) :

304 with 
tf
 . 
variable_scope
 ( 
name
 ) as 
scope
 :

305 
block
 = 
conv2d
 ( 
input
 , 
num_kernels
 = 
num_kernels
 , 
kernel_size
 = 
kernel_size
 , 
stride
 = 
stride
 , 
padding
 = 
padding
 , 
has_bias
 = True )

306 
block
 = 
relu
 ( 
block
 )

307 return 
block
 
	}

309 def 
	$linear_bn_relu
 ( 
input
 , 
num_hiddens
 = 1 , 
name
 = 'conv' ) :

310 with 
tf
 . 
variable_scope
 ( 
name
 ) as 
scope
 :

311 
block
 = 
linear
 ( 
input
 , 
num_hiddens
 = 
num_hiddens
 , 
has_bias
 = False )

312 
block
 = 
bn
 ( 
block
 )

313 
block
 = 
relu
 ( 
block
 )

314 return 
block
 
	}


	@./net/lib/nms/__init__.py


	@./net/lib/nms/py_cpu_nms.py

8 import 
	~numpy
 as 
np

10 def 
	$py_cpu_nms
 ( 
dets
 , 
thresh
 ) :

12 
x1
 = 
dets
 [ : , 0 ]

13 
y1
 = 
dets
 [ : , 1 ]

14 
x2
 = 
dets
 [ : , 2 ]

15 
y2
 = 
dets
 [ : , 3 ]

16 
scores
 = 
dets
 [ : , 4 ]

18 
areas
 = ( 
x2
 - 
x1
 + 1 ) * ( 
y2
 - 
y1
 + 1 )

19 
order
 = 
scores
 . 
argsort
 ( ) [ : : - 1 ]

21 
keep
 = [ ]

22 while 
order
 . 
size
 > 0 :

23 
i
 = 
order
 [ 0 ]

24 
keep
 . 
append
 ( 
i
 )

25 
xx1
 = 
np
 . 
maximum
 ( 
x1
 [ 
i
 ] , 
x1
 [ 
order
 [ 1 : ] ] )

26 
yy1
 = 
np
 . 
maximum
 ( 
y1
 [ 
i
 ] , 
y1
 [ 
order
 [ 1 : ] ] )

27 
xx2
 = 
np
 . 
minimum
 ( 
x2
 [ 
i
 ] , 
x2
 [ 
order
 [ 1 : ] ] )

28 
yy2
 = 
np
 . 
minimum
 ( 
y2
 [ 
i
 ] , 
y2
 [ 
order
 [ 1 : ] ] )

30 
w
 = 
np
 . 
maximum
 ( 0.0 , 
xx2
 - 
xx1
 + 1 )

31 
h
 = 
np
 . 
maximum
 ( 0.0 , 
yy2
 - 
yy1
 + 1 )

32 
inter
 = 
w
 * 
h

33 
ovr
 = 
inter
 / ( 
areas
 [ 
i
 ] + 
areas
 [ 
order
 [ 1 : ] ] - 
inter
 )

35 
inds
 = 
np
 . 
where
 ( 
ovr
 <= 
thresh
 ) [ 0 ]

36 
order
 = 
order
 [ 
inds
 + 1 ]

38 return 
keep
 
	}

40 if 
__name__
 == '__main__' :

44 
dets
 = 
np
 . 
array
 ( [ [ 0 , 0 , 1 , 1 , 0.9 ] ,

49 
keep
 = 
py_cpu_nms
 ( 
dets
 , 0.5 )

50 
print
 ( 
keep
 )


	@./net/lib/gt_data_layer/roidb.py


	@./net/lib/gt_data_layer/minibatch.py


	@./net/lib/gt_data_layer/__init__.py

7 import 
	~roidb


	@./net/lib/gt_data_layer/layer.py

13 import 
	~caffe

15 import 
	~numpy
 as 
np

16 import 
	~yaml

17 from 
	~multiprocessing
 import 
Process
 , 
Queue

19 from . 
	~minibatch
 import 
get_minibatch

23 from . . 
	~fast_rcnn.config
 import 
cfg

26 class 
	cGtDataLayer
 ( 
caffe
 . 
Layer
 ) :

29 def 
	$_shuffle_roidb_inds
 ( 
self
 ) :

31 
self
 . 
_perm
 = 
np
 . 
random
 . 
permutation
 ( 
np
 . 
arange
 ( 
len
 ( 
self
 . 
_roidb
 ) ) )

32 
self
 . 
_cur
 = 0 
	}

34 def 
	$_get_next_minibatch_inds
 ( 
self
 ) :

36 if 
self
 . 
_cur
 + 
cfg
 . 
TRAIN
 . 
IMS_PER_BATCH
 >= 
len
 ( 
self
 . 
_roidb
 ) :

37 
self
 . 
_shuffle_roidb_inds
 ( )

39 
db_inds
 = 
self
 . 
_perm
 [ 
self
 . 
_cur
 : 
self
 . 
_cur
 + 
cfg
 . 
TRAIN
 . 
IMS_PER_BATCH
 ]

40 
self
 . 
_cur
 += 
cfg
 . 
TRAIN
 . 
IMS_PER_BATCH
 """\n        # sample images with gt objects\n        db_inds = np.zeros((cfg.TRAIN.IMS_PER_BATCH), dtype=np.int32)\n        i = 0\n        while (i < cfg.TRAIN.IMS_PER_BATCH):\n            ind = self._perm[self._cur]\n            num_objs = self._roidb[ind]['boxes'].shape[0]\n            if num_objs != 0:\n                db_inds[i] = ind\n                i += 1\n\n            self._cur += 1\n            if self._cur >= len(self._roidb):\n                self._shuffle_roidb_inds()\n        """

58 return 
db_inds
 
	}

60 def 
	$_get_next_minibatch
 ( 
self
 ) :

62 
db_inds
 = 
self
 . 
_get_next_minibatch_inds
 ( )

63 
minibatch_db
 = [ 
self
 . 
_roidb
 [ 
i
 ] for 
i
 in 
db_inds
 ]

64 return 
get_minibatch
 ( 
minibatch_db
 , 
self
 . 
_num_classes
 ) 
	}

67 def 
	$set_roidb
 ( 
self
 , 
roidb
 ) :

69 
self
 . 
_roidb
 = 
roidb

70 
self
 . 
_shuffle_roidb_inds
 ( ) 
	}

72 def 
	$setup
 ( 
self
 , 
bottom
 , 
top
 ) :

76 
layer_params
 = 
yaml
 . 
load
 ( 
self
 . 
param_str_
 )

78 
self
 . 
_num_classes
 = 
layer_params
 [ 'num_classes' ]

80 
self
 . 
_name_to_top_map
 = { 'data'

87 
num_scale_base
 = 
len
 ( 
cfg
 . 
TRAIN
 . 
SCALES_BASE
 )

88 
top
 [ 0 ] . 
reshape
 ( 
num_scale_base
 , 3 , 100 , 100 )

91 
top
 [ 1 ] . 
reshape
 ( 1 , 18 )

94 
num_scale
 = 
len
 ( 
cfg
 . 
TRAIN
 . 
SCALES
 )

95 
num_aspect
 = 
len
 ( 
cfg
 . 
TRAIN
 . 
ASPECTS
 )

96 
top
 [ 2 ] . 
reshape
 ( 2 + 2 * 
num_scale
 + 2 * 
num_aspect
 ) 
	}

98 def 
	$forward
 ( 
self
 , 
bottom
 , 
top
 ) :

100 
blobs
 = 
self
 . 
_get_next_minibatch
 ( )

102 for 
blob_name
 , 
blob
 in 
blobs
 . 
iteritems
 ( ) :

103 
top_ind
 = 
self
 . 
_name_to_top_map
 [ 
blob_name
 ]

105 
top
 [ 
top_ind
 ] . 
reshape
 ( * ( 
blob
 . 
shape
 ) )

107 
top
 [ 
top_ind
 ] . 
data
 [ ... ] = 
blob
 . 
astype
 ( 
np
 . 
float32
 , 
copy
 = False ) 
	}

109 def 
	$backward
 ( 
self
 , 
top
 , 
propagate_down
 , 
bottom
 ) :

111 pass 
	}

113 def 
	$reshape
 ( 
self
 , 
bottom
 , 
top
 ) :

115 pass 
	}


	@./net/lib/pycocotools/coco.py


	@./net/lib/pycocotools/__init__.py

1 
__author__
 = 'tylin'


	@./net/lib/pycocotools/cocoeval.py


	@./net/lib/pycocotools/mask.py

1 
__author__
 = 'tsungyi'

3 from . import 
_mask

76 
encode
 = 
_mask
 . 
encode

77 
decode
 = 
_mask
 . 
decode

78 
iou
 = 
_mask
 . 
iou

79 
merge
 = 
_mask
 . 
merge

80 
area
 = 
_mask
 . 
area

81 
toBbox
 = 
_mask
 . 
toBbox

82 
frPyObjects
 = 
_mask
 . 
frPyObjects


	@./net/lib/fast_rcnn/config2.py


	@./net/lib/fast_rcnn/config.py

19 import 
	~os

20 import 
	~os.path
 as 
osp

21 import 
	~numpy
 as 
np

22 from 
	~time
 import 
strftime
 , 
localtime

23 from 
	~easydict
 import 
EasyDict
 as 
edict

25 
__C
 = 
edict
 ( )

28 
cfg
 = 
__C

35 
__C
 . 
IS_RPN
 = True

36 
__C
 . 
ANCHOR_SCALES
 = [ 8 , 16 , 32 ]

37 
__C
 . 
NCLASSES
 = 21

40 
__C
 . 
IS_MULTISCALE
 = False

41 
__C
 . 
IS_EXTRAPOLATING
 = True

43 
__C
 . 
REGION_PROPOSAL
 = 'RPN'

45 
__C
 . 
NET_NAME
 = 'VGGnet'

46 
__C
 . 
SUBCLS_NAME
 = 'voxel_exemplars'

48 
__C
 . 
TRAIN
 = 
edict
 ( )

50 
__C
 . 
TRAIN
 . 
SOLVER
 = 'Momentum'

52 
__C
 . 
TRAIN
 . 
WEIGHT_DECAY
 = 0.0005

53 
__C
 . 
TRAIN
 . 
LEARNING_RATE
 = 0.001

54 
__C
 . 
TRAIN
 . 
MOMENTUM
 = 0.9

55 
__C
 . 
TRAIN
 . 
GAMMA
 = 0.1

56 
__C
 . 
TRAIN
 . 
STEPSIZE
 = 50000

57 
__C
 . 
TRAIN
 . 
DISPLAY
 = 10

58 
__C
 . 
TRAIN
 . 
LOG_IMAGE_ITERS
 = 100

59 
__C
 . 
TRAIN
 . 
OHEM
 = False

60 
__C
 . 
TRAIN
 . 
RANDOM_DOWNSAMPLE
 = False

63 
__C
 . 
TRAIN
 . 
SCALES_BASE
 = ( 0.25 , 0.5 , 1.0 , 2.0 , 3.0 )

68 
__C
 . 
TRAIN
 . 
KERNEL_SIZE
 = 5

72 
__C
 . 
TRAIN
 . 
ASPECTS
 = ( 1 , )

77 
__C
 . 
TRAIN
 . 
SCALES
 = ( 600 , )

80 
__C
 . 
TRAIN
 . 
MAX_SIZE
 = 1000

83 
__C
 . 
TRAIN
 . 
IMS_PER_BATCH
 = 2

86 
__C
 . 
TRAIN
 . 
BATCH_SIZE
 = 128

89 
__C
 . 
TRAIN
 . 
FG_FRACTION
 = 0.25

92 
__C
 . 
TRAIN
 . 
FG_THRESH
 = 0.5

96 
__C
 . 
TRAIN
 . 
BG_THRESH_HI
 = 0.5

97 
__C
 . 
TRAIN
 . 
BG_THRESH_LO
 = 0.1

100 
__C
 . 
TRAIN
 . 
USE_FLIPPED
 = True

103 
__C
 . 
TRAIN
 . 
BBOX_REG
 = True

107 
__C
 . 
TRAIN
 . 
BBOX_THRESH
 = 0.5

110 
__C
 . 
TRAIN
 . 
SNAPSHOT_ITERS
 = 5000

114 
__C
 . 
TRAIN
 . 
SNAPSHOT_PREFIX
 = 'VGGnet_fast_rcnn'

115 
__C
 . 
TRAIN
 . 
SNAPSHOT_INFIX
 = ''

119 
__C
 . 
TRAIN
 . 
USE_PREFETCH
 = False

122 
__C
 . 
TRAIN
 . 
BBOX_NORMALIZE_TARGETS
 = True

125 
__C
 . 
TRAIN
 . 
BBOX_INSIDE_WEIGHTS
 = ( 1.0 , 1.0 , 1.0 , 1.0 )

128 
__C
 . 
TRAIN
 . 
BBOX_NORMALIZE_TARGETS_PRECOMPUTED
 = True

129 
__C
 . 
TRAIN
 . 
BBOX_NORMALIZE_MEANS
 = ( 0.0 , 0.0 , 0.0 , 0.0 )

130 
__C
 . 
TRAIN
 . 
BBOX_NORMALIZE_STDS
 = ( 0.1 , 0.1 , 0.2 , 0.2 )

135 
__C
 . 
TRAIN
 . 
PROPOSAL_METHOD
 = 'selective_search'

140 
__C
 . 
TRAIN
 . 
ASPECT_GROUPING
 = True

142 
__C
 . 
TRAIN
 . 
DONTCARE_AREA_INTERSECTION_HI
 = 0.5

143 
__C
 . 
TRAIN
 . 
PRECLUDE_HARD_SAMPLES
 = True

145 
__C
 . 
TRAIN
 . 
HAS_RPN
 = True

147 
__C
 . 
TRAIN
 . 
RPN_POSITIVE_OVERLAP
 = 0.7

149 
__C
 . 
TRAIN
 . 
RPN_NEGATIVE_OVERLAP
 = 0.3

151 
__C
 . 
TRAIN
 . 
RPN_CLOBBER_POSITIVES
 = False

153 
__C
 . 
TRAIN
 . 
RPN_FG_FRACTION
 = 0.5

155 
__C
 . 
TRAIN
 . 
RPN_BATCHSIZE
 = 256

157 
__C
 . 
TRAIN
 . 
RPN_NMS_THRESH
 = 0.7

159 
__C
 . 
TRAIN
 . 
RPN_PRE_NMS_TOP_N
 = 12000

161 
__C
 . 
TRAIN
 . 
RPN_POST_NMS_TOP_N
 = 2000

163 
__C
 . 
TRAIN
 . 
RPN_MIN_SIZE
 = 16

165 
__C
 . 
TRAIN
 . 
RPN_BBOX_INSIDE_WEIGHTS
 = ( 1.0 , 1.0 , 1.0 , 1.0 )

169 
__C
 . 
TRAIN
 . 
RPN_POSITIVE_WEIGHT
 = - 1.0

177 
__C
 . 
TEST
 = 
edict
 ( )

181 
__C
 . 
TEST
 . 
SCALES
 = ( 600 , )

184 
__C
 . 
TEST
 . 
MAX_SIZE
 = 1000

188 
__C
 . 
TEST
 . 
NMS
 = 0.3

192 
__C
 . 
TEST
 . 
SVM
 = False

195 
__C
 . 
TEST
 . 
BBOX_REG
 = True

198 
__C
 . 
TEST
 . 
HAS_RPN
 = True

201 
__C
 . 
TEST
 . 
PROPOSAL_METHOD
 = 'selective_search'

204 
__C
 . 
TEST
 . 
RPN_NMS_THRESH
 = 0.7

206 
__C
 . 
TEST
 . 
RPN_PRE_NMS_TOP_N
 = 6000

209 
__C
 . 
TEST
 . 
RPN_POST_NMS_TOP_N
 = 300

212 
__C
 . 
TEST
 . 
RPN_MIN_SIZE
 = 16

224 
__C
 . 
DEDUP_BOXES
 = 1. / 16.

229 
__C
 . 
PIXEL_MEANS
 = 
np
 . 
array
 ( [ [ [ 102.9801 , 115.9465 , 122.7717 ] ] ] )

232 
__C
 . 
RNG_SEED
 = 3

235 
__C
 . 
EPS
 = 1e-14

238 
__C
 . 
ROOT_DIR
 = 
osp
 . 
abspath
 ( 
osp
 . 
join
 ( 
osp
 . 
dirname
 ( 
__file__
 ) , '..' , '..' ) )

241 
__C
 . 
DATA_DIR
 = 
osp
 . 
abspath
 ( 
osp
 . 
join
 ( 
__C
 . 
ROOT_DIR
 , 'data' ) )

244 
__C
 . 
MODELS_DIR
 = 
osp
 . 
abspath
 ( 
osp
 . 
join
 ( 
__C
 . 
ROOT_DIR
 , 'models' , 'pascal_voc' ) )

247 
__C
 . 
MATLAB
 = 'matlab'

250 
__C
 . 
EXP_DIR
 = 'default'

251 
__C
 . 
LOG_DIR
 = 'default'

254 
__C
 . 
USE_GPU_NMS
 = True

257 
__C
 . 
GPU_ID
 = 0

259 def 
	$get_output_dir
 ( 
imdb
 , 
weights_filename
 ) :

266 
outdir
 = 
osp
 . 
abspath
 ( 
osp
 . 
join
 ( 
__C
 . 
ROOT_DIR
 , 'output' , 
__C
 . 
EXP_DIR
 , 
imdb
 . 
name
 ) )

267 if 
weights_filename
 is not None :

268 
outdir
 = 
osp
 . 
join
 ( 
outdir
 , 
weights_filename
 )

269 if not 
os
 . 
path
 . 
exists
 ( 
outdir
 ) :

270 
os
 . 
makedirs
 ( 
outdir
 )

271 return 
outdir
 
	}

273 def 
	$get_log_dir
 ( 
imdb
 ) :

279 
log_dir
 = 
osp
 . 
abspath
 (

280 
osp
 . 
join
 ( 
__C
 . 
ROOT_DIR
 , 'logs' , 
__C
 . 
LOG_DIR
 , 
imdb
 . 
name
 , 
strftime
 ( "%Y-%m-%d-%H-%M-%S" , 
localtime
 ( ) ) ) )

281 if not 
os
 . 
path
 . 
exists
 ( 
log_dir
 ) :

282 
os
 . 
makedirs
 ( 
log_dir
 )

283 return 
log_dir
 
	}

285 def 
	$_merge_a_into_b
 ( 
a
 , 
b
 ) :

289 if 
type
 ( 
a
 ) is not 
edict
 :

292 for 
k
 , 
v
 in 
a
 . 
iteritems
 ( ) :

294 if not 
b
 . 
has_key
 ( 
k
 ) :

295 raise 
KeyError
 ( '{} is not a valid config key' . 
format
 ( 
k
 ) )

298 
old_type
 = 
type
 ( 
b
 [ 
k
 ] )

299 if 
old_type
 is not 
type
 ( 
v
 ) :

300 if 
isinstance
 ( 
b
 [ 
k
 ] , 
np
 . 
ndarray
 ) :

301 
v
 = 
np
 . 
array
 ( 
v
 , 
dtype
 = 
b
 [ 
k
 ] . 
dtype
 )

303 raise 
ValueError
 ( ( 'Type mismatch ({} vs. {}) ' 'for config key: {}'

304 ) . 
format
 ( 
type
 ( 
b
 [ 
k
 ] ) ,

305 
type
 ( 
v
 ) , 
k
 ) )

308 if 
type
 ( 
v
 ) is 
edict
 :

310 
_merge_a_into_b
 ( 
a
 [ 
k
 ] , 
b
 [ 
k
 ] )

312 
print
 ( 'Error under config key: {}' . 
format
 ( 
k
 ) )

315 
b
 [ 
k
 ] = 
v
 
	}

317 def 
	$cfg_from_file
 ( 
filename
 ) :

319 import 
	~yaml

320 with 
open
 ( 
filename
 , 'r' ) as 
f
 :

321 
yaml_cfg
 = 
edict
 ( 
yaml
 . 
load
 ( 
f
 ) )

323 
_merge_a_into_b
 ( 
yaml_cfg
 , 
__C
 ) 
	}

325 def 
	$cfg_from_list
 ( 
cfg_list
 ) :

327 from 
	~ast
 import 
literal_eval

328 assert 
len
 ( 
cfg_list
 ) % 2 == 0

329 for 
k
 , 
v
 in 
zip
 ( 
cfg_list
 [ 0 : : 2 ] , 
cfg_list
 [ 1 : : 2 ] ) :

330 
key_list
 = 
k
 . 
split
 ( '.' )

331 
d
 = 
__C

332 for 
subkey
 in 
key_list
 [ : - 1 ] :

333 assert 
d
 . 
has_key
 ( 
subkey
 )

334 
d
 = 
d
 [ 
subkey
 ]

335 
subkey
 = 
key_list
 [ - 1 ]

336 assert 
d
 . 
has_key
 ( 
subkey
 )

338 
value
 = 
literal_eval
 ( 
v
 )

341 
value
 = 
v

342 assert 
type
 ( 
value
 ) == 
type
 ( 
d
 [ 
subkey
 ] ) , 'type {} does not match original type {}'

343 . 
format
 (

344 
type
 ( 
value
 ) , 
type
 ( 
d
 [ 
subkey
 ] ) )

345 
d
 [ 
subkey
 ] = 
value
 
	}


	@./net/lib/fast_rcnn/nms_wrapper.py

8 import 
	~numpy
 as 
np

9 from . 
	~config
 import 
cfg

10 from . . 
	~nms.gpu_nms
 import 
gpu_nms

11 from . . 
	~nms.cpu_nms
 import 
cpu_nms

13 def 
	$nms
 ( 
dets
 , 
thresh
 , 
force_cpu
 = False ) :

16 if 
dets
 . 
shape
 [ 0 ] == 0 :

18 if 
cfg
 . 
USE_GPU_NMS
 and not 
force_cpu
 :

19 return 
gpu_nms
 ( 
dets
 , 
thresh
 , 
device_id
 = 
cfg
 . 
GPU_ID
 )

21 return 
cpu_nms
 ( 
dets
 , 
thresh
 ) 
	}

23 def 
	$nms_wrapper
 ( 
scores
 , 
boxes
 , 
threshold
 = 0.7 , 
class_sets
 = None ) :

31 
num_class
 = 
scores
 . 
shape
 [ 1 ] if 
class_sets
 is None else 
len
 ( 
class_sets
 )

32 assert 
num_class
 * 4 == 
boxes
 . 
shape
 [ 1 ] , 'Detection scores and boxes dont match'

34 
class_sets
 = [ 'class_' + 
str
 ( 
i
 ) for 
i
 in 
range
 ( 0 , 
num_class
 ) ] if 
class_sets
 is None else 
class_sets

36 
res
 = [ ]

37 for 
ind
 , 
cls
 in 
enumerate
 ( 
class_sets
 [ 1 : ] ) :

38 
ind
 += 1

39 
cls_boxes
 = 
boxes
 [ : , 4 * 
ind
 : 4 * ( 
ind
 + 1 ) ]

40 
cls_scores
 = 
scores
 [ : , 
ind
 ]

41 
dets
 = 
np
 . 
hstack
 ( ( 
cls_boxes
 , 
cls_scores
 [ : , 
np
 . 
newaxis
 ] ) ) . 
astype
 ( 
np
 . 
float32
 )

42 
keep
 = 
nms
 ( 
dets
 , 
thresh
 = 0.3 )

43 
dets
 = 
dets
 [ 
keep
 , : ]

44 
dets
 = 
dets
 [ 
np
 . 
where
 ( 
dets
 [ : , 4 ] > 
threshold
 ) ]

45 
r
 = { }

46 if 
dets
 . 
shape
 [ 0 ] > 0 :

47 
r
 [ 'class' ] , 
r
 [ 'dets' ] = 
cls
 , 
dets

49 
r
 [ 'class' ] , 
r
 [ 'dets' ] = 
cls
 , None

50 
res
 . 
append
 ( 
r
 )

51 return 
res
 
	}


	@./net/lib/fast_rcnn/bbox_transform.py

8 import 
	~numpy
 as 
np

9 import 
	~warnings

11 def 
	$bbox_transform
 ( 
ex_rois
 , 
gt_rois
 ) :

18 
ex_widths
 = 
ex_rois
 [ : , 2 ] - 
ex_rois
 [ : , 0 ] + 1.0

19 
ex_heights
 = 
ex_rois
 [ : , 3 ] - 
ex_rois
 [ : , 1 ] + 1.0

20 
ex_ctr_x
 = 
ex_rois
 [ : , 0 ] + 0.5 * 
ex_widths

21 
ex_ctr_y
 = 
ex_rois
 [ : , 1 ] + 0.5 * 
ex_heights

23 assert 
np
 . 
min
 ( 
ex_widths
 ) > 0.1 and 
np
 . 
min
 ( 
ex_heights
 ) > 0.1 , 'Invalid boxes found: {} {}'

25 
format
 ( 
ex_rois
 [ 
np
 . 
argmin
 ( 
ex_widths
 ) , : ] , 
ex_rois
 [ 
np
 . 
argmin
 ( 
ex_heights
 ) , : ] )

27 
gt_widths
 = 
gt_rois
 [ : , 2 ] - 
gt_rois
 [ : , 0 ] + 1.0

28 
gt_heights
 = 
gt_rois
 [ : , 3 ] - 
gt_rois
 [ : , 1 ] + 1.0

29 
gt_ctr_x
 = 
gt_rois
 [ : , 0 ] + 0.5 * 
gt_widths

30 
gt_ctr_y
 = 
gt_rois
 [ : , 1 ] + 0.5 * 
gt_heights

34 
targets_dx
 = ( 
gt_ctr_x
 - 
ex_ctr_x
 ) / 
ex_widths

35 
targets_dy
 = ( 
gt_ctr_y
 - 
ex_ctr_y
 ) / 
ex_heights

36 
targets_dw
 = 
np
 . 
log
 ( 
gt_widths
 / 
ex_widths
 )

37 
targets_dh
 = 
np
 . 
log
 ( 
gt_heights
 / 
ex_heights
 )

39 
targets
 = 
np
 . 
vstack
 (

40 ( 
targets_dx
 , 
targets_dy
 , 
targets_dw
 , 
targets_dh
 ) ) . 
transpose
 ( )

41 return 
targets
 
	}

43 def 
	$bbox_transform_inv
 ( 
boxes
 , 
deltas
 ) :

44 if 
boxes
 . 
shape
 [ 0 ] == 0 :

45 return 
np
 . 
zeros
 ( ( 0 , 
deltas
 . 
shape
 [ 1 ] ) , 
dtype
 = 
deltas
 . 
dtype
 )

47 
boxes
 = 
boxes
 . 
astype
 ( 
deltas
 . 
dtype
 , 
copy
 = False )

49 
widths
 = 
boxes
 [ : , 2 ] - 
boxes
 [ : , 0 ] + 1.0

50 
heights
 = 
boxes
 [ : , 3 ] - 
boxes
 [ : , 1 ] + 1.0

51 
ctr_x
 = 
boxes
 [ : , 0 ] + 0.5 * 
widths

52 
ctr_y
 = 
boxes
 [ : , 1 ] + 0.5 * 
heights

54 
dx
 = 
deltas
 [ : , 0 : : 4 ]

55 
dy
 = 
deltas
 [ : , 1 : : 4 ]

56 
dw
 = 
deltas
 [ : , 2 : : 4 ]

57 
dh
 = 
deltas
 [ : , 3 : : 4 ]

59 
pred_ctr_x
 = 
dx
 * 
widths
 [ : , 
np
 . 
newaxis
 ] + 
ctr_x
 [ : , 
np
 . 
newaxis
 ]

60 
pred_ctr_y
 = 
dy
 * 
heights
 [ : , 
np
 . 
newaxis
 ] + 
ctr_y
 [ : , 
np
 . 
newaxis
 ]

61 
pred_w
 = 
np
 . 
exp
 ( 
dw
 ) * 
widths
 [ : , 
np
 . 
newaxis
 ]

62 
pred_h
 = 
np
 . 
exp
 ( 
dh
 ) * 
heights
 [ : , 
np
 . 
newaxis
 ]

64 
pred_boxes
 = 
np
 . 
zeros
 ( 
deltas
 . 
shape
 , 
dtype
 = 
deltas
 . 
dtype
 )

66 
pred_boxes
 [ : , 0 : : 4 ] = 
pred_ctr_x
 - 0.5 * 
pred_w

68 
pred_boxes
 [ : , 1 : : 4 ] = 
pred_ctr_y
 - 0.5 * 
pred_h

70 
pred_boxes
 [ : , 2 : : 4 ] = 
pred_ctr_x
 + 0.5 * 
pred_w

72 
pred_boxes
 [ : , 3 : : 4 ] = 
pred_ctr_y
 + 0.5 * 
pred_h

74 return 
pred_boxes
 
	}

76 def 
	$clip_boxes
 ( 
boxes
 , 
im_shape
 ) :

82 
boxes
 [ : , 0 : : 4 ] = 
np
 . 
maximum
 ( 
np
 . 
minimum
 ( 
boxes
 [ : , 0 : : 4 ] , 
im_shape
 [ 1 ] - 1 ) , 0 )

84 
boxes
 [ : , 1 : : 4 ] = 
np
 . 
maximum
 ( 
np
 . 
minimum
 ( 
boxes
 [ : , 1 : : 4 ] , 
im_shape
 [ 0 ] - 1 ) , 0 )

86 
boxes
 [ : , 2 : : 4 ] = 
np
 . 
maximum
 ( 
np
 . 
minimum
 ( 
boxes
 [ : , 2 : : 4 ] , 
im_shape
 [ 1 ] - 1 ) , 0 )

88 
boxes
 [ : , 3 : : 4 ] = 
np
 . 
maximum
 ( 
np
 . 
minimum
 ( 
boxes
 [ : , 3 : : 4 ] , 
im_shape
 [ 0 ] - 1 ) , 0 )

89 return 
boxes
 
	}


	@./net/lib/fast_rcnn/__init__.py

8 from . import 
config

9 from . import 
train

10 from . import 
test

11 from . import 
nms_wrapper


	@./net/lib/fast_rcnn/test.py


	@./net/lib/fast_rcnn/train.py


	@./net/lib/setup.py

8 import 
	~os

9 from 
	~os.path
 import 
join
 as 
pjoin

10 import 
	~numpy
 as 
np

11 from 
	~distutils.core
 import 
setup

12 from 
	~distutils.extension
 import 
Extension

13 from 
	~Cython.Distutils
 import 
build_ext

15 def 
	$find_in_path
 ( 
name
 , 
path
 ) :

18 for 
dir
 in 
path
 . 
split
 ( 
os
 . 
pathsep
 ) :

19 
binpath
 = 
pjoin
 ( 
dir
 , 
name
 )

20 if 
os
 . 
path
 . 
exists
 ( 
binpath
 ) :

21 return 
os
 . 
path
 . 
abspath
 ( 
binpath
 )

22 return None 
	}

24 def 
	$locate_cuda
 ( ) :

35 if 'CUDAHOME' in 
os
 . 
environ
 :

36 
home
 = 
os
 . 
environ
 [ 'CUDAHOME' ]

37 
nvcc
 = 
pjoin
 ( 
home
 , 'bin' , 'nvcc' )

40 
default_path
 = 
pjoin
 ( 
os
 . 
sep
 , 'usr' , 'local' , 'cuda' , 'bin' )

41 
nvcc
 = 
find_in_path
 ( 'nvcc' , 
os
 . 
environ
 [ 'PATH' ] + 
os
 . 
pathsep
 + 
default_path
 )

42 if 
nvcc
 is None :

43 raise 
EnvironmentError
 ( 'The nvcc binary could not be ' 'located in your $PATH. Either add it to your path, or set $CUDAHOME'

45 
home
 = 
os
 . 
path
 . 
dirname
 ( 
os
 . 
path
 . 
dirname
 ( 
nvcc
 ) )

47 
cudaconfig
 = { 'home' : 
home
 , 'nvcc' : 
nvcc
 , 'include'

48 : 
pjoin
 ( 
home
 , 'include' ) , 'lib64'

49 : 
pjoin
 ( 
home
 , 'lib64' ) }

50 for 
k
 , 
v
 in 
cudaconfig
 . 
items
 ( ) :

51 if not 
os
 . 
path
 . 
exists
 ( 
v
 ) :

52 raise 
EnvironmentError
 ( 'The CUDA %s path could not be located in %s' % ( 
k
 , 
v
 ) )

54 return 
cudaconfig
 
	}

55 
CUDA
 = 
locate_cuda
 ( )

59 
numpy_include
 = 
np
 . 
get_include
 ( )

60 except 
AttributeError
 :

61 
numpy_include
 = 
np
 . 
get_numpy_include
 ( )

63 def 
	$customize_compiler_for_nvcc
 ( 
self
 ) :

74 
self
 . 
src_extensions
 . 
append
 ( '.cu' )

77 
default_compiler_so
 = 
self
 . 
compiler_so

78 
super
 = 
self
 . 
_compile

83 def 
_compile
 ( 
obj
 , 
src
 , 
ext
 , 
cc_args
 , 
extra_postargs
 , 
pp_opts
 ) :

84 
print
 ( 
extra_postargs
 )

85 if 
os
 . 
path
 . 
splitext
 ( 
src
 ) [ 1 ] == '.cu' :

87 
self
 . 
set_executable
 ( 'compiler_so' , 
CUDA
 [ 'nvcc' ] )

90 
postargs
 = 
extra_postargs
 [ 'nvcc' ]

92 
postargs
 = 
extra_postargs
 [ 'gcc' ]

94 
super
 ( 
obj
 , 
src
 , 
ext
 , 
cc_args
 , 
postargs
 , 
pp_opts
 )

96 
self
 . 
compiler_so
 = 
default_compiler_so

99 
self
 . 
_compile
 = 
_compile
 
	}

103 class 
	ccustom_build_ext
 ( 
build_ext
 ) :

104 def 
	$build_extensions
 ( 
self
 ) :

105 
customize_compiler_for_nvcc
 ( 
self
 . 
compiler
 )

106 
build_ext
 . 
build_extensions
 ( 
self
 ) 
	}

108 
ext_modules
 = [

109 
Extension
 ( "utils.bbox"

112 
extra_compile_args
 = { 'gcc' : [ "-Wno-cpp" , "-Wno-unused-function" ] } ,

113 
include_dirs
 = [ 
numpy_include
 ]

115 
Extension
 ( "nms.cpu_nms"

118 
extra_compile_args
 = { 'gcc' : [ "-Wno-cpp" , "-Wno-unused-function" ] } ,

119 
include_dirs
 = [ 
numpy_include
 ]

121 
Extension
 ( 'nms.gpu_nms' ,

123 
library_dirs
 = [ 
CUDA
 [ 'lib64' ] ] ,

124 
libraries
 = [ 'cudart' ] ,

125 
language
 = 'c++' ,

126 
runtime_library_dirs
 = [ 
CUDA
 [ 'lib64' ] ] ,

130 
extra_compile_args
 = { 'gcc' : [ "-Wno-unused-function" ] , 'nvcc'

136 
include_dirs
 = [ 
numpy_include
 , 
CUDA
 [ 'include' ] ]

138 
Extension
 ( 'pycocotools._mask'

140 
sources
 = [ 'pycocotools/maskApi.c' , 'pycocotools/_mask.pyx' ] ,

141 
include_dirs
 = [ 
numpy_include
 , 'pycocotools' ] ,

142 
extra_compile_args
 = { 'gcc'

147 
setup
 (

148 
name
 = 'fast_rcnn' ,

149 
ext_modules
 = 
ext_modules
 ,

151 
cmdclass
 = { 'build_ext' : 
custom_build_ext
 } ,


	@./net/lib/roi_data_layer/minibatch2.py


	@./net/lib/roi_data_layer/roidb.py


	@./net/lib/roi_data_layer/minibatch.py


	@./net/lib/roi_data_layer/roidb2.py

10 import 
	~numpy
 as 
np

14 from . . 
	~fast_rcnn.config
 import 
cfg

15 from . . 
	~fast_rcnn.bbox_transform
 import 
bbox_transform

17 from . . 
	~utils.cython_bbox
 import 
bbox_overlaps

19 def 
	$prepare_roidb
 ( 
imdb
 ) :

26 
roidb
 = 
imdb
 . 
roidb

27 for 
i
 in 
xrange
 ( 
len
 ( 
imdb
 . 
image_index
 ) ) :

28 
roidb
 [ 
i
 ] [ 'image' ] = 
imdb
 . 
image_path_at
 ( 
i
 )

30 
gt_overlaps
 = 
roidb
 [ 
i
 ] [ 'gt_overlaps' ] . 
toarray
 ( )

32 
max_overlaps
 = 
gt_overlaps
 . 
max
 ( 
axis
 = 1 )

34 
max_classes
 = 
gt_overlaps
 . 
argmax
 ( 
axis
 = 1 )

36 
roidb
 [ 
i
 ] [ 'max_classes' ] = 
max_classes

37 
roidb
 [ 
i
 ] [ 'max_overlaps' ] = 
max_overlaps

41 
zero_inds
 = 
np
 . 
where
 ( 
max_overlaps
 == 0 ) [ 0 ]

42 assert 
all
 ( 
max_classes
 [ 
zero_inds
 ] == 0 )

44 
nonzero_inds
 = 
np
 . 
where
 ( 
max_overlaps
 > 0 ) [ 0 ]

45 assert 
all
 ( 
max_classes
 [ 
nonzero_inds
 ] != 0 ) 
	}

47 def 
	$add_bbox_regression_targets
 ( 
roidb
 ) :

49 assert 
len
 ( 
roidb
 ) > 0

50 assert 'max_classes' in 
roidb
 [ 0 ] , 'Did you call prepare_roidb first?'

52 
num_images
 = 
len
 ( 
roidb
 )

54 
num_classes
 = 
roidb
 [ 0 ] [ 'gt_overlaps' ] . 
shape
 [ 1 ]

55 for 
im_i
 in 
xrange
 ( 
num_images
 ) :

56 
rois
 = 
roidb
 [ 
im_i
 ] [ 'boxes' ]

57 
max_overlaps
 = 
roidb
 [ 
im_i
 ] [ 'max_overlaps' ]

58 
max_classes
 = 
roidb
 [ 
im_i
 ] [ 'max_classes' ]

59 
roidb
 [ 
im_i
 ] [ 'bbox_targets' ] =

60 
_compute_targets
 ( 
rois
 , 
max_overlaps
 , 
max_classes
 , 
num_classes
 )

64 
class_counts
 = 
np
 . 
zeros
 ( ( 
num_classes
 , 1 ) ) + 
cfg
 . 
EPS

65 
sums
 = 
np
 . 
zeros
 ( ( 
num_classes
 , 4 ) )

66 
squared_sums
 = 
np
 . 
zeros
 ( ( 
num_classes
 , 4 ) )

67 for 
im_i
 in 
xrange
 ( 
num_images
 ) :

68 
targets
 = 
roidb
 [ 
im_i
 ] [ 'bbox_targets' ]

69 for 
cls
 in 
xrange
 ( 1 , 
num_classes
 ) :

70 
cls_inds
 = 
np
 . 
where
 ( 
targets
 [ : , 0 ] == 
cls
 ) [ 0 ]

71 if 
cls_inds
 . 
size
 > 0 :

72 
class_counts
 [ 
cls
 ] += 
cls_inds
 . 
size

73 
sums
 [ 
cls
 , : ] += 
targets
 [ 
cls_inds
 , 1 : ] . 
sum
 ( 
axis
 = 0 )

74 
squared_sums
 [ 
cls
 , : ] += ( 
targets
 [ 
cls_inds
 , 1 : ] ** 2 ) . 
sum
 ( 
axis
 = 0 )

76 
means
 = 
sums
 / 
class_counts

77 
stds
 = 
np
 . 
sqrt
 ( 
squared_sums
 / 
class_counts
 - 
means
 ** 2 )

80 for 
im_i
 in 
xrange
 ( 
num_images
 ) :

81 
targets
 = 
roidb
 [ 
im_i
 ] [ 'bbox_targets' ]

82 for 
cls
 in 
xrange
 ( 1 , 
num_classes
 ) :

83 
cls_inds
 = 
np
 . 
where
 ( 
targets
 [ : , 0 ] == 
cls
 ) [ 0 ]

84 
roidb
 [ 
im_i
 ] [ 'bbox_targets' ] [ 
cls_inds
 , 1 : ] -= 
means
 [ 
cls
 , : ]

85 if 
stds
 [ 
cls
 , 0 ] != 0 :

86 
roidb
 [ 
im_i
 ] [ 'bbox_targets' ] [ 
cls_inds
 , 1 : ] /= 
stds
 [ 
cls
 , : ]

90 return 
means
 . 
ravel
 ( ) , 
stds
 . 
ravel
 ( ) 
	}

92 def 
	$_compute_targets
 ( 
rois
 , 
overlaps
 , 
labels
 , 
num_classes
 ) :

95 
rois
 = 
rois
 . 
astype
 ( 
np
 . 
float
 , 
copy
 = False )

98 
gt_inds
 = 
np
 . 
where
 ( 
overlaps
 == 1 ) [ 0 ]

100 
ex_inds
 = [ ]

101 for 
i
 in 
xrange
 ( 1 , 
num_classes
 ) :

102 
ex_inds
 . 
extend
 ( 
np
 . 
where
 ( ( 
labels
 == 
i
 ) & ( 
overlaps
 >= 
cfg
 . 
TRAIN
 . 
BBOX_THRESH
 ) ) [ 0 ] )

105 
ex_gt_overlaps
 = 
utils
 . 
cython_bbox
 . 
bbox_overlaps
 ( 
rois
 [ 
ex_inds
 , : ] ,

106 
rois
 [ 
gt_inds
 , : ] )

110 if 
ex_gt_overlaps
 . 
shape
 [ 0 ] != 0 :

111 
gt_assignment
 = 
ex_gt_overlaps
 . 
argmax
 ( 
axis
 = 1 )

113 
gt_assignment
 = [ ]

114 
gt_rois
 = 
rois
 [ 
gt_inds
 [ 
gt_assignment
 ] , : ]

115 
ex_rois
 = 
rois
 [ 
ex_inds
 , : ]

117 
ex_widths
 = 
ex_rois
 [ : , 2 ] - 
ex_rois
 [ : , 0 ] + 
cfg
 . 
EPS

118 
ex_heights
 = 
ex_rois
 [ : , 3 ] - 
ex_rois
 [ : , 1 ] + 
cfg
 . 
EPS

119 
ex_ctr_x
 = 
ex_rois
 [ : , 0 ] + 0.5 * 
ex_widths

120 
ex_ctr_y
 = 
ex_rois
 [ : , 1 ] + 0.5 * 
ex_heights

122 
gt_widths
 = 
gt_rois
 [ : , 2 ] - 
gt_rois
 [ : , 0 ] + 
cfg
 . 
EPS

123 
gt_heights
 = 
gt_rois
 [ : , 3 ] - 
gt_rois
 [ : , 1 ] + 
cfg
 . 
EPS

124 
gt_ctr_x
 = 
gt_rois
 [ : , 0 ] + 0.5 * 
gt_widths

125 
gt_ctr_y
 = 
gt_rois
 [ : , 1 ] + 0.5 * 
gt_heights

127 
targets_dx
 = ( 
gt_ctr_x
 - 
ex_ctr_x
 ) / 
ex_widths

128 
targets_dy
 = ( 
gt_ctr_y
 - 
ex_ctr_y
 ) / 
ex_heights

129 
targets_dw
 = 
np
 . 
log
 ( 
gt_widths
 / 
ex_widths
 )

130 
targets_dh
 = 
np
 . 
log
 ( 
gt_heights
 / 
ex_heights
 )

132 
targets
 = 
np
 . 
zeros
 ( ( 
rois
 . 
shape
 [ 0 ] , 5 ) , 
dtype
 = 
np
 . 
float32
 )

133 
targets
 [ 
ex_inds
 , 0 ] = 
labels
 [ 
ex_inds
 ]

134 
targets
 [ 
ex_inds
 , 1 ] = 
targets_dx

135 
targets
 [ 
ex_inds
 , 2 ] = 
targets_dy

136 
targets
 [ 
ex_inds
 , 3 ] = 
targets_dw

137 
targets
 [ 
ex_inds
 , 4 ] = 
targets_dh

138 return 
targets
 
	}


	@./net/lib/roi_data_layer/__init__.py

7 import 
	~roidb


	@./net/lib/roi_data_layer/layer.py

13 import 
	~numpy
 as 
np

17 from . . 
	~fast_rcnn.config
 import 
cfg

19 from . . 
	~roi_data_layer.minibatch
 import 
get_minibatch

21 class 
	cRoIDataLayer
 ( 
object
 ) :

24 def 
	$__init__
 ( 
self
 , 
roidb
 , 
num_classes
 ) :

26 
self
 . 
_roidb
 = 
roidb

27 
self
 . 
_num_classes
 = 
num_classes

28 
self
 . 
_shuffle_roidb_inds
 ( ) 
	}

30 def 
	$_shuffle_roidb_inds
 ( 
self
 ) :

32 
self
 . 
_perm
 = 
np
 . 
random
 . 
permutation
 ( 
np
 . 
arange
 ( 
len
 ( 
self
 . 
_roidb
 ) ) )

33 
self
 . 
_cur
 = 0 
	}

35 def 
	$_get_next_minibatch_inds
 ( 
self
 ) :

38 if 
cfg
 . 
TRAIN
 . 
HAS_RPN
 :

39 if 
self
 . 
_cur
 + 
cfg
 . 
TRAIN
 . 
IMS_PER_BATCH
 >= 
len
 ( 
self
 . 
_roidb
 ) :

40 
self
 . 
_shuffle_roidb_inds
 ( )

42 
db_inds
 = 
self
 . 
_perm
 [ 
self
 . 
_cur
 : 
self
 . 
_cur
 + 
cfg
 . 
TRAIN
 . 
IMS_PER_BATCH
 ]

43 
self
 . 
_cur
 += 
cfg
 . 
TRAIN
 . 
IMS_PER_BATCH

46 
db_inds
 = 
np
 . 
zeros
 ( ( 
cfg
 . 
TRAIN
 . 
IMS_PER_BATCH
 ) , 
dtype
 = 
np
 . 
int32
 )

47 
i
 = 0

48 while ( 
i
 < 
cfg
 . 
TRAIN
 . 
IMS_PER_BATCH
 ) :

49 
ind
 = 
self
 . 
_perm
 [ 
self
 . 
_cur
 ]

50 
num_objs
 = 
self
 . 
_roidb
 [ 
ind
 ] [ 'boxes' ] . 
shape
 [ 0 ]

51 if 
num_objs
 != 0 :

52 
db_inds
 [ 
i
 ] = 
ind

53 
i
 += 1

55 
self
 . 
_cur
 += 1

56 if 
self
 . 
_cur
 >= 
len
 ( 
self
 . 
_roidb
 ) :

57 
self
 . 
_shuffle_roidb_inds
 ( )

59 return 
db_inds
 
	}

61 def 
	$_get_next_minibatch
 ( 
self
 ) :

67 
db_inds
 = 
self
 . 
_get_next_minibatch_inds
 ( )

68 
minibatch_db
 = [ 
self
 . 
_roidb
 [ 
i
 ] for 
i
 in 
db_inds
 ]

69 return 
get_minibatch
 ( 
minibatch_db
 , 
self
 . 
_num_classes
 ) 
	}

71 def 
	$forward
 ( 
self
 ) :

73 
blobs
 = 
self
 . 
_get_next_minibatch
 ( )

74 return 
blobs
 
	}


	@./net/lib/__init__.py


	@./net/lib/psroi_pooling_layer/psroi_pooling_op.py

1 import 
	~tensorflow
 as 
tf

2 import 
	~os.path
 as 
osp

4 
filename
 = 
osp
 . 
join
 ( 
osp
 . 
dirname
 ( 
__file__
 ) , 'psroi_pooling.so' )

5 
_psroi_pooling_module
 = 
tf
 . 
load_op_library
 ( 
filename
 )

6 
psroi_pool
 = 
_psroi_pooling_module
 . 
psroi_pool

7 
psroi_pool_grad
 = 
_psroi_pooling_module
 . 
psroi_pool_grad


	@./net/lib/psroi_pooling_layer/psroi_pooling_op_test.py

1 import 
	~tensorflow
 as 
tf

2 import 
	~numpy
 as 
np

3 import 
	~psroi_pooling_op

4 import 
	~psroi_pooling_op_grad

5 import 
	~pdb

7 
pdb
 . 
set_trace
 ( )

9 
rois
 = 
tf
 . 
convert_to_tensor
 ( [ [ 0 , 0 , 0 , 4 , 4 ] ] , 
dtype
 = 
tf
 . 
float32
 )

10 
hh
 = 
tf
 . 
convert_to_tensor
 ( 
np
 . 
random
 . 
rand
 ( 1 , 5 , 5 , 25 ) , 
dtype
 = 
tf
 . 
float32
 )

11 [ 
y2
 , 
channels
 ] = 
psroi_pooling_op
 . 
psroi_pool
 ( 
hh
 , 
rois
 , 
output_dim
 = 1 , 
group_size
 = 5 , 
spatial_scale
 = 1.0 )

13 
sess
 = 
tf
 . 
Session
 ( 
config
 = 
tf
 . 
ConfigProto
 ( 
log_device_placement
 = True ) )

14 
print
 ( 
sess
 . 
run
 ( 
hh
 ) )

15 
print
 ( 
sess
 . 
run
 ( 
y2
 ) )

16 
pdb
 . 
set_trace
 ( )


	@./net/lib/psroi_pooling_layer/__init__.py


	@./net/lib/psroi_pooling_layer/psroi_pooling_op_grad.py

1 import 
	~tensorflow
 as 
tf

2 from 
	~tensorflow.python.framework
 import 
ops

3 import 
	~psroi_pooling_op

4 import 
	~pdb

7 @ 
tf
 . 
	`RegisterShape
 ( "PSROIPool" )

8 def 
	$_psroi_pool_shape
 ( 
op
 ) :

12 
dims_data
 = 
op
 . 
inputs
 [ 0 ] . 
get_shape
 ( ) . 
as_list
 ( )

13 
channels
 = 
dims_data
 [ 3 ]

14 
dims_rois
 = 
op
 . 
inputs
 [ 1 ] . 
get_shape
 ( ) . 
as_list
 ( )

15 
num_rois
 = 
dims_rois
 [ 0 ]

16 
output_dim
 = 
op
 . 
get_attr
 ( 'output_dim' )

17 
group_size
 = 
op
 . 
get_attr
 ( 'group_size' )

18 
pooled_height
 = 
group_size

19 
pooled_width
 = 
group_size

21 
output_shape
 = 
tf
 . 
TensorShape
 ( [ 
num_rois
 , 
pooled_height
 , 
pooled_width
 , 
output_dim
 ] )

22 return [ 
output_shape
 , 
output_shape
 ] 
	}

24 @ 
ops
 . 
	`RegisterGradient
 ( "PSROIPool" )

25 def 
	$_psroi_pool_grad
 ( 
op
 , 
grad
 , 
_
 ) :

35 
data
 = 
op
 . 
inputs
 [ 0 ]

36 
rois
 = 
op
 . 
inputs
 [ 1 ]

37 
mapping_channel
 = 
op
 . 
outputs
 [ 1 ]

38 
spatial_scale
 = 
op
 . 
get_attr
 ( 'spatial_scale' )

42 
data_grad
 = 
psroi_pooling_op
 . 
psroi_pool_grad
 ( 
data
 , 
rois
 , 
mapping_channel
 , 
grad
 , 
spatial_scale
 )

44 return [ 
data_grad
 , None ] 
	}


	@./net/lib/datasets/imagenet3d.py


	@./net/lib/datasets/pascal_voc2.py


	@./net/lib/datasets/nissan.py


	@./net/lib/datasets/nthu.py


	@./net/lib/datasets/factory.py


	@./net/lib/datasets/pascal3d.py


	@./net/lib/datasets/ds_utils.py

7 import 
	~numpy
 as 
np

9 def 
	$unique_boxes
 ( 
boxes
 , 
scale
 = 1.0 ) :

11 
v
 = 
np
 . 
array
 ( [ 1 , 1e3 , 1e6 , 1e9 ] )

12 
hashes
 = 
np
 . 
round
 ( 
boxes
 * 
scale
 ) . 
dot
 ( 
v
 )

13 
_
 , 
index
 = 
np
 . 
unique
 ( 
hashes
 , 
return_index
 = True )

14 return 
np
 . 
sort
 ( 
index
 ) 
	}

16 def 
	$xywh_to_xyxy
 ( 
boxes
 ) :

18 return 
np
 . 
hstack
 ( ( 
boxes
 [ : , 0 : 2 ] , 
boxes
 [ : , 0 : 2 ] + 
boxes
 [ : , 2 : 4 ] - 1 ) ) 
	}

20 def 
	$xyxy_to_xywh
 ( 
boxes
 ) :

22 return 
np
 . 
hstack
 ( ( 
boxes
 [ : , 0 : 2 ] , 
boxes
 [ : , 2 : 4 ] - 
boxes
 [ : , 0 : 2 ] + 1 ) ) 
	}

24 def 
	$validate_boxes
 ( 
boxes
 , 
width
 = 0 , 
height
 = 0 ) :

26 
x1
 = 
boxes
 [ : , 0 ]

27 
y1
 = 
boxes
 [ : , 1 ]

28 
x2
 = 
boxes
 [ : , 2 ]

29 
y2
 = 
boxes
 [ : , 3 ]

30 assert ( 
x1
 >= 0 ) . 
all
 ( )

31 assert ( 
y1
 >= 0 ) . 
all
 ( )

32 assert ( 
x2
 >= 
x1
 ) . 
all
 ( )

33 assert ( 
y2
 >= 
y1
 ) . 
all
 ( )

34 assert ( 
x2
 < 
width
 ) . 
all
 ( )

35 assert ( 
y2
 < 
height
 ) . 
all
 ( ) 
	}

37 def 
	$filter_small_boxes
 ( 
boxes
 , 
min_size
 ) :

38 
w
 = 
boxes
 [ : , 2 ] - 
boxes
 [ : , 0 ]

39 
h
 = 
boxes
 [ : , 3 ] - 
boxes
 [ : , 1 ]

40 
keep
 = 
np
 . 
where
 ( ( 
w
 >= 
min_size
 ) & ( 
h
 > 
min_size
 ) ) [ 0 ]

41 return 
keep
 
	}


	@./net/lib/datasets/kitti.py


	@./net/lib/datasets/coco.py


	@./net/lib/datasets/pascal_voc.py


	@./net/lib/datasets/__init__.py

10 from . 
	~imdb
 import 
imdb

11 from . 
	~pascal_voc
 import 
pascal_voc

12 from . 
	~pascal3d
 import 
pascal3d

13 from . 
	~imagenet3d
 import 
imagenet3d

14 from . 
	~kitti
 import 
kitti

15 from . 
	~kitti_tracking
 import 
kitti_tracking

16 from . 
	~nissan
 import 
nissan

17 from . 
	~nthu
 import 
nthu

18 from . import 
factory

21 import 
	~os.path
 as 
osp

22 from . 
	~imdb
 import 
ROOT_DIR

23 from . 
	~imdb
 import 
MATLAB

26 def 
	$_which
 ( 
program
 ) :

27 import 
	~os

28 def 
is_exe
 ( 
fpath
 ) :

29 return 
os
 . 
path
 . 
isfile
 ( 
fpath
 ) and 
os
 . 
access
 ( 
fpath
 , 
os
 . 
X_OK
 )

31 
fpath
 , 
fname
 = 
os
 . 
path
 . 
split
 ( 
program
 )

32 if 
fpath
 :

33 if 
is_exe
 ( 
program
 ) :

34 return 
program

36 for 
path
 in 
os
 . 
environ
 [ "PATH" ] . 
split
 ( 
os
 . 
pathsep
 ) :

37 
path
 = 
path
 . 
strip
 ( '"' )

38 
exe_file
 = 
os
 . 
path
 . 
join
 ( 
path
 , 
program
 )

39 if 
is_exe
 ( 
exe_file
 ) :

40 return 
exe_file

42 return None 
	}
 """\nif _which(MATLAB) is None:\n    msg = ("MATLAB command '{}' not found. "\n           "Please add '{}' to your PATH.").format(MATLAB, MATLAB)\n    raise EnvironmentError(msg)\n"""


	@./net/lib/datasets/imdb.py


	@./net/lib/datasets/kitti_tracking.py


	@./net/lib/datasets/kittivoc.py


	@./net/lib/datasets/imdb2.py


	@./net/lib/datasets/voc_eval.py


	@./net/lib/utils/blob.py

10 import 
	~numpy
 as 
np

11 import 
	~cv2

12 from . . 
	~fast_rcnn.config
 import 
cfg

14 def 
	$im_list_to_blob
 ( 
ims
 ) :

19 
max_shape
 = 
np
 . 
array
 ( [ 
im
 . 
shape
 for 
im
 in 
ims
 ] ) . 
max
 ( 
axis
 = 0 )

20 
num_images
 = 
len
 ( 
ims
 )

21 
blob
 = 
np
 . 
zeros
 ( ( 
num_images
 , 
max_shape
 [ 0 ] , 
max_shape
 [ 1 ] , 3 ) ,

22 
dtype
 = 
np
 . 
float32
 )

23 for 
i
 in 
xrange
 ( 
num_images
 ) :

24 
im
 = 
ims
 [ 
i
 ]

25 
blob
 [ 
i
 , 0 : 
im
 . 
shape
 [ 0 ] , 0 : 
im
 . 
shape
 [ 1 ] , : ] = 
im

27 return 
blob
 
	}

29 def 
	$prep_im_for_blob
 ( 
im
 , 
pixel_means
 , 
target_size
 , 
max_size
 ) :

31 
im
 = 
im
 . 
astype
 ( 
np
 . 
float32
 , 
copy
 = False )

32 
im
 -= 
pixel_means

33 
im_shape
 = 
im
 . 
shape

34 
im_size_min
 = 
np
 . 
min
 ( 
im_shape
 [ 0 : 2 ] )

35 
im_size_max
 = 
np
 . 
max
 ( 
im_shape
 [ 0 : 2 ] )

36 
im_scale
 = 
float
 ( 
target_size
 ) / 
float
 ( 
im_size_min
 )

38 if 
np
 . 
round
 ( 
im_scale
 * 
im_size_max
 ) > 
max_size
 :

39 
im_scale
 = 
float
 ( 
max_size
 ) / 
float
 ( 
im_size_max
 )

40 if 
cfg
 . 
TRAIN
 . 
RANDOM_DOWNSAMPLE
 :

41 
r
 = 0.6 + 
np
 . 
random
 . 
rand
 ( ) * 0.4

42 
im_scale
 *= 
r

43 
im
 = 
cv2
 . 
resize
 ( 
im
 , None , None , 
fx
 = 
im_scale
 , 
fy
 = 
im_scale
 ,

44 
interpolation
 = 
cv2
 . 
INTER_LINEAR
 )

46 return 
im
 , 
im_scale
 
	}


	@./net/lib/utils/bbox_test.py

1 from 
	~net.lib.utils.bbox
 import 
bbox_overlaps
 as 
box_overlaps

2 import 
	~numpy
 as 
np

4 if 
__name__
 == '__main__' :

5 
bbox
 = 
np
 . 
array
 ( [ [ 0. , 0. , 0. , 1. , 1. ] ] )

6 
bbox_gt
 = 
np
 . 
array
 ( [ [ 0. , 0.5 , 0.5 , 1.5 , 1.5 ] ] )

7 
overlaps
 = 
box_overlaps
 ( 
bbox
 , 
bbox_gt
 )

8 
print
 ( 
overlaps
 )


	@./net/lib/utils/timer.py

8 import 
	~time

10 class 
	cTimer
 ( 
object
 ) :

12 def 
	$__init__
 ( 
self
 ) :

13 
self
 . 
total_time
 = 0.

14 
self
 . 
calls
 = 0

15 
self
 . 
start_time
 = 0.

16 
self
 . 
diff
 = 0.

17 
self
 . 
average_time
 = 0. 
	}

19 def 
	$tic
 ( 
self
 ) :

22 
self
 . 
start_time
 = 
time
 . 
time
 ( ) 
	}

24 def 
	$toc
 ( 
self
 , 
average
 = True ) :

25 
self
 . 
diff
 = 
time
 . 
time
 ( ) - 
self
 . 
start_time

26 
self
 . 
total_time
 += 
self
 . 
diff

27 
self
 . 
calls
 += 1

28 
self
 . 
average_time
 = 
self
 . 
total_time
 / 
self
 . 
calls

29 if 
average
 :

30 return 
self
 . 
average_time

32 return 
self
 . 
diff
 
	}


	@./net/lib/utils/__init__.py


	@./net/lib/utils/boxes_grid.py

8 import 
	~numpy
 as 
np

9 import 
	~math

12 from . . 
	~fast_rcnn.config
 import 
cfg

15 def 
	$get_boxes_grid
 ( 
image_height
 , 
image_width
 ) :

24 if 
cfg
 . 
NET_NAME
 == 'CaffeNet' :

25 
height
 = 
np
 . 
floor
 ( ( 
image_height
 * 
max
 ( 
cfg
 . 
TRAIN
 . 
SCALES_BASE
 ) - 1 ) / 4.0 + 1 )

26 
height
 = 
np
 . 
floor
 ( ( 
height
 - 1 ) / 2.0 + 1 + 0.5 )

27 
height
 = 
np
 . 
floor
 ( ( 
height
 - 1 ) / 2.0 + 1 + 0.5 )

29 
width
 = 
np
 . 
floor
 ( ( 
image_width
 * 
max
 ( 
cfg
 . 
TRAIN
 . 
SCALES_BASE
 ) - 1 ) / 4.0 + 1 )

30 
width
 = 
np
 . 
floor
 ( ( 
width
 - 1 ) / 2.0 + 1 + 0.5 )

31 
width
 = 
np
 . 
floor
 ( ( 
width
 - 1 ) / 2.0 + 1 + 0.5 )

32 elif 
cfg
 . 
NET_NAME
 == 'VGGnet' :

33 
height
 = 
np
 . 
floor
 ( 
image_height
 * 
max
 ( 
cfg
 . 
TRAIN
 . 
SCALES_BASE
 ) / 2.0 + 0.5 )

34 
height
 = 
np
 . 
floor
 ( 
height
 / 2.0 + 0.5 )

35 
height
 = 
np
 . 
floor
 ( 
height
 / 2.0 + 0.5 )

36 
height
 = 
np
 . 
floor
 ( 
height
 / 2.0 + 0.5 )

38 
width
 = 
np
 . 
floor
 ( 
image_width
 * 
max
 ( 
cfg
 . 
TRAIN
 . 
SCALES_BASE
 ) / 2.0 + 0.5 )

39 
width
 = 
np
 . 
floor
 ( 
width
 / 2.0 + 0.5 )

40 
width
 = 
np
 . 
floor
 ( 
width
 / 2.0 + 0.5 )

41 
width
 = 
np
 . 
floor
 ( 
width
 / 2.0 + 0.5 )

46 
h
 = 
np
 . 
arange
 ( 
height
 )

47 
w
 = 
np
 . 
arange
 ( 
width
 )

48 
y
 , 
x
 = 
np
 . 
meshgrid
 ( 
h
 , 
w
 , 
indexing
 = 'ij' )

49 
centers
 = 
np
 . 
dstack
 ( ( 
x
 , 
y
 ) )

50 
centers
 = 
np
 . 
reshape
 ( 
centers
 , ( - 1 , 2 ) )

51 
num
 = 
centers
 . 
shape
 [ 0 ]

54 
area
 = 
cfg
 . 
TRAIN
 . 
KERNEL_SIZE
 * 
cfg
 . 
TRAIN
 . 
KERNEL_SIZE

55 
aspect
 = 
cfg
 . 
TRAIN
 . 
ASPECTS

56 
num_aspect
 = 
len
 ( 
aspect
 )

57 
widths
 = 
np
 . 
zeros
 ( ( 1 , 
num_aspect
 ) , 
dtype
 = 
np
 . 
float32
 )

58 
heights
 = 
np
 . 
zeros
 ( ( 1 , 
num_aspect
 ) , 
dtype
 = 
np
 . 
float32
 )

59 for 
i
 in 
xrange
 ( 
num_aspect
 ) :

60 
widths
 [ 0 , 
i
 ] = 
math
 . 
sqrt
 ( 
area
 / 
aspect
 [ 
i
 ] )

61 
heights
 [ 0 , 
i
 ] = 
widths
 [ 0 , 
i
 ] * 
aspect
 [ 
i
 ]

64 
centers
 = 
np
 . 
repeat
 ( 
centers
 , 
num_aspect
 , 
axis
 = 0 )

65 
widths
 = 
np
 . 
tile
 ( 
widths
 , 
num
 ) . 
transpose
 ( )

66 
heights
 = 
np
 . 
tile
 ( 
heights
 , 
num
 ) . 
transpose
 ( )

68 
x1
 = 
np
 . 
reshape
 ( 
centers
 [ : , 0 ] , ( - 1 , 1 ) ) - 
widths
 * 0.5

69 
x2
 = 
np
 . 
reshape
 ( 
centers
 [ : , 0 ] , ( - 1 , 1 ) ) + 
widths
 * 0.5

70 
y1
 = 
np
 . 
reshape
 ( 
centers
 [ : , 1 ] , ( - 1 , 1 ) ) - 
heights
 * 0.5

71 
y2
 = 
np
 . 
reshape
 ( 
centers
 [ : , 1 ] , ( - 1 , 1 ) ) + 
heights
 * 0.5

73 
boxes_grid
 = 
np
 . 
hstack
 ( ( 
x1
 , 
y1
 , 
x2
 , 
y2
 ) ) / 
cfg
 . 
TRAIN
 . 
SPATIAL_SCALE

75 return 
boxes_grid
 , 
centers
 [ : , 0 ] , 
centers
 [ : , 1 ] 
	}


	@./net/lib/rpn_msr/anchor_target_layer.py


	@./net/lib/rpn_msr/proposal_layer.py


	@./net/lib/rpn_msr/generate_anchors.py


	@./net/lib/rpn_msr/generate.py


	@./net/lib/rpn_msr/__init__.py


	@./net/lib/rpn_msr/proposal_target_layer_tf.py

8 import 
	~yaml

9 import 
	~numpy
 as 
np

10 import 
	~numpy.random
 as 
npr

11 import 
	~pdb

13 from . . 
	~utils.cython_bbox
 import 
bbox_overlaps
 , 
bbox_intersections

17 from . . 
	~fast_rcnn.config
 import 
cfg

18 from . . 
	~fast_rcnn.bbox_transform
 import 
bbox_transform

21 
DEBUG
 = False

23 def 
	$proposal_target_layer
 ( 
rpn_rois
 , 
gt_boxes
 , 
gt_ishard
 , 
dontcare_areas
 , 
_num_classes
 ) :

46 
all_rois
 = 
rpn_rois

51 if 
cfg
 . 
TRAIN
 . 
PRECLUDE_HARD_SAMPLES
 and 
gt_ishard
 is not None and 
gt_ishard
 . 
shape
 [ 0 ] > 0 :

52 assert 
gt_ishard
 . 
shape
 [ 0 ] == 
gt_boxes
 . 
shape
 [ 0 ]

53 
gt_ishard
 = 
gt_ishard
 . 
astype
 ( 
int
 )

54 
gt_easyboxes
 = 
gt_boxes
 [ 
gt_ishard
 != 1 , : ]

56 
gt_easyboxes
 = 
gt_boxes
 """\n    add the ground-truth to rois will cause zero loss! not good for visuallization\n    """

61 
jittered_gt_boxes
 = 
_jitter_gt_boxes
 ( 
gt_easyboxes
 )

62 
zeros
 = 
np
 . 
zeros
 ( ( 
gt_easyboxes
 . 
shape
 [ 0 ] * 2 , 1 ) , 
dtype
 = 
gt_easyboxes
 . 
dtype
 )

63 
all_rois
 = 
np
 . 
vstack
 ( ( 
all_rois
 ,

64 
np
 . 
hstack
 ( ( 
zeros
 , 
np
 . 
vstack
 ( ( 
gt_easyboxes
 [ : , : - 1 ] , 
jittered_gt_boxes
 [ : , : - 1 ] ) ) ) ) ) )

67 assert 
np
 . 
all
 ( 
all_rois
 [ : , 0 ] == 0 ) , 'Only single item batches are supported'

70 
num_images
 = 1

71 
rois_per_image
 = 
cfg
 . 
TRAIN
 . 
BATCH_SIZE
 / 
num_images

72 
fg_rois_per_image
 = 
int
 ( 
np
 . 
round
 ( 
cfg
 . 
TRAIN
 . 
FG_FRACTION
 * 
rois_per_image
 ) )

76 
labels
 , 
rois
 , 
bbox_targets
 , 
bbox_inside_weights
 = 
_sample_rois
 (

77 
all_rois
 , 
gt_boxes
 , 
gt_ishard
 , 
dontcare_areas
 , 
fg_rois_per_image
 ,

78 
rois_per_image
 , 
_num_classes
 )

93 
rois
 = 
rois
 . 
reshape
 ( - 1 , 5 )

94 
labels
 = 
labels
 . 
reshape
 ( - 1 , 1 )

95 
bbox_targets
 = 
bbox_targets
 . 
reshape
 ( - 1 , 
_num_classes
 * 4 )

96 
bbox_inside_weights
 = 
bbox_inside_weights
 . 
reshape
 ( - 1 , 
_num_classes
 * 4 )

98 
bbox_outside_weights
 = 
np
 . 
array
 ( 
bbox_inside_weights
 > 0 ) . 
astype
 ( 
np
 . 
float32
 )

100 return 
rois
 , 
labels
 , 
bbox_targets
 , 
bbox_inside_weights
 , 
bbox_outside_weights
 
	}

102 def 
	$_sample_rois
 ( 
all_rois
 , 
gt_boxes
 , 
gt_ishard
 , 
dontcare_areas
 , 
fg_rois_per_image
 , 
rois_per_image
 , 
num_classes
 ) :

107 
overlaps
 = 
bbox_overlaps
 (

108 
np
 . 
ascontiguousarray
 ( 
all_rois
 [ : , 1 : 5 ] , 
dtype
 = 
np
 . 
float
 ) ,

109 
np
 . 
ascontiguousarray
 ( 
gt_boxes
 [ : , : 4 ] , 
dtype
 = 
np
 . 
float
 ) )

110 
gt_assignment
 = 
overlaps
 . 
argmax
 ( 
axis
 = 1 )

111 
max_overlaps
 = 
overlaps
 . 
max
 ( 
axis
 = 1 )

112 
labels
 = 
gt_boxes
 [ 
gt_assignment
 , 4 ]

115 
ignore_inds
 = 
np
 . 
empty
 ( 
shape
 = ( 0 ) , 
dtype
 = 
int
 )

116 if 
cfg
 . 
TRAIN
 . 
PRECLUDE_HARD_SAMPLES
 and 
gt_ishard
 is not None and 
gt_ishard
 . 
shape
 [ 0 ] > 0 :

117 
gt_ishard
 = 
gt_ishard
 . 
astype
 ( 
int
 )

118 
gt_hardboxes
 = 
gt_boxes
 [ 
gt_ishard
 == 1 , : ]

119 if 
gt_hardboxes
 . 
shape
 [ 0 ] > 0 :

121 
hard_overlaps
 = 
bbox_overlaps
 (

122 
np
 . 
ascontiguousarray
 ( 
all_rois
 [ : , 1 : 5 ] , 
dtype
 = 
np
 . 
float
 ) ,

123 
np
 . 
ascontiguousarray
 ( 
gt_hardboxes
 [ : , : 4 ] , 
dtype
 = 
np
 . 
float
 ) )

124 
hard_max_overlaps
 = 
hard_overlaps
 . 
max
 ( 
axis
 = 1 )

126 
ignore_inds
 = 
np
 . 
append
 ( 
ignore_inds
 ,

127 
np
 . 
where
 ( 
hard_max_overlaps
 >= 
cfg
 . 
TRAIN
 . 
FG_THRESH
 ) [ 0 ] )

136 if 
dontcare_areas
 is not None and 
dontcare_areas
 . 
shape
 [ 0 ] > 0 :

138 
intersecs
 = 
bbox_intersections
 (

139 
np
 . 
ascontiguousarray
 ( 
dontcare_areas
 , 
dtype
 = 
np
 . 
float
 ) ,

140 
np
 . 
ascontiguousarray
 ( 
all_rois
 [ : , 1 : 5 ] , 
dtype
 = 
np
 . 
float
 )

142 
intersecs_sum
 = 
intersecs
 . 
sum
 ( 
axis
 = 0 )

143 
ignore_inds
 = 
np
 . 
append
 ( 
ignore_inds
 ,

144 
np
 . 
where
 ( 
intersecs_sum
 > 
cfg
 . 
TRAIN
 . 
DONTCARE_AREA_INTERSECTION_HI
 ) [ 0 ] )

152 
fg_inds
 = 
np
 . 
where
 ( 
max_overlaps
 >= 
cfg
 . 
TRAIN
 . 
FG_THRESH
 ) [ 0 ]

153 
fg_inds
 = 
np
 . 
setdiff1d
 ( 
fg_inds
 , 
ignore_inds
 )

156 
fg_rois_per_this_image
 = 
min
 ( 
fg_rois_per_image
 , 
fg_inds
 . 
size
 )

158 if 
fg_inds
 . 
size
 > 0 :

159 
fg_inds
 = 
npr
 . 
choice
 ( 
fg_inds
 , 
size
 = 
fg_rois_per_this_image
 , 
replace
 = False )

162 
bg_inds
 = 
np
 . 
where
 ( ( 
max_overlaps
 < 
cfg
 . 
TRAIN
 . 
BG_THRESH_HI
 ) &

163 ( 
max_overlaps
 >= 
cfg
 . 
TRAIN
 . 
BG_THRESH_LO
 ) ) [ 0 ]

164 
bg_inds
 = 
np
 . 
setdiff1d
 ( 
bg_inds
 , 
ignore_inds
 )

167 
bg_rois_per_this_image
 = 
rois_per_image
 - 
fg_rois_per_this_image

168 
bg_rois_per_this_image
 = 
min
 ( 
bg_rois_per_this_image
 , 
bg_inds
 . 
size
 )

170 if 
bg_inds
 . 
size
 > 0 :

171 
bg_inds
 = 
npr
 . 
choice
 ( 
bg_inds
 , 
size
 = 
bg_rois_per_this_image
 , 
replace
 = False )

174 
keep_inds
 = 
np
 . 
append
 ( 
fg_inds
 , 
bg_inds
 )

176 
labels
 = 
labels
 [ 
keep_inds
 ]

178 
labels
 [ 
fg_rois_per_this_image
 : ] = 0

179 
rois
 = 
all_rois
 [ 
keep_inds
 ]

181 
bbox_target_data
 = 
_compute_targets
 (

182 
rois
 [ : , 1 : 5 ] , 
gt_boxes
 [ 
gt_assignment
 [ 
keep_inds
 ] , : 4 ] , 
labels
 )

187 
bbox_targets
 , 
bbox_inside_weights
 =

188 
_get_bbox_regression_labels
 ( 
bbox_target_data
 , 
num_classes
 )

190 return 
labels
 , 
rois
 , 
bbox_targets
 , 
bbox_inside_weights
 
	}

192 def 
	$_get_bbox_regression_labels
 ( 
bbox_target_data
 , 
num_classes
 ) :

204 
clss
 = 
bbox_target_data
 [ : , 0 ]

205 
bbox_targets
 = 
np
 . 
zeros
 ( ( 
clss
 . 
size
 , 4 * 
num_classes
 ) , 
dtype
 = 
np
 . 
float32
 )

206 
bbox_inside_weights
 = 
np
 . 
zeros
 ( 
bbox_targets
 . 
shape
 , 
dtype
 = 
np
 . 
float32
 )

207 
inds
 = 
np
 . 
where
 ( 
clss
 > 0 ) [ 0 ]

208 for 
ind
 in 
inds
 :

209 
cls
 = 
int
 ( 
clss
 [ 
ind
 ] )

210 
start
 = 4 * 
cls

211 
end
 = 
start
 + 4

212 
bbox_targets
 [ 
ind
 , 
start
 : 
end
 ] = 
bbox_target_data
 [ 
ind
 , 1 : ]

213 
bbox_inside_weights
 [ 
ind
 , 
start
 : 
end
 ] = 
cfg
 . 
TRAIN
 . 
BBOX_INSIDE_WEIGHTS

214 return 
bbox_targets
 , 
bbox_inside_weights
 
	}

217 def 
	$_compute_targets
 ( 
ex_rois
 , 
gt_rois
 , 
labels
 ) :

220 assert 
ex_rois
 . 
shape
 [ 0 ] == 
gt_rois
 . 
shape
 [ 0 ]

221 assert 
ex_rois
 . 
shape
 [ 1 ] == 4

222 assert 
gt_rois
 . 
shape
 [ 1 ] == 4

224 
targets
 = 
bbox_transform
 ( 
ex_rois
 , 
gt_rois
 )

225 if 
cfg
 . 
TRAIN
 . 
BBOX_NORMALIZE_TARGETS_PRECOMPUTED
 :

227 
targets
 = ( ( 
targets
 - 
np
 . 
array
 ( 
cfg
 . 
TRAIN
 . 
BBOX_NORMALIZE_MEANS
 ) )

228 / 
np
 . 
array
 ( 
cfg
 . 
TRAIN
 . 
BBOX_NORMALIZE_STDS
 ) )

229 return 
np
 . 
hstack
 (

230 ( 
labels
 [ : , 
np
 . 
newaxis
 ] , 
targets
 ) ) . 
astype
 ( 
np
 . 
float32
 , 
copy
 = False ) 
	}

232 def 
	$_jitter_gt_boxes
 ( 
gt_boxes
 , 
jitter
 = 0.05 ) :

236 
jittered_boxes
 = 
gt_boxes
 . 
copy
 ( )

237 
ws
 = 
jittered_boxes
 [ : , 2 ] - 
jittered_boxes
 [ : , 0 ] + 1.0

238 
hs
 = 
jittered_boxes
 [ : , 3 ] - 
jittered_boxes
 [ : , 1 ] + 1.0

239 
width_offset
 = ( 
np
 . 
random
 . 
rand
 ( 
jittered_boxes
 . 
shape
 [ 0 ] ) - 0.5 ) * 
jitter
 * 
ws

240 
height_offset
 = ( 
np
 . 
random
 . 
rand
 ( 
jittered_boxes
 . 
shape
 [ 0 ] ) - 0.5 ) * 
jitter
 * 
hs

241 
jittered_boxes
 [ : , 0 ] += 
width_offset

242 
jittered_boxes
 [ : , 2 ] += 
width_offset

243 
jittered_boxes
 [ : , 1 ] += 
height_offset

244 
jittered_boxes
 [ : , 3 ] += 
height_offset

246 return 
jittered_boxes
 
	}


	@./net/lib/rpn_msr/anchor_target_layer_tf.py


	@./net/lib/rpn_msr/proposal_layer_tf.py


	@./net/lib/roi_pooling_layer/roi_pooling_op.py

1 import 
	~tensorflow
 as 
tf

2 import 
	~os.path
 as 
osp

4 
filename
 = 
osp
 . 
join
 ( 
osp
 . 
dirname
 ( 
__file__
 ) , 'roi_pooling.so' )

5 
_roi_pooling_module
 = 
tf
 . 
load_op_library
 ( 
filename
 )

6 
roi_pool
 = 
_roi_pooling_module
 . 
roi_pool

7 
roi_pool_grad
 = 
_roi_pooling_module
 . 
roi_pool_grad


	@./net/lib/roi_pooling_layer/__init__.py

7 import 
	~roi_pooling_op

8 import 
	~roi_pooling_op_grad


	@./net/lib/roi_pooling_layer/roi_pooling_op_grad.py

1 import 
	~tensorflow
 as 
tf

2 from 
	~tensorflow.python.framework
 import 
ops

3 import 
	~roi_pooling_op

5 @ 
ops
 . 
	`RegisterGradient
 ( "RoiPool" )

6 def 
	$_roi_pool_grad
 ( 
op
 , 
grad
 , 
_
 ) :

15 
data
 = 
op
 . 
inputs
 [ 0 ]

16 
rois
 = 
op
 . 
inputs
 [ 1 ]

17 
argmax
 = 
op
 . 
outputs
 [ 1 ]

18 
pooled_height
 = 
op
 . 
get_attr
 ( 'pooled_height' )

19 
pooled_width
 = 
op
 . 
get_attr
 ( 'pooled_width' )

20 
spatial_scale
 = 
op
 . 
get_attr
 ( 'spatial_scale' )

23 
data_grad
 = 
roi_pooling_op
 . 
roi_pool_grad
 ( 
data
 , 
rois
 , 
argmax
 , 
grad
 , 
pooled_height
 , 
pooled_width
 , 
spatial_scale
 )

25 return [ 
data_grad
 , None ] 
	}


	@./net/lib/roi_pooling_layer/roi_pooling_op_test.py

1 import 
	~tensorflow
 as 
tf

2 import 
	~numpy
 as 
np

3 import 
	~roi_pooling_op

4 import 
	~roi_pooling_op_grad

5 import 
	~tensorflow
 as 
tf

6 import 
	~pdb

9 def 
	$weight_variable
 ( 
shape
 ) :

10 
initial
 = 
tf
 . 
truncated_normal
 ( 
shape
 , 
stddev
 = 0.1 )

11 return 
tf
 . 
Variable
 ( 
initial
 ) 
	}

13 def 
	$conv2d
 ( 
x
 , 
W
 ) :

14 return 
tf
 . 
nn
 . 
conv2d
 ( 
x
 , 
W
 , 
strides
 = [ 1 , 1 , 1 , 1 ] , 
padding
 = 'SAME' ) 
	}

16 
array
 = 
np
 . 
random
 . 
rand
 ( 32 , 100 , 100 , 3 )

17 
data
 = 
tf
 . 
convert_to_tensor
 ( 
array
 , 
dtype
 = 
tf
 . 
float32
 )

18 
rois
 = 
tf
 . 
convert_to_tensor
 ( [ [ 0 , 10 , 10 , 20 , 20 ] , [ 31 , 30 , 30 , 40 , 40 ] ] , 
dtype
 = 
tf
 . 
float32
 )

20 
W
 = 
weight_variable
 ( [ 3 , 3 , 3 , 1 ] )

21 
h
 = 
conv2d
 ( 
data
 , 
W
 )

23 [ 
y
 , 
argmax
 ] = 
roi_pooling_op
 . 
roi_pool
 ( 
h
 , 
rois
 , 6 , 6 , 1.0 / 3 )

24 
pdb
 . 
set_trace
 ( )

25 
y_data
 = 
tf
 . 
convert_to_tensor
 ( 
np
 . 
ones
 ( ( 2 , 6 , 6 , 1 ) ) , 
dtype
 = 
tf
 . 
float32
 )

26 
print
 ( 
y_data
 , 
y
 , 
argmax
 )

29 
loss
 = 
tf
 . 
reduce_mean
 ( 
tf
 . 
square
 ( 
y
 - 
y_data
 ) )

30 
optimizer
 = 
tf
 . 
train
 . 
GradientDescentOptimizer
 ( 0.5 )

31 
train
 = 
optimizer
 . 
minimize
 ( 
loss
 )

33 
init
 = 
tf
 . 
global_variables_initializer
 ( )

36 
sess
 = 
tf
 . 
Session
 ( 
config
 = 
tf
 . 
ConfigProto
 ( 
log_device_placement
 = True ) )

37 
sess
 . 
run
 ( 
init
 )

38 
pdb
 . 
set_trace
 ( )

39 for 
step
 in 
xrange
 ( 10 ) :

40 
sess
 . 
run
 ( 
train
 )

41 
print
 ( 
step
 , 
sess
 . 
run
 ( 
W
 ) )

42 
print
 ( 
sess
 . 
run
 ( 
y
 ) )


	@./net/rcnn_target_op.py

1 from 
	~net.configuration
 import *

2 from 
	~net.processing.boxes
 import *

3 from 
	~net.processing.boxes3d
 import *

4 from 
	~net.utility.draw
 import *

12 def 
	$rcnn_target
 ( 
rois
 , 
gt_labels
 , 
gt_boxes
 , 
gt_boxes3d
 ) :

15 
rois
 = 
rois
 . 
reshape
 ( - 1 , 5 )

16 
num
 = 
len
 ( 
gt_boxes
 )

17 
zeros
 = 
np
 . 
zeros
 ( ( 
num
 , 1 ) , 
dtype
 = 
np
 . 
float32
 )

18 
extended_rois
 = 
np
 . 
vstack
 ( ( 
rois
 , 
np
 . 
hstack
 ( ( 
zeros
 , 
gt_boxes
 ) ) ) )

19 assert 
np
 . 
all
 ( 
extended_rois
 [ : , 0 ] == 0 ) , 'Only single image batches are supported'

22 
rois_per_image
 = 
CFG
 . 
TRAIN
 . 
RCNN_BATCH_SIZE

23 
fg_rois_per_image
 = 
np
 . 
round
 ( 
CFG
 . 
TRAIN
 . 
RCNN_FG_FRACTION
 * 
rois_per_image
 )

26 
overlaps
 = 
bbox_overlaps
 (

27 
np
 . 
ascontiguousarray
 ( 
extended_rois
 [ : , 1 : 5 ] , 
dtype
 = 
np
 . 
float
 ) ,

28 
np
 . 
ascontiguousarray
 ( 
gt_boxes
 , 
dtype
 = 
np
 . 
float
 )

33 
max_overlaps
 = 
overlaps
 . 
max
 ( 
axis
 = 1 )

34 
gt_assignment
 = 
overlaps
 . 
argmax
 ( 
axis
 = 1 )

35 
labels
 = 
gt_labels
 [ 
gt_assignment
 ]

38 
fg_inds
 = 
np
 . 
where
 ( 
max_overlaps
 >= 
CFG
 . 
TRAIN
 . 
RCNN_FG_THRESH_LO
 ) [ 0 ]

39 
fg_rois_per_this_image
 = 
int
 ( 
min
 ( 
fg_rois_per_image
 , 
fg_inds
 . 
size
 ) )

40 if 
fg_inds
 . 
size
 > 0 :

41 
fg_inds
 = 
np
 . 
random
 . 
choice
 ( 
fg_inds
 , 
size
 = 
fg_rois_per_this_image
 , 
replace
 = False )

44 
bg_inds
 = 
np
 . 
where
 ( ( 
max_overlaps
 < 
CFG
 . 
TRAIN
 . 
RCNN_BG_THRESH_HI
 ) &

45 ( 
max_overlaps
 >= 
CFG
 . 
TRAIN
 . 
RCNN_BG_THRESH_LO
 ) ) [ 0 ]

46 
bg_rois_per_this_image
 = 
rois_per_image
 - 
fg_rois_per_this_image

47 
bg_rois_per_this_image
 = 
int
 ( 
min
 ( 
bg_rois_per_this_image
 , 
bg_inds
 . 
size
 ) )

48 if 
bg_inds
 . 
size
 > 0 :

49 
bg_inds
 = 
np
 . 
random
 . 
choice
 ( 
bg_inds
 , 
size
 = 
bg_rois_per_this_image
 , 
replace
 = False )

53 
keep
 = 
np
 . 
append
 ( 
fg_inds
 , 
bg_inds
 )

54 
rois
 = 
extended_rois
 [ 
keep
 ]

55 
labels
 = 
labels
 [ 
keep
 ]

56 
labels
 [ 
fg_rois_per_this_image
 : ] = 0

59 
gt_boxes3d
 = 
gt_boxes3d
 [ 
gt_assignment
 [ 
keep
 ] ]

60 
et_boxes
 = 
rois
 [ : , 1 : 5 ]

61 if 
gt_boxes3d
 . 
shape
 [ 1 : ] == 
gt_boxes
 . 
shape
 [ 1 : ] :

63 
targets
 = 
box_transform
 ( 
et_boxes
 , 
gt_boxes3d
 )

66 
et_boxes3d
 = 
top_box_to_box3d
 ( 
et_boxes
 )

67 
targets
 = 
box3d_transform
 ( 
et_boxes3d
 , 
gt_boxes3d
 )

70 return 
rois
 , 
labels
 , 
targets
 
	}

77 def 
	$fusion_target
 ( 
rois
 , 
gt_labels
 , 
gt_boxes
 , 
gt_boxes3d
 ) :

80 
rois
 = 
rois
 . 
reshape
 ( - 1 , 5 )

81 
num
 = 
len
 ( 
gt_boxes
 )

82 
zeros
 = 
np
 . 
zeros
 ( ( 
num
 , 1 ) , 
dtype
 = 
np
 . 
float32
 )

84 
extended_rois
 = 
np
 . 
vstack
 ( ( 
rois
 , 
np
 . 
hstack
 ( ( 
zeros
 , 
gt_boxes
 ) ) ) )

85 assert 
np
 . 
all
 ( 
extended_rois
 [ : , 0 ] == 0 ) , 'Only single image batches are supported'

88 
overlaps
 = 
bbox_overlaps
 (

89 
np
 . 
ascontiguousarray
 ( 
extended_rois
 [ : , 1 : 5 ] , 
dtype
 = 
np
 . 
float
 ) ,

90 
np
 . 
ascontiguousarray
 ( 
gt_boxes
 , 
dtype
 = 
np
 . 
float
 )

92 
max_overlaps
 = 
overlaps
 . 
max
 ( 
axis
 = 1 )

93 
gt_assignment
 = 
overlaps
 . 
argmax
 ( 
axis
 = 1 )

94 
labels
 = 
gt_labels
 [ 
gt_assignment
 ]

103 
num_fg
 = 
int
 ( 
np
 . 
round
 ( 
CFG
 . 
TRAIN
 . 
RCNN_FG_FRACTION
 * 
CFG
 . 
TRAIN
 . 
RCNN_BATCH_SIZE
 ) )

104 
fg_inds
 = 
np
 . 
where
 ( 
max_overlaps
 >= 
CFG
 . 
TRAIN
 . 
RCNN_FG_THRESH_LO
 ) [ 0 ]

105 if 
len
 ( 
fg_inds
 ) > 
num_fg
 :

106 
fg_inds
 = 
np
 . 
random
 . 
choice
 ( 
fg_inds
 , 
size
 = 
num_fg
 , 
replace
 = False )

109 
num_fp
 = 
int
 ( 
CFG
 . 
TRAIN
 . 
RCNN_BATCH_SIZE
 - 
len
 ( 
fg_inds
 ) )

110 
fp_inds
 = 
np
 . 
intersect1d
 (

111 
np
 . 
where
 ( 
max_overlaps
 <= 
CFG
 . 
TRAIN
 . 
RCNN_BG_THRESH_HI
 ) [ 0 ] ,

112 
np
 . 
where
 ( 
CFG
 . 
TRAIN
 . 
RCNN_BG_THRESH_LO
 <= 
max_overlaps
 ) [ 0 ]

114 if 
len
 ( 
fp_inds
 ) > 
num_fp
 :

115 
fp_inds
 = 
np
 . 
random
 . 
choice
 ( 
fp_inds
 , 
size
 = 
num_fp
 , 
replace
 = False )

119 
keep
 = 
np
 . 
append
 ( 
fg_inds
 , 
fp_inds
 )

120 
rois
 = 
extended_rois
 [ 
keep
 ]

121 
labels
 = 
labels
 [ 
keep
 ]

122 
labels
 [ 
fg_inds
 . 
size
 : ] = 0

125 
gt_boxes3d
 = 
gt_boxes3d
 [ 
gt_assignment
 [ 
keep
 ] ]

126 
et_boxes
 = 
rois
 [ : , 1 : 5 ]

128 
et_boxes3d
 = 
top_box_to_box3d
 ( 
et_boxes
 )

129 
targets
 = 
box3d_transform
 ( 
et_boxes3d
 , 
gt_boxes3d
 )

130 
targets
 [ 
np
 . 
where
 ( 
labels
 == 0 ) , : , : ] = 0

133 return 
rois
 , 
labels
 , 
targets
 
	}

135 def 
	$proprosal_to_top_rois
 ( 
rois
 ) :

138 
rois
 = 
rois
 . 
reshape
 ( - 1 , 5 )

139 
num
 = 
len
 ( 
rois
 )

140 
zeros
 = 
np
 . 
zeros
 ( ( 
num
 , 1 ) , 
dtype
 = 
np
 . 
float32
 )

141 
extended_rois
 = 
np
 . 
vstack
 ( ( 
rois
 , 
np
 . 
hstack
 ( ( 
zeros
 , 
gt_boxes
 ) ) ) )

142 assert 
np
 . 
all
 ( 
extended_rois
 [ : , 0 ] == 0 ) , 'Only single image batches are supported'

145 
rois_per_image
 = 
CFG
 . 
TRAIN
 . 
RCNN_BATCH_SIZE

146 
fg_rois_per_image
 = 
np
 . 
round
 ( 
CFG
 . 
TRAIN
 . 
RCNN_FG_FRACTION
 * 
rois_per_image
 )

158 
fg_inds
 = 
np
 . 
where
 ( 
max_overlaps
 >= 
CFG
 . 
TRAIN
 . 
RCNN_FG_THRESH_LO
 ) [ 0 ]

159 
fg_rois_per_this_image
 = 
int
 ( 
min
 ( 
fg_rois_per_image
 , 
fg_inds
 . 
size
 ) )

160 if 
fg_inds
 . 
size
 > 0 :

161 
fg_inds
 = 
np
 . 
random
 . 
choice
 ( 
fg_inds
 , 
size
 = 
fg_rois_per_this_image
 , 
replace
 = False )

164 
bg_inds
 = 
np
 . 
where
 ( ( 
max_overlaps
 < 
CFG
 . 
TRAIN
 . 
RCNN_BG_THRESH_HI
 ) &

165 ( 
max_overlaps
 >= 
CFG
 . 
TRAIN
 . 
RCNN_BG_THRESH_LO
 ) ) [ 0 ]

166 
bg_rois_per_this_image
 = 
rois_per_image
 - 
fg_rois_per_this_image

167 
bg_rois_per_this_image
 = 
int
 ( 
min
 ( 
bg_rois_per_this_image
 , 
bg_inds
 . 
size
 ) )

168 if 
bg_inds
 . 
size
 > 0 :

169 
bg_inds
 = 
np
 . 
random
 . 
choice
 ( 
bg_inds
 , 
size
 = 
bg_rois_per_this_image
 , 
replace
 = False )

173 
keep
 = 
np
 . 
append
 ( 
fg_inds
 , 
bg_inds
 )

174 
rois
 = 
extended_rois
 [ 
keep
 ]

190 return 
rois
 
	}

193 def 
	$draw_rcnn_labels
 ( 
image
 , 
rois
 , 
labels
 , 
darker
 = 0.7 ) :

194 
is_print
 = 0

197 
boxes
 = 
rois
 [ : , 1 : 5 ]

198 
labels
 = 
labels
 . 
reshape
 ( - 1 )

200 
fg_label_inds
 = 
np
 . 
where
 ( 
labels
 != 0 ) [ 0 ]

201 
bg_label_inds
 = 
np
 . 
where
 ( 
labels
 == 0 ) [ 0 ]

202 
num_pos_label
 = 
len
 ( 
fg_label_inds
 )

203 
num_neg_label
 = 
len
 ( 
bg_label_inds
 )

204 if 
is_print
 : 
print
 ( 'rcnn label : num_pos=%d num_neg=%d,  all = %d' % ( 
num_pos_label
 , 
num_neg_label
 , 
num_pos_label
 + 
num_neg_label
 ) )

206 
img_label
 = 
image
 . 
copy
 ( ) * 
darker

208 for 
i
 in 
bg_label_inds
 :

209 
a
 = 
boxes
 [ 
i
 ]

210 
cv2
 . 
rectangle
 ( 
img_label
 , ( 
a
 [ 0 ] , 
a
 [ 1 ] ) , ( 
a
 [ 2 ] , 
a
 [ 3 ] ) , ( 32 , 32 , 32 ) , 1 )

211 
cv2
 . 
circle
 ( 
img_label
 , ( 
a
 [ 0 ] , 
a
 [ 1 ] ) , 2 , ( 32 , 32 , 32 ) , - 1 )

213 for 
i
 in 
fg_label_inds
 :

214 
a
 = 
boxes
 [ 
i
 ]

215 
cv2
 . 
rectangle
 ( 
img_label
 , ( 
a
 [ 0 ] , 
a
 [ 1 ] ) , ( 
a
 [ 2 ] , 
a
 [ 3 ] ) , ( 0 , 0 , 255 ) , 1 )

216 
cv2
 . 
circle
 ( 
img_label
 , ( 
a
 [ 0 ] , 
a
 [ 1 ] ) , 2 , ( 0 , 0 , 255 ) , - 1 )

218 return 
img_label
 
	}

220 def 
	$draw_rcnn_targets
 ( 
image
 , 
rois
 , 
labels
 , 
targets
 , 
darker
 = 0.7 ) :

221 
is_print
 = 0

224 
boxes
 = 
rois
 [ : , 1 : 5 ]

226 
fg_target_inds
 = 
np
 . 
where
 ( 
labels
 != 0 ) [ 0 ]

227 
num_pos_target
 = 
len
 ( 
fg_target_inds
 )

228 if 
is_print
 : 
print
 ( 'rcnn target : num_pos=%d' % ( 
num_pos_target
 ) )

230 
img_target
 = 
image
 . 
copy
 ( ) * 
darker

231 for 
n
 , 
i
 in 
enumerate
 ( 
fg_target_inds
 ) :

232 
a
 = 
boxes
 [ 
i
 ]

233 
cv2
 . 
rectangle
 ( 
img_target
 , ( 
a
 [ 0 ] , 
a
 [ 1 ] ) , ( 
a
 [ 2 ] , 
a
 [ 3 ] ) , ( 255 , 0 , 255 ) , 1 )

235 if 
targets
 . 
shape
 [ 1 : ] == ( 4 , ) :

236 
t
 = 
targets
 [ 
n
 ]

237 
b
 = 
box_transform_inv
 ( 
a
 . 
reshape
 ( 1 , 4 ) , 
t
 . 
reshape
 ( 1 , 4 ) )

238 
b
 = 
b
 . 
reshape
 ( 4 )

239 
cv2
 . 
rectangle
 ( 
img_target
 , ( 
b
 [ 0 ] , 
b
 [ 1 ] ) , ( 
b
 [ 2 ] , 
b
 [ 3 ] ) , ( 255 , 255 , 255 ) , 1 )

241 if 
targets
 . 
shape
 [ 1 : ] == ( 8 , 3 ) :

242 
t
 = 
targets
 [ 
n
 ]

243 
a3d
 = 
top_box_to_box3d
 ( 
a
 . 
reshape
 ( 1 , 4 ) )

244 
b3d
 = 
box3d_transform_inv
 ( 
a3d
 , 
t
 . 
reshape
 ( 1 , 8 , 3 ) )

246 
img_target
 = 
draw_box3d_on_top
 ( 
img_target
 , 
b3d
 )

248 return 
img_target
 
	}


	@./net/utility/draw.py

1 import 
	~numpy
 as 
np

2 import 
	~matplotlib

3 
matplotlib
 . 
use
 ( 'AGG' )

4 import 
	~matplotlib.pyplot
 as 
plt

5 import 
	~cv2

6 import 
	~os

7 import 
	~net.utility.file
 as 
file

8 from 
	~config
 import 
cfg

9 import 
	~net.processing.boxes3d
 as 
box3d

12 
file
 . 
makedirs
 ( 
cfg
 . 
LOG_DIR
 )

14 def 
	$imshow
 ( 
name
 , 
image
 , 
resize
 = 1 ) :

15 
H
 , 
W
 , 
_
 = 
image
 . 
shape

16 
cv2
 . 
namedWindow
 ( 
name
 , 
cv2
 . 
WINDOW_NORMAL
 )

17 
cv2
 . 
imshow
 ( 
name
 , 
image
 . 
astype
 ( 
np
 . 
uint8
 ) )

18 
cv2
 . 
resizeWindow
 ( 
name
 , 
round
 ( 
resize
 * 
W
 ) , 
round
 ( 
resize
 * 
H
 ) ) 
	}

21 def 
	$normalise
 ( 
image
 , 
limit
 = 255.0 ) :

22 
image
 -= 
image
 . 
min
 ( )

23 
image
 *= ( 
limit
 / 
image
 . 
max
 ( ) )

24 return 
image
 
	}

26 def 
	$imsave
 ( 
name
 , 
image
 , 
subdir
 = '' ) :

27 
dir
 = 
os
 . 
path
 . 
join
 ( 
cfg
 . 
LOG_DIR
 , 
subdir
 )

28 
os
 . 
makedirs
 ( 
dir
 , 
exist_ok
 = True )

29 
plt
 . 
imsave
 ( 
os
 . 
path
 . 
join
 ( 
dir
 , 
name
 ) + '.png' , 
image
 ) 
	}

31 def 
	$npsave
 ( 
name
 , 
numpy_array
 ) :

32 
np
 . 
save
 ( 
os
 . 
path
 . 
join
 ( 
cfg
 . 
LOG_DIR
 , 
name
 ) , 
numpy_array
 ) 
	}

34 def 
	$draw_box3d_on_camera
 ( 
rgb
 , 
boxes3d
 , 
color
 = ( 255 , 0 , 255 ) , 
thickness
 = 1 , 
text_lables
 = [ ] ) :

35 
projections
 = 
box3d
 . 
box3d_to_rgb_box
 ( 
boxes3d
 )

36 
rgb
 = 
box3d
 . 
draw_rgb_projections
 ( 
rgb
 , 
projections
 , 
color
 = 
color
 , 
thickness
 = 
thickness
 )

37 
font
 = 
cv2
 . 
FONT_HERSHEY_SIMPLEX

38 for 
i
 , 
text
 in 
enumerate
 ( 
text_lables
 ) :

39 
text_pos
 = ( 
np
 . 
min
 ( 
projections
 [ 
i
 , : , 0 ] ) , 
max
 ( 
np
 . 
min
 ( 
projections
 [ 
i
 , : , 1 ] ) , 15 ) )

40 
cv2
 . 
putText
 ( 
rgb
 , 
text
 , 
text_pos
 , 
font
 , 0.7 , ( 0 , 255 , 100 ) , 1 , 
cv2
 . 
LINE_AA
 )

42 return 
rgb
 
	}


	@./net/utility/demo.py

2 from 
	~__future__
 import 
print_function

3 from 
	~__future__
 import 
absolute_import

4 import 
	~pycuda.driver
 as 
cuda

5 import 
	~pycuda.autoinit

6 from 
	~pycuda.compiler
 import 
SourceModule

8 import 
	~numpy

9 
a
 = 
numpy
 . 
random
 . 
randn
 ( 4 , 4 )

11 
a
 = 
a
 . 
astype
 ( 
numpy
 . 
float32
 )

13 
a_gpu
 = 
cuda
 . 
mem_alloc
 ( 
a
 . 
size
 * 
a
 . 
dtype
 . 
itemsize
 )

15 
cuda
 . 
memcpy_htod
 ( 
a_gpu
 , 
a
 )

17 
mod
 = 
SourceModule
 ( """\n    __global__ void doublify(float *a)\n    {\n      int idx = threadIdx.x + threadIdx.y*4;\n      a[idx] *= 2;\n    }\n    """

25 
func
 = 
mod
 . 
get_function
 ( "doublify" )

26 
func
 ( 
a_gpu
 , 
block
 = ( 4 , 4 , 1 ) , 
grid
 = ( 1 , 1 ) , 
shared
 = 0 )

28 
a_doubled
 = 
numpy
 . 
empty_like
 ( 
a
 )

29 
cuda
 . 
memcpy_dtoh
 ( 
a_doubled
 , 
a_gpu
 )

30 
print
 ( "original array:" )

31 
print
 ( 
a
 )

32 
print
 ( "doubled with kernel:" )

33 
print
 ( 
a_doubled
 )

37 
func
 ( 
cuda
 . 
InOut
 ( 
a
 ) , 
block
 = ( 4 , 4 , 1 ) )

38 
print
 ( "doubled with InOut:" )

39 
print
 ( 
a
 )

43 import 
	~pycuda.gpuarray
 as 
gpuarray

44 
a_gpu
 = 
gpuarray
 . 
to_gpu
 ( 
numpy
 . 
random
 . 
randn
 ( 4 , 4 ) . 
astype
 ( 
numpy
 . 
float32
 ) )

45 
a_doubled
 = ( 2 * 
a_gpu
 ) . 
get
 ( )

47 
print
 ( "original array:" )

48 
print
 ( 
a_gpu
 )

49 
print
 ( "doubled with gpuarray:" )

50 
print
 ( 
a_doubled
 )


	@./net/utility/file.py

2 import 
	~builtins

3 import 
	~sys

4 import 
	~os

5 import 
	~glob

6 import 
	~shutil

25 def 
	$remove_comments
 ( 
lines
 , 
token
 = '#' ) :

29 
l
 = [ ]

30 for 
line
 in 
lines
 :

31 
s
 = 
line
 . 
split
 ( 
token
 , 1 ) [ 0 ] . 
strip
 ( )

32 if 
s
 != '' :

33 
l
 . 
append
 ( 
s
 )

34 return 
l
 
	}

37 def 
	$open
 ( 
file
 , 
mode
 = None , 
encoding
 = None ) :

38 if 
mode
 == None : 
mode
 = 'r'

40 if '/' in 
file
 :

41 if 'w' or 'a' in 
mode
 :

42 
dir
 = 
os
 . 
path
 . 
dirname
 ( 
file
 )

43 if not 
os
 . 
path
 . 
isdir
 ( 
dir
 ) : 
os
 . 
makedirs
 ( 
dir
 )

46 
f
 = 
open
 ( 
file
 , 
mode
 = 
mode
 , 
encoding
 = 
encoding
 )

47 return 
f
 
	}

50 def 
	$makedirs
 ( 
dir
 ) :

51 if not 
os
 . 
path
 . 
isdir
 ( 
dir
 ) : 
os
 . 
makedirs
 ( 
dir
 ) 
	}

54 def 
	$remove
 ( 
file
 ) :

55 if 
os
 . 
path
 . 
exists
 ( 
file
 ) : 
os
 . 
remove
 ( 
file
 ) 
	}

58 def 
	$empty
 ( 
dir
 ) :

59 if 
os
 . 
path
 . 
isdir
 ( 
dir
 ) :

60 
shutil
 . 
rmtree
 ( 
dir
 , 
ignore_errors
 = True )

62 
os
 . 
makedirs
 ( 
dir
 ) 
	}

65 class 
	cLogger
 ( 
object
 ) :

66 def 
	$__init__
 ( 
self
 , 
file
 = None , 
mode
 = None ) :

67 
self
 . 
terminal
 = 
sys
 . 
stdout

68 
self
 . 
file
 = None

69 if 
file
 is not None : 
self
 . 
open
 ( 
file
 , 
mode
 ) 
	}

72 def 
	$open
 ( 
self
 , 
file
 , 
mode
 = None ) :

73 if 
mode
 is None : 
mode
 = 'w'

74 
self
 . 
file
 = 
builtins
 . 
open
 ( 
file
 , 
mode
 ) 
	}

76 def 
	$write
 ( 
self
 , 
message
 , 
is_terminal
 = 1 , 
is_file
 = 1 ) :

77 if 
message
 == '\r' : 
is_file
 = 0

79 if 
is_terminal
 == 1 :

80 
self
 . 
terminal
 . 
write
 ( 
message
 )

81 
self
 . 
terminal
 . 
flush
 ( )

83 if 
is_file
 == 1 :

84 
self
 . 
file
 . 
write
 ( 
message
 )

85 
self
 . 
file
 . 
flush
 ( ) 
	}

87 def 
	$flush
 ( 
self
 ) :

91 pass 
	}

97 if 
__name__
 == '__main__' :

98 
print
 ( '%s: calling main function ... ' % 
os
 . 
path
 . 
basename
 ( 
__file__
 ) )


	@./net/utility/__init__.py


	@./net/utility/test_remove_empty_box.py

1 import 
	~tensorflow
 as 
tf

2 from 
	~remove_empty_box
 import 
remove_empty_anchor

4 if 
__name__
 == '__main__' :

5 import 
	~time

6 import 
	~random

7 import 
	~numpy
 as 
np

8 
sess
 = 
tf
 . 
InteractiveSession
 ( )

9 
a
 = 120000

10 
anchors
 = 
np
 . 
hstack
 ( [

11 0 * 
np
 . 
ones
 ( ( 
a
 , 1 ) ) ,

12 0 * 
np
 . 
ones
 ( ( 
a
 , 1 ) ) ,

13 40 * 
np
 . 
ones
 ( ( 
a
 , 1 ) ) ,

14 16 * 
np
 . 
ones
 ( ( 
a
 , 1 ) )

15 ] ) . 
astype
 ( 
np
 . 
int32
 )

16 for 
i
 , 
j
 in 
enumerate
 ( 
anchors
 ) :

17 
l
 = 
random
 . 
randint
 ( 0 , 900 )

18 
anchors
 [ 
i
 ] += 
l

21 
view
 = 0.01 * 
np
 . 
random
 . 
randn
 ( 800 , 600 , 27 ) . 
astype
 ( 
np
 . 
float32
 )

22 
t
 = 
time
 . 
time
 ( )

23 
index
 = 
remove_empty_anchor
 ( 
view
 , 
anchors
 , 0 )

24 
print
 ( 'done, {}' . 
format
 ( 
time
 . 
time
 ( ) - 
t
 ) )

25 
print
 ( 
index
 )

26 
print
 ( 
len
 ( 
index
 ) )

27 
tf
 . 
ones
 ( 10 ) . 
eval
 ( )


	@./net/utility/remove_empty_box.py

1 from 
	~__future__
 import 
print_function

2 from 
	~__future__
 import 
absolute_import

3 from 
	~__future__
 import 
division

4 import 
	~pycuda.driver
 as 
cuda

5 import 
	~pycuda.autoinit

6 import 
	~numpy
 as 
np

7 from 
	~config
 import 
cfg

8 import 
	~os

19 
module_buff
 = b"" . 
join
 ( 
open
 ( 
os
 . 
path
 . 
join
 ( 
cfg
 . 
ROOT_DIR
 , 'src/net/utility' , 'remove_empty_box_kernel.cubin' ) , 'rb' ) . 
readlines
 ( ) )

21 def 
	$get_gpu_info
 ( ) :

22 
cuda
 . 
init
 ( )

23 
device
 = 
cuda
 . 
Device
 ( 0 )

24 
print
 ( 
device
 . 
get_attributes
 ( ) ) 
	}

26 def 
	$remove_empty_anchor
 ( 
view
 , 
anchors
 , 
limit
 ) :

31 
mod
 = 
cuda
 . 
module_from_buffer
 ( 
module_buff
 )

32 
func
 = 
mod
 . 
get_function
 ( '_Z12remove_emptyPfPiS_S0_S0_' )

34 
anchors_shape
 = 
np
 . 
array
 ( 
anchors
 . 
shape
 ) . 
astype
 ( 
np
 . 
int32
 )

35 
view_shape
 = 
np
 . 
array
 ( 
view
 . 
shape
 ) . 
astype
 ( 
np
 . 
int32
 )

36 
index
 = 
np
 . 
zeros
 ( ( 
anchors
 . 
shape
 [ 0 ] , 
view_shape
 [ 2 ] ) ) . 
astype
 ( 
np
 . 
float32
 )

37 
func
 (

38 
cuda
 . 
InOut
 ( 
index
 ) ,

39 
cuda
 . 
In
 ( 
anchors
 ) ,

40 
cuda
 . 
In
 ( 
view
 ) ,

41 
cuda
 . 
In
 ( 
anchors_shape
 ) ,

42 
cuda
 . 
In
 ( 
view_shape
 ) ,

43 
block
 = ( 
int
 ( 
view_shape
 [ 2 ] ) , 1 , 1 ) ,

44 
grid
 = ( 
int
 ( 
anchors_shape
 [ 0 ] ) , 50 , 1 )

46 
index
 = 
np
 . 
sum
 ( 
index
 , 
axis
 = 1 )

47 return 
np
 . 
where
 ( 
index
 > 
limit
 ) [ 0 ] 
	}

49 if 
__name__
 == '__main__' :

50 import 
	~time

51 import 
	~random

52 import 
	~numpy
 as 
np

53 
a
 = 120000

54 
anchors
 = 
np
 . 
hstack
 ( [

55 0 * 
np
 . 
ones
 ( ( 
a
 , 1 ) ) ,

56 0 * 
np
 . 
ones
 ( ( 
a
 , 1 ) ) ,

57 40 * 
np
 . 
ones
 ( ( 
a
 , 1 ) ) ,

58 16 * 
np
 . 
ones
 ( ( 
a
 , 1 ) )

59 ] ) . 
astype
 ( 
np
 . 
int32
 )

60 for 
i
 , 
j
 in 
enumerate
 ( 
anchors
 ) :

61 
l
 = 
random
 . 
randint
 ( 0 , 900 )

62 
anchors
 [ 
i
 ] += 
l

64 
view
 = 0.01 * 
np
 . 
random
 . 
randn
 ( 800 , 600 , 27 ) . 
astype
 ( 
np
 . 
float32
 )

65 
t
 = 
time
 . 
time
 ( )

66 
index
 = 
remove_empty_anchor
 ( 
view
 , 
anchors
 , 0 )

67 
print
 ( 'done, {}' . 
format
 ( 
time
 . 
time
 ( ) - 
t
 ) )

68 
print
 ( 
index
 )

69 
print
 ( 
len
 ( 
index
 ) )


	@./utils/check_data.py

1 import 
	~os

2 import 
	~glob

3 from 
	~collections
 import 
defaultdict

4 from 
	~warnings
 import 
warn

8 def 
	$get_file_names
 ( 
data_dir
 , 
data_type
 , 
driver
 , 
date
 , 
index
 = None ) :

9 
dir_path
 = 
os
 . 
path
 . 
join
 ( 
data_dir
 , 
data_type
 )

10 
driver_path
 = 
os
 . 
path
 . 
join
 ( 
dir_path
 , 
date
 , 
driver
 )

11 if 
index
 is None :

12 
prefix
 = 
driver_path
 + '/*'

13 
driver_files
 = 
glob
 . 
glob
 ( 
prefix
 )

15 
prefix
 = [ 
os
 . 
path
 . 
join
 ( 
driver_path
 , 
file_name
 ) for 
file_name
 in 
index
 ]

16 
driver_files
 = [ 
glob
 . 
glob
 ( 
i
 + '*' ) [ 0 ] for 
i
 in 
prefix
 ]

17 return 
driver_files
 
	}

19 def 
	$check_preprocessed_data
 ( 
data_seg
 , 
dates_to_drivers
 , 
is_testset
 = False ) :

20 
problem_driver
 = 
defaultdict
 ( 
list
 )

21 
right_driver
 = 
defaultdict
 ( 
list
 )

23 for 
date
 , 
drivers
 in 
dates_to_drivers
 . 
items
 ( ) :

24 for 
driver
 in 
drivers
 :

25 
rgb_files
 = 
get_file_names
 ( 
data_seg
 , "rgb" , 
driver
 , 
date
 )

26 
top_files
 = 
get_file_names
 ( 
data_seg
 , "top" , 
driver
 , 
date
 )

28 
gt_labels_files
 = 
get_file_names
 ( 
data_seg
 , "gt_labels" , 
driver
 , 
date
 )

29 
gt_boxes3d_files
 = 
get_file_names
 ( 
data_seg
 , "gt_boxes3d" , 
driver
 , 
date
 )

31 if 
is_testset
 :

32 
value_set
 = 
set
 ( [ 
len
 ( 
rgb_files
 ) , 
len
 ( 
top_files
 ) ] )

34 
value_set
 = 
set
 ( [ 
len
 ( 
rgb_files
 ) , 
len
 ( 
top_files
 ) , 
len
 ( 
gt_labels_files
 ) , 
len
 ( 
gt_boxes3d_files
 ) ] )

35 if 
len
 ( 
value_set
 ) != 1 :

37 
problem_driver
 [ 
date
 ] . 
append
 ( 
driver
 )

39 
right_driver
 [ 
date
 ] . 
append
 ( 
driver
 )

41 for 
key
 , 
value
 in 
right_driver
 . 
items
 ( ) :

42 
print
 ( "CORRECT!, date {{'{}':{}}} has same number of rgbs, tops, gt_labels or gt_boxes" . 
format
 ( 
key
 , 
value
 ) )

44 if 
len
 ( 
problem_driver
 . 
keys
 ( ) ) != 0 :

45 for 
key
 , 
value
 in 
problem_driver
 . 
items
 ( ) :

46 
warn
 ( "INCORRECT! date {{'{}':{}}} has different number of rgbs, tops, gt_labels or gt_boxes" . 
format
 ( 
key
 ,

47 
value
 ) )

48 raise 
ValueError
 ( 'Check above warning info to find which date and driver data is incomplete. ' )

49 return True 
	}


	@./utils/lidar_top_feature_visualize.py

1 import 
	~os

2 
os
 . 
environ
 [ "DISPLAY" ] = ":0"

5 import 
	~glob

9 import 
	~math

10 import 
	~random

11 import 
	~numpy
 as 
np

13 import 
	~cv2

14 import 
	~mayavi.mlab
 as 
mlab

15 import 
	~config

16 from 
	~config
 import 
TOP_X_MAX
 , 
TOP_X_MIN
 , 
TOP_Y_MAX
 , 
TOP_Z_MIN
 , 
TOP_Z_MAX
 ,

17 
TOP_Y_MIN
 , 
TOP_X_DIVISION
 , 
TOP_Y_DIVISION
 , 
TOP_Z_DIVISION

31 
MM_TOP_VIEW
 = 180 , 0 , 120 , [ 0 , 0 , 0 ]

32 
MM_PER_VIEW1
 = 120 , 30 , 70 , [ 0 , 0 , 0 ]

33 
MM_PER_VIEW2
 = 30 , 45 , 100 , [ 0 , 0 , 0 ]

34 
MM_PER_VIEW3
 = 120 , 30 , 100 , [ 0 , 0 , 0 ]

41 def 
	$draw_shadow_text
 ( 
img
 , 
text
 , 
pt
 , 
fontScale
 , 
color
 , 
thickness
 , 
color1
 = None , 
thickness1
 = None ) :

43 if 
color1
 is None : 
color1
 = ( 0 , 0 , 0 )

44 if 
thickness1
 is None : 
thickness1
 = 
thickness
 + 2

46 
font
 = 
cv2
 . 
FONT_HERSHEY_SIMPLEX

47 
cv2
 . 
putText
 ( 
img
 , 
text
 , 
pt
 , 
font
 , 
fontScale
 , 
color1
 , 
thickness1
 , 
cv2
 . 
LINE_AA
 )

48 
cv2
 . 
putText
 ( 
img
 , 
text
 , 
pt
 , 
font
 , 
fontScale
 , 
color
 , 
thickness
 , 
cv2
 . 
LINE_AA
 ) 
	}

50 def 
	$imshow
 ( 
name
 , 
image
 , 
resize
 = 1 ) :

51 
H
 , 
W
 = 
image
 . 
shape
 [ 0 : 2 ]

52 
cv2
 . 
namedWindow
 ( 
name
 , 
cv2
 . 
WINDOW_NORMAL
 )

53 
cv2
 . 
imshow
 ( 
name
 , 
image
 . 
astype
 ( 
np
 . 
uint8
 ) )

54 
cv2
 . 
resizeWindow
 ( 
name
 , 
round
 ( 
resize
 * 
W
 ) , 
round
 ( 
resize
 * 
H
 ) ) 
	}

57 def 
	$draw_didi_lidar
 ( 
fig
 , 
lidar
 , 
is_grid
 = 1 , 
is_axis
 = 1 ) :

59 
pxs
 = 
lidar
 [ : , 0 ]

60 
pys
 = 
lidar
 [ : , 1 ]

61 
pzs
 = 
lidar
 [ : , 2 ]

62 
prs
 = 
lidar
 [ : , 3 ]

64 
prs
 = 
np
 . 
clip
 ( 
prs
 / 15 , 0 , 1 )

67 if 
is_grid
 :

68 
L
 = 25

69 
dL
 = 5

70 
Z
 = - 2

71 
mlab
 . 
points3d
 ( 0 , 0 , 0 , 
color
 = ( 1 , 1 , 1 ) , 
mode
 = 'sphere' , 
scale_factor
 = 0.2 )

73 for 
y
 in 
np
 . 
arange
 ( - 
L
 , 
L
 + 1 , 
dL
 ) :

74 
x1
 , 
y1
 , 
z1
 = - 
L
 , 
y
 , 
Z

75 
x2
 , 
y2
 , 
z2
 = 
L
 , 
y
 , 
Z

76 
mlab
 . 
plot3d
 ( [ 
x1
 , 
x2
 ] , [ 
y1
 , 
y2
 ] , [ 
z1
 , 
z2
 ] , 
color
 = ( 0.3 , 0.3 , 0.3 ) , 
tube_radius
 = None , 
line_width
 = 1 , 
figure
 = 
fig
 )

78 for 
x
 in 
np
 . 
arange
 ( - 
L
 , 
L
 + 1 , 
dL
 ) :

79 
x1
 , 
y1
 , 
z1
 = 
x
 , - 
L
 , 
Z

80 
x2
 , 
y2
 , 
z2
 = 
x
 , 
L
 , 
Z

81 
mlab
 . 
plot3d
 ( [ 
x1
 , 
x2
 ] , [ 
y1
 , 
y2
 ] , [ 
z1
 , 
z2
 ] , 
color
 = ( 0.3 , 0.3 , 0.3 ) , 
tube_radius
 = None , 
line_width
 = 1 , 
figure
 = 
fig
 )

84 if 
is_axis
 :

85 
axes
 = 
np
 . 
array
 ( [

89 ] , 
dtype
 = 
np
 . 
float64
 )

91 
mlab
 . 
points3d
 ( 0 , 0 , 0 , 
color
 = ( 1 , 1 , 1 ) , 
mode
 = 'sphere' , 
scale_factor
 = 0.2 )

92 
mlab
 . 
plot3d
 ( [ 0 , 
axes
 [ 0 , 0 ] ] , [ 0 , 
axes
 [ 0 , 1 ] ] , [ 0 , 
axes
 [ 0 , 2 ] ] , 
color
 = ( 1 , 0 , 0 ) , 
tube_radius
 = None , 
line_width
 = 2 , 
figure
 = 
fig
 )

93 
mlab
 . 
plot3d
 ( [ 0 , 
axes
 [ 1 , 0 ] ] , [ 0 , 
axes
 [ 1 , 1 ] ] , [ 0 , 
axes
 [ 1 , 2 ] ] , 
color
 = ( 0 , 1 , 0 ) , 
tube_radius
 = None , 
line_width
 = 2 , 
figure
 = 
fig
 )

94 
mlab
 . 
plot3d
 ( [ 0 , 
axes
 [ 2 , 0 ] ] , [ 0 , 
axes
 [ 2 , 1 ] ] , [ 0 , 
axes
 [ 2 , 2 ] ] , 
color
 = ( 0 , 0 , 1 ) , 
tube_radius
 = None , 
line_width
 = 2 , 
figure
 = 
fig
 )

97 
mlab
 . 
points3d
 (

98 
pxs
 , 
pys
 , 
pzs
 , 
prs
 ,

99 
mode
 = 'point' ,

103 
scale_factor
 = 1 ,

104 
figure
 = 
fig
 ) 
	}

114 def 
	$draw_didi_boxes3d
 ( 
fig
 , 
boxes3d
 , 
is_number
 = False , 
color
 = ( 1 , 1 , 1 ) , 
line_width
 = 1 ) :

116 if 
boxes3d
 . 
shape
 == ( 8 , 3 ) : 
boxes3d
 = 
boxes3d
 . 
reshape
 ( 1 , 8 , 3 )

118 
num
 = 
len
 ( 
boxes3d
 )

119 for 
n
 in 
range
 ( 
num
 ) :

120 
b
 = 
boxes3d
 [ 
n
 ]

122 if 
is_number
 :

123 
mlab
 . 
text3d
 ( 
b
 [ 0 , 0 ] , 
b
 [ 0 , 1 ] , 
b
 [ 0 , 2 ] , '%d' % 
n
 , 
scale
 = ( 1 , 1 , 1 ) , 
color
 = 
color
 , 
figure
 = 
fig
 )

124 for 
k
 in 
range
 ( 0 , 4 ) :

127 
i
 , 
j
 = 
k
 , ( 
k
 + 1 ) % 4

128 
mlab
 . 
plot3d
 ( [ 
b
 [ 
i
 , 0 ] , 
b
 [ 
j
 , 0 ] ] , [ 
b
 [ 
i
 , 1 ] , 
b
 [ 
j
 , 1 ] ] , [ 
b
 [ 
i
 , 2 ] , 
b
 [ 
j
 , 2 ] ] , 
color
 = 
color
 , 
tube_radius
 = None , 
line_width
 = 
line_width
 , 
figure
 = 
fig
 )

130 
i
 , 
j
 = 
k
 + 4 , ( 
k
 + 1 ) % 4 + 4

131 
mlab
 . 
plot3d
 ( [ 
b
 [ 
i
 , 0 ] , 
b
 [ 
j
 , 0 ] ] , [ 
b
 [ 
i
 , 1 ] , 
b
 [ 
j
 , 1 ] ] , [ 
b
 [ 
i
 , 2 ] , 
b
 [ 
j
 , 2 ] ] , 
color
 = 
color
 , 
tube_radius
 = None , 
line_width
 = 
line_width
 , 
figure
 = 
fig
 )

133 
i
 , 
j
 = 
k
 , 
k
 + 4

134 
mlab
 . 
plot3d
 ( [ 
b
 [ 
i
 , 0 ] , 
b
 [ 
j
 , 0 ] ] , [ 
b
 [ 
i
 , 1 ] , 
b
 [ 
j
 , 1 ] ] , [ 
b
 [ 
i
 , 2 ] , 
b
 [ 
j
 , 2 ] ] , 
color
 = 
color
 , 
tube_radius
 = None , 
line_width
 = 
line_width
 , 
figure
 = 
fig
 ) 
	}

139 def 
	$dir_to_avi
 ( 
avi_file
 , 
png_dir
 ) :

141 
tmp_dir
 = '~temp_png'

142 
os
 . 
makedirs
 ( 
tmp_dir
 , 
exist_ok
 = True )

144 for 
i
 , 
file
 in 
enumerate
 ( 
sorted
 ( 
glob
 . 
glob
 ( 
png_dir
 + '/*.png' ) ) ) :

145 
name
 = 
os
 . 
path
 . 
basename
 ( 
file
 ) . 
replace
 ( '.png' , '' )

148 
png_file
 = 
png_dir
 + '/' + 
name
 + '.png'

149 
tmp_file
 = 
tmp_dir
 + '/%06d.png' % 
i

150 
img
 = 
cv2
 . 
imread
 ( 
png_file
 , 1 )

151 
draw_shadow_text
 ( 
img
 , 'timestamp=' + 
name
 . 
replace
 ( '_' , ':' ) , ( 5 , 20 ) , 0.5 , ( 225 , 225 , 225 ) , 1 )

152 
imshow
 ( 'img' , 
img
 )

153 
cv2
 . 
waitKey
 ( 1 )

154 
cv2
 . 
imwrite
 ( 
tmp_file
 , 
img
 )

157 
os
 . 
system
 ( 'ffmpeg -y -loglevel 0 -f image2 -r 15 -i %s/%%06d.png -b:v 8000k %s' % ( 
tmp_dir
 , 
avi_file
 ) )

158 
os
 . 
system
 ( 'rm -rf %s' % 
tmp_dir
 ) 
	}

164 def 
	$draw_top_feature_map
 ( 
top_dir
 , 
gt_boxes3d_dir
 , 
mark_dir
 , 
index
 ) :

166 
os
 . 
makedirs
 ( 
mark_dir
 , 
exist_ok
 = True )

167 
fig
 = 
mlab
 . 
figure
 ( 
figure
 = None , 
bgcolor
 = ( 0 , 0 , 0 ) , 
fgcolor
 = None , 
engine
 = None , 
size
 = ( 500 , 500 ) )

169 
count
 = 0

170 
channel_num
 = 
int
 ( ( 
TOP_Z_MAX
 - 
TOP_Z_MIN
 ) / 
TOP_Z_DIVISION
 )

171 for 
file
 in 
sorted
 ( 
glob
 . 
glob
 ( 
top_dir
 + '/*.npy' ) ) :

172 if 
count
 != 
index
 :

173 
count
 += 1

175 
count
 += 1

176 
name
 = 
os
 . 
path
 . 
basename
 ( 
file
 ) . 
replace
 ( '.npy' , '' )

178 
top_path
 = 
top_dir
 + '/' + 
name
 + '.npy'

180 
top
 = 
np
 . 
load
 ( 
top_path
 )

181 
feature_map_points
 = [ ]

182 for 
i
 in 
range
 ( 
top
 . 
shape
 [ 0 ] ) :

183 for 
j
 in 
range
 ( 
top
 . 
shape
 [ 1 ] ) :

184 if 
top
 [ 
i
 , 
j
 , 7 ] != 0 :

185 for 
height_i
 in 
range
 ( 
channel_num
 ) :

186 
z
 = 
top
 [ 
i
 , 
j
 , 
height_i
 ]

187 if 
z
 != 0 :

188 
x
 = ( 
TOP_X_MAX
 - 
TOP_X_MIN
 ) / 2. - 
i
 * 
TOP_X_DIVISION

189 
y
 = ( 
TOP_Y_MAX
 - 
TOP_Y_MIN
 ) / 2. - 
j
 * 
TOP_Y_DIVISION

190 
intensity
 = 
top
 [ 
i
 , 
j
 , 6 ]

191 
feature_map_points
 . 
append
 ( 
np
 . 
array
 ( [ 
x
 , 
y
 , 
z
 , 
intensity
 ] ) )

192 
feature_map_points
 = 
np
 . 
array
 ( 
feature_map_points
 )

194 
mlab
 . 
clf
 ( 
fig
 )

195 
draw_didi_lidar
 ( 
fig
 , 
feature_map_points
 , 
is_grid
 = 1 , 
is_axis
 = 1 )

199 
azimuth
 , 
elevation
 , 
distance
 , 
focalpoint
 = 
MM_PER_VIEW1

200 
mlab
 . 
view
 ( 
azimuth
 , 
elevation
 , 
distance
 , 
focalpoint
 )

201 
print
 ( 'show now' )

202 
mlab
 . 
show
 ( ) 
	}

210 if 
__name__
 == '__main__' :

212 
preprocessed_dir
 = 
config
 . 
cfg
 . 
PREPROCESSING_DATA_SETS_DIR

213 
dataset
 = '/Round1Test/19_f2'

214 
lidar_dir
 = 
preprocessed_dir
 + '/top' + 
dataset

215 
gt_boxes3d_dir
 = 
preprocessed_dir
 + '/gt_boxes3d' + 
dataset

216 
mark_dir
 = 
config
 . 
cfg
 . 
LOG_DIR
 + '/mark-gt-box3d'

217 
avi_file
 = 
config
 . 
cfg
 . 
LOG_DIR
 + '/mark-gt-box3d.avi'

219 
draw_top_feature_map
 ( 
lidar_dir
 , 
gt_boxes3d_dir
 , 
mark_dir
 , 11 )


	@./utils/batch_loading.py

1 import 
	~cv2

2 import 
	~numpy
 as 
np

3 from 
	~config
 import 
cfg

4 import 
	~os

5 import 
	~glob

6 from 
	~sklearn.utils
 import 
shuffle

7 from 
	~utils.check_data
 import 
check_preprocessed_data
 , 
get_file_names

8 import 
	~net.processing.boxes3d
 as 
box

9 from 
	~multiprocessing
 import 
Process
 , 
Queue
 as 
Queue
 , 
Value
 , 
Array
 , 
cpu_count

10 import 
	~queue

11 import 
	~time

13 import 
	~config

14 import 
	~os

15 import 
	~numpy
 as 
np

16 import 
	~glob

17 import 
	~cv2

18 from 
	~kitti_data.pykitti.tracklet
 import 
parseXML
 , 
TRUNC_IN_IMAGE
 , 
TRUNC_TRUNCATED

19 from 
	~config
 import 
cfg

20 import 
	~data

21 import 
	~net.utility.draw
 as 
draw

22 from 
	~raw_data
 import *

23 from 
	~utils.training_validation_data_splitter
 import 
TrainingValDataSplitter

24 import 
	~pickle

25 import 
	~array

26 import 
	~data

27 from 
	~sklearn.utils
 import 
shuffle

28 import 
	~threading

29 import 
	~scipy.io

30 from 
	~net.processing.boxes3d
 import *

31 import 
	~math

39 def 
	$load
 ( 
file_names
 , 
is_testset
 = False ) :

41 
first_item
 = 
file_names
 [ 0 ] . 
split
 ( '/' )

42 
prefix
 = '/' . 
join
 ( 
first_item
 [ : - 4 ] )

44 
frame_num_list
 = [ '/' . 
join
 ( 
name
 . 
split
 ( '/' ) [ - 3 : ] ) for 
name
 in 
file_names
 ]

47 
train_rgbs
 = [ 
cv2
 . 
imread
 ( 
os
 . 
path
 . 
join
 ( 
prefix
 , 'rgb' , 
file
 + '.png' ) , 1 ) for 
file
 in 
frame_num_list
 ]

48 
train_tops
 = [ 
np
 . 
load
 ( 
os
 . 
path
 . 
join
 ( 
prefix
 , 'top' , 
file
 + '.npy.npz' ) ) [ 'top_view' ] for 
file
 in 
frame_num_list
 ]

49 
train_fronts
 = [ 
np
 . 
zeros
 ( ( 1 , 1 ) , 
dtype
 = 
np
 . 
float32
 ) for 
file
 in 
frame_num_list
 ]

51 if 
is_testset
 == True :

52 
train_gt_boxes3d
 = None

53 
train_gt_labels
 = None

55 
train_gt_boxes3d
 = [ 
np
 . 
load
 ( 
os
 . 
path
 . 
join
 ( 
prefix
 , 'gt_boxes3d' , 
file
 + '.npy' ) ) for 
file
 in 
frame_num_list
 ]

57 
train_gt_labels
 = [ 
np
 . 
load
 ( 
os
 . 
path
 . 
join
 ( 
prefix
 , 'gt_labels' , 
file
 + '.npy' ) ) for 
file
 in

58 
frame_num_list
 ]

60 return 
train_rgbs
 , 
train_tops
 , 
train_fronts
 , 
train_gt_labels
 , 
train_gt_boxes3d
 
	}

63 class 
	cbatch_loading
 :

64 def 
	$__init__
 ( 
self
 , 
dir_path
 , 
dates_to_drivers
 = None , 
indice
 = None , 
cache_num
 = 10 , 
is_testset
 = False ) :

65 
self
 . 
dates_to_drivers
 = 
dates_to_drivers

66 
self
 . 
indice
 = 
indice

67 
self
 . 
cache_num
 = 
cache_num

68 
self
 . 
preprocess_path
 = 
dir_path

69 
self
 . 
is_testset
 = 
is_testset

71 
self
 . 
preprocess
 = 
data
 . 
Preprocess
 ( )

72 
self
 . 
raw_img
 = 
Image
 ( )

73 
self
 . 
raw_tracklet
 = 
Tracklet
 ( )

74 
self
 . 
raw_lidar
 = 
Lidar
 ( )

77 if 
indice
 is None :

78 
self
 . 
load_file_names
 = 
self
 . 
get_all_load_index
 ( 
self
 . 
preprocess_path
 , 
self
 . 
dates_to_drivers
 , 
is_testset
 )

79 
self
 . 
tags
 = 
self
 . 
raw_img
 . 
get_tags
 ( )

82 
self
 . 
load_file_names
 = 
self
 . 
get_specific_load_index
 ( 
indice
 , 
self
 . 
preprocess_path
 , 
self
 . 
dates_to_drivers
 ,

83 
is_testset
 )

84 
self
 . 
load_once
 = True

85 
self
 . 
size
 = 
len
 ( 
self
 . 
tags
 )

89 
self
 . 
batch_start_index
 = 0

92 
self
 . 
num_frame_used
 = 
cache_num

95 
self
 . 
train_rgbs
 = [ ]

96 
self
 . 
train_tops
 = [ ]

97 
self
 . 
train_fronts
 = [ ]

98 
self
 . 
train_gt_labels
 = [ ]

99 
self
 . 
train_gt_boxes3d
 = [ ]

100 
self
 . 
current_batch_file_names
 = [ ] 
	}

102 def 
	$load_from_one_tag
 ( 
self
 , 
one_frame_tag
 ) :

103 
obstacles
 = 
self
 . 
raw_tracklet
 . 
load
 ( 
one_frame_tag
 )

104 
rgb
 = 
self
 . 
raw_img
 . 
load
 ( 
one_frame_tag
 )

105 
lidar
 = 
self
 . 
raw_lidar
 . 
load
 ( 
one_frame_tag
 )

106 return 
obstacles
 , 
rgb
 , 
lidar
 
	}

108 def 
	$preprocess
 ( 
self
 , 
rgb
 , 
lidar
 , 
obstacles
 ) :

109 
rgb
 = 
preprocess
 . 
rgb
 ( 
rgb
 )

110 
top
 = 
preprocess
 . 
lidar_to_top
 ( 
lidar
 )

111 
boxes3d
 = [ 
preprocess
 . 
bbox3d
 ( 
obs
 ) for 
obs
 in 
obstacles
 ]

112 
labels
 = [ 
preprocess
 . 
label
 ( 
obs
 ) for 
obs
 in 
obstacles
 ]

113 return 
rgb
 , 
top
 , 
boxes3d
 , 
labels
 
	}

115 def 
	$draw_bbox_on_rgb
 ( 
self
 , 
rgb
 , 
boxes3d
 ) :

116 
img
 = 
draw
 . 
draw_box3d_on_camera
 ( 
rgb
 , 
boxes3d
 )

117 
new_size
 = ( 
img
 . 
shape
 [ 1 ] // 3 , 
img
 . 
shape
 [ 0 ] // 3 )

118 
img
 = 
cv2
 . 
resize
 ( 
img
 , 
new_size
 )

119 
path
 = 
os
 . 
path
 . 
join
 ( 
config
 . 
cfg
 . 
LOG_DIR
 , 'test' , 'rgb' , '%s.png' % 
one_frame_tag
 . 
replace
 ( '/' , '_' ) )

120 
cv2
 . 
imwrite
 ( 
path
 , 
img
 )

121 
print
 ( 'write %s finished' % 
path
 ) 
	}

123 def 
	$draw_bbox_on_lidar_top
 ( 
self
 , 
top
 , 
boxes3d
 ) :

124 
path
 = 
os
 . 
path
 . 
join
 ( 
config
 . 
cfg
 . 
LOG_DIR
 , 'test' , 'top' , '%s.png' % 
one_frame_tag
 . 
replace
 ( '/' , '_' ) )

125 
top_image
 = 
data
 . 
draw_top_image
 ( 
top
 )

126 
top_image
 = 
data
 . 
draw_box3d_on_top
 ( 
top_image
 , 
boxes3d
 , 
color
 = ( 0 , 0 , 80 ) )

127 
cv2
 . 
imwrite
 ( 
path
 , 
top_image
 )

128 
print
 ( 'write %s finished' % 
path
 ) 
	}

130 def 
	$get_shape
 ( 
self
 ) :

133 
train_rgbs
 , 
train_tops
 , 
train_fronts
 , 
train_gt_labels
 , 
train_gt_boxes3d
 = 
load
 ( [ 
self
 . 
load_file_names
 [ 0 ] ] ,

134 
is_testset
 = 
self
 . 
is_testset
 )

136 
obstacles
 , 
rgb
 , 
lidar
 = 
self
 . 
load_from_one_tag
 ( [ 
self
 . 
tags
 [ 0 ] ] ,

137 
is_testset
 = 
self
 . 
is_testset
 )

138 
train_rgbs
 , 
train_tops
 , 
train_fronts
 , 
train_gt_labels
 , 
train_gt_boxes3d
 = 
self
 . 
preprocess
 ( )

140 
top_shape
 = 
train_tops
 [ 0 ] . 
shape

141 
front_shape
 = 
train_fronts
 [ 0 ] . 
shape

142 
rgb_shape
 = 
train_rgbs
 [ 0 ] . 
shape

144 return 
top_shape
 , 
front_shape
 , 
rgb_shape
 
	}

146 def 
	$get_all_load_index
 ( 
self
 , 
data_seg
 , 
dates_to_drivers
 , 
gt_included
 ) :

148 
check_preprocessed_data
 ( 
data_seg
 , 
dates_to_drivers
 , 
gt_included
 )

149 
top_dir
 = 
os
 . 
path
 . 
join
 ( 
data_seg
 , "top" )

151 
load_indexs
 = [ ]

152 for 
date
 , 
drivers
 in 
dates_to_drivers
 . 
items
 ( ) :

153 for 
driver
 in 
drivers
 :

155 
file_prefix
 = 
os
 . 
path
 . 
join
 ( 
data_seg
 , "top" , 
date
 , 
driver
 )

156 
driver_files
 = 
get_file_names
 ( 
data_seg
 , "top" , 
driver
 , 
date
 )

157 if 
len
 ( 
driver_files
 ) == 0 :

158 raise 
ValueError
 ( 'Directory has no data starts from {}, please revise.' . 
format
 ( 
file_prefix
 ) )

160 
name_list
 = [ 
file
 . 
split
 ( '/' ) [ - 1 ] . 
split
 ( '.' ) [ 0 ] for 
file
 in 
driver_files
 ]

161 
name_list
 = [ 
file
 . 
split
 ( '.' ) [ 0 ] for 
file
 in 
driver_files
 ]

162 
load_indexs
 += 
name_list

163 
load_indexs
 = 
sorted
 ( 
load_indexs
 )

164 return 
load_indexs
 
	}

166 def 
	$get_specific_load_index
 ( 
self
 , 
index
 , 
data_seg
 , 
dates_to_drivers
 , 
gt_included
 ) :

168 
check_preprocessed_data
 ( 
data_seg
 , 
dates_to_drivers
 , 
gt_included
 )

169 
top_dir
 = 
os
 . 
path
 . 
join
 ( 
data_seg
 , "top" )

171 
load_indexs
 = [ ]

172 for 
date
 , 
drivers
 in 
dates_to_drivers
 . 
items
 ( ) :

173 for 
driver
 in 
drivers
 :

175 
file_prefix
 = 
os
 . 
path
 . 
join
 ( 
data_seg
 , "top" , 
driver
 , 
date
 )

176 
driver_files
 = 
get_file_names
 ( 
data_seg
 , "top" , 
driver
 , 
date
 , 
index
 )

177 if 
len
 ( 
driver_files
 ) == 0 :

178 raise 
ValueError
 ( 'Directory has no data starts from {}, please revise.' . 
format
 ( 
file_prefix
 ) )

180 
name_list
 = [ 
file
 . 
split
 ( '/' ) [ - 1 ] . 
split
 ( '.' ) [ 0 ] for 
file
 in 
driver_files
 ]

181 
name_list
 = [ 
file
 . 
split
 ( '.' ) [ 0 ] for 
file
 in 
driver_files
 ]

182 
load_indexs
 += 
name_list

183 
load_indexs
 = 
sorted
 ( 
load_indexs
 )

184 return 
load_indexs
 
	}

186 def 
	$load_test_frames
 ( 
self
 , 
size
 , 
shuffled
 ) :

188 if 
self
 . 
load_once
 :

189 if 
shuffled
 :

190 
self
 . 
load_file_names
 = 
shuffle
 ( 
self
 . 
load_file_names
 )

191 
self
 . 
train_rgbs
 , 
self
 . 
train_tops
 , 
self
 . 
train_fronts
 , 
self
 . 
train_gt_labels
 , 
self
 . 
train_gt_boxes3d
 =

192 
load
 ( 
self
 . 
load_file_names
 )

193 
self
 . 
num_frame_used
 = 0

194 
self
 . 
load_once
 = False

196 
self
 . 
current_batch_file_names
 = 
self
 . 
load_file_names

197 
frame_end
 = 
min
 ( 
self
 . 
num_frame_used
 + 
size
 , 
self
 . 
cache_num
 )

198 
train_rgbs
 = 
self
 . 
train_rgbs
 [ 
self
 . 
num_frame_used
 : 
frame_end
 ]

199 
train_tops
 = 
self
 . 
train_tops
 [ 
self
 . 
num_frame_used
 : 
frame_end
 ]

200 
train_fronts
 = 
self
 . 
train_fronts
 [ 
self
 . 
num_frame_used
 : 
frame_end
 ]

201 
train_gt_labels
 = 
self
 . 
train_gt_labels
 [ 
self
 . 
num_frame_used
 : 
frame_end
 ]

202 
train_gt_boxes3d
 = 
self
 . 
train_gt_boxes3d
 [ 
self
 . 
num_frame_used
 : 
frame_end
 ]

203 
handle_id
 = 
self
 . 
current_batch_file_names
 [ 
self
 . 
num_frame_used
 : 
frame_end
 ]

204 
handle_id
 = [ '/' . 
join
 ( 
name
 . 
split
 ( '/' ) [ - 3 : ] ) for 
name
 in 
handle_id
 ]

206 
self
 . 
num_frame_used
 = 
frame_end

207 if 
self
 . 
num_frame_used
 >= 
self
 . 
size
 :

208 
self
 . 
num_frame_used
 = 0

210 return 
train_rgbs
 , 
train_tops
 , 
train_fronts
 , 
train_gt_labels
 , 
train_gt_boxes3d
 , 
handle_id
 
	}

213 def 
	$load_batch
 ( 
self
 , 
size
 , 
shuffled
 ) :

214 if 
shuffled
 :

215 
self
 . 
load_file_names
 = 
shuffle
 ( 
self
 . 
load_file_names
 )

218 if 
self
 . 
num_frame_used
 >= 
self
 . 
cache_num
 :

219 
batch_end_index
 = 
self
 . 
batch_start_index
 + 
self
 . 
cache_num

221 if 
batch_end_index
 < 
self
 . 
size
 :

222 
loaded_file_names
 = 
self
 . 
load_file_names
 [ 
self
 . 
batch_start_index
 : 
batch_end_index
 ]

223 
self
 . 
batch_start_index
 = 
batch_end_index

227 
diff_to_end
 = 
self
 . 
size
 - 
self
 . 
batch_start_index

228 
start_offset
 = 
self
 . 
cache_num
 - 
diff_to_end

230 
file_names_to_end
 = 
self
 . 
load_file_names
 [ 
self
 . 
batch_start_index
 : 
self
 . 
size
 ]

231 if 
shuffled
 :

232 
self
 . 
load_file_names
 = 
shuffle
 ( 
self
 . 
load_file_names
 )

234 
file_names_from_start
 = 
self
 . 
load_file_names
 [ 0 : 
start_offset
 ]

236 
loaded_file_names
 = 
file_names_to_end
 + 
file_names_from_start

237 
self
 . 
batch_start_index
 = 
start_offset

241 
self
 . 
current_batch_file_names
 = 
loaded_file_names

242 
self
 . 
train_rgbs
 , 
self
 . 
train_tops
 , 
self
 . 
train_fronts
 , 
self
 . 
train_gt_labels
 , 
self
 . 
train_gt_boxes3d
 =

243 
load
 ( 
loaded_file_names
 , 
is_testset
 = 
self
 . 
is_testset
 )

244 
self
 . 
num_frame_used
 = 0

247 
frame_end
 = 
min
 ( 
self
 . 
num_frame_used
 + 
size
 , 
self
 . 
cache_num
 )

248 
train_rgbs
 = 
self
 . 
train_rgbs
 [ 
self
 . 
num_frame_used
 : 
frame_end
 ]

249 
train_tops
 = 
self
 . 
train_tops
 [ 
self
 . 
num_frame_used
 : 
frame_end
 ]

250 
train_fronts
 = 
self
 . 
train_fronts
 [ 
self
 . 
num_frame_used
 : 
frame_end
 ]

251 if 
self
 . 
is_testset
 :

252 
train_gt_labels
 = None

253 
train_gt_boxes3d
 = None

255 
train_gt_labels
 = 
self
 . 
train_gt_labels
 [ 
self
 . 
num_frame_used
 : 
frame_end
 ]

256 
train_gt_boxes3d
 = 
self
 . 
train_gt_boxes3d
 [ 
self
 . 
num_frame_used
 : 
frame_end
 ]

258 
handle_id
 = 
self
 . 
current_batch_file_names
 [ 
self
 . 
num_frame_used
 : 
frame_end
 ]

259 
handle_id
 = [ '/' . 
join
 ( 
name
 . 
split
 ( '/' ) [ - 3 : ] ) for 
name
 in 
handle_id
 ]

261 
self
 . 
num_frame_used
 = 
frame_end

263 return 
train_rgbs
 , 
train_tops
 , 
train_fronts
 , 
train_gt_labels
 , 
train_gt_boxes3d
 , 
handle_id
 
	}

265 def 
	$get_date_and_driver
 ( 
self
 , 
handle_id
 ) :

266 
date_n_driver
 = [ '/' . 
join
 ( 
item
 . 
split
 ( '/' ) [ 0 : 2 ] ) for 
item
 in 
handle_id
 ]

267 return 
date_n_driver
 
	}

269 def 
	$get_frame_info
 ( 
self
 , 
handle_id
 ) :

270 return 
handle_id
 
	}

272 def 
	$keep_gt_inside_range
 ( 
self
 , 
train_gt_labels
 , 
train_gt_boxes3d
 ) :

274 if 
train_gt_labels
 . 
shape
 [ 0 ] == 0 :

276 assert 
train_gt_labels
 . 
shape
 [ 0 ] == 
train_gt_boxes3d
 . 
shape
 [ 0 ]

279 
keep
 = 
np
 . 
zeros
 ( ( 
len
 ( 
train_gt_labels
 ) ) , 
dtype
 = 
bool
 )

281 for 
i
 in 
range
 ( 
len
 ( 
train_gt_labels
 ) ) :

282 if 
box
 . 
box3d_in_top_view
 ( 
train_gt_boxes3d
 [ 
i
 ] ) :

283 
keep
 [ 
i
 ] = 1

286 if 
np
 . 
sum
 ( 
keep
 ) == 0 :

289 
train_gt_labels
 = 
train_gt_labels
 [ 
keep
 ]

290 
train_gt_boxes3d
 = 
train_gt_boxes3d
 [ 
keep
 ]

291 return True , 
train_gt_labels
 , 
train_gt_boxes3d
 
	}

293 def 
	$load
 ( 
self
 , 
size
 , 
batch
 = True , 
shuffled
 = False ) :

294 
load_frames
 = True

295 while 
load_frames
 :

296 if 
batch
 :

297 
train_rgbs
 , 
train_tops
 , 
train_fronts
 , 
train_gt_labels
 , 
train_gt_boxes3d
 , 
frame_id
 = 
self
 . 
load_batch
 ( 
size
 ,

298 
shuffled
 )

300 
train_rgbs
 , 
train_tops
 , 
train_fronts
 , 
train_gt_labels
 , 
train_gt_boxes3d
 , 
frame_id
 =

301 
self
 . 
load_test_frames
 ( 
size
 , 
shuffled
 )

302 
load_frames
 = False

304 if not 
self
 . 
is_testset
 :

306 
is_gt_inside_range
 , 
batch_gt_labels_in_range
 , 
batch_gt_boxes3d_in_range
 =

307 
self
 . 
keep_gt_inside_range
 ( 
train_gt_labels
 [ 0 ] , 
train_gt_boxes3d
 [ 0 ] )

309 if not 
is_gt_inside_range
 :

310 
load_frames
 = True

315 
train_gt_labels
 = 
np
 . 
zeros
 ( ( 1 , 
batch_gt_labels_in_range
 . 
shape
 [ 0 ] ) , 
dtype
 = 
np
 . 
int32
 )

316 
train_gt_boxes3d
 = 
np
 . 
zeros
 ( ( 1 , 
batch_gt_labels_in_range
 . 
shape
 [ 0 ] , 8 , 3 ) , 
dtype
 = 
np
 . 
float32
 )

317 
train_gt_labels
 [ 0 ] = 
batch_gt_labels_in_range

318 
train_gt_boxes3d
 [ 0 ] = 
batch_gt_boxes3d_in_range

320 return 
np
 . 
array
 ( 
train_rgbs
 ) , 
np
 . 
array
 ( 
train_tops
 ) , 
np
 . 
array
 ( 
train_fronts
 ) , 
np
 . 
array
 ( 
train_gt_labels
 ) ,

321 
np
 . 
array
 ( 
train_gt_boxes3d
 ) , 
frame_id
 
	}

324 def 
	$draw_bbox_on_rgb
 ( 
rgb
 , 
boxes3d
 , 
one_frame_tag
 ) :

325 
img
 = 
draw
 . 
draw_box3d_on_camera
 ( 
rgb
 , 
boxes3d
 )

326 
new_size
 = ( 
img
 . 
shape
 [ 1 ] // 3 , 
img
 . 
shape
 [ 0 ] // 3 )

327 
img
 = 
cv2
 . 
resize
 ( 
img
 , 
new_size
 )

328 
path
 = 
os
 . 
path
 . 
join
 ( 
config
 . 
cfg
 . 
LOG_DIR
 , 'test' , 'rgb' , '%s.png' % 
one_frame_tag
 . 
replace
 ( '/' , '_' ) )

329 
cv2
 . 
imwrite
 ( 
path
 , 
img
 )

330 
print
 ( 'write %s finished' % 
path
 ) 
	}

333 def 
	$draw_bbox_on_lidar_top
 ( 
top
 , 
boxes3d
 , 
one_frame_tag
 ) :

334 
path
 = 
os
 . 
path
 . 
join
 ( 
config
 . 
cfg
 . 
LOG_DIR
 , 'test' , 'top' , '%s.png' % 
one_frame_tag
 . 
replace
 ( '/' , '_' ) )

335 
top_image
 = 
data
 . 
draw_top_image
 ( 
top
 )

336 
top_image
 = 
data
 . 
draw_box3d_on_top
 ( 
top_image
 , 
boxes3d
 , 
color
 = ( 0 , 0 , 80 ) )

337 
cv2
 . 
imwrite
 ( 
path
 , 
top_image
 )

338 
print
 ( 'write %s finished' % 
path
 ) 
	}

341 
use_thread
 = True

343 class 
	cBatchLoading2
 :

345 def 
	$__init__
 ( 
self
 , 
bags
 = [ ] , 
tags
 = [ ] , 
queue_size
 = 20 , 
require_shuffle
 = False ,

346 
require_log
 = False , 
is_testset
 = False ) :

347 
self
 . 
is_testset
 = 
is_testset

348 
self
 . 
shuffled
 = 
require_shuffle

349 
self
 . 
preprocess
 = 
data
 . 
Preprocess
 ( )

350 
self
 . 
raw_img
 = 
Image
 ( )

351 
self
 . 
raw_tracklet
 = 
Tracklet
 ( )

352 
self
 . 
raw_lidar
 = 
Lidar
 ( )

354 
self
 . 
bags
 = 
bags

356 
self
 . 
tags
 = 
tags

358 if 
self
 . 
shuffled
 :

359 
self
 . 
tags
 = 
shuffle
 ( 
self
 . 
tags
 )

361 
self
 . 
tag_index
 = 0

362 
self
 . 
size
 = 
len
 ( 
self
 . 
tags
 )

364 
self
 . 
require_log
 = 
require_log

366 
self
 . 
cache_size
 = 
queue_size

367 
self
 . 
loader_need_exit
 = 
Value
 ( 'i' , 0 )

369 if 
use_thread
 :

370 
self
 . 
prepr_data
 = [ ]

371 
self
 . 
lodaer_processing
 = 
threading
 . 
Thread
 ( 
target
 = 
self
 . 
loader
 )

373 
self
 . 
preproc_data_queue
 = 
Queue
 ( )

374 
self
 . 
buffer_blocks
 = [ 
Array
 ( 'h' , 41246691 ) for 
i
 in 
range
 ( 
queue_size
 ) ]

375 
self
 . 
blocks_usage
 = 
Array
 ( 'i' , 
range
 ( 
queue_size
 ) )

376 
self
 . 
lodaer_processing
 = 
Process
 ( 
target
 = 
self
 . 
loader
 )

377 
self
 . 
lodaer_processing
 . 
start
 ( ) 
	}

380 def 
	$__enter__
 ( 
self
 ) :

381 return 
self
 
	}

383 def 
	$__exit__
 ( 
self
 , 
exc_type
 , 
exc_val
 , 
exc_tb
 ) :

384 
self
 . 
loader_need_exit
 . 
value
 = True

385 if 
self
 . 
require_log
 : 
print
 ( 'set loader_need_exit True' )

386 
self
 . 
lodaer_processing
 . 
join
 ( )

387 if 
self
 . 
require_log
 : 
print
 ( 'exit lodaer_processing' ) 
	}

389 def 
	$keep_gt_inside_range
 ( 
self
 , 
train_gt_labels
 , 
train_gt_boxes3d
 ) :

390 
train_gt_labels
 = 
np
 . 
array
 ( 
train_gt_labels
 , 
dtype
 = 
np
 . 
int32
 )

391 
train_gt_boxes3d
 = 
np
 . 
array
 ( 
train_gt_boxes3d
 , 
dtype
 = 
np
 . 
float32
 )

392 if 
train_gt_labels
 . 
shape
 [ 0 ] == 0 :

394 assert 
train_gt_labels
 . 
shape
 [ 0 ] == 
train_gt_boxes3d
 . 
shape
 [ 0 ]

397 
keep
 = 
np
 . 
zeros
 ( ( 
len
 ( 
train_gt_labels
 ) ) , 
dtype
 = 
bool
 )

399 for 
i
 in 
range
 ( 
len
 ( 
train_gt_labels
 ) ) :

400 if 
box
 . 
box3d_in_top_view
 ( 
train_gt_boxes3d
 [ 
i
 ] ) :

401 
keep
 [ 
i
 ] = 1

404 if 
np
 . 
sum
 ( 
keep
 ) == 0 :

407 
train_gt_labels
 = 
train_gt_labels
 [ 
keep
 ]

408 
train_gt_boxes3d
 = 
train_gt_boxes3d
 [ 
keep
 ]

409 return True , 
train_gt_labels
 , 
train_gt_boxes3d
 
	}

411 def 
	$load_from_one_tag
 ( 
self
 , 
one_frame_tag
 ) :

412 if 
self
 . 
is_testset
 :

413 
obstacles
 = None

415 
obstacles
 = 
self
 . 
raw_tracklet
 . 
load
 ( 
one_frame_tag
 )

416 
rgb
 = 
self
 . 
raw_img
 . 
load
 ( 
one_frame_tag
 )

417 
lidar
 = 
self
 . 
raw_lidar
 . 
load
 ( 
one_frame_tag
 )

418 return 
obstacles
 , 
rgb
 , 
lidar
 
	}

421 def 
	$preprocess_one_frame
 ( 
self
 , 
rgb
 , 
lidar
 , 
obstacles
 ) :

422 
rgb
 = 
self
 . 
preprocess
 . 
rgb
 ( 
rgb
 )

423 
top
 = 
self
 . 
preprocess
 . 
lidar_to_top
 ( 
lidar
 )

424 
front
 = 
self
 . 
preprocess
 . 
lidar_to_front_fast
 ( 
lidar
 )

426 if 
self
 . 
is_testset
 :

427 return 
rgb
 , 
top
 , None , None

428 
boxes3d
 = [ 
self
 . 
preprocess
 . 
bbox3d
 ( 
obs
 ) for 
obs
 in 
obstacles
 ]

429 
labels
 = [ 
self
 . 
preprocess
 . 
label
 ( 
obs
 ) for 
obs
 in 
obstacles
 ]

430 return 
rgb
 , 
top
 , 
boxes3d
 , 
labels
 
	}

432 def 
	$get_shape
 ( 
self
 ) :

433 
train_rgbs
 , 
train_tops
 , 
train_fronts
 , 
train_gt_labels
 , 
train_gt_boxes3d
 , 
_
 = 
self
 . 
load
 ( )

434 
top_shape
 = 
train_tops
 [ 0 ] . 
shape

435 
front_shape
 = 
train_fronts
 [ 0 ] . 
shape

436 
rgb_shape
 = 
train_rgbs
 [ 0 ] . 
shape

438 return 
top_shape
 , 
front_shape
 , 
rgb_shape
 
	}

440 def 
	$data_preprocessed
 ( 
self
 ) :

442 
skip_frames
 = True

443 while 
skip_frames
 :

445 
frame_tag
 = 
self
 . 
tags
 [ 
self
 . 
tag_index
 ]

446 
obstacles
 , 
rgb
 , 
lidar
 = 
self
 . 
load_from_one_tag
 ( 
frame_tag
 )

447 
rgb
 , 
top
 , 
boxes3d
 , 
labels
 , 
fronts
 = 
self
 . 
preprocess_one_frame
 ( 
rgb
 , 
lidar
 , 
obstacles
 )

448 if 
self
 . 
require_log
 and not 
self
 . 
is_testset
 :

449 
draw_bbox_on_rgb
 ( 
rgb
 , 
boxes3d
 , 
frame_tag
 )

450 
draw_bbox_on_lidar_top
 ( 
top
 , 
boxes3d
 , 
frame_tag
 )

452 
self
 . 
tag_index
 += 1

455 if 
self
 . 
tag_index
 >= 
self
 . 
size
 :

456 
self
 . 
tag_index
 = 0

457 if 
self
 . 
shuffled
 :

458 
self
 . 
tags
 = 
shuffle
 ( 
self
 . 
tags
 )

459 
skip_frames
 = False

462 if not 
self
 . 
is_testset
 :

463 
is_gt_inside_range
 , 
batch_gt_labels_in_range
 , 
batch_gt_boxes3d_in_range
 =

464 
self
 . 
keep_gt_inside_range
 ( 
labels
 , 
boxes3d
 )

465 
labels
 = 
batch_gt_labels_in_range

466 
boxes3d
 = 
batch_gt_boxes3d_in_range

468 if not 
is_gt_inside_range
 :

469 
skip_frames
 = True

471 return 
np
 . 
array
 ( [ 
rgb
 ] ) , 
np
 . 
array
 ( [ 
top
 ] ) , 
np
 . 
array
 ( [ 
fronts
 ] ) , 
np
 . 
array
 ( [ 
labels
 ] ) ,

472 
np
 . 
array
 ( [ 
boxes3d
 ] ) , 
frame_tag
 
	}

474 def 
	$find_empty_block
 ( 
self
 ) :

475 
idx
 = - 1

476 for 
i
 in 
range
 ( 
self
 . 
cache_size
 ) :

477 if 
self
 . 
blocks_usage
 [ 
i
 ] == 1 :

480 
idx
 = 
i

482 return 
idx
 
	}

485 def 
	$loader
 ( 
self
 ) :

486 if 
use_thread
 :

487 while 
self
 . 
loader_need_exit
 . 
value
 == 0 :

489 if 
len
 ( 
self
 . 
prepr_data
 ) >= 
self
 . 
cache_size
 :

490 
time
 . 
sleep
 ( 1 )

493 
self
 . 
prepr_data
 = [ ( 
self
 . 
data_preprocessed
 ( ) ) ] + 
self
 . 
prepr_data

496 while 
self
 . 
loader_need_exit
 . 
value
 == 0 :

497 
empty_idx
 = 
self
 . 
find_empty_block
 ( )

498 if 
empty_idx
 == - 1 :

499 
time
 . 
sleep
 ( 1 )

502 
prepr_data
 = ( 
self
 . 
data_preprocessed
 ( ) )

504 
dumps
 = 
pickle
 . 
dumps
 ( 
prepr_data
 )

505 
length
 = 
len
 ( 
dumps
 )

506 
self
 . 
buffer_blocks
 [ 
empty_idx
 ] [ 0 : 
length
 ] = 
dumps
 [ 0 : 
length
 ]

508 
self
 . 
preproc_data_queue
 . 
put
 ( { 'index'

509 : 
empty_idx
 , 'length'

510 : 
length

514 if 
self
 . 
require_log
 : 
print
 ( 'loader exit' ) 
	}

518 def 
	$load
 ( 
self
 ) :

519 if 
use_thread
 :

520 while 
len
 ( 
self
 . 
prepr_data
 ) == 0 :

521 
time
 . 
sleep
 ( 1 )

522 
data_ori
 = 
self
 . 
prepr_data
 . 
pop
 ( )

528 
info
 = 
self
 . 
preproc_data_queue
 . 
get
 ( 
block
 = True )

529 
length
 = 
info
 [ 'length' ]

530 
block_index
 = 
info
 [ 'index' ]

531 
dumps
 = 
self
 . 
buffer_blocks
 [ 
block_index
 ] [ 0 : 
length
 ]

534 
self
 . 
blocks_usage
 [ 
block_index
 ] = 0

537 
dumps
 = 
array
 . 
array
 ( 'B' , 
dumps
 ) . 
tostring
 ( )

538 
data_ori
 = 
pickle
 . 
loads
 ( 
dumps
 )

540 return 
data_ori
 
	}

544 def 
	$get_frame_info
 ( 
self
 ) :

545 return 
self
 . 
tags
 [ 
self
 . 
tag_index
 ] 
	}

548 class 
	cKittiLoading
 ( 
object
 ) :

550 def 
	$__init__
 ( 
self
 , 
object_dir
 = '.' , 
queue_size
 = 20 , 
require_shuffle
 = False , 
is_testset
 = True , 
batch_size
 = 1 , 
use_precal_view
 = False ) :

551 
self
 . 
object_dir
 = 
object_dir

552 
self
 . 
is_testset
 , 
self
 . 
require_shuffle
 , 
self
 . 
use_precal_view
 = 
is_testset
 , 
require_shuffle
 , 
use_precal_view

553 
self
 . 
batch_size
 = 
batch_size

555 
self
 . 
f_rgb
 = 
glob
 . 
glob
 ( 
os
 . 
path
 . 
join
 ( 
self
 . 
object_dir
 , 'training' , 'image_2' , '*.png' ) )

556 
self
 . 
f_rgb
 . 
sort
 ( )

557 
self
 . 
f_lidar
 = 
glob
 . 
glob
 ( 
os
 . 
path
 . 
join
 ( 
self
 . 
object_dir
 , 'training' , 'velodyne' , '*.bin' ) )

558 
self
 . 
f_lidar
 . 
sort
 ( )

559 
self
 . 
f_top
 = 
glob
 . 
glob
 ( 
os
 . 
path
 . 
join
 ( 
self
 . 
object_dir
 , 'training' , 'top_view' , '*.npy' ) )

560 
self
 . 
f_top
 . 
sort
 ( )

561 
self
 . 
f_front
 = 
glob
 . 
glob
 ( 
os
 . 
path
 . 
join
 ( 
self
 . 
object_dir
 , 'training' , 'front_view' , '*.npy' ) )

562 
self
 . 
f_front
 . 
sort
 ( )

563 
self
 . 
f_label
 = 
glob
 . 
glob
 ( 
os
 . 
path
 . 
join
 ( 
self
 . 
object_dir
 , 'training' , 'label_2' , '*.txt' ) )

564 
self
 . 
f_label
 . 
sort
 ( )

565 
self
 . 
data_tag
 = [ 
name
 . 
split
 ( '/' ) [ - 1 ] . 
split
 ( '.' ) [ - 2 ] for 
name
 in 
self
 . 
f_label
 ]

566 assert ( 
len
 ( 
self
 . 
f_rgb
 ) == 
len
 ( 
self
 . 
f_lidar
 ) == 
len
 ( 
self
 . 
f_label
 ) == 
len
 ( 
self
 . 
data_tag
 ) )

567 
self
 . 
dataset_size
 = 
len
 ( 
self
 . 
f_rgb
 )

568 
self
 . 
alreay_extract_data
 = 0

570 
print
 ( "Dataset total length: {}" . 
format
 ( 
len
 ( 
self
 . 
f_rgb
 ) ) )

571 if 
self
 . 
require_shuffle
 :

572 
self
 . 
shuffle_dataset
 ( )

574 
self
 . 
queue_size
 = 
queue_size

575 
self
 . 
require_shuffle
 = 
require_shuffle

576 
self
 . 
preprocess
 = 
data
 . 
Preprocess
 ( )

577 
self
 . 
dataset_queue
 = 
Queue
 ( )

579 
self
 . 
load_index
 = 0

580 
self
 . 
fill_queue
 ( 
self
 . 
queue_size
 )

584 
tmp
 = 
self
 . 
dataset_queue
 . 
queue
 [ 0 ]

585 
self
 . 
top_shape
 = 
tmp
 [ 3 ] . 
shape

586 
self
 . 
front_shape
 = 
tmp
 [ 4 ] . 
shape

587 
self
 . 
rgb_shape
 = 
tmp
 [ 1 ] . 
shape

590 
self
 . 
top_shape
 = ( 800 , 600 , 27 )

591 
self
 . 
front_shape
 = ( 
cfg
 . 
FRONT_WIDTH
 , 
cfg
 . 
FRONT_HEIGHT
 , 3 )

592 
self
 . 
rgb_shape
 = ( 
cfg
 . 
IMAGE_HEIGHT
 , 
cfg
 . 
IMAGE_WIDTH
 , 3 )

595 
self
 . 
loader_worker
 = [ 
Process
 ( 
target
 = 
self
 . 
loader_worker_main
 ) for 
i
 in 
range
 ( 
cpu_count
 ( ) ) ]

596 
self
 . 
work_exit
 = False

597 [ 
i
 . 
start
 ( ) for 
i
 in 
self
 . 
loader_worker
 ] 
	}

599 def 
	$__enter__
 ( 
self
 ) :

600 return 
self
 
	}

602 def 
	$__exit__
 ( 
self
 , 
exc_type
 , 
exc_val
 , 
exc_tb
 ) :

603 
self
 . 
work_exit
 = True 
	}

605 def 
	$__len__
 ( 
self
 ) :

606 return 
self
 . 
dataset_size
 
	}

608 def 
	$fill_queue
 ( 
self
 , 
max_load_amount
 = 0 ) :

610 def 
to_label
 ( 
raw_labels
 ) :

613 
ret
 = [ ]

614 for 
line
 in 
raw_labels
 :

615 
data
 = 
line
 . 
split
 ( )

616 
obj_class
 = 
data
 [ 0 ]

618 
h
 , 
w
 , 
l
 , 
x
 , 
y
 , 
z
 , 
ry
 = [ 
float
 ( 
i
 ) for 
i
 in 
data
 [ 8 : 15 ] ]

621 
h
 , 
w
 , 
l
 , 
x
 , 
y
 , 
z
 , 
rz
 = 
h
 , 
w
 , 
l
 , 
box
 . 
camera_to_lidar_coords
 ( 
x
 , 
y
 , 
z
 ) , - 
ry
 - 
math
 . 
pi
 / 2

622 
ret
 . 
append
 ( ( 
obj_class
 , 
box3d_compose
 ( ( 
x
 , 
y
 , 
z
 ) , ( 
h
 , 
w
 , 
l
 ) , ( 0 , 0 , 
rz
 ) ) ) )

623 return 
ret

625 for 
_
 in 
range
 ( 
max_load_amount
 ) :

627 
rgb
 = 
self
 . 
preprocess
 . 
rgb
 ( 
cv2
 . 
imread
 ( 
self
 . 
f_rgb
 [ 
self
 . 
load_index
 ] ) )

628 
raw_lidar
 = 
np
 . 
fromfile
 ( 
self
 . 
f_lidar
 [ 
self
 . 
load_index
 ] , 
dtype
 = 
np
 . 
float32
 ) . 
reshape
 ( ( - 1 , 4 ) )

629 if 
self
 . 
use_precal_view
 :

631 
top_view
 = 
np
 . 
load
 ( 
self
 . 
f_top
 [ 
self
 . 
load_index
 ] )

633 
top_view
 = 
self
 . 
preprocess
 . 
lidar_to_top
 ( 
raw_lidar
 )

635 
front_view
 = 
np
 . 
load
 ( 
self
 . 
f_front
 [ 
self
 . 
load_index
 ] )

637 
front_view
 = 
self
 . 
preprocess
 . 
lidar_to_front_fast
 ( 
raw_lidar
 )

639 
top_view
 = 
self
 . 
preprocess
 . 
lidar_to_top
 ( 
raw_lidar
 )

641 
front_view
 = 
self
 . 
preprocess
 . 
lidar_to_front_fast
 ( 
raw_lidar
 )

643 
labels
 = [ 
line
 for 
line
 in 
open
 ( 
self
 . 
f_label
 [ 
self
 . 
load_index
 ] , 'r' ) . 
readlines
 ( ) ]

644 
tag
 = 
self
 . 
data_tag
 [ 
self
 . 
load_index
 ]

646 
self
 . 
dataset_queue
 . 
put_nowait
 ( ( 
labels
 , 
rgb
 , 
raw_lidar
 , 
top_view
 , 
front_view
 , 
tag
 ) )

647 
self
 . 
load_index
 += 1

650 if not 
self
 . 
is_testset
 :

651 
self
 . 
load_index
 = 0

652 if 
self
 . 
require_shuffle
 :

653 
self
 . 
shuffle_dataset
 ( )

655 
self
 . 
work_exit
 = True 
	}

657 def 
	$load
 ( 
self
 ) :

664 
label
 , 
rgb
 , 
raw_lidar
 , 
top_view
 , 
front_view
 , 
tag
 = [ ] , [ ] , [ ] , [ ] , [ ] , [ ]

665 for 
_
 in 
range
 ( 
self
 . 
batch_size
 ) :

667 if 
self
 . 
is_testset
 and 
self
 . 
alreay_extract_data
 == 
self
 . 
dataset_size
 :

670 
buff
 = 
self
 . 
dataset_queue
 . 
get
 ( )

671 
label
 . 
append
 ( 
buff
 [ 0 ] )

672 
rgb
 . 
append
 ( 
buff
 [ 1 ] )

673 
raw_lidar
 . 
append
 ( 
buff
 [ 2 ] )

674 
top_view
 . 
append
 ( 
buff
 [ 3 ] )

675 
front_view
 . 
append
 ( 
buff
 [ 4 ] )

676 
tag
 . 
append
 ( 
buff
 [ 5 ] )

678 
self
 . 
alreay_extract_data
 += 1

679 if 
self
 . 
is_testset
 :

680 
ret
 = (

681 
np
 . 
array
 ( 
tag
 ) ,

682 
np
 . 
array
 ( 
rgb
 ) ,

683 
np
 . 
array
 ( 
raw_lidar
 ) ,

684 
np
 . 
array
 ( 
top_view
 ) ,

685 
np
 . 
array
 ( 
front_view
 )

688 
ret
 = (

689 
np
 . 
array
 ( 
tag
 ) ,

690 
np
 . 
array
 ( 
label
 ) ,

691 
np
 . 
array
 ( 
rgb
 ) ,

692 
np
 . 
array
 ( 
raw_lidar
 ) ,

693 
np
 . 
array
 ( 
top_view
 ) ,

694 
np
 . 
array
 ( 
front_view
 )

697 
print
 ( "Dataset empty!" )

698 
ret
 = None

699 return 
ret
 
	}

701 def 
	$load_specified
 ( 
self
 , 
index
 = 0 ) :

702 
rgb
 = 
self
 . 
preprocess
 . 
rgb
 ( 
cv2
 . 
imread
 ( 
self
 . 
f_rgb
 [ 
index
 ] ) )

703 
raw_lidar
 = 
np
 . 
fromfile
 ( 
self
 . 
f_lidar
 [ 
index
 ] , 
dtype
 = 
np
 . 
float32
 ) . 
reshape
 ( ( - 1 , 4 ) )

704 if 
self
 . 
use_precal_view
 :

705 
top_view
 = 
np
 . 
load
 ( 
self
 . 
f_top
 [ 
index
 ] )

706 
front_view
 = 
np
 . 
load
 ( 
self
 . 
f_front
 [ 
index
 ] )

708 
top_view
 = 
self
 . 
preprocess
 . 
lidar_to_top
 ( 
raw_lidar
 )

710 
front_view
 = 
self
 . 
preprocess
 . 
lidar_to_front_fast
 ( 
raw_lidar
 )

712 
labels
 = [ 
line
 for 
line
 in 
open
 ( 
self
 . 
f_label
 [ 
index
 ] , 'r' ) . 
readlines
 ( ) ]

713 
tag
 = 
self
 . 
data_tag
 [ 
index
 ]

715 if 
self
 . 
is_testset
 :

716 
ret
 = (

717 
np
 . 
array
 ( [ 
tag
 ] ) ,

718 
np
 . 
array
 ( [ 
rgb
 ] ) ,

719 
np
 . 
array
 ( [ 
raw_lidar
 ] ) ,

720 
np
 . 
array
 ( [ 
top_view
 ] ) ,

721 
np
 . 
array
 ( [ 
front_view
 ] )

724 
ret
 = (

725 
np
 . 
array
 ( [ 
tag
 ] ) ,

726 
np
 . 
array
 ( [ 
labels
 ] ) ,

727 
np
 . 
array
 ( [ 
rgb
 ] ) ,

728 
np
 . 
array
 ( [ 
raw_lidar
 ] ) ,

729 
np
 . 
array
 ( [ 
top_view
 ] ) ,

730 
np
 . 
array
 ( [ 
front_view
 ] )

732 return 
ret
 
	}

735 def 
	$loader_worker_main
 ( 
self
 ) :

736 while not 
self
 . 
work_exit
 :

737 if 
self
 . 
dataset_queue
 . 
qsize
 ( ) >= 
self
 . 
queue_size
 // 2 :

738 
time
 . 
sleep
 ( 1 )

740 
self
 . 
fill_queue
 ( 1 ) 
	}

744 def 
	$get_shape
 ( 
self
 ) :

745 return 
self
 . 
top_shape
 , 
self
 . 
front_shape
 , 
self
 . 
rgb_shape
 
	}

747 def 
	$shuffle_dataset
 ( 
self
 ) :

748 
index
 = 
shuffle
 ( [ 
i
 for 
i
 in 
range
 ( 
len
 ( 
self
 . 
f_rgb
 ) ) ] )

749 
self
 . 
f_label
 = [ 
self
 . 
f_label
 [ 
i
 ] for 
i
 in 
index
 ]

750 
self
 . 
f_rgb
 = [ 
self
 . 
f_rgb
 [ 
i
 ] for 
i
 in 
index
 ]

751 
self
 . 
f_lidar
 = [ 
self
 . 
f_lidar
 [ 
i
 ] for 
i
 in 
index
 ] 
	}

755 class 
	cLoading3DOP
 ( 
object
 ) :

757 def 
	$__init__
 ( 
self
 , 
object_dir
 = '.' , 
proposals_dir
 = '.' , 
queue_size
 = 20 , 
require_shuffle
 = False , 
is_testset
 = True ) :

758 
self
 . 
object_dir
 , 
self
 . 
proposals_dir
 = 
object_dir
 , 
proposals_dir

759 
self
 . 
is_testset
 , 
self
 . 
require_shuffle
 = 
is_testset
 , 
require_shuffle

761 
self
 . 
f_proposal
 = 
glob
 . 
glob
 ( 
os
 . 
path
 . 
join
 ( 
self
 . 
proposals_dir
 , 'best/*_best.npy' if 
cfg
 . 
LOAD_BEST_PROPOSALS
 else 'all/*_all.npy' ) )

762 
self
 . 
f_proposal
 . 
sort
 ( )

763 
self
 . 
f_rgb
 = 
glob
 . 
glob
 ( 
os
 . 
path
 . 
join
 ( 
self
 . 
object_dir
 , 'training' , 'image_2' , '*.png' ) )

764 
self
 . 
f_rgb
 . 
sort
 ( )

765 
self
 . 
f_lidar
 = 
glob
 . 
glob
 ( 
os
 . 
path
 . 
join
 ( 
self
 . 
object_dir
 , 'training' , 'velodyne' , '*.bin' ) )

766 
self
 . 
f_lidar
 . 
sort
 ( )

767 assert ( 
len
 ( 
self
 . 
f_proposal
 ) == 
len
 ( 
self
 . 
f_rgb
 ) == 
len
 ( 
self
 . 
f_lidar
 ) )

768 
print
 ( 
len
 ( 
self
 . 
f_proposal
 ) )

769 if 
self
 . 
require_shuffle
 :

770 
index
 = 
shuffle
 ( [ 
i
 for 
i
 in 
range
 ( 
len
 ( 
self
 . 
f_proposal
 ) ) ] )

771 
self
 . 
f_proposal
 = [ 
self
 . 
f_proposal
 [ 
i
 ] for 
i
 in 
index
 ]

772 
self
 . 
f_rgb
 = [ 
self
 . 
f_rgb
 [ 
i
 ] for 
i
 in 
index
 ]

773 
self
 . 
f_lidar
 = [ 
self
 . 
f_lidar
 [ 
i
 ] for 
i
 in 
index
 ]

775 
self
 . 
queue_size
 = 
queue_size

776 
self
 . 
require_shuffle
 = 
require_shuffle

777 
self
 . 
preprocess
 = 
data
 . 
Preprocess
 ( )

779 
self
 . 
rgb_queue
 , 
self
 . 
front_view_queue
 , 
self
 . 
top_view_queue
 = 
Queue
 ( ) , 
Queue
 ( ) , 
Queue
 ( )

780 
self
 . 
proposals_queue
 , 
self
 . 
proposal_scores_queue
 = 
Queue
 ( ) , 
Queue
 ( )

782 if not 
self
 . 
is_testset
 :

783 
self
 . 
f_label
 = 
glob
 . 
glob
 ( 
os
 . 
path
 . 
join
 ( 
self
 . 
object_dir
 , 'training' , 'label_2' , '*.txt' ) ) . 
sort
 ( )

784 
self
 . 
label_queue
 = 
Queue
 ( )

786 
self
 . 
load_index
 = 0

787 
self
 . 
fill_queue
 ( 
self
 . 
queue_size
 )

791 
self
 . 
top_shape
 = 
self
 . 
top_view_queue
 . 
queue
 [ 0 ] . 
shape

792 
self
 . 
front_shape
 = 
self
 . 
front_view_queue
 . 
queue
 [ 0 ] . 
shape

793 
self
 . 
rgb_shape
 = 
self
 . 
rgb_queue
 . 
queue
 [ 0 ] . 
shape

796 
self
 . 
top_shape
 = ( 100 , 100 )

797 
self
 . 
front_shape
 = ( 100 , 100 )

798 
self
 . 
rgb_shape
 = ( 100 , 100 ) 
	}

800 def 
	$__enter__
 ( 
self
 ) :

801 return 
self
 
	}

803 def 
	$__exit__
 ( 
self
 , 
exc_type
 , 
exc_val
 , 
exc_tb
 ) :

804 pass 
	}

806 def 
	$fill_queue
 ( 
self
 , 
load_amount
 = 0 ) :

807 def 
to_label
 ( 
raw_labels
 ) :

810 
ret
 = [ ]

811 for 
line
 in 
raw_labels
 :

812 
data
 = 
line
 . 
split
 ( )

813 
obj_class
 = 
data
 [ 0 ]

815 
h
 , 
w
 , 
l
 , 
x
 , 
y
 , 
z
 , 
ry
 = [ 
float
 ( 
i
 ) for 
i
 in 
data
 [ 8 : 15 ] ]

818 
h
 , 
w
 , 
l
 , 
x
 , 
y
 , 
z
 , 
rz
 = 
h
 , 
w
 , 
l
 , 
box
 . 
camera_to_lidar_coords
 ( 
x
 , 
y
 , 
z
 ) , - 
ry
 - 
math
 . 
pi
 / 2

819 
ret
 . 
append
 ( ( 
obj_class
 , 
box3d_compose
 ( ( 
x
 , 
y
 , 
z
 ) , ( 
h
 , 
w
 , 
l
 ) , ( 0 , 0 , 
rz
 ) ) ) )

820 return 
ret

823 for 
i
 in 
range
 ( 
load_amount
 ) :

826 
proposals
 = 
np
 . 
load
 ( 
self
 . 
f_proposal
 [ 
self
 . 
load_index
 ] )

827 while 
len
 ( 
proposals
 ) == 0 :

828 
self
 . 
load_index
 += 1

829 
proposals
 = 
np
 . 
load
 ( 
self
 . 
f_proposal
 [ 
self
 . 
load_index
 ] )

831 
self
 . 
proposals_queue
 . 
put
 ( 
proposals
 [ : , 0 : 7 ] )

832 
self
 . 
proposal_scores_queue
 . 
put
 ( 
proposals
 [ : , 7 ] )

834 
self
 . 
rgb_queue
 . 
put
 ( 
self
 . 
preprocess
 . 
rgb
 ( 
cv2
 . 
imread
 ( 
self
 . 
f_rgb
 [ 
self
 . 
load_index
 ] ) ) )

837 
raw_lidar
 = 
np
 . 
fromfile
 ( 
self
 . 
f_lidar
 [ 
self
 . 
load_index
 ] , 
dtype
 = 
np
 . 
float32
 ) . 
reshape
 ( ( - 1 , 4 ) )

838 
self
 . 
top_view_queue
 . 
put
 ( 
self
 . 
preprocess
 . 
lidar_to_top
 ( 
raw_lidar
 ) )

839 
self
 . 
front_view_queue
 . 
put
 ( 
self
 . 
preprocess
 . 
lidar_to_front_fast
 ( 
raw_lidar
 ) )

841 if not 
self
 . 
is_testset
 :

842 
labels
 = [ 
line
 for 
line
 in 
open
 ( 
self
 . 
f_label
 [ 
self
 . 
load_index
 ] , 'r' ) . 
readlines
 ( ) ]

843 
self
 . 
label_queue
 . 
put
 ( 
to_label
 ( 
labels
 ) )

845 
self
 . 
load_index
 += 1

847 pass 
	}

849 def 
	$load
 ( 
self
 , 
batch_size
 = 1 ) :

851 if 
batch_size
 == 1 :

852 
ret
 = ( 
self
 . 
proposals_queue
 . 
get_nowait
 ( ) , 
self
 . 
proposal_scores_queue
 . 
get_nowait
 ( ) ,

853 
self
 . 
top_view_queue
 . 
get_nowait
 ( ) , 
self
 . 
front_view_queue
 . 
get_nowait
 ( ) ,

854 
self
 . 
rgb_queue
 . 
get_nowait
 ( ) )

856 
ret
 = ( 
np
 . 
array
 ( [ 
self
 . 
proposals_queue
 . 
get_nowait
 ( ) for 
i
 in 
range
 ( 
batch_size
 ) ] ) ,

857 
np
 . 
array
 ( [ 
self
 . 
proposal_scores_queue
 . 
get_nowait
 ( ) for 
i
 in 
range
 ( 
batch_size
 ) ] ) ,

858 
np
 . 
array
 ( [ 
self
 . 
top_view_queue
 . 
get_nowait
 ( ) for 
i
 in 
range
 ( 
batch_size
 ) ] ) ,

859 
np
 . 
array
 ( [ 
self
 . 
front_view_queue
 . 
get_nowait
 ( ) for 
i
 in 
range
 ( 
batch_size
 ) ] ) ,

860 
np
 . 
array
 ( [ 
self
 . 
rgb_queue
 . 
get_nowait
 ( ) for 
i
 in 
range
 ( 
batch_size
 ) ] ) )

861 
self
 . 
fill_queue
 ( 
batch_size
 )

863 
ret
 = None

864 return 
ret
 
	}

866 def 
	$get_shape
 ( 
self
 ) :

867 return 
self
 . 
top_shape
 , 
self
 . 
front_shape
 , 
self
 . 
rgb_shape
 
	}

870 class 
	cBatchLoading3
 :

872 def 
	$__init__
 ( 
self
 , 
bags
 = { } , 
tags
 = { } , 
queue_size
 = 20 , 
require_shuffle
 = False ,

873 
require_log
 = False , 
is_testset
 = False , 
batch_size
 = 1 , 
use_precal_view
 = False , 
use_multi_process_num
 = 
cpu_count
 ( ) ) :

874 
self
 . 
is_testset
 = 
is_testset

875 
self
 . 
use_precal_view
 = 
use_precal_view

876 
self
 . 
shuffled
 = 
require_shuffle

877 
self
 . 
preprocess
 = 
data
 . 
Preprocess
 ( )

878 
self
 . 
raw_img
 = 
Image
 ( 
tags
 )

879 
self
 . 
raw_tracklet
 = 
Tracklet
 ( 
tags
 )

880 
self
 . 
raw_lidar
 = 
Lidar
 ( 
tags
 )

881 
self
 . 
tags
 = 
self
 . 
raw_lidar
 . 
get_tags
 ( )

882 
self
 . 
batch_size
 = 
batch_size

883 
self
 . 
use_multi_process_num
 = 
use_multi_process_num

884 
print
 ( 
len
 ( 
self
 . 
raw_img
 . 
get_tags
 ( ) ) , 
len
 ( 
self
 . 
raw_lidar
 . 
get_tags
 ( ) ) , 
len
 ( 
self
 . 
raw_tracklet
 . 
get_tags
 ( ) ) )

885 assert ( 
len
 ( 
self
 . 
raw_img
 . 
get_tags
 ( ) ) ==

886 
len
 ( 
self
 . 
raw_lidar
 . 
get_tags
 ( ) ) ==

887 
len
 ( 
self
 . 
raw_tracklet
 . 
get_tags
 ( ) ) )

889 
self
 . 
bags
 = 
bags

893 if 
self
 . 
shuffled
 :

894 
self
 . 
tags
 = 
shuffle
 ( 
self
 . 
tags
 )

896 
self
 . 
tag_index
 = 0

897 
self
 . 
size
 = 
len
 ( 
self
 . 
tags
 )

899 
self
 . 
require_log
 = 
require_log

901 
self
 . 
cache_size
 = 
queue_size

902 
self
 . 
loader_need_exit
 = 
Value
 ( 'i' , 0 )

904 
self
 . 
prepr_data
 = 
Queue
 ( )

905 if 
self
 . 
use_multi_process_num
 > 0 :

906 
self
 . 
loader_processing
 = [ 
Process
 ( 
target
 = 
self
 . 
loader
 ) for 
i
 in 
range
 ( 
self
 . 
use_multi_process_num
 ) ]

908 
self
 . 
loader_processing
 = [ 
threading
 . 
Thread
 ( 
target
 = 
self
 . 
loader
 ) ]

913 [ 
i
 . 
start
 ( ) for 
i
 in 
self
 . 
loader_processing
 ] 
	}

916 def 
	$__enter__
 ( 
self
 ) :

917 return 
self
 
	}

919 def 
	$__exit__
 ( 
self
 , 
exc_type
 , 
exc_val
 , 
exc_tb
 ) :

920 
self
 . 
loader_need_exit
 . 
value
 = True

921 if 
self
 . 
require_log
 : 
print
 ( 'set loader_need_exit True' )

922 [ 
i
 . 
join
 ( ) for 
i
 in 
self
 . 
loader_processing
 ]

923 if 
self
 . 
require_log
 : 
print
 ( 'exit loader_processing' ) 
	}

925 def 
	$keep_gt_inside_range
 ( 
self
 , 
train_gt_labels
 , 
train_gt_boxes3d
 ) :

926 
train_gt_labels
 = 
np
 . 
array
 ( 
train_gt_labels
 , 
dtype
 = 
np
 . 
int32
 )

927 
train_gt_boxes3d
 = 
np
 . 
array
 ( 
train_gt_boxes3d
 , 
dtype
 = 
np
 . 
float32
 )

928 if 
train_gt_labels
 . 
shape
 [ 0 ] == 0 :

930 assert 
train_gt_labels
 . 
shape
 [ 0 ] == 
train_gt_boxes3d
 . 
shape
 [ 0 ]

933 
keep
 = 
np
 . 
zeros
 ( ( 
len
 ( 
train_gt_labels
 ) ) , 
dtype
 = 
bool
 )

935 for 
i
 in 
range
 ( 
len
 ( 
train_gt_labels
 ) ) :

936 if 
box
 . 
box3d_in_top_view
 ( 
train_gt_boxes3d
 [ 
i
 ] ) :

937 
keep
 [ 
i
 ] = 1

940 if 
np
 . 
sum
 ( 
keep
 ) == 0 :

943 
train_gt_labels
 = 
train_gt_labels
 [ 
keep
 ]

944 
train_gt_boxes3d
 = 
train_gt_boxes3d
 [ 
keep
 ]

945 return True , 
train_gt_labels
 , 
train_gt_boxes3d
 
	}

947 def 
	$load_from_one_tag
 ( 
self
 , 
one_frame_tag
 ) :

948 if 
self
 . 
is_testset
 :

949 
obstacles
 = None

951 
obstacles
 = 
self
 . 
raw_tracklet
 . 
load
 ( 
one_frame_tag
 )

952 
rgb
 = 
self
 . 
raw_img
 . 
load
 ( 
one_frame_tag
 )

953 
lidar
 = 
self
 . 
raw_lidar
 . 
load
 ( 
one_frame_tag
 )

954 return 
obstacles
 , 
rgb
 , 
lidar
 
	}

957 def 
	$preprocess_one_frame
 ( 
self
 , 
rgb
 , 
lidar
 , 
obstacles
 , 
tag
 ) :

958 
rgb
 = 
self
 . 
preprocess
 . 
rgb
 ( 
rgb
 )

959 if 
self
 . 
use_precal_view
 :

960 
top
 = 
np
 . 
load
 ( 
os
 . 
path
 . 
join
 ( 
cfg
 . 
RAW_DATA_SETS_DIR
 , 'top_view' , 
tag
 + '.npy' ) )

961 
front
 = 
np
 . 
load
 ( 
os
 . 
path
 . 
join
 ( 
cfg
 . 
RAW_DATA_SETS_DIR
 , 'front_view' , 
tag
 + '.npy' ) )

963 
top
 = 
self
 . 
preprocess
 . 
lidar_to_top
 ( 
lidar
 )

964 
front
 = 
self
 . 
preprocess
 . 
lidar_to_front_fast
 ( 
lidar
 )

965 if 
self
 . 
is_testset
 :

966 return 
rgb
 , 
top
 , None , None

967 
boxes3d
 = [ 
self
 . 
preprocess
 . 
bbox3d
 ( 
obs
 ) for 
obs
 in 
obstacles
 ]

968 
labels
 = [ 
self
 . 
preprocess
 . 
label
 ( 
obs
 ) for 
obs
 in 
obstacles
 ]

969 return 
rgb
 , 
top
 , 
boxes3d
 , 
labels
 , 
front
 
	}

971 def 
	$get_shape
 ( 
self
 ) :

972 
train_rgbs
 , 
train_tops
 , 
train_fronts
 , 
train_gt_labels
 , 
train_gt_boxes3d
 , 
_
 = 
self
 . 
load
 ( )

973 
top_shape
 = 
train_tops
 [ 0 ] . 
shape

974 
front_shape
 = 
train_fronts
 [ 0 ] . 
shape

975 
rgb_shape
 = 
train_rgbs
 [ 0 ] . 
shape

977 return 
top_shape
 , 
front_shape
 , 
rgb_shape
 
	}

979 def 
	$data_preprocessed
 ( 
self
 ) :

981 
skip_frames
 = True

982 
batch_rgb
 , 
batch_top
 , 
batch_fronts
 , 
batch_labels
 , 
batch_boxes3d
 , 
batch_frame_tag
 = [ ] , [ ] , [ ] , [ ] , [ ] , [ ]

983 for 
_
 in 
range
 ( 
self
 . 
batch_size
 ) :

984 while 
skip_frames
 :

986 
frame_tag
 = 
self
 . 
tags
 [ 
self
 . 
tag_index
 ]

987 
obstacles
 , 
rgb
 , 
lidar
 = 
self
 . 
load_from_one_tag
 ( 
frame_tag
 )

988 
rgb
 , 
top
 , 
boxes3d
 , 
labels
 , 
fronts
 = 
self
 . 
preprocess_one_frame
 ( 
rgb
 , 
lidar
 , 
obstacles
 , 
frame_tag
 )

989 if 
self
 . 
require_log
 and not 
self
 . 
is_testset
 :

990 
draw_bbox_on_rgb
 ( 
rgb
 , 
boxes3d
 , 
frame_tag
 )

991 
draw_bbox_on_lidar_top
 ( 
top
 , 
boxes3d
 , 
frame_tag
 )

993 
self
 . 
tag_index
 += 1

997 if 
self
 . 
tag_index
 >= 
self
 . 
size
 :

998 
self
 . 
tag_index
 = 0

999 if 
self
 . 
shuffled
 :

1000 
self
 . 
tags
 = 
shuffle
 ( 
self
 . 
tags
 )

1001 
skip_frames
 = False

1004 if not 
self
 . 
is_testset
 :

1005 
is_gt_inside_range
 , 
batch_gt_labels_in_range
 , 
batch_gt_boxes3d_in_range
 =

1006 
self
 . 
keep_gt_inside_range
 ( 
labels
 , 
boxes3d
 )

1007 
labels
 = 
batch_gt_labels_in_range

1008 
boxes3d
 = 
batch_gt_boxes3d_in_range

1010 if not 
is_gt_inside_range
 :

1011 
skip_frames
 = True

1012 
batch_rgb
 . 
append
 ( 
rgb
 )

1013 
batch_top
 . 
append
 ( 
top
 )

1014 
batch_fronts
 . 
append
 ( 
fronts
 )

1015 
batch_labels
 . 
append
 ( 
labels
 )

1016 
batch_boxes3d
 . 
append
 ( 
boxes3d
 )

1017 
batch_frame_tag
 . 
append
 ( 
frame_tag
 )

1021 return 
np
 . 
array
 ( 
batch_rgb
 ) , 
np
 . 
array
 ( 
batch_top
 ) , 
np
 . 
array
 ( 
batch_fronts
 ) , 
np
 . 
array
 ( 
batch_labels
 ) , 
np
 . 
array
 ( 
batch_boxes3d
 ) , 
np
 . 
array
 ( 
batch_frame_tag
 ) 
	}

1023 def 
	$find_empty_block
 ( 
self
 ) :

1024 
idx
 = - 1

1025 for 
i
 in 
range
 ( 
self
 . 
cache_size
 ) :

1026 if 
self
 . 
blocks_usage
 [ 
i
 ] == 1 :

1029 
idx
 = 
i

1031 return 
idx
 
	}

1034 def 
	$loader
 ( 
self
 ) :

1036 while 
self
 . 
loader_need_exit
 . 
value
 == 0 :

1039 if 
self
 . 
prepr_data
 . 
qsize
 ( ) >= 
self
 . 
cache_size
 :

1040 
time
 . 
sleep
 ( 1 )

1044 
self
 . 
prepr_data
 . 
put
 ( ( 
self
 . 
data_preprocessed
 ( ) ) )

1047 while 
self
 . 
loader_need_exit
 . 
value
 == 0 :

1048 
empty_idx
 = 
self
 . 
find_empty_block
 ( )

1049 if 
empty_idx
 == - 1 :

1050 
time
 . 
sleep
 ( 1 )

1053 
prepr_data
 = ( 
self
 . 
data_preprocessed
 ( ) )

1055 
dumps
 = 
pickle
 . 
dumps
 ( 
prepr_data
 )

1056 
length
 = 
len
 ( 
dumps
 )

1057 
self
 . 
buffer_blocks
 [ 
empty_idx
 ] [ 0 : 
length
 ] = 
dumps
 [ 0 : 
length
 ]

1059 
self
 . 
preproc_data_queue
 . 
put
 ( { 'index'

1060 : 
empty_idx
 , 'length'

1061 : 
length

1065 if 
self
 . 
require_log
 : 
print
 ( 'loader exit' ) 
	}

1069 def 
	$load
 ( 
self
 ) :

1072 while 
self
 . 
prepr_data
 . 
qsize
 ( ) == 0 :

1073 
time
 . 
sleep
 ( 1 )

1075 
data_ori
 = 
self
 . 
prepr_data
 . 
get
 ( )

1080 
info
 = 
self
 . 
preproc_data_queue
 . 
get
 ( 
block
 = True )

1081 
length
 = 
info
 [ 'length' ]

1082 
block_index
 = 
info
 [ 'index' ]

1083 
dumps
 = 
self
 . 
buffer_blocks
 [ 
block_index
 ] [ 0 : 
length
 ]

1086 
self
 . 
blocks_usage
 [ 
block_index
 ] = 0

1089 
dumps
 = 
array
 . 
array
 ( 'B' , 
dumps
 ) . 
tostring
 ( )

1090 
data_ori
 = 
pickle
 . 
loads
 ( 
dumps
 )

1092 return 
data_ori
 
	}

1096 def 
	$get_frame_info
 ( 
self
 ) :

1097 return 
self
 . 
tags
 [ 
self
 . 
tag_index
 ] 
	}

1100 if 
__name__
 == '__main__' :

1103 
dataset_dir
 = 
cfg
 . 
PREPROCESSED_DATA_SETS_DIR

1105 
dates_to_drivers
 = { '1' : [ '11' ] }

1121 
train_key_list
 = [ 'nissan_pulling_away' , 'nissan_pulling_up_to_it'

1143 
train_key_full_path_list
 = [ 
os
 . 
path
 . 
join
 ( 
cfg
 . 
RAW_DATA_SETS_DIR
 , 
key
 ) for 
key
 in 
train_key_list
 ]

1144 
train_value_list
 = [ 
os
 . 
listdir
 ( 
value
 ) [ 0 ] for 
value
 in 
train_key_full_path_list
 ]

1146 
train_n_val_dataset
 = [ 
k
 + '/' + 
v
 for 
k
 , 
v
 in 
zip
 ( 
train_key_list
 , 
train_value_list
 ) ]

1148 
splitter
 = 
TrainingValDataSplitter
 ( 
train_n_val_dataset
 )

1152 with 
BatchLoading2
 ( 
splitter
 . 
training_bags
 , 
splitter
 . 
training_tags
 ) as 
bl
 :

1153 
time
 . 
sleep
 ( 5 )

1154 for 
i
 in 
range
 ( 5 ) :

1155 
t0
 = 
time
 . 
time
 ( )

1156 
data
 = 
bl
 . 
load
 ( )

1157 
print
 ( 'use time =' , 
time
 . 
time
 ( ) - 
t0
 )

1158 
print
 ( 
data
 )

1159 
time
 . 
sleep
 ( 3 )

1161 
print
 ( 'Done' )


	@./utils/batch_loading_for_data_py_output.py

1 import 
	~cv2

2 import 
	~numpy
 as 
np

3 from 
	~config
 import 
cfg

4 import 
	~os

5 import 
	~glob

6 from 
	~sklearn.utils
 import 
shuffle

7 from 
	~utils.check_data
 import 
check_preprocessed_data
 , 
get_file_names

8 import 
	~net.processing.boxes3d
 as 
box

15 def 
	$load
 ( 
file_names
 , 
is_testset
 = False ) :

18 
first_item
 = 
file_names
 [ 0 ] . 
split
 ( '/' )

19 
prefix
 = '/' . 
join
 ( 
first_item
 [ : - 4 ] )

21 
frame_num_list
 = [ '/' . 
join
 ( 
name
 . 
split
 ( '/' ) [ - 3 : ] ) for 
name
 in 
file_names
 ]

24 
train_rgbs
 = [ 
cv2
 . 
imread
 ( 
os
 . 
path
 . 
join
 ( 
prefix
 , 'rgb' , 
file
 + '.png' ) , 1 ) for 
file
 in 
frame_num_list
 ]

25 
train_tops
 = [ 
np
 . 
load
 ( 
os
 . 
path
 . 
join
 ( 
prefix
 , 'top' , 
file
 + '.npy.npz' ) ) [ 'top_view' ] for 
file
 in 
frame_num_list
 ]

26 
train_fronts
 = [ 
np
 . 
zeros
 ( ( 1 , 1 ) , 
dtype
 = 
np
 . 
float32
 ) for 
file
 in 
frame_num_list
 ]

28 if 
is_testset
 == True :

29 
train_gt_boxes3d
 = None

30 
train_gt_labels
 = None

32 
train_gt_boxes3d
 = [ 
np
 . 
load
 ( 
os
 . 
path
 . 
join
 ( 
prefix
 , 'gt_boxes3d' , 
file
 + '.npy' ) ) for 
file
 in 
frame_num_list
 ]

34 
train_gt_labels
 = [ 
np
 . 
load
 ( 
os
 . 
path
 . 
join
 ( 
prefix
 , 'gt_labels' , 
file
 + '.npy' ) ) for 
file
 in

35 
frame_num_list
 ]

37 return 
train_rgbs
 , 
train_tops
 , 
train_fronts
 , 
train_gt_labels
 , 
train_gt_boxes3d
 
	}

40 class 
	cbatch_loading
 :

41 def 
	$__init__
 ( 
self
 , 
dir_path
 , 
dates_to_drivers
 = None , 
indice
 = None , 
cache_num
 = 10 , 
is_testset
 = False ) :

42 
self
 . 
dates_to_drivers
 = 
dates_to_drivers

43 
self
 . 
indice
 = 
indice

44 
self
 . 
cache_num
 = 
cache_num

45 
self
 . 
preprocess_path
 = 
dir_path

46 
self
 . 
is_testset
 = 
is_testset

48 if 
indice
 is None :

49 
self
 . 
load_file_names
 = 
self
 . 
get_all_load_index
 ( 
self
 . 
preprocess_path
 , 
self
 . 
dates_to_drivers
 , 
is_testset
 )

52 
self
 . 
load_file_names
 = 
self
 . 
get_specific_load_index
 ( 
indice
 , 
self
 . 
preprocess_path
 , 
self
 . 
dates_to_drivers
 ,

53 
is_testset
 )

54 
self
 . 
load_once
 = True

55 
self
 . 
size
 = 
len
 ( 
self
 . 
load_file_names
 )

59 
self
 . 
batch_start_index
 = 0

62 
self
 . 
num_frame_used
 = 
cache_num

65 
self
 . 
train_rgbs
 = [ ]

66 
self
 . 
train_tops
 = [ ]

67 
self
 . 
train_fronts
 = [ ]

68 
self
 . 
train_gt_labels
 = [ ]

69 
self
 . 
train_gt_boxes3d
 = [ ]

70 
self
 . 
current_batch_file_names
 = [ ] 
	}

73 def 
	$get_shape
 ( 
self
 ) :

76 
train_rgbs
 , 
train_tops
 , 
train_fronts
 , 
train_gt_labels
 , 
train_gt_boxes3d
 = 
load
 ( [ 
self
 . 
load_file_names
 [ 0 ] ] ,

77 
is_testset
 = 
self
 . 
is_testset
 )

79 
top_shape
 = 
train_tops
 [ 0 ] . 
shape

80 
front_shape
 = 
train_fronts
 [ 0 ] . 
shape

81 
rgb_shape
 = 
train_rgbs
 [ 0 ] . 
shape

83 return 
top_shape
 , 
front_shape
 , 
rgb_shape
 
	}

85 def 
	$get_all_load_index
 ( 
self
 , 
data_seg
 , 
dates_to_drivers
 , 
gt_included
 ) :

87 
check_preprocessed_data
 ( 
data_seg
 , 
dates_to_drivers
 , 
gt_included
 )

88 
top_dir
 = 
os
 . 
path
 . 
join
 ( 
data_seg
 , "top" )

90 
load_indexs
 = [ ]

91 for 
date
 , 
drivers
 in 
dates_to_drivers
 . 
items
 ( ) :

92 for 
driver
 in 
drivers
 :

94 
file_prefix
 = 
os
 . 
path
 . 
join
 ( 
data_seg
 , "top" , 
date
 , 
driver
 )

95 
driver_files
 = 
get_file_names
 ( 
data_seg
 , "top" , 
driver
 , 
date
 )

96 if 
len
 ( 
driver_files
 ) == 0 :

97 raise 
ValueError
 ( 'Directory has no data starts from {}, please revise.' . 
format
 ( 
file_prefix
 ) )

99 
name_list
 = [ 
file
 . 
split
 ( '/' ) [ - 1 ] . 
split
 ( '.' ) [ 0 ] for 
file
 in 
driver_files
 ]

100 
name_list
 = [ 
file
 . 
split
 ( '.' ) [ 0 ] for 
file
 in 
driver_files
 ]

101 
load_indexs
 += 
name_list

102 
load_indexs
 = 
sorted
 ( 
load_indexs
 )

103 return 
load_indexs
 
	}

105 def 
	$get_specific_load_index
 ( 
self
 , 
index
 , 
data_seg
 , 
dates_to_drivers
 , 
gt_included
 ) :

107 
check_preprocessed_data
 ( 
data_seg
 , 
dates_to_drivers
 , 
gt_included
 )

108 
top_dir
 = 
os
 . 
path
 . 
join
 ( 
data_seg
 , "top" )

110 
load_indexs
 = [ ]

111 for 
date
 , 
drivers
 in 
dates_to_drivers
 . 
items
 ( ) :

112 for 
driver
 in 
drivers
 :

114 
file_prefix
 = 
os
 . 
path
 . 
join
 ( 
data_seg
 , "top" , 
driver
 , 
date
 )

115 
driver_files
 = 
get_file_names
 ( 
data_seg
 , "top" , 
driver
 , 
date
 , 
index
 )

116 if 
len
 ( 
driver_files
 ) == 0 :

117 raise 
ValueError
 ( 'Directory has no data starts from {}, please revise.' . 
format
 ( 
file_prefix
 ) )

119 
name_list
 = [ 
file
 . 
split
 ( '/' ) [ - 1 ] . 
split
 ( '.' ) [ 0 ] for 
file
 in 
driver_files
 ]

120 
name_list
 = [ 
file
 . 
split
 ( '.' ) [ 0 ] for 
file
 in 
driver_files
 ]

121 
load_indexs
 += 
name_list

122 
load_indexs
 = 
sorted
 ( 
load_indexs
 )

123 return 
load_indexs
 
	}

125 def 
	$load_test_frames
 ( 
self
 , 
size
 , 
shuffled
 ) :

127 if 
self
 . 
load_once
 :

128 if 
shuffled
 :

129 
self
 . 
load_file_names
 = 
shuffle
 ( 
self
 . 
load_file_names
 )

130 
self
 . 
train_rgbs
 , 
self
 . 
train_tops
 , 
self
 . 
train_fronts
 , 
self
 . 
train_gt_labels
 , 
self
 . 
train_gt_boxes3d
 =

131 
load
 ( 
self
 . 
load_file_names
 )

132 
self
 . 
num_frame_used
 = 0

133 
self
 . 
load_once
 = False

135 
self
 . 
current_batch_file_names
 = 
self
 . 
load_file_names

136 
frame_end
 = 
min
 ( 
self
 . 
num_frame_used
 + 
size
 , 
self
 . 
cache_num
 )

137 
train_rgbs
 = 
self
 . 
train_rgbs
 [ 
self
 . 
num_frame_used
 : 
frame_end
 ]

138 
train_tops
 = 
self
 . 
train_tops
 [ 
self
 . 
num_frame_used
 : 
frame_end
 ]

139 
train_fronts
 = 
self
 . 
train_fronts
 [ 
self
 . 
num_frame_used
 : 
frame_end
 ]

140 
train_gt_labels
 = 
self
 . 
train_gt_labels
 [ 
self
 . 
num_frame_used
 : 
frame_end
 ]

141 
train_gt_boxes3d
 = 
self
 . 
train_gt_boxes3d
 [ 
self
 . 
num_frame_used
 : 
frame_end
 ]

142 
handle_id
 = 
self
 . 
current_batch_file_names
 [ 
self
 . 
num_frame_used
 : 
frame_end
 ]

143 
handle_id
 = [ '/' . 
join
 ( 
name
 . 
split
 ( '/' ) [ - 3 : ] ) for 
name
 in 
handle_id
 ]

145 
self
 . 
num_frame_used
 = 
frame_end

146 if 
self
 . 
num_frame_used
 >= 
self
 . 
size
 :

147 
self
 . 
num_frame_used
 = 0

149 return 
train_rgbs
 , 
train_tops
 , 
train_fronts
 , 
train_gt_labels
 , 
train_gt_boxes3d
 , 
handle_id
 
	}

153 def 
	$load_batch
 ( 
self
 , 
size
 , 
shuffled
 ) :

154 if 
shuffled
 :

155 
self
 . 
load_file_names
 = 
shuffle
 ( 
self
 . 
load_file_names
 )

158 if 
self
 . 
num_frame_used
 >= 
self
 . 
cache_num
 :

159 
batch_end_index
 = 
self
 . 
batch_start_index
 + 
self
 . 
cache_num

161 if 
batch_end_index
 < 
self
 . 
size
 :

162 
loaded_file_names
 = 
self
 . 
load_file_names
 [ 
self
 . 
batch_start_index
 : 
batch_end_index
 ]

163 
self
 . 
batch_start_index
 = 
batch_end_index

167 
diff_to_end
 = 
self
 . 
size
 - 
self
 . 
batch_start_index

168 
start_offset
 = 
self
 . 
cache_num
 - 
diff_to_end

170 
file_names_to_end
 = 
self
 . 
load_file_names
 [ 
self
 . 
batch_start_index
 : 
self
 . 
size
 ]

171 if 
shuffled
 :

172 
self
 . 
load_file_names
 = 
shuffle
 ( 
self
 . 
load_file_names
 )

174 
file_names_from_start
 = 
self
 . 
load_file_names
 [ 0 : 
start_offset
 ]

176 
loaded_file_names
 = 
file_names_to_end
 + 
file_names_from_start

177 
self
 . 
batch_start_index
 = 
start_offset

181 
self
 . 
current_batch_file_names
 = 
loaded_file_names

182 
self
 . 
train_rgbs
 , 
self
 . 
train_tops
 , 
self
 . 
train_fronts
 , 
self
 . 
train_gt_labels
 , 
self
 . 
train_gt_boxes3d
 =

183 
load
 ( 
loaded_file_names
 , 
is_testset
 = 
self
 . 
is_testset
 )

184 
self
 . 
num_frame_used
 = 0

187 
frame_end
 = 
min
 ( 
self
 . 
num_frame_used
 + 
size
 , 
self
 . 
cache_num
 )

188 
train_rgbs
 = 
self
 . 
train_rgbs
 [ 
self
 . 
num_frame_used
 : 
frame_end
 ]

189 
train_tops
 = 
self
 . 
train_tops
 [ 
self
 . 
num_frame_used
 : 
frame_end
 ]

190 
train_fronts
 = 
self
 . 
train_fronts
 [ 
self
 . 
num_frame_used
 : 
frame_end
 ]

191 if 
self
 . 
is_testset
 :

192 
train_gt_labels
 = None

193 
train_gt_boxes3d
 = None

195 
train_gt_labels
 = 
self
 . 
train_gt_labels
 [ 
self
 . 
num_frame_used
 : 
frame_end
 ]

196 
train_gt_boxes3d
 = 
self
 . 
train_gt_boxes3d
 [ 
self
 . 
num_frame_used
 : 
frame_end
 ]

198 
handle_id
 = 
self
 . 
current_batch_file_names
 [ 
self
 . 
num_frame_used
 : 
frame_end
 ]

199 
handle_id
 = [ '/' . 
join
 ( 
name
 . 
split
 ( '/' ) [ - 3 : ] ) for 
name
 in 
handle_id
 ]

201 
self
 . 
num_frame_used
 = 
frame_end

203 return 
train_rgbs
 , 
train_tops
 , 
train_fronts
 , 
train_gt_labels
 , 
train_gt_boxes3d
 , 
handle_id
 
	}

205 def 
	$get_date_and_driver
 ( 
self
 , 
handle_id
 ) :

206 
date_n_driver
 = [ '/' . 
join
 ( 
item
 . 
split
 ( '/' ) [ 0 : 2 ] ) for 
item
 in 
handle_id
 ]

207 return 
date_n_driver
 
	}

209 def 
	$get_frame_info
 ( 
self
 , 
handle_id
 ) :

210 return 
handle_id
 
	}

212 def 
	$keep_gt_inside_range
 ( 
self
 , 
train_gt_labels
 , 
train_gt_boxes3d
 ) :

214 if 
train_gt_labels
 . 
shape
 [ 0 ] == 0 :

216 assert 
train_gt_labels
 . 
shape
 [ 0 ] == 
train_gt_boxes3d
 . 
shape
 [ 0 ]

219 
keep
 = 
np
 . 
zeros
 ( ( 
len
 ( 
train_gt_labels
 ) ) , 
dtype
 = 
bool
 )

221 for 
i
 in 
range
 ( 
len
 ( 
train_gt_labels
 ) ) :

222 if 
box
 . 
box3d_in_top_view
 ( 
train_gt_boxes3d
 [ 
i
 ] ) :

223 
keep
 [ 
i
 ] = 1

226 if 
np
 . 
sum
 ( 
keep
 ) == 0 :

229 
train_gt_labels
 = 
train_gt_labels
 [ 
keep
 ]

230 
train_gt_boxes3d
 = 
train_gt_boxes3d
 [ 
keep
 ]

231 return True , 
train_gt_labels
 , 
train_gt_boxes3d
 
	}

233 def 
	$load
 ( 
self
 , 
size
 , 
batch
 = True , 
shuffled
 = False ) :

234 
load_frames
 = True

235 while 
load_frames
 :

236 if 
batch
 :

237 
train_rgbs
 , 
train_tops
 , 
train_fronts
 , 
train_gt_labels
 , 
train_gt_boxes3d
 , 
frame_id
 = 
self
 . 
load_batch
 ( 
size
 ,

238 
shuffled
 )

240 
train_rgbs
 , 
train_tops
 , 
train_fronts
 , 
train_gt_labels
 , 
train_gt_boxes3d
 , 
frame_id
 =

241 
self
 . 
load_test_frames
 ( 
size
 , 
shuffled
 )

242 
load_frames
 = False

244 if not 
self
 . 
is_testset
 :

246 
is_gt_inside_range
 , 
batch_gt_labels_in_range
 , 
batch_gt_boxes3d_in_range
 =

247 
self
 . 
keep_gt_inside_range
 ( 
train_gt_labels
 [ 0 ] , 
train_gt_boxes3d
 [ 0 ] )

249 if not 
is_gt_inside_range
 :

250 
load_frames
 = True

255 
train_gt_labels
 = 
np
 . 
zeros
 ( ( 1 , 
batch_gt_labels_in_range
 . 
shape
 [ 0 ] ) , 
dtype
 = 
np
 . 
int32
 )

256 
train_gt_boxes3d
 = 
np
 . 
zeros
 ( ( 1 , 
batch_gt_labels_in_range
 . 
shape
 [ 0 ] , 8 , 3 ) , 
dtype
 = 
np
 . 
float32
 )

257 
train_gt_labels
 [ 0 ] = 
batch_gt_labels_in_range

258 
train_gt_boxes3d
 [ 0 ] = 
batch_gt_boxes3d_in_range

261 return 
np
 . 
array
 ( 
train_rgbs
 ) , 
np
 . 
array
 ( 
train_tops
 ) , 
np
 . 
array
 ( 
train_fronts
 ) , 
np
 . 
array
 ( 
train_gt_labels
 ) ,

262 
np
 . 
array
 ( 
train_gt_boxes3d
 ) , 
frame_id
 
	}

265 if 
__name__
 == '__main__' :

268 
dataset_dir
 = 
cfg
 . 
PREPROCESSED_DATA_SETS_DIR

270 
dates_to_drivers
 = { '1' : [ '11' ] }

281 
load_indexs
 = [ '00000' , '00001' , '00002' , '00003' ]

282 
batches
 = 
batch_loading
 ( 
dataset_dir
 , 
dates_to_drivers
 , 
load_indexs
 , 
is_testset
 = True )

284 for 
i
 in 
range
 ( 1000 ) :

285 
train_rgbs
 , 
train_tops
 , 
train_fronts
 , 
train_gt_labels
 , 
train_gt_boxes3d
 , 
handle_id
 = 
batches
 . 
load
 ( 1 , False )


	@./utils/training_validation_data_splitter.py

1 from 
	~sklearn.utils
 import 
shuffle

2 from 
	~raw_data
 import 
Image
 , 
Tracklet

3 import 
	~re

4 from 
	~config
 import 
cfg

5 import 
	~os

6 import 
	~glob

9 def 
	$get_test_tags
 ( 
bags
 ) :

10 
raw_img
 = 
Image
 ( )

11 
tags_all
 = 
raw_img
 . 
get_tags
 ( )

13 
all_tags
 = [ ]

14 for 
bag
 in 
bags
 :

16 
r
 = 
re
 . 
compile
 ( 
bag
 + "*" )

17 
tag_list
 = 
filter
 ( 
r
 . 
match
 , 
tags_all
 )

18 
bag_tag_list
 = 
list
 ( 
tag_list
 )

19 
all_tags
 += 
bag_tag_list

20 return 
all_tags
 
	}

23 class 
	cTrainingValDataSplitter
 :

24 def 
	$__init__
 ( 
self
 , 
bags
 , 
split_rate
 = 0.7 ) :

25 
self
 . 
bags
 = 
bags

26 
self
 . 
raw_img
 = 
Image
 ( )

27 
self
 . 
raw_tracklet_tag_list
 = 
list
 ( 
Tracklet
 ( ) . 
frames_object
 . 
keys
 ( ) )

30 
self
 . 
tags_all
 = 
self
 . 
raw_img
 . 
get_tags
 ( )

31 
self
 . 
size
 = 
len
 ( 
self
 . 
tags_all
 )

34 
self
 . 
training_bags
 = [ ]

36 
self
 . 
training_tags
 = [ ]

38 
self
 . 
val_bags
 = [ ]

39 
self
 . 
val_tags
 = [ ]

40 
self
 . 
split_rate
 = 
split_rate

41 
self
 . 
real_split_rate
 = - 1

44 
self
 . 
split_bags_by_tag_name
 ( ) 
	}

46 def 
	$check_frames_integrity
 ( 
self
 , 
bag
 ) :

48 
name
 = 
bag
 . 
split
 ( '/' )

49 
bag_dir
 = 
os
 . 
path
 . 
join
 ( 
cfg
 . 
RAW_DATA_SETS_DIR
 , 
name
 [ 0 ] , 
name
 [ 1 ] )

50 
img_path
 = 
os
 . 
path
 . 
join
 ( 
bag_dir
 , 'image_02' , 'data' , '*' )

51 
lidar_path
 = 
os
 . 
path
 . 
join
 ( 
bag_dir
 , 'velodyne_points' , 'data' , '*' )

53 
img_num
 = 
len
 ( 
glob
 . 
glob
 ( 
img_path
 ) )

54 
lidar_num
 = 
len
 ( 
glob
 . 
glob
 ( 
lidar_path
 ) )

55 
r
 = 
re
 . 
compile
 ( 
bag
 + '*' )

56 
tracklet_tag_list
 = 
filter
 ( 
r
 . 
match
 , 
self
 . 
raw_tracklet_tag_list
 )

57 
tracklet_num
 = 
len
 ( 
list
 ( 
tracklet_tag_list
 ) )

58 if not 
img_num
 == 
lidar_num
 == 
tracklet_num
 :

60 return True 
	}

62 def 
	$split_bags_by_tag_name
 ( 
self
 ) :

65 
self
 . 
bags
 = 
shuffle
 ( 
self
 . 
bags
 , 
random_state
 = 0 )

68 
problematic_bags
 = [ ]

69 for 
bag
 in 
self
 . 
bags
 :

70 
if_same
 = 
self
 . 
check_frames_integrity
 ( 
bag
 )

71 if not 
if_same
 :

72 
problematic_bags
 . 
append
 ( 
bag
 )

74 if 
len
 ( 
problematic_bags
 ) != 0 :

75 raise 
ValueError
 ( 'Number of images, lidar and tracklet of these bags are not the same ' ,

76 
problematic_bags
 )

79 
all_tags
 = [ ]

80 for 
bag
 in 
self
 . 
bags
 :

82 
r
 = 
re
 . 
compile
 ( 
bag
 + "*" )

83 
tag_list
 = 
filter
 ( 
r
 . 
match
 , 
self
 . 
tags_all
 )

84 
bag_tag_list
 = 
list
 ( 
tag_list
 )

85 
all_tags
 += 
bag_tag_list

87 
tag_size
 = 
len
 ( 
all_tags
 )

88 
split_point
 = 
round
 ( 
tag_size
 * 
self
 . 
split_rate
 )

90 for 
i
 in 
range
 ( 
split_point
 , 
tag_size
 ) :

91 
first_frame
 = 
all_tags
 [ 
i
 ]

92 
sec_frame
 = 
all_tags
 [ 
i
 + 1 ]

93 if ( '/' ) . 
join
 ( 
first_frame
 . 
split
 ( '/' ) [ : 2 ] ) != ( '/' ) . 
join
 ( 
sec_frame
 . 
split
 ( '/' ) [ : 2 ] ) :

94 
split_point
 = 
i

97 
self
 . 
training_tags
 = 
all_tags
 [ : 
split_point
 + 1 ]

98 
self
 . 
val_tags
 = 
all_tags
 [ 
split_point
 + 1 : ]

100 
self
 . 
real_split_rate
 = 1. * 
split_point
 / 
tag_size

101 
print
 ( 'real split rate is here: ' , 
self
 . 
real_split_rate
 )

104 
split_bag
 = ( '/' ) . 
join
 ( 
all_tags
 [ 
i
 + 1 ] . 
split
 ( '/' ) [ : 2 ] )

106 
in_training_bag
 = True

107 for 
i
 in 
self
 . 
bags
 :

108 if 
i
 == 
split_bag
 :

109 
in_training_bag
 = False

111 if 
in_training_bag
 :

112 
self
 . 
training_bags
 += [ 
i
 ]

114 
self
 . 
val_bags
 += [ 
i
 ] 
	}

117 if 
__name__
 == '__main__' :

118 
train_key_list
 = [ 'nissan_pulling_away' , 'nissan_pulling_up_to_it'

140 
train_key_full_path_list
 = [ 
os
 . 
path
 . 
join
 ( 
cfg
 . 
RAW_DATA_SETS_DIR
 , 
key
 ) for 
key
 in 
train_key_list
 ]

141 
train_value_list
 = [ 
os
 . 
listdir
 ( 
value
 ) [ 0 ] for 
value
 in 
train_key_full_path_list
 ]

143 
train_n_val_dataset
 = [ 
k
 + '/' + 
v
 for 
k
 , 
v
 in 
zip
 ( 
train_key_list
 , 
train_value_list
 ) ]

145 
splitter
 = 
TrainingValDataSplitter
 ( 
train_n_val_dataset
 )

147 
print
 ( 'completed' )


	@./utils/timer.py

1 from 
	~time
 import 
time

3 class 
	ctimer
 :

4 def 
	$__init__
 ( 
self
 ) :

5 
self
 . 
init_time
 = 
time
 ( )

6 
self
 . 
time_now
 = 
self
 . 
init_time
 
	}

8 def 
	$time_diff_per_n_loops
 ( 
self
 ) :

9 
time_diff
 = 
time
 ( ) - 
self
 . 
time_now

10 
self
 . 
time_now
 = 
time
 ( )

11 return 
time_diff
 
	}

13 def 
	$total_time
 ( 
self
 ) :

14 return 
time
 ( ) - 
self
 . 
init_time
 
	}

18 if 
__name__
 == '__main__' :

19 from 
	~time
 import 
sleep

21 
timeit
 = 
timer
 ( )

22 for 
i
 in 
range
 ( 10 ) :

23 
sleep
 ( 1 )

24 
print
 ( 'It takes {} secs per loop.' . 
format
 ( 
timeit
 . 
time_diff_per_n_loops
 ( ) ) )

26 
print
 ( 'It takes {} secs per whole script.' . 
format
 ( 
timeit
 . 
total_time
 ( ) ) )


	@./utils/check_top_view.py

1 import 
	~os

2 
os
 . 
environ
 [ "DISPLAY" ] = ":0"

5 import 
	~glob

9 import 
	~math

10 import 
	~random

11 import 
	~numpy
 as 
np

13 import 
	~cv2

14 import 
	~config

15 import 
	~data

16 import 
	~net.utility.draw
 as 
draw

20 if 
__name__
 == '__main__' :

23 
preprocessed_dir
 = 
config
 . 
cfg
 . 
PREPROCESSING_DATA_SETS_DIR

24 
dataset
 = '/1/15/00070.npy'

25 
top_view_dir
 = 
preprocessed_dir
 + '/top' + 
dataset

26 
gt_boxes3d_dir
 = 
preprocessed_dir
 + '/gt_boxes3d' + 
dataset

27 
top
 = 
np
 . 
load
 ( 
top_view_dir
 )

28 
gt_boxes3d
 = 
np
 . 
load
 ( 
gt_boxes3d_dir
 )

30 
top_img
 = 
data
 . 
draw_top_image
 ( 
top
 )

31 
top_img_marked
 = 
data
 . 
draw_box3d_on_top
 ( 
top_img
 , 
gt_boxes3d
 )

32 
draw
 . 
imsave
 ( 'top_img_marked' , 
top_img_marked
 , 'debug' )

33 
print
 ( 'top_img_marked dump finished!!' )


	@./utils/3d_visualize.py

1 import 
	~os

2 
os
 . 
environ
 [ "DISPLAY" ] = ":0"

5 import 
	~glob

9 import 
	~math

10 import 
	~random

11 import 
	~numpy
 as 
np

13 import 
	~cv2

14 import 
	~mayavi.mlab
 as 
mlab

15 import 
	~config

29 
MM_TOP_VIEW
 = 180 , 0 , 120 , [ 0 , 0 , 0 ]

30 
MM_PER_VIEW1
 = 120 , 30 , 70 , [ 0 , 0 , 0 ]

31 
MM_PER_VIEW2
 = 30 , 45 , 100 , [ 0 , 0 , 0 ]

32 
MM_PER_VIEW3
 = 120 , 30 , 100 , [ 0 , 0 , 0 ]

39 def 
	$draw_shadow_text
 ( 
img
 , 
text
 , 
pt
 , 
fontScale
 , 
color
 , 
thickness
 , 
color1
 = None , 
thickness1
 = None ) :

41 if 
color1
 is None : 
color1
 = ( 0 , 0 , 0 )

42 if 
thickness1
 is None : 
thickness1
 = 
thickness
 + 2

44 
font
 = 
cv2
 . 
FONT_HERSHEY_SIMPLEX

45 
cv2
 . 
putText
 ( 
img
 , 
text
 , 
pt
 , 
font
 , 
fontScale
 , 
color1
 , 
thickness1
 , 
cv2
 . 
LINE_AA
 )

46 
cv2
 . 
putText
 ( 
img
 , 
text
 , 
pt
 , 
font
 , 
fontScale
 , 
color
 , 
thickness
 , 
cv2
 . 
LINE_AA
 ) 
	}

48 def 
	$imshow
 ( 
name
 , 
image
 , 
resize
 = 1 ) :

49 
H
 , 
W
 = 
image
 . 
shape
 [ 0 : 2 ]

50 
cv2
 . 
namedWindow
 ( 
name
 , 
cv2
 . 
WINDOW_NORMAL
 )

51 
cv2
 . 
imshow
 ( 
name
 , 
image
 . 
astype
 ( 
np
 . 
uint8
 ) )

52 
cv2
 . 
resizeWindow
 ( 
name
 , 
round
 ( 
resize
 * 
W
 ) , 
round
 ( 
resize
 * 
H
 ) ) 
	}

55 def 
	$draw_didi_lidar
 ( 
fig
 , 
lidar
 , 
is_grid
 = 1 , 
is_axis
 = 1 ) :

57 
pxs
 = 
lidar
 [ : , 0 ]

58 
pys
 = 
lidar
 [ : , 1 ]

59 
pzs
 = 
lidar
 [ : , 2 ]

60 
prs
 = 
lidar
 [ : , 3 ]

62 
prs
 = 
np
 . 
clip
 ( 
prs
 / 15 , 0 , 1 )

65 if 
is_grid
 :

66 
L
 = 25

67 
dL
 = 5

68 
Z
 = - 2

69 
mlab
 . 
points3d
 ( 0 , 0 , 0 , 
color
 = ( 1 , 1 , 1 ) , 
mode
 = 'sphere' , 
scale_factor
 = 0.2 )

71 for 
y
 in 
np
 . 
arange
 ( - 
L
 , 
L
 + 1 , 
dL
 ) :

72 
x1
 , 
y1
 , 
z1
 = - 
L
 , 
y
 , 
Z

73 
x2
 , 
y2
 , 
z2
 = 
L
 , 
y
 , 
Z

74 
mlab
 . 
plot3d
 ( [ 
x1
 , 
x2
 ] , [ 
y1
 , 
y2
 ] , [ 
z1
 , 
z2
 ] , 
color
 = ( 0.3 , 0.3 , 0.3 ) , 
tube_radius
 = None , 
line_width
 = 1 , 
figure
 = 
fig
 )

76 for 
x
 in 
np
 . 
arange
 ( - 
L
 , 
L
 + 1 , 
dL
 ) :

77 
x1
 , 
y1
 , 
z1
 = 
x
 , - 
L
 , 
Z

78 
x2
 , 
y2
 , 
z2
 = 
x
 , 
L
 , 
Z

79 
mlab
 . 
plot3d
 ( [ 
x1
 , 
x2
 ] , [ 
y1
 , 
y2
 ] , [ 
z1
 , 
z2
 ] , 
color
 = ( 0.3 , 0.3 , 0.3 ) , 
tube_radius
 = None , 
line_width
 = 1 , 
figure
 = 
fig
 )

82 if 
is_axis
 :

83 
axes
 = 
np
 . 
array
 ( [

87 ] , 
dtype
 = 
np
 . 
float64
 )

89 
mlab
 . 
points3d
 ( 0 , 0 , 0 , 
color
 = ( 1 , 1 , 1 ) , 
mode
 = 'sphere' , 
scale_factor
 = 0.2 )

90 
mlab
 . 
plot3d
 ( [ 0 , 
axes
 [ 0 , 0 ] ] , [ 0 , 
axes
 [ 0 , 1 ] ] , [ 0 , 
axes
 [ 0 , 2 ] ] , 
color
 = ( 1 , 0 , 0 ) , 
tube_radius
 = None , 
line_width
 = 2 , 
figure
 = 
fig
 )

91 
mlab
 . 
plot3d
 ( [ 0 , 
axes
 [ 1 , 0 ] ] , [ 0 , 
axes
 [ 1 , 1 ] ] , [ 0 , 
axes
 [ 1 , 2 ] ] , 
color
 = ( 0 , 1 , 0 ) , 
tube_radius
 = None , 
line_width
 = 2 , 
figure
 = 
fig
 )

92 
mlab
 . 
plot3d
 ( [ 0 , 
axes
 [ 2 , 0 ] ] , [ 0 , 
axes
 [ 2 , 1 ] ] , [ 0 , 
axes
 [ 2 , 2 ] ] , 
color
 = ( 0 , 0 , 1 ) , 
tube_radius
 = None , 
line_width
 = 2 , 
figure
 = 
fig
 )

95 
mlab
 . 
points3d
 (

96 
pxs
 , 
pys
 , 
pzs
 , 
prs
 ,

97 
mode
 = 'point' ,

101 
scale_factor
 = 1 ,

102 
figure
 = 
fig
 ) 
	}

112 if 
__name__
 == '__main__' :

113 
maya
 = 
mlab
 . 
figure
 ( 1 , 
fgcolor
 = ( 0 , 0 , 0 ) , 
bgcolor
 = ( 1 , 1 , 1 ) )

114 
data_3d
 = 
np
 . 
load
 ( './00313.npy' )

115 
draw_didi_lidar
 ( 
maya
 , 
data_3d
 , 
is_grid
 = 1 , 
is_axis
 = 1 )

116 
print
 ( 'yes' )

119 def 
	$draw_didi_boxes3d
 ( 
fig
 , 
boxes3d
 , 
is_number
 = False , 
color
 = ( 1 , 1 , 1 ) , 
line_width
 = 1 ) :

121 if 
boxes3d
 . 
shape
 == ( 8 , 3 ) : 
boxes3d
 = 
boxes3d
 . 
reshape
 ( 1 , 8 , 3 )

123 
num
 = 
len
 ( 
boxes3d
 )

124 for 
n
 in 
range
 ( 
num
 ) :

125 
b
 = 
boxes3d
 [ 
n
 ]

127 if 
is_number
 :

128 
mlab
 . 
text3d
 ( 
b
 [ 0 , 0 ] , 
b
 [ 0 , 1 ] , 
b
 [ 0 , 2 ] , '%d' % 
n
 , 
scale
 = ( 1 , 1 , 1 ) , 
color
 = 
color
 , 
figure
 = 
fig
 )

129 for 
k
 in 
range
 ( 0 , 4 ) :

132 
i
 , 
j
 = 
k
 , ( 
k
 + 1 ) % 4

133 
mlab
 . 
plot3d
 ( [ 
b
 [ 
i
 , 0 ] , 
b
 [ 
j
 , 0 ] ] , [ 
b
 [ 
i
 , 1 ] , 
b
 [ 
j
 , 1 ] ] , [ 
b
 [ 
i
 , 2 ] , 
b
 [ 
j
 , 2 ] ] , 
color
 = 
color
 , 
tube_radius
 = None , 
line_width
 = 
line_width
 , 
figure
 = 
fig
 )

135 
i
 , 
j
 = 
k
 + 4 , ( 
k
 + 1 ) % 4 + 4

136 
mlab
 . 
plot3d
 ( [ 
b
 [ 
i
 , 0 ] , 
b
 [ 
j
 , 0 ] ] , [ 
b
 [ 
i
 , 1 ] , 
b
 [ 
j
 , 1 ] ] , [ 
b
 [ 
i
 , 2 ] , 
b
 [ 
j
 , 2 ] ] , 
color
 = 
color
 , 
tube_radius
 = None , 
line_width
 = 
line_width
 , 
figure
 = 
fig
 )

138 
i
 , 
j
 = 
k
 , 
k
 + 4

139 
mlab
 . 
plot3d
 ( [ 
b
 [ 
i
 , 0 ] , 
b
 [ 
j
 , 0 ] ] , [ 
b
 [ 
i
 , 1 ] , 
b
 [ 
j
 , 1 ] ] , [ 
b
 [ 
i
 , 2 ] , 
b
 [ 
j
 , 2 ] ] , 
color
 = 
color
 , 
tube_radius
 = None , 
line_width
 = 
line_width
 , 
figure
 = 
fig
 ) 
	}

144 def 
	$dir_to_avi
 ( 
avi_file
 , 
png_dir
 ) :

146 
tmp_dir
 = '~temp_png'

147 
os
 . 
makedirs
 ( 
tmp_dir
 , 
exist_ok
 = True )

149 for 
i
 , 
file
 in 
enumerate
 ( 
sorted
 ( 
glob
 . 
glob
 ( 
png_dir
 + '/*.png' ) ) ) :

150 
name
 = 
os
 . 
path
 . 
basename
 ( 
file
 ) . 
replace
 ( '.png' , '' )

153 
png_file
 = 
png_dir
 + '/' + 
name
 + '.png'

154 
tmp_file
 = 
tmp_dir
 + '/%06d.png' % 
i

155 
img
 = 
cv2
 . 
imread
 ( 
png_file
 , 1 )

156 
draw_shadow_text
 ( 
img
 , 'timestamp=' + 
name
 . 
replace
 ( '_' , ':' ) , ( 5 , 20 ) , 0.5 , ( 225 , 225 , 225 ) , 1 )

157 
imshow
 ( 'img' , 
img
 )

158 
cv2
 . 
waitKey
 ( 1 )

159 
cv2
 . 
imwrite
 ( 
tmp_file
 , 
img
 )

162 
os
 . 
system
 ( 'ffmpeg -y -loglevel 0 -f image2 -r 15 -i %s/%%06d.png -b:v 8000k %s' % ( 
tmp_dir
 , 
avi_file
 ) )

163 
os
 . 
system
 ( 'rm -rf %s' % 
tmp_dir
 ) 
	}

169 def 
	$mark_gt_box3d
 ( 
lidar_dir
 , 
gt_boxes3d_dir
 , 
mark_dir
 , 
index
 ) :

171 
os
 . 
makedirs
 ( 
mark_dir
 , 
exist_ok
 = True )

172 
fig
 = 
mlab
 . 
figure
 ( 
figure
 = None , 
bgcolor
 = ( 0 , 0 , 0 ) , 
fgcolor
 = None , 
engine
 = None , 
size
 = ( 500 , 500 ) )

174 
count
 = 0

175 for 
file
 in 
sorted
 ( 
glob
 . 
glob
 ( 
lidar_dir
 + '/*.npy' ) ) :

176 if 
count
 != 
index
 :

177 
count
 += 1

179 
count
 += 1

180 
name
 = 
os
 . 
path
 . 
basename
 ( 
file
 ) . 
replace
 ( '.npy' , '' )

182 
lidar_file
 = 
lidar_dir
 + '/' + 
name
 + '.npy'

183 
boxes3d_file
 = 
gt_boxes3d_dir
 + '/' + 
name
 + '.npy'

184 
lidar
 = 
np
 . 
load
 ( 
lidar_file
 )

185 
boxes3d
 = 
np
 . 
load
 ( 
boxes3d_file
 )

187 
mlab
 . 
clf
 ( 
fig
 )

188 
draw_didi_lidar
 ( 
fig
 , 
lidar
 , 
is_grid
 = 1 , 
is_axis
 = 1 )

189 if 
len
 ( 
boxes3d
 ) != 0 :

190 
draw_didi_boxes3d
 ( 
fig
 , 
boxes3d
 )

192 
azimuth
 , 
elevation
 , 
distance
 , 
focalpoint
 = 
MM_PER_VIEW1

193 
mlab
 . 
view
 ( 
azimuth
 , 
elevation
 , 
distance
 , 
focalpoint
 )

194 
mlab
 . 
show
 ( ) 
	}


	@./test.py

1 import 
	~mv3d

2 import 
	~mv3d_net

3 import 
	~glob

4 from 
	~config
 import *

5 import 
	~utils.batch_loading
 as 
ub

6 import 
	~argparse

7 import 
	~os

8 import 
	~sys

9 import 
	~time

10 from 
	~utils.training_validation_data_splitter
 import 
TrainingValDataSplitter

11 from 
	~utils.batch_loading
 import 
Loading3DOP
 , 
KittiLoading

12 import 
	~net.processing.boxes3d
 as 
box

13 import 
	~data
 as 
Data

14 from 
	~net.rpn_target_op
 import 
make_bases

17 def 
	$test_3dop
 ( 
args
 ) :

19 with 
Loading3DOP
 ( 
object_dir
 = '~/data/kitti/object_3dop' , 
proposals_dir
 = '/data/mxj/kitti/3dop_proposal' , 
queue_size
 = 20 , 
require_shuffle
 = False ,

20 
is_testset
 = True ) as 
testset
 :

21 
test
 = 
mv3d
 . 
Tester_3DOP
 ( * 
testset
 . 
get_shape
 ( ) , 
log_tag
 = 
args
 . 
tag
 )

22 
data
 = 
testset
 . 
load
 ( )

23 
count
 = 0

24 while 
data
 :

25 
boxes
 , 
labels
 = 
test
 ( * 
data
 )

26 
data
 = 
testset
 . 
load
 ( )

27 
print
 ( "Process {} data" . 
format
 ( 
count
 ) )

28 
boxes
 , 
labels
 = 
np
 . 
array
 ( 
boxes
 ) , 
np
 . 
array
 ( 
labels
 )

29 
np
 . 
save
 ( 
os
 . 
path
 . 
join
 ( 
args
 . 
target_dir
 , 
str
 ( 
count
 ) + "_boxes.npy" ) , 
boxes
 )

30 
np
 . 
save
 ( 
os
 . 
path
 . 
join
 ( 
args
 . 
target_dir
 , 
str
 ( 
count
 ) + "_labels.npy" ) , 
labels
 )

32 
count
 += 1 
	}

34 def 
	$test_rpn
 ( 
args
 ) :

35 with 
KittiLoading
 ( 
object_dir
 = '~/data/kitti/object_3dop' , 
queue_size
 = 50 , 
require_shuffle
 = False ,

36 
is_testset
 = True , 
use_precal_view
 = True ) as 
testset
 :

37 
os
 . 
makedirs
 ( 
args
 . 
target_dir
 , 
exist_ok
 = True )

38 
test
 = 
mv3d
 . 
Tester_RPN
 ( * 
testset
 . 
get_shape
 ( ) , 
log_tag
 = 
args
 . 
tag
 )

39 
data
 = 
testset
 . 
load
 ( )

40 
count
 = 1

41 while 
data
 :

42 
print
 ( 'Process {} data' . 
format
 ( 
count
 ) )

43 
tag
 , 
rgb
 , 
_
 , 
top_view
 , 
front_view
 = 
data

44 
box3d
 , 
rgb_roi
 , 
top_roi
 , 
roi_score
 = 
test
 ( 
top_view
 , 
front_view
 , 
rgb
 )

46 
np
 . 
save
 ( 
os
 . 
path
 . 
join
 ( 
args
 . 
target_dir
 , '{}_boxes3d.npy' . 
format
 ( 
tag
 [ 0 ] ) ) , 
box3d
 )

47 
np
 . 
save
 ( 
os
 . 
path
 . 
join
 ( 
args
 . 
target_dir
 , '{}_score.npy' . 
format
 ( 
tag
 [ 0 ] ) ) , 
roi_score
 )

49 
data
 = 
testset
 . 
load
 ( )

50 
count
 += 1 
	}

52 def 
	$test_mv3d
 ( 
args
 ) :

53 with 
KittiLoading
 ( 
object_dir
 = '~/data/kitti/object' , 
queue_size
 = 50 , 
require_shuffle
 = False ,

54 
is_testset
 = True , 
use_precal_view
 = True ) as 
testset
 :

55 
os
 . 
makedirs
 ( 
args
 . 
target_dir
 , 
exist_ok
 = True )

56 
test
 = 
mv3d
 . 
Predictor
 ( * 
testset
 . 
get_shape
 ( ) , 
log_tag
 = 
args
 . 
tag
 )

57 
data
 = 
testset
 . 
load
 ( )

59 
count
 = 1

60 while 
data
 :

61 
print
 ( 'Process {} data' . 
format
 ( 
count
 ) )

62 
tag
 , 
rgb
 , 
_
 , 
top_view
 , 
front_view
 = 
data

63 
boxes3d
 , 
labels
 , 
probs
 = 
test
 ( 
top_view
 , 
front_view
 , 
rgb
 , 
score_threshold
 = 0.5 )

64 
np
 . 
save
 ( 
os
 . 
path
 . 
join
 ( 
args
 . 
target_dir
 , '{}_boxes3d.npy' . 
format
 ( 
tag
 [ 0 ] ) ) , 
boxes3d
 )

65 
np
 . 
save
 ( 
os
 . 
path
 . 
join
 ( 
args
 . 
target_dir
 , '{}_labels.npy' . 
format
 ( 
tag
 [ 0 ] ) ) , 
labels
 )

66 
np
 . 
save
 ( 
os
 . 
path
 . 
join
 ( 
args
 . 
target_dir
 , '{}_probs.npy' . 
format
 ( 
tag
 [ 0 ] ) ) , 
probs
 )

68 
data
 = 
testset
 . 
load
 ( )

69 
count
 += 1 
	}

71 def 
	$test_single_mv3d
 ( 
args
 ) :

72 with 
KittiLoading
 ( 
object_dir
 = '/home/maxiaojian/data/kitti/object' , 
queue_size
 = 1 , 
require_shuffle
 = False ,

73 
is_testset
 = False , 
use_precal_view
 = True ) as 
testset
 :

74 
test
 = 
mv3d
 . 
Predictor_for_test
 ( * 
testset
 . 
get_shape
 ( ) , 
log_tag
 = 
args
 . 
tag
 )

76 
print
 ( 'Please input frame index for test, q for exit:' )

77 
index
 = 
sys
 . 
stdin
 . 
readline
 ( )

78 if 
index
 == 'q\n' : 
sys
 . 
exit
 ( )

79 
index
 , 
threshold
 = 
index
 . 
split
 ( ',' )

80 
index
 = 
int
 ( 
index
 )

81 
threshold
 = 
float
 ( 
threshold
 )

83 
data
 = 
testset
 . 
load_specified
 ( 
index
 )

84 
tag
 , 
label
 , 
rgb
 , 
_
 , 
top_view
 , 
front_view
 = 
data

85 
gt_box3d
 = 
Data
 . 
kitti_label_to_lidar_box3d
 ( 
label
 [ 0 ] , 'Car' )

86 
boxes3d
 , 
labels
 , 
probs
 = 
test
 ( 
top_view
 , 
front_view
 , 
rgb
 , 
threshold
 , 
gt_boxes3d
 = 
gt_box3d
 )

87 
test
 . 
dump_log
 ( 
args
 . 
target_dir
 , 
index
 )

89 
print
 ( 'test {} failed!' . 
format
 ( 
index
 ) ) 
	}

91 def 
	$test_rpn_target_interact
 ( 
args
 ) :

93 
ratios
 = 
np
 . 
array
 ( [ 0.5 , 1 , 2 ] , 
dtype
 = 
np
 . 
float32
 )

94 
scales
 = 
np
 . 
array
 ( [ 1 , 2 , 3 ] , 
dtype
 = 
np
 . 
float32
 )

95 
bases
 = 
make_bases
 (

96 
base_size
 = 16 ,

97 
ratios
 = 
ratios
 ,

98 
scales
 = 
scales

107 with 
KittiLoading
 ( 
object_dir
 = '~/data/kitti/object' , 
queue_size
 = 1 , 
require_shuffle
 = False ,

108 
is_testset
 = False , 
use_precal_view
 = True ) as 
testset
 :

109 
test
 = 
mv3d
 . 
Tester_RPN_Target
 ( * 
testset
 . 
get_shape
 ( ) , 
log_tag
 = 
args
 . 
tag
 )

111 
print
 ( 'Please input frame index for test, q for exit:' )

112 
index
 = 
sys
 . 
stdin
 . 
readline
 ( )

113 if 
index
 == 'q\n' : 
sys
 . 
exit
 ( )

114 
index
 = 
int
 ( 
index
 )

116 
data
 = 
testset
 . 
load_specified
 ( 
index
 )

117 
tag
 , 
label
 , 
rgb
 , 
_
 , 
top_view
 , 
front_view
 = 
data

118 
gt_box3d
 = 
Data
 . 
kitti_label_to_lidar_box3d
 ( 
label
 [ 0 ] , 'Car' )

119 
gt_labels
 = 
np
 . 
ones
 ( ( 1 , 
len
 ( 
gt_box3d
 [ 0 ] ) ) )

120 
amount
 , 
amount_pos
 = 
test
 ( 
top_view
 , 
front_view
 , 
rgb
 , 
bases
 , 
gt_boxes3d
 = 
gt_box3d
 , 
gt_labels
 = 
gt_labels
 )

121 
print
 ( 'anchor amount: {}, pos:{}' . 
format
 ( 
amount
 , 
amount_pos
 ) )

123 
print
 ( 'test {} failed!' . 
format
 ( 
index
 ) ) 
	}

125 def 
	$test_rpn_target
 ( 
args
 ) :

127 
ratios
 = 
np
 . 
array
 ( [ 0.5 , 1 , 2 ] , 
dtype
 = 
np
 . 
float32
 )

128 
scales
 = 
np
 . 
array
 ( [ 1 , 2 , 3 ] , 
dtype
 = 
np
 . 
float32
 )

129 
bases
 = 
make_bases
 (

130 
base_size
 = 16 ,

131 
ratios
 = 
ratios
 ,

132 
scales
 = 
scales

141 with 
KittiLoading
 ( 
object_dir
 = '~/data/kitti/object' , 
queue_size
 = 1 , 
require_shuffle
 = False ,

142 
is_testset
 = False , 
use_precal_view
 = True ) as 
testset
 :

143 
test
 = 
mv3d
 . 
Tester_RPN_Target
 ( * 
testset
 . 
get_shape
 ( ) , 
log_tag
 = 
args
 . 
tag
 )

144 
res
 = [ ]

145 
length
 = 
len
 ( 
testset
 ) if 
len
 ( 
testset
 ) < 1000 else 1000

146 for 
index
 in 
range
 ( 
length
 ) :

148 
data
 = 
testset
 . 
load_specified
 ( 
index
 )

149 
tag
 , 
label
 , 
rgb
 , 
_
 , 
top_view
 , 
front_view
 = 
data

150 
gt_box3d
 = 
Data
 . 
kitti_label_to_lidar_box3d
 ( 
label
 [ 0 ] , 'Car' )

151 
gt_labels
 = 
np
 . 
ones
 ( ( 1 , 
len
 ( 
gt_box3d
 [ 0 ] ) ) )

152 
amount
 , 
amount_pos
 = 
test
 ( 
top_view
 , 
front_view
 , 
rgb
 , 
bases
 , 
gt_boxes3d
 = 
gt_box3d
 , 
gt_labels
 = 
gt_labels
 )

153 
print
 ( '{} anchor amount: {}, pos:{}' . 
format
 ( 
index
 , 
amount
 , 
amount_pos
 ) )

154 
res
 . 
append
 ( ( 
amount
 , 
amount_pos
 ) )

156 
print
 ( 'test {} failed!' . 
format
 ( 
index
 ) )

157 
np
 . 
save
 ( 
args
 . 
save_name
 + '.npy' , 
np
 . 
array
 ( 
res
 ) ) 
	}

160 def 
	$test_front
 ( 
args
 ) :

161 pass 
	}

163 def 
	$lidar_to_front
 ( 
lidar
 ) :

165 def 
cal_height
 ( 
point
 ) :

166 return 
np
 . 
clip
 ( 
point
 [ 2 ] + 
cfg
 . 
VELODYNE_HEIGHT
 , 
a_min
 = 0 , 
a_max
 = None )

167 def 
cal_distance
 ( 
point
 ) :

168 return 
math
 . 
sqrt
 ( 
sum
 ( 
np
 . 
array
 ( 
point
 ) ** 2 ) )

169 def 
cal_intensity
 ( 
point
 ) :

170 return 
point
 [ 3 ]

171 def 
to_front
 ( 
point
 ) :

173 
int
 ( 
math
 . 
atan2
 ( 
point
 [ 1 ] , 
point
 [ 0 ] ) / 
cfg
 . 
VELODYNE_ANGULAR_RESOLUTION
 ) ,

174 
int
 ( 
math
 . 
atan2
 ( 
point
 [ 2 ] , 
math
 . 
sqrt
 ( 
point
 [ 0 ] ** 2 + 
point
 [ 1 ] ** 2 ) )

175 / 
cfg
 . 
VELODYNE_VERTICAL_RESOLUTION
 )

179 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 0 ] > 
TOP_X_MIN
 )

180 
lidar
 = 
lidar
 [ 
idx
 ]

181 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 0 ] < 
TOP_X_MAX
 )

182 
lidar
 = 
lidar
 [ 
idx
 ]

184 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 1 ] > 
TOP_Y_MIN
 )

185 
lidar
 = 
lidar
 [ 
idx
 ]

186 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 1 ] < 
TOP_Y_MAX
 )

187 
lidar
 = 
lidar
 [ 
idx
 ]

189 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 2 ] > 
TOP_Z_MIN
 )

190 
lidar
 = 
lidar
 [ 
idx
 ]

191 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 2 ] < 
TOP_Z_MAX
 )

192 
lidar
 = 
lidar
 [ 
idx
 ]

194 
r
 , 
c
 , 
l
 = [ ] , [ ] , [ ]

195 for 
point
 in 
lidar
 :

196 
pc
 , 
pr
 = 
to_front
 ( 
point
 )

197 if 
cfg
 . 
FRONT_C_MIN
 < 
pc
 < 
cfg
 . 
FRONT_C_MAX
 and 
cfg
 . 
FRONT_R_MIN
 < 
pr
 < 
cfg
 . 
FRONT_R_MAX
 :

198 
c
 . 
append
 ( 
pc
 )

199 
r
 . 
append
 ( 
pr
 )

200 
l
 . 
append
 ( 
point
 )

201 
c
 , 
r
 = 
np
 . 
array
 ( 
c
 ) . 
astype
 ( 
np
 . 
int32
 ) , 
np
 . 
array
 ( 
r
 ) . 
astype
 ( 
np
 . 
int32
 )

202 
c
 += 
int
 ( 
cfg
 . 
FRONT_C_OFFSET
 )

203 
r
 += 
int
 ( 
cfg
 . 
FRONT_R_OFFSET
 )

209 
channel
 = 3

210 
front
 = 
np
 . 
zeros
 ( ( 
cfg
 . 
FRONT_WIDTH
 , 
cfg
 . 
FRONT_HEIGHT
 , 
channel
 + 1 ) , 
dtype
 = 
np
 . 
float32
 )

211 for 
point
 , 
p_c
 , 
p_r
 in 
zip
 ( 
l
 , 
c
 , 
r
 ) :

212 if 0 <= 
p_c
 < 
cfg
 . 
FRONT_WIDTH
 and 0 <= 
p_r
 < 
cfg
 . 
FRONT_HEIGHT
 :

213 
front
 [ 
p_c
 , 
p_r
 , 0 : 
channel
 ] *= 
front
 [ 
p_c
 , 
p_r
 , 
channel
 ]

214 
front
 [ 
p_c
 , 
p_r
 , 0 : 
channel
 ] += 
np
 . 
array
 ( [ 
cal_height
 ( 
point
 ) , 
cal_distance
 ( 
point
 ) , 
cal_intensity
 ( 
point
 ) ] )

215 
front
 [ 
p_c
 , 
p_r
 , 
channel
 ] += 1

216 
front
 [ 
p_c
 , 
p_r
 , 0 : 
channel
 ] /= 
front
 [ 
p_c
 , 
p_r
 , 
channel
 ]

218 return 
front
 [ : , : , 0 : 
channel
 ] 
	}

220 def 
	$lidar_to_front_fast
 ( 
lidar
 ) :

222 def 
cal_height
 ( 
points
 ) :

223 return 
np
 . 
clip
 ( 
points
 [ : , 2 ] + 
cfg
 . 
VELODYNE_HEIGHT
 , 
a_min
 = 0 , 
a_max
 = None ) . 
astype
 ( 
np
 . 
float32
 ) . 
reshape
 ( ( - 1 , 1 ) )

224 def 
cal_distance
 ( 
points
 ) :

225 return 
np
 . 
sqrt
 ( 
np
 . 
sum
 ( 
points
 ** 2 , 
axis
 = 1 ) ) . 
astype
 ( 
np
 . 
float32
 ) . 
reshape
 ( ( - 1 , 1 ) )

226 def 
cal_intensity
 ( 
points
 ) :

227 return 
points
 [ : , 3 ] . 
astype
 ( 
np
 . 
float32
 ) . 
reshape
 ( ( - 1 , 1 ) )

228 def 
to_front
 ( 
points
 ) :

229 return 
np
 . 
array
 ( [

230 
np
 . 
arctan2
 ( 
points
 [ : , 1 ] , 
points
 [ : , 0 ] ) / 
cfg
 . 
VELODYNE_ANGULAR_RESOLUTION
 ,

231 
np
 . 
arctan2
 ( 
points
 [ : , 2 ] , 
np
 . 
sqrt
 ( 
points
 [ : , 0 ] ** 2 + 
points
 [ : , 1 ] ** 2 ) )

232 / 
cfg
 . 
VELODYNE_VERTICAL_RESOLUTION

233 ] , 
dtype
 = 
np
 . 
int32
 ) . 
T

236 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 0 ] > 
TOP_X_MIN
 )

237 
lidar
 = 
lidar
 [ 
idx
 ]

238 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 0 ] < 
TOP_X_MAX
 )

239 
lidar
 = 
lidar
 [ 
idx
 ]

241 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 1 ] > 
TOP_Y_MIN
 )

242 
lidar
 = 
lidar
 [ 
idx
 ]

243 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 1 ] < 
TOP_Y_MAX
 )

244 
lidar
 = 
lidar
 [ 
idx
 ]

246 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 2 ] > 
TOP_Z_MIN
 )

247 
lidar
 = 
lidar
 [ 
idx
 ]

248 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 2 ] < 
TOP_Z_MAX
 )

249 
lidar
 = 
lidar
 [ 
idx
 ]

251 
points
 = 
to_front
 ( 
lidar
 )

252 
ind
 = 
np
 . 
where
 ( 
cfg
 . 
FRONT_C_MIN
 < 
points
 [ : , 0 ] )

253 
points
 , 
lidar
 = 
points
 [ 
ind
 ] , 
lidar
 [ 
ind
 ]

254 
ind
 = 
np
 . 
where
 ( 
points
 [ : , 0 ] < 
cfg
 . 
FRONT_C_MAX
 )

255 
points
 , 
lidar
 = 
points
 [ 
ind
 ] , 
lidar
 [ 
ind
 ]

256 
ind
 = 
np
 . 
where
 ( 
cfg
 . 
FRONT_R_MIN
 < 
points
 [ : , 1 ] )

257 
points
 , 
lidar
 = 
points
 [ 
ind
 ] , 
lidar
 [ 
ind
 ]

258 
ind
 = 
np
 . 
where
 ( 
points
 [ : , 1 ] < 
cfg
 . 
FRONT_R_MAX
 )

259 
points
 , 
lidar
 = 
points
 [ 
ind
 ] , 
lidar
 [ 
ind
 ]

261 
points
 [ : , 0 ] += 
int
 ( 
cfg
 . 
FRONT_C_OFFSET
 )

262 
points
 [ : , 1 ] += 
int
 ( 
cfg
 . 
FRONT_R_OFFSET
 )

265 
ind
 = 
np
 . 
where
 ( 0 <= 
points
 [ : , 0 ] )

266 
points
 , 
lidar
 = 
points
 [ 
ind
 ] , 
lidar
 [ 
ind
 ]

267 
ind
 = 
np
 . 
where
 ( 
points
 [ : , 0 ] < 
cfg
 . 
FRONT_WIDTH
 )

268 
points
 , 
lidar
 = 
points
 [ 
ind
 ] , 
lidar
 [ 
ind
 ]

269 
ind
 = 
np
 . 
where
 ( 0 <= 
points
 [ : , 1 ] )

270 
points
 , 
lidar
 = 
points
 [ 
ind
 ] , 
lidar
 [ 
ind
 ]

271 
ind
 = 
np
 . 
where
 ( 
points
 [ : , 1 ] < 
cfg
 . 
FRONT_HEIGHT
 )

272 
points
 , 
lidar
 = 
points
 [ 
ind
 ] , 
lidar
 [ 
ind
 ]

274 
channel
 = 3

275 
front
 = 
np
 . 
zeros
 ( ( 
cfg
 . 
FRONT_WIDTH
 , 
cfg
 . 
FRONT_HEIGHT
 , 
channel
 ) , 
dtype
 = 
np
 . 
float32
 )

276 
weight_mask
 = 
np
 . 
zeros_like
 ( 
front
 [ : , : , 0 ] )

277 def 
_add
 ( 
x
 ) :

278 
weight_mask
 [ 
int
 ( 
x
 [ 0 ] ) , 
int
 ( 
x
 [ 1 ] ) ] += 1

279 def 
_fill
 ( 
x
 ) :

280 
front
 [ 
int
 ( 
x
 [ 0 ] ) , 
int
 ( 
x
 [ 1 ] ) , : ] += 
x
 [ 2 : ]

281 
np
 . 
apply_along_axis
 ( 
_add
 , 1 , 
points
 )

282 
weight_mask
 [ 
weight_mask
 == 0 ] = 1

283 
buf
 = 
np
 . 
hstack
 ( ( 
points
 , 
cal_height
 ( 
lidar
 ) , 
cal_distance
 ( 
lidar
 ) , 
cal_intensity
 ( 
lidar
 ) ) )

284 
np
 . 
apply_along_axis
 ( 
_fill
 , 1 , 
buf
 )

285 
front
 /= 
weight_mask
 [ : , : , 
np
 . 
newaxis
 ]

287 return 
front
 
	}

288 def 
	$lidar_to_top
 ( 
lidar
 ) :

290 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 0 ] > 
TOP_X_MIN
 )

291 
lidar
 = 
lidar
 [ 
idx
 ]

292 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 0 ] < 
TOP_X_MAX
 )

293 
lidar
 = 
lidar
 [ 
idx
 ]

295 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 1 ] > 
TOP_Y_MIN
 )

296 
lidar
 = 
lidar
 [ 
idx
 ]

297 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 1 ] < 
TOP_Y_MAX
 )

298 
lidar
 = 
lidar
 [ 
idx
 ]

300 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 2 ] > 
TOP_Z_MIN
 )

301 
lidar
 = 
lidar
 [ 
idx
 ]

302 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 2 ] < 
TOP_Z_MAX
 )

303 
lidar
 = 
lidar
 [ 
idx
 ]

305 if ( 
cfg
 . 
DATA_SETS_TYPE
 == 'didi' or 
cfg
 . 
DATA_SETS_TYPE
 == 'test' or 
cfg
 . 
DATA_SETS_TYPE
 == 'didi2' ) :

306 
lidar
 = 
filter_center_car
 ( 
lidar
 )

309 
pxs
 = 
lidar
 [ : , 0 ]

310 
pys
 = 
lidar
 [ : , 1 ]

311 
pzs
 = 
lidar
 [ : , 2 ]

312 
prs
 = 
lidar
 [ : , 3 ]

313 
qxs
 = ( ( 
pxs
 - 
TOP_X_MIN
 ) // 
TOP_X_DIVISION
 ) . 
astype
 ( 
np
 . 
int32
 )

314 
qys
 = ( ( 
pys
 - 
TOP_Y_MIN
 ) // 
TOP_Y_DIVISION
 ) . 
astype
 ( 
np
 . 
int32
 )

316 
qzs
 = ( 
pzs
 - 
TOP_Z_MIN
 ) / 
TOP_Z_DIVISION

317 
quantized
 = 
np
 . 
dstack
 ( ( 
qxs
 , 
qys
 , 
qzs
 , 
prs
 ) ) . 
squeeze
 ( )

319 
X0
 , 
Xn
 = 0 , 
int
 ( ( 
TOP_X_MAX
 - 
TOP_X_MIN
 ) // 
TOP_X_DIVISION
 ) + 1

320 
Y0
 , 
Yn
 = 0 , 
int
 ( ( 
TOP_Y_MAX
 - 
TOP_Y_MIN
 ) // 
TOP_Y_DIVISION
 ) + 1

321 
Z0
 , 
Zn
 = 0 , 
int
 ( ( 
TOP_Z_MAX
 - 
TOP_Z_MIN
 ) / 
TOP_Z_DIVISION
 )

322 
height
 = 
Xn
 - 
X0

323 
width
 = 
Yn
 - 
Y0

324 
channel
 = 
Zn
 - 
Z0
 + 2

326 
top
 = 
np
 . 
zeros
 ( 
shape
 = ( 
height
 , 
width
 , 
channel
 ) , 
dtype
 = 
np
 . 
float32
 )

333 for 
x
 in 
range
 ( 
Xn
 ) :

334 
ix
 = 
np
 . 
where
 ( 
quantized
 [ : , 0 ] == 
x
 )

335 
quantized_x
 = 
quantized
 [ 
ix
 ]

336 if 
len
 ( 
quantized_x
 ) == 0 : continue

337 
yy
 = - 
x

339 for 
y
 in 
range
 ( 
Yn
 ) :

340 
iy
 = 
np
 . 
where
 ( 
quantized_x
 [ : , 1 ] == 
y
 )

341 
quantized_xy
 = 
quantized_x
 [ 
iy
 ]

342 
count
 = 
len
 ( 
quantized_xy
 )

343 if 
count
 == 0 : continue

344 
xx
 = - 
y

346 
top
 [ 
yy
 , 
xx
 , 
Zn
 + 1 ] = 
min
 ( 1 , 
np
 . 
log
 ( 
count
 + 1 ) / 
math
 . 
log
 ( 32 ) )

347 
max_height_point
 = 
np
 . 
argmax
 ( 
quantized_xy
 [ : , 2 ] )

348 
top
 [ 
yy
 , 
xx
 , 
Zn
 ] = 
quantized_xy
 [ 
max_height_point
 , 3 ]

350 for 
z
 in 
range
 ( 
Zn
 ) :

351 
iz
 = 
np
 . 
where
 ( ( 
quantized_xy
 [ : , 2 ] >= 
z
 ) & ( 
quantized_xy
 [ : , 2 ] <= 
z
 + 1 ) )

352 
quantized_xyz
 = 
quantized_xy
 [ 
iz
 ]

353 if 
len
 ( 
quantized_xyz
 ) == 0 : continue

354 
zz
 = 
z

357 
max_height
 = 
max
 ( 0 , 
np
 . 
max
 ( 
quantized_xyz
 [ : , 2 ] ) - 
z
 )

358 
top
 [ 
yy
 , 
xx
 , 
zz
 ] = 
max_height

359 return 
top
 
	}

361 def 
	$lidar_to_top_fast
 ( 
lidar
 ) :

363 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 0 ] > 
TOP_X_MIN
 )

364 
lidar
 = 
lidar
 [ 
idx
 ]

365 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 0 ] < 
TOP_X_MAX
 )

366 
lidar
 = 
lidar
 [ 
idx
 ]

368 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 1 ] > 
TOP_Y_MIN
 )

369 
lidar
 = 
lidar
 [ 
idx
 ]

370 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 1 ] < 
TOP_Y_MAX
 )

371 
lidar
 = 
lidar
 [ 
idx
 ]

373 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 2 ] > 
TOP_Z_MIN
 )

374 
lidar
 = 
lidar
 [ 
idx
 ]

375 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 2 ] < 
TOP_Z_MAX
 )

376 
lidar
 = 
lidar
 [ 
idx
 ]

378 if ( 
cfg
 . 
DATA_SETS_TYPE
 == 'didi' or 
cfg
 . 
DATA_SETS_TYPE
 == 'test' or 
cfg
 . 
DATA_SETS_TYPE
 == 'didi2' ) :

379 
lidar
 = 
filter_center_car
 ( 
lidar
 )

382 
lidar
 [ : , 0 ] = ( ( 
lidar
 [ : , 0 ] - 
TOP_X_MIN
 ) // 
TOP_X_DIVISION
 ) . 
astype
 ( 
np
 . 
int32
 )

383 
lidar
 [ : , 1 ] = ( ( 
lidar
 [ : , 1 ] - 
TOP_Y_MIN
 ) // 
TOP_Y_DIVISION
 ) . 
astype
 ( 
np
 . 
int32
 )

384 
lidar
 [ : , 2 ] = ( ( 
lidar
 [ : , 2 ] - 
TOP_Z_MIN
 ) / 
TOP_Z_DIVISION
 ) . 
astype
 ( 
np
 . 
float32
 )

387 
X0
 , 
Xn
 = 0 , 
int
 ( ( 
TOP_X_MAX
 - 
TOP_X_MIN
 ) // 
TOP_X_DIVISION
 ) + 1

388 
Y0
 , 
Yn
 = 0 , 
int
 ( ( 
TOP_Y_MAX
 - 
TOP_Y_MIN
 ) // 
TOP_Y_DIVISION
 ) + 1

389 
Z0
 , 
Zn
 = 0 , 
int
 ( ( 
TOP_Z_MAX
 - 
TOP_Z_MIN
 ) / 
TOP_Z_DIVISION
 )

390 
height
 = 
Xn
 - 
X0

391 
width
 = 
Yn
 - 
Y0

392 
channel
 = 
Zn
 - 
Z0
 + 2

394 
grid
 = 
np
 . 
zeros
 ( ( 
height
 , 
width
 , 1 ) , 
dtype
 = 
np
 . 
object
 )

395 def 
_fill
 ( 
x
 ) :

396 if 
grid
 [ 
int
 ( 
x
 [ 0 ] ) , 
int
 ( 
x
 [ 1 ] ) , 0 ] == 0 :

397 
grid
 [ 
int
 ( 
x
 [ 0 ] ) , 
int
 ( 
x
 [ 1 ] ) , 0 ] = [ ]

398 
grid
 [ 
int
 ( 
x
 [ 0 ] ) , 
int
 ( 
x
 [ 1 ] ) , 0 ] . 
append
 ( 
x
 )

399 def 
_sort_by_height
 ( 
x
 ) :

400 
x
 = 
x
 [ 0 ]

401 if 
x
 != 0 :

402 
h
 = 
np
 . 
array
 ( [ 
i
 [ 2 ] for 
i
 in 
x
 ] )

403 
grid
 [ 
int
 ( 
x
 [ 0 ] [ 0 ] ) , 
int
 ( 
x
 [ 0 ] [ 1 ] ) , 0 ] = 
list
 ( 
np
 . 
array
 ( 
x
 ) [ 
h
 . 
argsort
 ( 
kind
 = 'heapsort' ) ] )

404 
np
 . 
apply_along_axis
 ( 
_fill
 , 1 , 
lidar
 )

405 
np
 . 
apply_along_axis
 ( 
_sort_by_height
 , 2 , 
grid
 )

408 
top
 = 
np
 . 
zeros
 ( ( 
height
 , 
width
 , 
channel
 ) , 
dtype
 = 
np
 . 
float32
 )

409 def 
_cal_height
 ( 
x
 ) :

410 
x
 = 
x
 [ 0 ]

411 if 
x
 != 0 :

412 
i
 = 0

413 for 
z
 in 
range
 ( 
Zn
 ) :

414 if 
z
 + 1 < 
x
 [ 
i
 ] [ 2 ] : continue

416 while not ( 
x
 [ 
i
 ] [ 2 ] <= 
z
 + 1 and 
x
 [ 
i
 + 1 ] [ 2 ] > 
z
 + 1 ) :

417 
i
 += 1

419 
top
 [ 
int
 ( 
x
 [ 0 ] [ 0 ] ) , 
int
 ( 
x
 [ 0 ] [ 1 ] ) , 
z
 ] = 
max
 ( 
x
 [ - 1 ] [ 2 ] - 
z
 , 0 )

422 
top
 [ 
int
 ( 
x
 [ 0 ] [ 0 ] ) , 
int
 ( 
x
 [ 0 ] [ 1 ] ) , 
z
 ] = 
max
 ( 
x
 [ 
i
 ] [ 2 ] - 
z
 , 0 )

423 
i
 += 1

424 def 
_cal_density
 ( 
x
 ) :

425 
x
 = 
x
 [ 0 ]

426 if 
x
 != 0 :

427 
top
 [ 
int
 ( 
x
 [ 0 ] [ 0 ] ) , 
int
 ( 
x
 [ 0 ] [ 1 ] ) , 
Zn
 + 1 ] = 
min
 ( 1 , 
np
 . 
log
 ( 
len
 ( 
x
 ) + 1 ) / 
np
 . 
log
 ( 32 ) )

428 def 
_cal_intensity
 ( 
x
 ) :

429 
x
 = 
x
 [ 0 ]

430 if 
x
 != 0 :

431 
top
 [ 
int
 ( 
x
 [ 0 ] [ 0 ] ) , 
int
 ( 
x
 [ 0 ] [ 1 ] ) , 
Zn
 ] = 
x
 [ - 1 ] [ 3 ]

432 
np
 . 
apply_along_axis
 ( 
_cal_height
 , 2 , 
grid
 )

433 
np
 . 
apply_along_axis
 ( 
_cal_density
 , 2 , 
grid
 )

434 
np
 . 
apply_along_axis
 ( 
_cal_intensity
 , 2 , 
grid
 )

436 return 
top
 
	}

438 def 
	$test_lidar_fast
 ( ) :

440 
raw
 = 
np
 . 
fromfile
 ( '/home/maxiaojian/data/kitti/2011_09_26/2011_09_26_drive_0001_sync/velodyne_points/data/0000000000.bin' , 
dtype
 = 
np
 . 
float32
 ) . 
reshape
 ( ( - 1 , 4 ) )

441 
t
 = 
time
 . 
time
 ( )

442 
lidar_to_top_fast
 ( 
raw
 )

443 
t
 = 
time
 . 
time
 ( ) - 
t

444 
print
 ( 'Costs:{}s' . 
format
 ( 
t
 ) )

445 
t
 = 
time
 . 
time
 ( )

446 
lidar_to_front_fast
 ( 
raw
 )

447 
t
 = 
time
 . 
time
 ( ) - 
t

448 
print
 ( 'Costs:{}s' . 
format
 ( 
t
 ) ) 
	}

450 def 
	$test_lidar
 ( ) :

452 
raw
 = 
np
 . 
fromfile
 ( '/home/maxiaojian/data/kitti/2011_09_26/2011_09_26_drive_0001_sync/velodyne_points/data/0000000000.bin' , 
dtype
 = 
np
 . 
float32
 ) . 
reshape
 ( ( - 1 , 4 ) )

453 
t
 = 
time
 . 
time
 ( )

454 
lidar_to_top
 ( 
raw
 )

455 
t
 = 
time
 . 
time
 ( ) - 
t

456 
print
 ( 'Costs:{}s' . 
format
 ( 
t
 ) )

457 
t
 = 
time
 . 
time
 ( )

458 
lidar_to_front
 ( 
raw
 )

459 
t
 = 
time
 . 
time
 ( ) - 
t

460 
print
 ( 'Costs:{}s' . 
format
 ( 
t
 ) ) 
	}

463 if 
__name__
 == '__main__' :

464 
parser
 = 
argparse
 . 
ArgumentParser
 ( 
description
 = 'testing' )

466 
parser
 . 
add_argument
 ( '-n' , '--tag' , 
type
 = 
str
 , 
nargs
 = '?' , 
default
 = 'unknown_tag' ,

467 
help
 = 'set log tag' )

468 
parser
 . 
add_argument
 ( '-t' , '--target-dir' , 
type
 = 
str
 , 
nargs
 = '?' , 
default
 = 'test_dir' )

469 
parser
 . 
add_argument
 ( '-s' , '--save-name' , 
type
 = 
str
 , 
nargs
 = '?' , 
default
 = 'test' )

470 
parser
 . 
add_argument
 ( '-i' , '--interactive' , 
action
 = "store_true" )

473 
args
 = 
parser
 . 
parse_args
 ( )

475 
print
 ( '\n\n{}\n\n' . 
format
 ( 
args
 ) )

482 
test_single_mv3d
 ( 
args
 )


	@./lidar_data_preprocess/python_call_liblidar_test_osx.py

1 from 
	~ctypes
 import *

4 
liblidar
 = 
CDLL
 ( './liblidar.dylib' )

9 
lidar_data_src_dir
 = "./raw/kitti/2011_09_26/2011_09_26_drive_0001_sync/velodyne_points/data/"

10 
top_image_dst_dir
 = "./preprocessed/kitti/top_image/"

11 
front_image_dst_dir
 = "./preprocessed/kitti/front_image/"

12 
delay
 = "0"

14 
argc
 = "5"

17 
b_argc
 = 
argc
 . 
encode
 ( 'utf-8' )

18 
b_lidar_data_src_dir
 = 
lidar_data_src_dir
 . 
encode
 ( 'utf-8' )

19 
b_top_image_dst_dir
 = 
top_image_dst_dir
 . 
encode
 ( 'utf-8' )

20 
b_front_image_dst_dir
 = 
front_image_dst_dir
 . 
encode
 ( 'utf-8' )

21 
b_delay
 = 
delay
 . 
encode
 ( 'utf-8' )

23 def 
	$call_liblidar
 ( 
L
 ) :

24 
arr
 = ( 
c_char_p
 * 
len
 ( 
L
 ) ) ( )

25 
arr
 [ : ] = 
L

26 
liblidar
 . 
main
 ( 
len
 ( 
L
 ) , 
arr
 ) 
	}

28 
call_liblidar
 ( [ 
b_argc
 , 
b_lidar_data_src_dir
 , 
b_top_image_dst_dir
 , 
b_front_image_dst_dir
 , 
b_delay
 ] )


	@./lidar_data_preprocess/Python_to_C_Interface/SampleProgram.py


	@./lidar_data_preprocess/Python_to_C_Interface/ver3/createTopAndFrontMaps.py

1 import 
	~ctypes

2 import 
	~numpy
 as 
np

4 def 
	$createTopAndFrontMaps
 ( 
raw
 , 
num
 , 
top_flip
 , 
front_flip
 , 
top_paras
 , 
front_paras
 , 
c_lib_path
 ) :

5 [ 
TOP_X_MIN
 , 
TOP_X_MAX
 , 
TOP_Y_MIN
 ,

6 
TOP_Y_MAX
 , 
TOP_Z_MIN
 , 
TOP_Z_MAX
 ,

7 
TOP_X_DIVISION
 , 
TOP_Y_DIVISION
 , 
TOP_Z_DIVISION
 ,

8 
Xn
 , 
Yn
 , 
Zn
 ] = 
top_paras

10 [ 
FRONT_PHI_MIN
 , 
FRONT_PHI_MAX
 ,

11 
FRONT_THETA_MIN
 , 
FRONT_THETA_MAX
 ,

12 
FRONT_PHI_DIVISION
 , 
FRONT_THETA_DIVISION
 ,

13 
Rn
 , 
Cn
 , 
Fn
 ] = 
front_paras

16 
SharedLib
 = 
ctypes
 . 
cdll
 . 
LoadLibrary
 ( 
c_lib_path
 )

20 
SharedLib
 . 
createTopAndFrontMaps
 ( 
ctypes
 . 
c_void_p
 ( 
raw
 . 
ctypes
 . 
data
 ) ,

21 
ctypes
 . 
c_int
 ( 
num
 ) ,

22 
ctypes
 . 
c_void_p
 ( 
top_flip
 . 
ctypes
 . 
data
 ) ,

23 
ctypes
 . 
c_void_p
 ( 
front_flip
 . 
ctypes
 . 
data
 ) ,

24 
ctypes
 . 
c_float
 ( 
TOP_X_MIN
 ) , 
ctypes
 . 
c_float
 ( 
TOP_X_MAX
 ) ,

25 
ctypes
 . 
c_float
 ( 
TOP_Y_MIN
 ) , 
ctypes
 . 
c_float
 ( 
TOP_Y_MAX
 ) ,

26 
ctypes
 . 
c_float
 ( 
TOP_Z_MIN
 ) , 
ctypes
 . 
c_float
 ( 
TOP_Z_MAX
 ) ,

27 
ctypes
 . 
c_float
 ( 
TOP_X_DIVISION
 ) , 
ctypes
 . 
c_float
 ( 
TOP_Y_DIVISION
 ) , 
ctypes
 . 
c_float
 ( 
TOP_Z_DIVISION
 ) ,

28 
ctypes
 . 
c_int
 ( 
Xn
 ) , 
ctypes
 . 
c_int
 ( 
Yn
 ) , 
ctypes
 . 
c_int
 ( 
Zn
 ) ,

29 
ctypes
 . 
c_float
 ( 
FRONT_PHI_MIN
 ) , 
ctypes
 . 
c_float
 ( 
FRONT_PHI_MAX
 ) ,

30 
ctypes
 . 
c_float
 ( 
FRONT_THETA_MIN
 ) , 
ctypes
 . 
c_float
 ( 
FRONT_THETA_MAX
 ) ,

31 
ctypes
 . 
c_float
 ( 
FRONT_PHI_DIVISION
 ) , 
ctypes
 . 
c_float
 ( 
FRONT_THETA_DIVISION
 ) ,

32 
ctypes
 . 
c_float
 ( 
Cn
 ) , 
ctypes
 . 
c_float
 ( 
Rn
 ) , 
ctypes
 . 
c_float
 ( 
Fn
 )

33 ) 
	}


	@./lidar_data_preprocess/Python_to_C_Interface/ver3/ExampleUsage_TopAndFront.py

1 import 
	~numpy
 as 
np

2 import 
	~math

6 def 
	$lidar_to_top
 ( 
lidar
 ) :

7 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 0 ] > 
TOP_X_MIN
 )

8 
lidar
 = 
lidar
 [ 
idx
 ]

9 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 0 ] < 
TOP_X_MAX
 )

10 
lidar
 = 
lidar
 [ 
idx
 ]

12 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 1 ] > 
TOP_Y_MIN
 )

13 
lidar
 = 
lidar
 [ 
idx
 ]

14 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 1 ] < 
TOP_Y_MAX
 )

15 
lidar
 = 
lidar
 [ 
idx
 ]

17 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 2 ] > 
TOP_Z_MIN
 )

18 
lidar
 = 
lidar
 [ 
idx
 ]

19 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 2 ] < 
TOP_Z_MAX
 )

20 
lidar
 = 
lidar
 [ 
idx
 ]

22 
pxs
 = 
lidar
 [ : , 0 ]

23 
pys
 = 
lidar
 [ : , 1 ]

24 
pzs
 = 
lidar
 [ : , 2 ]

25 
prs
 = 
lidar
 [ : , 3 ]

28 
qxs
 = ( ( 
pxs
 - 
TOP_X_MIN
 ) / 
TOP_X_DIVISION
 ) . 
astype
 ( 
np
 . 
int32
 )

29 
qys
 = ( ( 
pys
 - 
TOP_Y_MIN
 ) / 
TOP_Y_DIVISION
 ) . 
astype
 ( 
np
 . 
int32
 )

31 
qzs
 = ( 
pzs
 - 
TOP_Z_MIN
 ) / 
TOP_Z_DIVISION

32 
quantized
 = 
np
 . 
dstack
 ( ( 
qxs
 , 
qys
 , 
qzs
 , 
prs
 ) ) . 
squeeze
 ( )

37 
X0
 , 
Xn
 = 0 , 
int
 ( ( 
TOP_X_MAX
 - 
TOP_X_MIN
 ) / 
TOP_X_DIVISION
 )

38 
Y0
 , 
Yn
 = 0 , 
int
 ( ( 
TOP_Y_MAX
 - 
TOP_Y_MIN
 ) / 
TOP_Y_DIVISION
 )

39 
Z0
 , 
Zn
 = 0 , 
int
 ( ( 
TOP_Z_MAX
 - 
TOP_Z_MIN
 ) / 
TOP_Z_DIVISION
 )

41 
height
 = 
Xn
 - 
X0

42 
width
 = 
Yn
 - 
Y0

43 
channel
 = 
Zn
 - 
Z0
 + 2

46 
top
 = 
np
 . 
zeros
 ( 
shape
 = ( 
height
 , 
width
 , 
channel
 ) , 
dtype
 = 
np
 . 
float32
 )

52 for 
x
 in 
range
 ( 
Xn
 ) :

53 
ix
 = 
np
 . 
where
 ( 
quantized
 [ : , 0 ] == 
x
 )

54 
quantized_x
 = 
quantized
 [ 
ix
 ]

55 if 
len
 ( 
quantized_x
 ) == 0 : continue

56 
yy
 = - 
x

58 for 
y
 in 
range
 ( 
Yn
 ) :

59 
iy
 = 
np
 . 
where
 ( 
quantized_x
 [ : , 1 ] == 
y
 )

60 
quantized_xy
 = 
quantized_x
 [ 
iy
 ]

61 
count
 = 
len
 ( 
quantized_xy
 )

62 if 
count
 == 0 : continue

63 
xx
 = - 
y

65 
top
 [ 
yy
 , 
xx
 , 
Zn
 + 1 ] = 
min
 ( 1 , 
np
 . 
log
 ( 
count
 + 1 ) / 
math
 . 
log
 ( 32 ) )

66 
max_height_point
 = 
np
 . 
argmax
 ( 
quantized_xy
 [ : , 2 ] )

67 
top
 [ 
yy
 , 
xx
 , 
Zn
 ] = 
quantized_xy
 [ 
max_height_point
 , 3 ]

69 for 
z
 in 
range
 ( 
Zn
 ) :

71 
iz
 = 
np
 . 
where
 ( ( 
quantized_xy
 [ : , 2 ] >= 
z
 ) & ( 
quantized_xy
 [ : , 2 ] < 
z
 + 1 ) )

72 
quantized_xyz
 = 
quantized_xy
 [ 
iz
 ]

73 if 
len
 ( 
quantized_xyz
 ) == 0 : continue

74 
zz
 = 
z

77 
max_height
 = 
max
 ( 0 , 
np
 . 
max
 ( 
quantized_xyz
 [ : , 2 ] ) - 
z
 )

78 
top
 [ 
yy
 , 
xx
 , 
zz
 ] = 
max_height

79 return 
top
 
	}

83 
TOP_X_MIN
 = 0

84 
TOP_X_MAX
 = 40

85 
TOP_Y_MIN
 = - 20

86 
TOP_Y_MAX
 = 20

87 
TOP_Z_MIN
 = - 2

88 
TOP_Z_MAX
 = 1.0

89 
TOP_X_DIVISION
 = 0.1

90 
TOP_Y_DIVISION
 = 0.1

91 
TOP_Z_DIVISION
 = 0.4

92 
FRONT_PHI_MIN
 = - 20

93 
FRONT_PHI_MAX
 = - 
FRONT_PHI_MIN

94 
FRONT_THETA_MIN
 = - 45

95 
FRONT_THETA_MAX
 = - 
FRONT_THETA_MIN

96 
FRONT_PHI_DIVISION
 = 0.1

97 
FRONT_THETA_DIVISION
 = 0.2

134 
Xn
 = 
int
 ( ( 
TOP_X_MAX
 - 
TOP_X_MIN
 ) / 
TOP_X_DIVISION
 )

135 
Yn
 = 
int
 ( ( 
TOP_Y_MAX
 - 
TOP_Y_MIN
 ) / 
TOP_Y_DIVISION
 )

136 
Zn
 = 
int
 ( ( 
TOP_Z_MAX
 - 
TOP_Z_MIN
 ) / 
TOP_Z_DIVISION
 )

138 
Rn
 = 
int
 ( ( 
FRONT_PHI_MAX
 - 
FRONT_PHI_MIN
 ) / 
FRONT_PHI_DIVISION
 )

139 
Cn
 = 
int
 ( ( 
FRONT_THETA_MAX
 - 
FRONT_THETA_MIN
 ) / 
FRONT_THETA_DIVISION
 )

140 
Fn
 = 3

142 
top_paras
 = ( 
TOP_X_MIN
 , 
TOP_X_MAX
 , 
TOP_Y_MIN
 , 
TOP_Y_MAX
 , 
TOP_Z_MIN
 , 
TOP_Z_MAX
 , 
TOP_X_DIVISION
 , 
TOP_Y_DIVISION
 , 
TOP_Z_DIVISION
 , 
Xn
 , 
Yn
 , 
Zn
 )

143 
front_paras
 = ( 
FRONT_PHI_MIN
 , 
FRONT_PHI_MAX
 , 
FRONT_THETA_MAX
 , 
FRONT_THETA_MAX
 , 
FRONT_PHI_DIVISION
 , 
FRONT_THETA_DIVISION
 , 
Rn
 , 
Cn
 , 
Fn
 )

150 
raw
 = 
np
 . 
load
 ( "raw_0.npy" )

151 
num
 = 
raw
 . 
shape
 [ 0 ]

157 
top_flip
 = 
np
 . 
ones
 ( ( 
Xn
 , 
Yn
 , 
Zn
 + 2 ) , 
dtype
 = 
np
 . 
float32
 )

161 
front_flip
 = 
np
 . 
ones
 ( ( 
Rn
 , 
Cn
 , 
Fn
 ) , 
dtype
 = 
np
 . 
float32
 )

171 from 
	~createTopAndFrontMaps
 import *

172 
createTopAndFrontMaps
 ( 
raw
 , 
num
 , 
top_flip
 , 
front_flip
 , 
top_paras
 , 
front_paras
 , './LidarTopAndFrontPreprocess.so' )

173 
top
 = 
np
 . 
flipud
 ( 
np
 . 
fliplr
 ( 
top_flip
 ) )

174 
front
 = 
np
 . 
flipud
 ( 
np
 . 
fliplr
 ( 
front_flip
 ) )

182 import 
	~matplotlib.pyplot
 as 
plt

184 
map_num
 = 
len
 ( 
top
 [ 0 ] [ 0 ] )

185 
plt
 . 
figure
 ( 'C version - top view' )

186 for 
i
 in 
range
 ( 
map_num
 ) :

187 
plt
 . 
subplot
 ( 1 , 
map_num
 , 
i
 + 1 )

188 
plt
 . 
imshow
 ( 
top
 [ : , : , 
i
 ] )

189 
plt
 . 
gray
 ( )

193 
python_top
 = 
lidar_to_top
 ( 
raw
 )

195 
map_num
 = 
len
 ( 
python_top
 [ 0 ] [ 0 ] )

196 
plt
 . 
figure
 ( 'Python version - top view' )

197 for 
i
 in 
range
 ( 
map_num
 ) :

198 
plt
 . 
subplot
 ( 1 , 
map_num
 , 
i
 + 1 )

199 
plt
 . 
imshow
 ( 
python_top
 [ : , : , 
i
 ] )

200 
plt
 . 
gray
 ( )

201 
plt
 . 
show
 ( )

203 for 
i
 in 
range
 ( 
map_num
 - 2 ) :

204 
print
 ( 'Top view layer ' , 
i
 , ':' )

205 
print
 ( '- max in    C   ver:' , 
max
 ( 
top
 [ : , : , 
i
 ] . 
flatten
 ( ) ) )

206 
print
 ( '- max in Python ver:' , 
max
 ( 
python_top
 [ : , : , 
i
 ] . 
flatten
 ( ) ) )

207 
print
 ( '- min in    C   ver:' , 
min
 ( 
top
 [ : , : , 
i
 ] . 
flatten
 ( ) ) )

208 
print
 ( '- min in Python ver:' , 
min
 ( 
python_top
 [ : , : , 
i
 ] . 
flatten
 ( ) ) )

210 
print
 ( 'Top view layer ' , 
map_num
 - 2 , ' (density map) :' )

211 
print
 ( '- max in    C   ver:' , 
max
 ( 
top
 [ : , : , 
map_num
 - 2 ] . 
flatten
 ( ) ) )

212 
print
 ( '- max in Python ver:' , 
max
 ( 
python_top
 [ : , : , 
map_num
 - 2 ] . 
flatten
 ( ) ) )

213 
print
 ( '- min in    C   ver:' , 
min
 ( 
top
 [ : , : , 
map_num
 - 2 ] . 
flatten
 ( ) ) )

214 
print
 ( '- min in Python ver:' , 
min
 ( 
python_top
 [ : , : , 
map_num
 - 2 ] . 
flatten
 ( ) ) )

216 
print
 ( 'Top view layer ' , 
map_num
 - 1 , ' (intensity map) :' )

217 
print
 ( '- max in    C   ver:' , 
max
 ( 
top
 [ : , : , 
map_num
 - 1 ] . 
flatten
 ( ) ) )

218 
print
 ( '- max in Python ver:' , 
max
 ( 
python_top
 [ : , : , 
map_num
 - 1 ] . 
flatten
 ( ) ) )

219 
print
 ( '- min in    C   ver:' , 
min
 ( 
top
 [ : , : , 
map_num
 - 1 ] . 
flatten
 ( ) ) )

220 
print
 ( '- min in Python ver:' , 
min
 ( 
python_top
 [ : , : , 
map_num
 - 1 ] . 
flatten
 ( ) ) )

225 
plt
 . 
figure
 ( 'height map - front view' )

226 
plt
 . 
imshow
 ( 
front
 [ : , : , 0 ] )

227 
plt
 . 
gray
 ( )

228 
plt
 . 
show
 ( )

230 
plt
 . 
figure
 ( 'distance map - front view' )

231 
plt
 . 
imshow
 ( 
front
 [ : , : , 1 ] )

232 
plt
 . 
gray
 ( )

233 
plt
 . 
show
 ( )

235 
plt
 . 
figure
 ( 'intensity map - front view' )

236 
plt
 . 
imshow
 ( 
front
 [ : , : , 2 ] )

237 
plt
 . 
gray
 ( )

238 
plt
 . 
show
 ( )

240 
print
 ( 'Front view height map :' )

241 
print
 ( '- max value : ' , 
max
 ( 
front
 [ : , : , 0 ] . 
flatten
 ( ) ) )

242 
print
 ( '- min value : ' , 
min
 ( 
front
 [ : , : , 0 ] . 
flatten
 ( ) ) )

243 
print
 ( 'Front view distance map :' )

244 
print
 ( '- max value : ' , 
max
 ( 
front
 [ : , : , 1 ] . 
flatten
 ( ) ) )

245 
print
 ( '- min value : ' , 
min
 ( 
front
 [ : , : , 1 ] . 
flatten
 ( ) ) )

246 
print
 ( 'Front view intensity map :' )

247 
print
 ( '- max value : ' , 
max
 ( 
front
 [ : , : , 2 ] . 
flatten
 ( ) ) )

248 
print
 ( '- min value : ' , 
min
 ( 
front
 [ : , : , 2 ] . 
flatten
 ( ) ) )


	@./lidar_data_preprocess/Python_to_C_Interface/ver3/createTopMaps.py

1 import 
	~ctypes

2 import 
	~numpy
 as 
np

4 def 
	$createTopMaps
 ( 
raw
 , 
num
 , 
top_flip
 , 
top_paras
 , 
c_lib_path
 ) :

5 [ 
TOP_X_MIN
 , 
TOP_X_MAX
 , 
TOP_Y_MIN
 ,

6 
TOP_Y_MAX
 , 
TOP_Z_MIN
 , 
TOP_Z_MAX
 ,

7 
TOP_X_DIVISION
 , 
TOP_Y_DIVISION
 , 
TOP_Z_DIVISION
 ,

8 
Xn
 , 
Yn
 , 
Zn
 ] = 
top_paras

11 
SharedLib
 = 
ctypes
 . 
cdll
 . 
LoadLibrary
 ( 
c_lib_path
 )

15 
SharedLib
 . 
createTopMaps
 ( 
ctypes
 . 
c_void_p
 ( 
raw
 . 
ctypes
 . 
data
 ) ,

16 
ctypes
 . 
c_int
 ( 
num
 ) ,

17 
ctypes
 . 
c_void_p
 ( 
top_flip
 . 
ctypes
 . 
data
 ) ,

18 
ctypes
 . 
c_float
 ( 
TOP_X_MIN
 ) , 
ctypes
 . 
c_float
 ( 
TOP_X_MAX
 ) ,

19 
ctypes
 . 
c_float
 ( 
TOP_Y_MIN
 ) , 
ctypes
 . 
c_float
 ( 
TOP_Y_MAX
 ) ,

20 
ctypes
 . 
c_float
 ( 
TOP_Z_MIN
 ) , 
ctypes
 . 
c_float
 ( 
TOP_Z_MAX
 ) ,

21 
ctypes
 . 
c_float
 ( 
TOP_X_DIVISION
 ) , 
ctypes
 . 
c_float
 ( 
TOP_Y_DIVISION
 ) , 
ctypes
 . 
c_float
 ( 
TOP_Z_DIVISION
 ) ,

22 
ctypes
 . 
c_int
 ( 
Xn
 ) , 
ctypes
 . 
c_int
 ( 
Yn
 ) , 
ctypes
 . 
c_int
 ( 
Zn
 )

23 ) 
	}


	@./lidar_data_preprocess/Python_to_C_Interface/ver3/ExampleUsage_Top.py

1 import 
	~numpy
 as 
np

2 import 
	~math

5 def 
	$lidar_to_top
 ( 
lidar
 ) :

6 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 0 ] > 
TOP_X_MIN
 )

7 
lidar
 = 
lidar
 [ 
idx
 ]

8 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 0 ] < 
TOP_X_MAX
 )

9 
lidar
 = 
lidar
 [ 
idx
 ]

11 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 1 ] > 
TOP_Y_MIN
 )

12 
lidar
 = 
lidar
 [ 
idx
 ]

13 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 1 ] < 
TOP_Y_MAX
 )

14 
lidar
 = 
lidar
 [ 
idx
 ]

16 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 2 ] > 
TOP_Z_MIN
 )

17 
lidar
 = 
lidar
 [ 
idx
 ]

18 
idx
 = 
np
 . 
where
 ( 
lidar
 [ : , 2 ] < 
TOP_Z_MAX
 )

19 
lidar
 = 
lidar
 [ 
idx
 ]

21 
pxs
 = 
lidar
 [ : , 0 ]

22 
pys
 = 
lidar
 [ : , 1 ]

23 
pzs
 = 
lidar
 [ : , 2 ]

24 
prs
 = 
lidar
 [ : , 3 ]

27 
qxs
 = ( ( 
pxs
 - 
TOP_X_MIN
 ) / 
TOP_X_DIVISION
 ) . 
astype
 ( 
np
 . 
int32
 )

28 
qys
 = ( ( 
pys
 - 
TOP_Y_MIN
 ) / 
TOP_Y_DIVISION
 ) . 
astype
 ( 
np
 . 
int32
 )

30 
qzs
 = ( 
pzs
 - 
TOP_Z_MIN
 ) / 
TOP_Z_DIVISION

31 
quantized
 = 
np
 . 
dstack
 ( ( 
qxs
 , 
qys
 , 
qzs
 , 
prs
 ) ) . 
squeeze
 ( )

36 
X0
 , 
Xn
 = 0 , 
int
 ( ( 
TOP_X_MAX
 - 
TOP_X_MIN
 ) / 
TOP_X_DIVISION
 )

37 
Y0
 , 
Yn
 = 0 , 
int
 ( ( 
TOP_Y_MAX
 - 
TOP_Y_MIN
 ) / 
TOP_Y_DIVISION
 )

38 
Z0
 , 
Zn
 = 0 , 
int
 ( ( 
TOP_Z_MAX
 - 
TOP_Z_MIN
 ) / 
TOP_Z_DIVISION
 )

40 
height
 = 
Xn
 - 
X0

41 
width
 = 
Yn
 - 
Y0

42 
channel
 = 
Zn
 - 
Z0
 + 2

45 
top
 = 
np
 . 
zeros
 ( 
shape
 = ( 
height
 , 
width
 , 
channel
 ) , 
dtype
 = 
np
 . 
float32
 )

51 for 
x
 in 
range
 ( 
Xn
 ) :

52 
ix
 = 
np
 . 
where
 ( 
quantized
 [ : , 0 ] == 
x
 )

53 
quantized_x
 = 
quantized
 [ 
ix
 ]

54 if 
len
 ( 
quantized_x
 ) == 0 : continue

55 
yy
 = - 
x

57 for 
y
 in 
range
 ( 
Yn
 ) :

58 
iy
 = 
np
 . 
where
 ( 
quantized_x
 [ : , 1 ] == 
y
 )

59 
quantized_xy
 = 
quantized_x
 [ 
iy
 ]

60 
count
 = 
len
 ( 
quantized_xy
 )

61 if 
count
 == 0 : continue

62 
xx
 = - 
y

64 
top
 [ 
yy
 , 
xx
 , 
Zn
 + 1 ] = 
min
 ( 1 , 
np
 . 
log
 ( 
count
 + 1 ) / 
math
 . 
log
 ( 32 ) )

65 
max_height_point
 = 
np
 . 
argmax
 ( 
quantized_xy
 [ : , 2 ] )

66 
top
 [ 
yy
 , 
xx
 , 
Zn
 ] = 
quantized_xy
 [ 
max_height_point
 , 3 ]

68 for 
z
 in 
range
 ( 
Zn
 ) :

70 
iz
 = 
np
 . 
where
 ( ( 
quantized_xy
 [ : , 2 ] >= 
z
 ) & ( 
quantized_xy
 [ : , 2 ] < 
z
 + 1 ) )

71 
quantized_xyz
 = 
quantized_xy
 [ 
iz
 ]

72 if 
len
 ( 
quantized_xyz
 ) == 0 : continue

73 
zz
 = 
z

76 
max_height
 = 
max
 ( 0 , 
np
 . 
max
 ( 
quantized_xyz
 [ : , 2 ] ) - 
z
 )

77 
top
 [ 
yy
 , 
xx
 , 
zz
 ] = 
max_height

78 return 
top
 
	}

82 
TOP_X_MIN
 = 0

83 
TOP_X_MAX
 = 40

84 
TOP_Y_MIN
 = - 20

85 
TOP_Y_MAX
 = 20

86 
TOP_Z_MIN
 = - 2

87 
TOP_Z_MAX
 = 1.0

88 
TOP_X_DIVISION
 = 0.1

89 
TOP_Y_DIVISION
 = 0.1

90 
TOP_Z_DIVISION
 = 0.4

93 
TOP_X_MIN
 = - 45

94 
TOP_X_MAX
 = 45

95 
TOP_Y_MIN
 = - 10

96 
TOP_Y_MAX
 = 10

97 
TOP_Z_MIN
 = - 3

98 
TOP_Z_MAX
 = 1.0

99 
TOP_X_DIVISION
 = 0.2

100 
TOP_Y_DIVISION
 = 0.2

101 
TOP_Z_DIVISION
 = 1

116 
Xn
 = 
int
 ( ( 
TOP_X_MAX
 - 
TOP_X_MIN
 ) / 
TOP_X_DIVISION
 )

117 
Yn
 = 
int
 ( ( 
TOP_Y_MAX
 - 
TOP_Y_MIN
 ) / 
TOP_Y_DIVISION
 )

118 
Zn
 = 
int
 ( ( 
TOP_Z_MAX
 - 
TOP_Z_MIN
 ) / 
TOP_Z_DIVISION
 )

120 
top_paras
 = ( 
TOP_X_MIN
 , 
TOP_X_MAX
 , 
TOP_Y_MIN
 , 
TOP_Y_MAX
 , 
TOP_Z_MIN
 , 
TOP_Z_MAX
 , 
TOP_X_DIVISION
 , 
TOP_Y_DIVISION
 , 
TOP_Z_DIVISION
 , 
Xn
 , 
Yn
 , 
Zn
 )

127 
raw
 = 
np
 . 
load
 ( "raw_0.npy" )

128 
raw
 = 
np
 . 
load
 ( "./lidar_dumps/00000.npy" )

129 
num
 = 
raw
 . 
shape
 [ 0 ]

136 
top_flip
 = 
np
 . 
ones
 ( ( 
Xn
 , 
Yn
 , 
Zn
 + 2 ) , 
dtype
 = 
np
 . 
float32
 )

146 from 
	~createTopMaps
 import *

147 
createTopMaps
 ( 
raw
 , 
num
 , 
top_flip
 , 
top_paras
 , './LidarTopPreprocess.so' )

148 
top
 = 
np
 . 
flipud
 ( 
np
 . 
fliplr
 ( 
top_flip
 ) )

156 import 
	~matplotlib.pyplot
 as 
plt

158 
map_num
 = 
len
 ( 
top
 [ 0 ] [ 0 ] )

159 
plt
 . 
figure
 ( 'C version - top view' )

160 for 
i
 in 
range
 ( 
map_num
 ) :

161 
plt
 . 
subplot
 ( 1 , 
map_num
 , 
i
 + 1 )

162 
plt
 . 
imshow
 ( 
top
 [ : , : , 
i
 ] )

163 
plt
 . 
gray
 ( )

166 
python_top
 = 
lidar_to_top
 ( 
raw
 )

169 
map_num
 = 
len
 ( 
python_top
 [ 0 ] [ 0 ] )

170 
plt
 . 
figure
 ( 'Python version - top view' )

171 for 
i
 in 
range
 ( 
map_num
 ) :

172 
plt
 . 
subplot
 ( 1 , 
map_num
 , 
i
 + 1 )

173 
plt
 . 
imshow
 ( 
python_top
 [ : , : , 
i
 ] )

174 
plt
 . 
gray
 ( )

175 
plt
 . 
show
 ( )

177 for 
i
 in 
range
 ( 
map_num
 - 2 ) :

178 
print
 ( 'Top view layer ' , 
i
 , ':' )

179 
print
 ( '- max in    C   ver:' , 
max
 ( 
top
 [ : , : , 
i
 ] . 
flatten
 ( ) ) )

180 
print
 ( '- max in Python ver:' , 
max
 ( 
python_top
 [ : , : , 
i
 ] . 
flatten
 ( ) ) )

181 
print
 ( '- min in    C   ver:' , 
min
 ( 
top
 [ : , : , 
i
 ] . 
flatten
 ( ) ) )

182 
print
 ( '- min in Python ver:' , 
min
 ( 
python_top
 [ : , : , 
i
 ] . 
flatten
 ( ) ) )

184 
print
 ( 'Top view layer ' , 
map_num
 - 2 , ' (density map) :' )

185 
print
 ( '- max in    C   ver:' , 
max
 ( 
top
 [ : , : , 
map_num
 - 2 ] . 
flatten
 ( ) ) )

186 
print
 ( '- max in Python ver:' , 
max
 ( 
python_top
 [ : , : , 
map_num
 - 2 ] . 
flatten
 ( ) ) )

187 
print
 ( '- min in    C   ver:' , 
min
 ( 
top
 [ : , : , 
map_num
 - 2 ] . 
flatten
 ( ) ) )

188 
print
 ( '- min in Python ver:' , 
min
 ( 
python_top
 [ : , : , 
map_num
 - 2 ] . 
flatten
 ( ) ) )

189 
print
 ( 'Top view layer ' , 
map_num
 - 1 , ' (intensity map) :' )

190 
print
 ( '- max in    C   ver:' , 
max
 ( 
top
 [ : , : , 
map_num
 - 1 ] . 
flatten
 ( ) ) )

191 
print
 ( '- max in Python ver:' , 
max
 ( 
python_top
 [ : , : , 
map_num
 - 1 ] . 
flatten
 ( ) ) )

192 
print
 ( '- min in    C   ver:' , 
min
 ( 
top
 [ : , : , 
map_num
 - 1 ] . 
flatten
 ( ) ) )

193 
print
 ( '- min in Python ver:' , 
min
 ( 
python_top
 [ : , : , 
map_num
 - 1 ] . 
flatten
 ( ) ) )


	@./lidar_data_preprocess/Python_to_C_Interface/ver2/SampleProgram.py

1 import 
	~ctypes

2 import 
	~numpy
 as 
np

3 import 
	~matplotlib.pyplot
 as 
plt

4 import 
	~math

7 
TOP_X_MIN
 = - 45

8 
TOP_X_MAX
 = 45

9 
TOP_Y_MIN
 = - 10

10 
TOP_Y_MAX
 = 10

11 
TOP_Z_MIN
 = - 3

12 
TOP_Z_MAX
 = 1.0

13 
TOP_X_DIVISION
 = 0.2

14 
TOP_Y_DIVISION
 = 0.2

15 
TOP_Z_DIVISION
 = 0.5

17 
Xn
 = 
int
 ( ( 
TOP_X_MAX
 - 
TOP_X_MIN
 ) // 
TOP_X_DIVISION
 ) + 1

18 
Yn
 = 
int
 ( ( 
TOP_Y_MAX
 - 
TOP_Y_MIN
 ) // 
TOP_Y_DIVISION
 ) + 1

19 
Zn
 = 
int
 ( ( 
TOP_Z_MAX
 - 
TOP_Z_MIN
 ) / 
TOP_Z_DIVISION
 )

20 
height
 = 
Xn

21 
width
 = 
Yn

22 
channel
 = 
Zn
 + 2

24 
print
 ( 'Feature Maps Size (height, width, channel) is (' + 
str
 ( 
height
 ) + ", " + 
str
 ( 
width
 ) + ", " + 
str
 ( 
channel
 ) + ")" )

25 
print
 ( 'LiDAR data pre-processing starting...' )

28 
top
 = 
np
 . 
ones
 ( ( 
height
 , 
width
 , 
channel
 ) , 
dtype
 = 
np
 . 
double
 )

31 
SharedLib
 = 
ctypes
 . 
cdll
 . 
LoadLibrary
 ( './LidarPreprocess.so' )

34 
lidar_data_src_dir
 = "../../raw/kitti/2011_09_26/2011_09_26_drive_0001_sync/velodyne_points/data/"

37 for 
frameNum
 in 
range
 ( 0 , 1 ) :

38 
lidar_data_src_path
 = 
lidar_data_src_dir
 + 
str
 ( 
frameNum
 ) . 
zfill
 ( 10 ) + ".bin"

41 
lidar_data_src_path
 = "0000000002.bin"

43 
b_lidar_data_src_path
 = 
lidar_data_src_path
 . 
encode
 ( 'utf-8' )

46 
SharedLib
 . 
createTopViewMaps
 ( 
ctypes
 . 
c_void_p
 ( 
top
 . 
ctypes
 . 
data
 ) , 
ctypes
 . 
c_char_p
 ( 
b_lidar_data_src_path
 ) , 
ctypes
 . 
c_float
 ( 
TOP_X_MIN
 ) ,

47 
ctypes
 . 
c_float
 ( 
TOP_X_MAX
 ) , 
ctypes
 . 
c_float
 ( 
TOP_Y_MIN
 ) , 
ctypes
 . 
c_float
 ( 
TOP_Z_MAX
 ) , 
ctypes
 . 
c_float
 ( 
TOP_Z_MIN
 ) ,

48 
ctypes
 . 
c_float
 ( 
TOP_Z_MAX
 ) , 
ctypes
 . 
c_float
 ( 
TOP_X_DIVISION
 ) , 
ctypes
 . 
c_float
 ( 
TOP_Y_DIVISION
 ) , 
ctypes
 . 
c_float
 ( 
TOP_Z_DIVISION
 ) ,

49 
ctypes
 . 
c_int
 ( 
Xn
 ) , 
ctypes
 . 
c_int
 ( 
Yn
 ) , 
ctypes
 . 
c_int
 ( 
Zn
 ) )

52 
top
 = 
np
 . 
flipud
 ( 
np
 . 
fliplr
 ( 
top
 ) )

81 
print
 ( 'LiDAR data pre-processing complete for' , 
frameNum
 + 1 , 'frames' )


	@./lidar_data_preprocess/python_call_liblidar_test_ubuntu.py

1 from 
	~ctypes
 import *

5 
liblidar
 = 
CDLL
 ( './liblidar.so' )

9 
lidar_data_src_dir
 = "./raw/kitti/2011_09_26/2011_09_26_drive_0001_sync/velodyne_points/data/"

10 
top_image_dst_dir
 = "./preprocessed/kitti/top_image/"

11 
front_image_dst_dir
 = "./preprocessed/kitti/front_image/"

12 
delay
 = "0"

14 
argc
 = "5"

17 
b_argc
 = 
argc
 . 
encode
 ( 'utf-8' )

18 
b_lidar_data_src_dir
 = 
lidar_data_src_dir
 . 
encode
 ( 'utf-8' )

19 
b_top_image_dst_dir
 = 
top_image_dst_dir
 . 
encode
 ( 'utf-8' )

20 
b_front_image_dst_dir
 = 
front_image_dst_dir
 . 
encode
 ( 'utf-8' )

21 
b_delay
 = 
delay
 . 
encode
 ( 'utf-8' )

23 def 
	$call_liblidar
 ( 
L
 ) :

24 
arr
 = ( 
c_char_p
 * 
len
 ( 
L
 ) ) ( )

25 
arr
 [ : ] = 
L

26 
liblidar
 . 
main
 ( 
len
 ( 
L
 ) , 
arr
 ) 
	}

28 
call_liblidar
 ( [ 
b_argc
 , 
b_lidar_data_src_dir
 , 
b_top_image_dst_dir
 , 
b_front_image_dst_dir
 , 
b_delay
 ] )


	@./tracklets/generate_tracklet.py

5 def 
	$writeln
 ( 
f
 , 
string
 , 
tab_count
 , 
tab_as_space
 = False ) :

6 
tab_spaces
 = 4

7 
indent_str
 = " " * 
tab_spaces
 * 
tab_count
 if 
tab_as_space
 else "\t" * 
tab_count

8 
f
 . 
write
 ( 
indent_str
 + 
string
 + "\n" )

9 pass 
	}

12 class 
	cTracklet
 ( 
object
 ) :

14 def 
	$__init__
 ( 
self
 , 
object_type
 , 
l
 , 
w
 , 
h
 , 
first_frame
 = 0 ) :

15 
self
 . 
object_type
 = 
object_type

16 
self
 . 
h
 = 
h

17 
self
 . 
w
 = 
w

18 
self
 . 
l
 = 
l

19 
self
 . 
first_frame
 = 
first_frame

20 
self
 . 
poses
 = [ ] 
	}

22 def 
	$write_xml
 ( 
self
 , 
f
 , 
class_id
 , 
tab_level
 = 0 ) :

23 
writeln
 ( 
f
 , '<item class_id="{:d}" tracking_level="0" version="1">' . 
format
 ( 
class_id
 ) , 
tab_level
 )

24 
tab_level
 += 1

25 
class_id
 += 1

26 
writeln
 ( 
f
 , '<objectType>{:s}</objectType>' . 
format
 ( 
self
 . 
object_type
 ) , 
tab_level
 )

27 
writeln
 ( 
f
 , '<h>{:.16f}</h>' . 
format
 ( 
self
 . 
h
 ) , 
tab_level
 )

28 
writeln
 ( 
f
 , '<w>{:.16f}</w>' . 
format
 ( 
self
 . 
w
 ) , 
tab_level
 )

29 
writeln
 ( 
f
 , '<l>{:.16f}</l>' . 
format
 ( 
self
 . 
l
 ) , 
tab_level
 )

30 
writeln
 ( 
f
 , '<first_frame>{:d}</first_frame>' . 
format
 ( 
self
 . 
first_frame
 ) , 
tab_level
 )

31 
writeln
 ( 
f
 , '<poses class_id="{:d}" tracking_level="0" version="0">' . 
format
 ( 
class_id
 ) , 
tab_level
 )

32 
class_id
 += 1

33 
tab_level
 += 1

34 
writeln
 ( 
f
 , '<count>{:d}</count>' . 
format
 ( 
len
 ( 
self
 . 
poses
 ) ) , 
tab_level
 )

35 
writeln
 ( 
f
 , '<item_version>2</item_version>' , 
tab_level
 )

36 
first_pose
 = True

37 for 
p
 in 
self
 . 
poses
 :

38 if 
first_pose
 :

39 
writeln
 ( 
f
 , '<item class_id="%d" tracking_level="0" version="2">' % 
class_id
 , 
tab_level
 )

40 
first_pose
 = False

42 
writeln
 ( 
f
 , '<item>' , 
tab_level
 )

43 
tab_level
 += 1

44 
class_id
 += 1

45 
writeln
 ( 
f
 , '<tx>{:.16f}</tx>' . 
format
 ( 
p
 [ 'tx' ] ) , 
tab_level
 )

46 
writeln
 ( 
f
 , '<ty>{:.16f}</ty>' . 
format
 ( 
p
 [ 'ty' ] ) , 
tab_level
 )

47 
writeln
 ( 
f
 , '<tz>{:.16f}</tz>' . 
format
 ( 
p
 [ 'tz' ] ) , 
tab_level
 )

48 
writeln
 ( 
f
 , '<rx>{:.16f}</rx>' . 
format
 ( 
p
 [ 'rx' ] ) , 
tab_level
 )

49 
writeln
 ( 
f
 , '<ry>{:.16f}</ry>' . 
format
 ( 
p
 [ 'ry' ] ) , 
tab_level
 )

50 
writeln
 ( 
f
 , '<rz>{:.16f}</rz>' . 
format
 ( 
p
 [ 'rz' ] ) , 
tab_level
 )

51 
writeln
 ( 
f
 , '<state>1</state>' , 
tab_level
 )

52 
writeln
 ( 
f
 , '<occlusion>-1</occlusion>' , 
tab_level
 )

53 
writeln
 ( 
f
 , '<occlusion_kf>-1</occlusion_kf>' , 
tab_level
 )

54 
writeln
 ( 
f
 , '<truncation>-1</truncation>' , 
tab_level
 )

55 
writeln
 ( 
f
 , '<amt_occlusion>0.0</amt_occlusion>' , 
tab_level
 )

56 
writeln
 ( 
f
 , '<amt_occlusion_kf>-1</amt_occlusion_kf>' , 
tab_level
 )

57 
writeln
 ( 
f
 , '<amt_border_l>0.0</amt_border_l>' , 
tab_level
 )

58 
writeln
 ( 
f
 , '<amt_border_r>0.0</amt_border_r>' , 
tab_level
 )

59 
writeln
 ( 
f
 , '<amt_border_kf>-1</amt_border_kf>' , 
tab_level
 )

60 
tab_level
 -= 1

61 
writeln
 ( 
f
 , '</item>' , 
tab_level
 )

62 
tab_level
 -= 1

63 
writeln
 ( 
f
 , '</poses>' , 
tab_level
 )

64 
writeln
 ( 
f
 , '<finished>1</finished>' , 
tab_level
 )

65 
tab_level
 -= 1

66 
writeln
 ( 
f
 , '</item>' , 
tab_level
 ) 
	}

69 class 
	cTrackletCollection
 ( 
object
 ) :

71 def 
	$__init__
 ( 
self
 ) :

72 
self
 . 
tracklets
 = [ ] 
	}

74 def 
	$write_xml
 ( 
self
 , 
filename
 ) :

75 
tab_level
 = 0

76 with 
open
 ( 
filename
 , 
mode
 = 'w' ) as 
f
 :

77 
writeln
 ( 
f
 , r'<?xml version="1.0" encoding="UTF-8" standalone="yes" ?>' , 
tab_level
 )

78 
writeln
 ( 
f
 , r'<!DOCTYPE boost_serialization>' , 
tab_level
 )

79 
writeln
 ( 
f
 , r'<boost_serialization signature="serialization::archive" version="9">' , 
tab_level
 )

80 
writeln
 ( 
f
 , r'<tracklets class_id="0" tracking_level="0" version="0">' , 
tab_level
 )

81 
tab_level
 += 1

82 
writeln
 ( 
f
 , '<count>%d</count>' % 
len
 ( 
self
 . 
tracklets
 ) , 
tab_level
 )

83 
writeln
 ( 
f
 , '<item_version>1</item_version> ' , 
tab_level
 )

84 
class_id
 = 1

85 for 
obj
 in 
self
 . 
tracklets
 :

88 
obj
 . 
write_xml
 ( 
f
 , 
class_id
 , 
tab_level
 )

89 
tab_level
 -= 1

90 
writeln
 ( 
f
 , '</tracklets>' , 
tab_level
 )

91 
writeln
 ( 
f
 , '</boost_serialization> ' , 
tab_level
 )

92 
f
 . 
close
 ( ) 
	}


	@./tracklets/parse_tracklet_round.py

26 from 
	~__future__
 import 
print_function

27 from 
	~xml.etree.ElementTree
 import 
ElementTree

28 import 
	~numpy
 as 
np

29 import 
	~itertools

30 from 
	~warnings
 import 
warn

32 
STATE_UNSET
 = 0

33 
STATE_INTERP
 = 1

34 
STATE_LABELED
 = 2

35 
stateFromText
 = { '0' : 
STATE_UNSET
 , '1' : 
STATE_INTERP
 , '2' : 
STATE_LABELED
 }

37 
OCC_UNSET
 = 255

38 
OCC_VISIBLE
 = 0

39 
OCC_PARTLY
 = 1

40 
OCC_FULLY
 = 2

41 
occFromText
 = { '-1' : 
OCC_UNSET
 , '0' : 
OCC_VISIBLE
 , '1' : 
OCC_PARTLY
 , '2' : 
OCC_FULLY
 }

43 
TRUNC_UNSET
 = 255

44 
TRUNC_IN_IMAGE
 = 0

45 
TRUNC_TRUNCATED
 = 1

46 
TRUNC_OUT_IMAGE
 = 2

47 
TRUNC_BEHIND_IMAGE
 = 3

48 
truncFromText
 = { '-1'

49 : 
TRUNC_UNSET
 , '99'

50 : 
TRUNC_UNSET
 , '0'

51 : 
TRUNC_IN_IMAGE
 , '1'

52 : 
TRUNC_TRUNCATED
 , '2'

53 : 
TRUNC_OUT_IMAGE
 , '3'

54 : 
TRUNC_BEHIND_IMAGE
 }

57 class 
	cTracklet
 ( 
object
 ) :

77 
object_type
 = None

78 
size
 = None

79 
first_frame
 = None

80 
trans
 = None

81 
rots
 = None

82 
states
 = None

83 
occs
 = None

84 
truncs
 = None

85 
amt_occs
 = None

86 
amt_borders
 = None

87 
num_frames
 = None

89 def 
	$__init__
 ( 
self
 ) :

91 
self
 . 
size
 = 
np
 . 
nan
 * 
np
 . 
ones
 ( 3 , 
dtype
 = 
float
 ) 
	}

93 def 
	$__str__
 ( 
self
 ) :

101 return '[Tracklet over {0} frames for {1}]' . 
format
 ( 
self
 . 
num_frames
 , 
self
 . 
object_type
 ) 
	}

103 def 
	$__iter__
 ( 
self
 ) :

112 if 
self
 . 
amt_occs
 is None :

113 return 
itertools
 . 
izip
 (

114 
self
 . 
trans
 , 
self
 . 
rots
 , 
self
 . 
states
 , 
self
 . 
occs
 , 
self
 . 
truncs
 ,

115 
itertools
 . 
repeat
 ( None ) , 
itertools
 . 
repeat
 ( None ) ,

116 
range
 ( 
self
 . 
first_frame
 , 
self
 . 
first_frame
 + 
self
 . 
num_frames
 ) )

118 return 
itertools
 . 
izip
 (

119 
self
 . 
trans
 , 
self
 . 
rots
 , 
self
 . 
states
 , 
self
 . 
occs
 , 
self
 . 
truncs
 ,

120 
self
 . 
amt_occs
 , 
self
 . 
amt_borders
 , 
range
 ( 
self
 . 
first_frame
 , 
self
 . 
first_frame
 + 
self
 . 
num_frames
 ) ) 
	}

125 def 
	$parse_xml
 ( 
tracklet_file
 ) :

133 
etree
 = 
ElementTree
 ( )

134 
print
 ( 'Parsing Tracklet file' , 
tracklet_file
 )

135 with 
open
 ( 
tracklet_file
 ) as 
f
 :

136 
etree
 . 
parse
 ( 
f
 )

139 
tracklets_elem
 = 
etree
 . 
find
 ( 'tracklets' )

140 
tracklets
 = [ ]

141 
tracklet_idx
 = 0

142 
num_tracklets
 = None

143 for 
tracklet_elem
 in 
tracklets_elem
 :

144 if 
tracklet_elem
 . 
tag
 == 'count' :

145 
num_tracklets
 = 
int
 ( 
tracklet_elem
 . 
text
 )

146 
print
 ( 'File contains' , 
num_tracklets
 , 'Tracklets' )

147 elif 
tracklet_elem
 . 
tag
 == 'item_version' :

149 elif 
tracklet_elem
 . 
tag
 == 'item' :

150 
new_track
 = 
Tracklet
 ( )

151 
is_finished
 = False

152 
has_amt
 = False

153 
frame_idx
 = None

154 for 
info
 in 
tracklet_elem
 :

155 if 
is_finished
 :

156 raise 
ValueError
 ( 'More info on element after finished!' )

157 if 
info
 . 
tag
 == 'objectType' :

158 
new_track
 . 
object_type
 = 
info
 . 
text

159 elif 
info
 . 
tag
 == 'h' :

160 
new_track
 . 
size
 [ 0 ] = 
round
 ( 
float
 ( 
info
 . 
text
 ) , 3 )

161 elif 
info
 . 
tag
 == 'w' :

162 
new_track
 . 
size
 [ 1 ] = 
round
 ( 
float
 ( 
info
 . 
text
 ) , 3 )

163 elif 
info
 . 
tag
 == 'l' :

164 
new_track
 . 
size
 [ 2 ] = 
round
 ( 
float
 ( 
info
 . 
text
 ) , 3 )

165 elif 
info
 . 
tag
 == 'first_frame' :

166 
new_track
 . 
first_frame
 = 
int
 ( 
info
 . 
text
 )

167 elif 
info
 . 
tag
 == 'poses' :

169 for 
pose
 in 
info
 :

170 if 
pose
 . 
tag
 == 'count' :

171 if 
new_track
 . 
num_frames
 is not None :

172 raise 
ValueError
 ( 'There are several pose lists for a single track!' )

173 elif 
frame_idx
 is not None :

174 raise 
ValueError
 ( '?!' )

175 
new_track
 . 
num_frames
 = 
int
 ( 
pose
 . 
text
 )

176 
new_track
 . 
trans
 = 
np
 . 
nan
 * 
np
 . 
ones
 ( ( 
new_track
 . 
num_frames
 , 3 ) , 
dtype
 = 
float
 )

177 
new_track
 . 
rots
 = 
np
 . 
nan
 * 
np
 . 
ones
 ( ( 
new_track
 . 
num_frames
 , 3 ) , 
dtype
 = 
float
 )

178 
new_track
 . 
states
 = 
np
 . 
nan
 * 
np
 . 
ones
 ( 
new_track
 . 
num_frames
 , 
dtype
 = 'uint8' )

179 
new_track
 . 
occs
 = 
np
 . 
nan
 * 
np
 . 
ones
 ( ( 
new_track
 . 
num_frames
 , 2 ) , 
dtype
 = 'uint8' )

180 
new_track
 . 
truncs
 = 
np
 . 
nan
 * 
np
 . 
ones
 ( 
new_track
 . 
num_frames
 , 
dtype
 = 'uint8' )

181 
new_track
 . 
amt_occs
 = 
np
 . 
nan
 * 
np
 . 
ones
 ( ( 
new_track
 . 
num_frames
 , 2 ) , 
dtype
 = 
float
 )

182 
new_track
 . 
amt_borders
 = 
np
 . 
nan
 * 
np
 . 
ones
 ( ( 
new_track
 . 
num_frames
 , 3 ) , 
dtype
 = 
float
 )

183 
frame_idx
 = 0

184 elif 
pose
 . 
tag
 == 'item_version' :

186 elif 
pose
 . 
tag
 == 'item' :

188 if 
frame_idx
 is None :

189 raise 
ValueError
 ( 'Pose item came before number of poses!' )

190 for 
poseInfo
 in 
pose
 :

191 if 
poseInfo
 . 
tag
 == 'tx' :

192 
new_track
 . 
trans
 [ 
frame_idx
 , 0 ] = 
round
 ( 
float
 ( 
poseInfo
 . 
text
 ) , 3 )

193 elif 
poseInfo
 . 
tag
 == 'ty' :

194 
new_track
 . 
trans
 [ 
frame_idx
 , 1 ] = 
round
 ( 
float
 ( 
poseInfo
 . 
text
 ) , 3 )

195 elif 
poseInfo
 . 
tag
 == 'tz' :

196 
new_track
 . 
trans
 [ 
frame_idx
 , 2 ] = 
round
 ( 
float
 ( 
poseInfo
 . 
text
 ) , 3 )

197 elif 
poseInfo
 . 
tag
 == 'rx' :

198 
new_track
 . 
rots
 [ 
frame_idx
 , 0 ] = 
round
 ( 
float
 ( 
poseInfo
 . 
text
 ) , 3 )

199 elif 
poseInfo
 . 
tag
 == 'ry' :

200 
new_track
 . 
rots
 [ 
frame_idx
 , 1 ] = 
round
 ( 
float
 ( 
poseInfo
 . 
text
 ) , 3 )

201 elif 
poseInfo
 . 
tag
 == 'rz' :

202 
new_track
 . 
rots
 [ 
frame_idx
 , 2 ] = 
round
 ( 
float
 ( 
poseInfo
 . 
text
 ) , 3 )

203 elif 
poseInfo
 . 
tag
 == 'state' :

204 
new_track
 . 
states
 [ 
frame_idx
 ] = 
stateFromText
 [ 
poseInfo
 . 
text
 ]

205 elif 
poseInfo
 . 
tag
 == 'occlusion' :

206 
new_track
 . 
occs
 [ 
frame_idx
 , 0 ] = 
occFromText
 [ 
poseInfo
 . 
text
 ]

207 elif 
poseInfo
 . 
tag
 == 'occlusion_kf' :

208 
new_track
 . 
occs
 [ 
frame_idx
 , 1 ] = 
occFromText
 [ 
poseInfo
 . 
text
 ]

209 elif 
poseInfo
 . 
tag
 == 'truncation' :

210 
new_track
 . 
truncs
 [ 
frame_idx
 ] = 
truncFromText
 [ 
poseInfo
 . 
text
 ]

211 elif 
poseInfo
 . 
tag
 == 'amt_occlusion' :

212 
new_track
 . 
amt_occs
 [ 
frame_idx
 , 0 ] = 
float
 ( 
poseInfo
 . 
text
 )

213 
has_amt
 = True

214 elif 
poseInfo
 . 
tag
 == 'amt_occlusion_kf' :

215 
new_track
 . 
amt_occs
 [ 
frame_idx
 , 1 ] = 
float
 ( 
poseInfo
 . 
text
 )

216 
has_amt
 = True

217 elif 
poseInfo
 . 
tag
 == 'amt_border_l' :

218 
new_track
 . 
amt_borders
 [ 
frame_idx
 , 0 ] = 
float
 ( 
poseInfo
 . 
text
 )

219 
has_amt
 = True

220 elif 
poseInfo
 . 
tag
 == 'amt_border_r' :

221 
new_track
 . 
amt_borders
 [ 
frame_idx
 , 1 ] = 
float
 ( 
poseInfo
 . 
text
 )

222 
has_amt
 = True

223 elif 
poseInfo
 . 
tag
 == 'amt_border_kf' :

224 
new_track
 . 
amt_borders
 [ 
frame_idx
 , 2 ] = 
float
 ( 
poseInfo
 . 
text
 )

225 
has_amt
 = True

227 raise 
ValueError
 ( 'Unexpected tag in poses item: {0}!' . 
format
 ( 
poseInfo
 . 
tag
 ) )

228 
frame_idx
 += 1

230 raise 
ValueError
 ( 'Unexpected pose info: {0}!' . 
format
 ( 
pose
 . 
tag
 ) )

231 elif 
info
 . 
tag
 == 'finished' :

232 
is_finished
 = True

234 raise 
ValueError
 ( 'Unexpected tag in tracklets: {0}!' . 
format
 ( 
info
 . 
tag
 ) )

238 if not 
is_finished
 :

239 
warn
 ( 'Tracklet {0} was not finished!' . 
format
 ( 
tracklet_idx
 ) )

240 if 
new_track
 . 
num_frames
 is None :

241 
warn
 ( 'Tracklet {0} contains no information!' . 
format
 ( 
tracklet_idx
 ) )

242 elif 
frame_idx
 != 
new_track
 . 
num_frames
 :

243 
warn
 ( 'Tracklet {0} is supposed to have {1} frames, but parser found {1}!' . 
format
 (

244 
tracklet_idx
 , 
new_track
 . 
num_frames
 , 
frame_idx
 ) )

245 if 
np
 . 
abs
 ( 
new_track
 . 
rots
 [ : , : 2 ] ) . 
sum
 ( ) > 1e-16 :

246 
warn
 ( 'Track contains rotation other than yaw!' )

249 if not 
has_amt
 :

250 
new_track
 . 
amt_occs
 = None

251 
new_track
 . 
amt_borders
 = None

254 
tracklets
 . 
append
 ( 
new_track
 )

255 
tracklet_idx
 += 1

258 raise 
ValueError
 ( 'Unexpected tracklet info' )

261 
print
 ( 'Loaded' , 
tracklet_idx
 , 'Tracklets' )

264 if 
tracklet_idx
 != 
num_tracklets
 :

265 
warn
 ( 'According to xml information the file has {0} tracklets, but parser found {1}!' . 
format
 (

266 
num_tracklets
 , 
tracklet_idx
 ) )

267 return 
tracklets
 
	}


	@./tracklets/parse_tracklet.py

26 from 
	~__future__
 import 
print_function

27 from 
	~xml.etree.ElementTree
 import 
ElementTree

28 import 
	~numpy
 as 
np

29 import 
	~itertools

30 from 
	~warnings
 import 
warn

32 
STATE_UNSET
 = 0

33 
STATE_INTERP
 = 1

34 
STATE_LABELED
 = 2

35 
stateFromText
 = { '0' : 
STATE_UNSET
 , '1' : 
STATE_INTERP
 , '2' : 
STATE_LABELED
 }

37 
OCC_UNSET
 = 255

38 
OCC_VISIBLE
 = 0

39 
OCC_PARTLY
 = 1

40 
OCC_FULLY
 = 2

41 
occFromText
 = { '-1' : 
OCC_UNSET
 , '0' : 
OCC_VISIBLE
 , '1' : 
OCC_PARTLY
 , '2' : 
OCC_FULLY
 }

43 
TRUNC_UNSET
 = 255

44 
TRUNC_IN_IMAGE
 = 0

45 
TRUNC_TRUNCATED
 = 1

46 
TRUNC_OUT_IMAGE
 = 2

47 
TRUNC_BEHIND_IMAGE
 = 3

48 
truncFromText
 = { '-1'

49 : 
TRUNC_UNSET
 , '99'

50 : 
TRUNC_UNSET
 , '0'

51 : 
TRUNC_IN_IMAGE
 , '1'

52 : 
TRUNC_TRUNCATED
 , '2'

53 : 
TRUNC_OUT_IMAGE
 , '3'

54 : 
TRUNC_BEHIND_IMAGE
 }

57 class 
	cTracklet
 ( 
object
 ) :

77 
object_type
 = None

78 
size
 = None

79 
first_frame
 = None

80 
trans
 = None

81 
rots
 = None

82 
states
 = None

83 
occs
 = None

84 
truncs
 = None

85 
amt_occs
 = None

86 
amt_borders
 = None

87 
num_frames
 = None

89 def 
	$__init__
 ( 
self
 ) :

91 
self
 . 
size
 = 
np
 . 
nan
 * 
np
 . 
ones
 ( 3 , 
dtype
 = 
float
 ) 
	}

93 def 
	$__str__
 ( 
self
 ) :

101 return '[Tracklet over {0} frames for {1}]' . 
format
 ( 
self
 . 
num_frames
 , 
self
 . 
object_type
 ) 
	}

103 def 
	$__iter__
 ( 
self
 ) :

112 if 
self
 . 
amt_occs
 is None :

113 return 
itertools
 . 
izip
 (

114 
self
 . 
trans
 , 
self
 . 
rots
 , 
self
 . 
states
 , 
self
 . 
occs
 , 
self
 . 
truncs
 ,

115 
itertools
 . 
repeat
 ( None ) , 
itertools
 . 
repeat
 ( None ) ,

116 
range
 ( 
self
 . 
first_frame
 , 
self
 . 
first_frame
 + 
self
 . 
num_frames
 ) )

118 return 
itertools
 . 
izip
 (

119 
self
 . 
trans
 , 
self
 . 
rots
 , 
self
 . 
states
 , 
self
 . 
occs
 , 
self
 . 
truncs
 ,

120 
self
 . 
amt_occs
 , 
self
 . 
amt_borders
 , 
range
 ( 
self
 . 
first_frame
 , 
self
 . 
first_frame
 + 
self
 . 
num_frames
 ) ) 
	}

125 def 
	$parse_xml
 ( 
tracklet_file
 ) :

133 
etree
 = 
ElementTree
 ( )

134 
print
 ( 'Parsing Tracklet file' , 
tracklet_file
 )

135 with 
open
 ( 
tracklet_file
 ) as 
f
 :

136 
etree
 . 
parse
 ( 
f
 )

139 
tracklets_elem
 = 
etree
 . 
find
 ( 'tracklets' )

140 
tracklets
 = [ ]

141 
tracklet_idx
 = 0

142 
num_tracklets
 = None

143 for 
tracklet_elem
 in 
tracklets_elem
 :

144 if 
tracklet_elem
 . 
tag
 == 'count' :

145 
num_tracklets
 = 
int
 ( 
tracklet_elem
 . 
text
 )

146 
print
 ( 'File contains' , 
num_tracklets
 , 'Tracklets' )

147 elif 
tracklet_elem
 . 
tag
 == 'item_version' :

149 elif 
tracklet_elem
 . 
tag
 == 'item' :

150 
new_track
 = 
Tracklet
 ( )

151 
is_finished
 = False

152 
has_amt
 = False

153 
frame_idx
 = None

154 for 
info
 in 
tracklet_elem
 :

155 if 
is_finished
 :

156 raise 
ValueError
 ( 'More info on element after finished!' )

157 if 
info
 . 
tag
 == 'objectType' :

161 
new_track
 . 
object_type
 = 'Car'

162 elif 
info
 . 
tag
 == 'h' :

163 
new_track
 . 
size
 [ 0 ] = 
float
 ( 
info
 . 
text
 )

164 elif 
info
 . 
tag
 == 'w' :

165 
new_track
 . 
size
 [ 1 ] = 
float
 ( 
info
 . 
text
 )

166 elif 
info
 . 
tag
 == 'l' :

167 
new_track
 . 
size
 [ 2 ] = 
float
 ( 
info
 . 
text
 )

168 elif 
info
 . 
tag
 == 'first_frame' :

169 
new_track
 . 
first_frame
 = 
int
 ( 
info
 . 
text
 )

170 elif 
info
 . 
tag
 == 'poses' :

172 for 
pose
 in 
info
 :

173 if 
pose
 . 
tag
 == 'count' :

174 if 
new_track
 . 
num_frames
 is not None :

175 raise 
ValueError
 ( 'There are several pose lists for a single track!' )

176 elif 
frame_idx
 is not None :

177 raise 
ValueError
 ( '?!' )

178 
new_track
 . 
num_frames
 = 
int
 ( 
pose
 . 
text
 )

179 
new_track
 . 
trans
 = 
np
 . 
nan
 * 
np
 . 
ones
 ( ( 
new_track
 . 
num_frames
 , 3 ) , 
dtype
 = 
float
 )

180 
new_track
 . 
rots
 = 
np
 . 
nan
 * 
np
 . 
ones
 ( ( 
new_track
 . 
num_frames
 , 3 ) , 
dtype
 = 
float
 )

181 
new_track
 . 
states
 = 
np
 . 
nan
 * 
np
 . 
ones
 ( 
new_track
 . 
num_frames
 , 
dtype
 = 'uint8' )

182 
new_track
 . 
occs
 = 
np
 . 
nan
 * 
np
 . 
ones
 ( ( 
new_track
 . 
num_frames
 , 2 ) , 
dtype
 = 'uint8' )

183 
new_track
 . 
truncs
 = 
np
 . 
nan
 * 
np
 . 
ones
 ( 
new_track
 . 
num_frames
 , 
dtype
 = 'uint8' )

184 
new_track
 . 
amt_occs
 = 
np
 . 
nan
 * 
np
 . 
ones
 ( ( 
new_track
 . 
num_frames
 , 2 ) , 
dtype
 = 
float
 )

185 
new_track
 . 
amt_borders
 = 
np
 . 
nan
 * 
np
 . 
ones
 ( ( 
new_track
 . 
num_frames
 , 3 ) , 
dtype
 = 
float
 )

186 
frame_idx
 = 0

187 elif 
pose
 . 
tag
 == 'item_version' :

189 elif 
pose
 . 
tag
 == 'item' :

191 if 
frame_idx
 is None :

192 raise 
ValueError
 ( 'Pose item came before number of poses!' )

193 for 
poseInfo
 in 
pose
 :

194 if 
poseInfo
 . 
tag
 == 'tx' :

195 
new_track
 . 
trans
 [ 
frame_idx
 , 0 ] = 
float
 ( 
poseInfo
 . 
text
 )

196 elif 
poseInfo
 . 
tag
 == 'ty' :

197 
new_track
 . 
trans
 [ 
frame_idx
 , 1 ] = 
float
 ( 
poseInfo
 . 
text
 )

198 elif 
poseInfo
 . 
tag
 == 'tz' :

199 
new_track
 . 
trans
 [ 
frame_idx
 , 2 ] = 
float
 ( 
poseInfo
 . 
text
 )

200 elif 
poseInfo
 . 
tag
 == 'rx' :

201 
new_track
 . 
rots
 [ 
frame_idx
 , 0 ] = 
float
 ( 
poseInfo
 . 
text
 )

202 elif 
poseInfo
 . 
tag
 == 'ry' :

203 
new_track
 . 
rots
 [ 
frame_idx
 , 1 ] = 
float
 ( 
poseInfo
 . 
text
 )

204 elif 
poseInfo
 . 
tag
 == 'rz' :

205 
new_track
 . 
rots
 [ 
frame_idx
 , 2 ] = 
float
 ( 
poseInfo
 . 
text
 )

206 elif 
poseInfo
 . 
tag
 == 'state' :

207 
new_track
 . 
states
 [ 
frame_idx
 ] = 
stateFromText
 [ 
poseInfo
 . 
text
 ]

208 elif 
poseInfo
 . 
tag
 == 'occlusion' :

209 
new_track
 . 
occs
 [ 
frame_idx
 , 0 ] = 
occFromText
 [ 
poseInfo
 . 
text
 ]

210 elif 
poseInfo
 . 
tag
 == 'occlusion_kf' :

211 
new_track
 . 
occs
 [ 
frame_idx
 , 1 ] = 
occFromText
 [ 
poseInfo
 . 
text
 ]

212 elif 
poseInfo
 . 
tag
 == 'truncation' :

213 
new_track
 . 
truncs
 [ 
frame_idx
 ] = 
truncFromText
 [ 
poseInfo
 . 
text
 ]

214 elif 
poseInfo
 . 
tag
 == 'amt_occlusion' :

215 
new_track
 . 
amt_occs
 [ 
frame_idx
 , 0 ] = 
float
 ( 
poseInfo
 . 
text
 )

216 
has_amt
 = True

217 elif 
poseInfo
 . 
tag
 == 'amt_occlusion_kf' :

218 
new_track
 . 
amt_occs
 [ 
frame_idx
 , 1 ] = 
float
 ( 
poseInfo
 . 
text
 )

219 
has_amt
 = True

220 elif 
poseInfo
 . 
tag
 == 'amt_border_l' :

221 
new_track
 . 
amt_borders
 [ 
frame_idx
 , 0 ] = 
float
 ( 
poseInfo
 . 
text
 )

222 
has_amt
 = True

223 elif 
poseInfo
 . 
tag
 == 'amt_border_r' :

224 
new_track
 . 
amt_borders
 [ 
frame_idx
 , 1 ] = 
float
 ( 
poseInfo
 . 
text
 )

225 
has_amt
 = True

226 elif 
poseInfo
 . 
tag
 == 'amt_border_kf' :

227 
new_track
 . 
amt_borders
 [ 
frame_idx
 , 2 ] = 
float
 ( 
poseInfo
 . 
text
 )

228 
has_amt
 = True

230 raise 
ValueError
 ( 'Unexpected tag in poses item: {0}!' . 
format
 ( 
poseInfo
 . 
tag
 ) )

231 
frame_idx
 += 1

233 raise 
ValueError
 ( 'Unexpected pose info: {0}!' . 
format
 ( 
pose
 . 
tag
 ) )

234 elif 
info
 . 
tag
 == 'finished' :

235 
is_finished
 = True

237 raise 
ValueError
 ( 'Unexpected tag in tracklets: {0}!' . 
format
 ( 
info
 . 
tag
 ) )

241 if not 
is_finished
 :

242 
warn
 ( 'Tracklet {0} was not finished!' . 
format
 ( 
tracklet_idx
 ) )

243 if 
new_track
 . 
num_frames
 is None :

244 
warn
 ( 'Tracklet {0} contains no information!' . 
format
 ( 
tracklet_idx
 ) )

245 elif 
frame_idx
 != 
new_track
 . 
num_frames
 :

246 
warn
 ( 'Tracklet {0} is supposed to have {1} frames, but parser found {1}!' . 
format
 (

247 
tracklet_idx
 , 
new_track
 . 
num_frames
 , 
frame_idx
 ) )

248 if 
np
 . 
abs
 ( 
new_track
 . 
rots
 [ : , : 2 ] ) . 
sum
 ( ) > 1e-16 :

249 
warn
 ( 'Track contains rotation other than yaw!' )

252 if not 
has_amt
 :

253 
new_track
 . 
amt_occs
 = None

254 
new_track
 . 
amt_borders
 = None

257 
tracklets
 . 
append
 ( 
new_track
 )

258 
tracklet_idx
 += 1

261 raise 
ValueError
 ( 'Unexpected tracklet info' )

264 
print
 ( 'Loaded' , 
tracklet_idx
 , 'Tracklets' )

267 if 
tracklet_idx
 != 
num_tracklets
 :

268 
warn
 ( 'According to xml information the file has {0} tracklets, but parser found {1}!' . 
format
 (

269 
num_tracklets
 , 
tracklet_idx
 ) )

270 return 
tracklets
 
	}


	@./tracklets/evaluate_tracklets.py

5 from 
	~__future__
 import 
print_function
 , 
division

6 from 
	~shapely.geometry
 import 
Polygon

7 from 
	~collections
 import 
Counter

8 import 
	~numpy
 as 
np

9 import 
	~argparse

10 import 
	~os

11 import 
	~sys

12 import 
	~yaml

13 from 
	~tracklets.parse_tracklet
 import *

15 
VOLUME_METHODS
 = [ 'box' , 'sphere' ]

18 def 
	$lwh_to_box
 ( 
l
 , 
w
 , 
h
 ) :

19 
box
 = 
np
 . 
array
 ( [

20 [ - 
l
 / 2 , - 
l
 / 2 , 
l
 / 2 , 
l
 / 2 , - 
l
 / 2 , - 
l
 / 2 , 
l
 / 2 , 
l
 / 2 ] ,

21 [ 
w
 / 2 , - 
w
 / 2 , - 
w
 / 2 , 
w
 / 2 , 
w
 / 2 , - 
w
 / 2 , - 
w
 / 2 , 
w
 / 2 ] ,

22 [ - 
h
 / 2 , - 
h
 / 2 , - 
h
 / 2 , - 
h
 / 2 , 
h
 / 2 , 
h
 / 2 , 
h
 / 2 , 
h
 / 2 ] ,

24 return 
box
 
	}

27 def 
	$iou_bbox_with_yaw
 ( 
vol_a
 , 
box_a
 , 
vol_b
 , 
box_b
 ) :

38 
min_h_a
 = 
np
 . 
min
 ( 
box_a
 [ 2 ] )

39 
max_h_a
 = 
np
 . 
max
 ( 
box_a
 [ 2 ] )

40 
min_h_b
 = 
np
 . 
min
 ( 
box_b
 [ 2 ] )

41 
max_h_b
 = 
np
 . 
max
 ( 
box_b
 [ 2 ] )

42 
max_of_min
 = 
np
 . 
max
 ( [ 
min_h_a
 , 
min_h_b
 ] )

43 
min_of_max
 = 
np
 . 
min
 ( [ 
max_h_a
 , 
max_h_b
 ] )

44 
z_intersection
 = 
np
 . 
max
 ( [ 0 , 
min_of_max
 - 
max_of_min
 ] )

45 if 
z_intersection
 == 0 :

49 
xy_poly_a
 = 
Polygon
 ( 
zip
 ( * 
box_a
 [ 0 : 2 , 0 : 4 ] ) )

50 
xy_poly_b
 = 
Polygon
 ( 
zip
 ( * 
box_b
 [ 0 : 2 , 0 : 4 ] ) )

51 
xy_intersection
 = 
xy_poly_a
 . 
intersection
 ( 
xy_poly_b
 ) . 
area

52 if 
xy_intersection
 == 0 :

55 
intersection
 = 
z_intersection
 * 
xy_intersection

56 
union
 = 
vol_a
 + 
vol_b
 - 
intersection

57 
iou
 = 
intersection
 / 
union

58 return 
iou
 , 
intersection
 
	}

61 def 
	$iou_sphere
 ( 
vol_a
 , 
sphere_a
 , 
vol_b
 , 
sphere_b
 ) :

62 
dist
 = 
np
 . 
linalg
 . 
norm
 ( 
sphere_a
 [ 0 : 3 ] - 
sphere_b
 [ 0 : 3 ] )

63 
r_a
 , 
r_b
 = 
sphere_a
 [ 3 ] , 
sphere_b
 [ 3 ]

64 if 
dist
 >= 
r_a
 + 
r_b
 :

67 elif 
dist
 <= 
abs
 ( 
r_a
 - 
r_b
 ) :

70 
intersection
 = 4 / 3. * 
np
 . 
pi
 * 
min
 ( 
r_a
 , 
r_b
 ) ** 3

74 
intersection
 = ( 
r_a
 + 
r_b
 - 
dist
 ) ** 2

75 
intersection
 *= ( 
dist
 ** 2 + 2 * 
dist
 * ( 
r_a
 + 
r_b
 ) - 3 * ( 
r_a
 - 
r_b
 ) ** 2 )

76 
intersection
 *= 
np
 . 
pi
 / ( 12 * 
dist
 )

77 
union
 = 
vol_a
 + 
vol_b
 - 
intersection

78 
iou
 = 
intersection
 / 
union

79 return 
iou
 , 
intersection
 
	}

82 class 
	cObs
 ( 
object
 ) :

84 def 
	$__init__
 ( 
self
 , 
tracklet_idx
 , 
object_type
 , 
size
 , 
position
 , 
rotation
 ) :

85 
self
 . 
tracklet_idx
 = 
tracklet_idx

86 
self
 . 
object_type
 = 
object_type

87 
self
 . 
h
 , 
self
 . 
w
 , 
self
 . 
l
 = 
size

88 
self
 . 
position
 = 
position

89 
self
 . 
yaw
 = 
rotation
 [ 2 ]

90 
self
 . 
_oriented_bbox
 = None 
	}

92 def 
	$get_bbox
 ( 
self
 ) :

93 if 
self
 . 
_oriented_bbox
 is None :

94 
bbox
 = 
lwh_to_box
 ( 
self
 . 
l
 , 
self
 . 
w
 , 
self
 . 
h
 )

96 
rot_mat
 = 
np
 . 
array
 ( [

97 [ 
np
 . 
cos
 ( 
self
 . 
yaw
 ) , - 
np
 . 
sin
 ( 
self
 . 
yaw
 ) , 0.0 ] ,

98 [ 
np
 . 
sin
 ( 
self
 . 
yaw
 ) , 
np
 . 
cos
 ( 
self
 . 
yaw
 ) , 0.0 ] ,

100 
self
 . 
_oriented_bbox
 = 
np
 . 
dot
 ( 
rot_mat
 , 
bbox
 ) + 
np
 . 
tile
 ( 
self
 . 
position
 , ( 8 , 1 ) ) . 
T

101 return 
self
 . 
_oriented_bbox
 
	}

103 def 
	$get_sphere
 ( 
self
 ) :

107 
r
 = 
max
 ( 
self
 . 
h
 , 
self
 . 
w
 , 
self
 . 
l
 ) / 2

109 return 
np
 . 
append
 ( 
self
 . 
position
 , 
r
 ) 
	}

111 def 
	$get_vol_sphere
 ( 
self
 ) :

112 
r
 = 
max
 ( 
self
 . 
h
 , 
self
 . 
w
 , 
self
 . 
l
 ) / 2

113 return 4 / 3. * 
np
 . 
pi
 * 
r
 ** 3 
	}

115 def 
	$get_vol_box
 ( 
self
 ) :

116 return 
self
 . 
h
 * 
self
 . 
w
 * 
self
 . 
l
 
	}

118 def 
	$get_vol
 ( 
self
 , 
method
 = 'box' ) :

119 return 
self
 . 
get_vol_sphere
 ( ) if 
method
 == 'sphere' else 
self
 . 
get_vol_box
 ( ) 
	}

121 def 
	$intersection
 ( 
self
 , 
other
 , 
method
 = 'box' ) :

122 if 
method
 == 'sphere' :

123 
iou_val
 , 
intersection_vol
 = 
iou_sphere
 (

124 
self
 . 
get_vol_sphere
 ( ) , 
self
 . 
get_sphere
 ( ) ,

125 
other
 . 
get_vol_sphere
 ( ) , 
other
 . 
get_sphere
 ( ) )

127 
iou_val
 , 
intersection_vol
 = 
iou_bbox_with_yaw
 (

128 
self
 . 
get_vol_box
 ( ) , 
self
 . 
get_bbox
 ( ) ,

129 
other
 . 
get_vol_box
 ( ) , 
other
 . 
get_bbox
 ( ) )

130 return 
iou_val
 , 
intersection_vol
 
	}

132 def 
	$__repr__
 ( 
self
 ) :

133 return 
str
 ( 
self
 . 
tracklet_idx
 ) + ' ' + 
str
 ( 
self
 . 
object_type
 ) 
	}

136 def 
	$generate_obstacles
 ( 
tracklets
 , 
override_size
 = None ) :

137 for 
tracklet_idx
 , 
tracklet
 in 
enumerate
 ( 
tracklets
 ) :

138 
frame_idx
 = 
tracklet
 . 
first_frame

139 for 
trans
 , 
rot
 in 
zip
 ( 
tracklet
 . 
trans
 , 
tracklet
 . 
rots
 ) :

140 
obstacle
 = 
Obs
 (

141 
tracklet_idx
 ,

142 
tracklet
 . 
object_type
 ,

143 
override_size
 if 
override_size
 is not None else 
tracklet
 . 
size
 ,

144 
trans
 ,

145 
rot
 )

146 yield 
frame_idx
 , 
obstacle

147 
frame_idx
 += 1 
	}

150 class 
	cEvalFrame
 ( 
object
 ) :

152 def 
	$__init__
 ( 
self
 ) :

153 
self
 . 
gt_obs
 = [ ]

154 
self
 . 
pred_obs
 = [ ] 
	}

156 def 
	$score
 ( 
self
 , 
intersection_count
 , 
union_count
 , 
pr_at_ious
 , 
method
 = 'box' ) :

162 
intersections
 = [ ]

163 
fn
 = 
set
 ( 
range
 ( 
len
 ( 
self
 . 
gt_obs
 ) ) )

164 
fp
 = 
set
 ( 
range
 ( 
len
 ( 
self
 . 
pred_obs
 ) ) )

167 for 
p_idx
 , 
p
 in 
enumerate
 ( 
self
 . 
pred_obs
 ) :

168 for 
g_idx
 , 
g
 in 
enumerate
 ( 
self
 . 
gt_obs
 ) :

169 if 
p
 . 
object_type
 == 
g
 . 
object_type
 :

170 
iou_val
 , 
intersection_vol
 = 
g
 . 
intersection
 ( 
p
 , 
method
 = 
method
 )

171 if 
iou_val
 > 0 :

172 
intersections
 . 
append
 ( ( 
iou_val
 , 
intersection_vol
 , 
p_idx
 , 
g_idx
 ) )

176 
intersections
 . 
sort
 ( 
key
 = lambda 
x
 : 
x
 [ 0 ] , 
reverse
 = True )

177 for 
iou_val
 , 
intersection_vol
 , 
p_idx
 , 
g_idx
 in 
intersections
 :

178 if 
g_idx
 in 
fn
 and 
p_idx
 in 
fp
 :

179 
fn
 . 
remove
 ( 
g_idx
 )

180 
fp
 . 
remove
 ( 
p_idx
 )

181 
obs
 = 
self
 . 
gt_obs
 [ 
g_idx
 ]

183 
intersection_count
 [ 
obs
 . 
object_type
 ] += 
intersection_vol

184 
union_count
 [ 
obs
 . 
object_type
 ] +=

185 
obs
 . 
get_vol
 ( 
method
 ) + 
self
 . 
pred_obs
 [ 
p_idx
 ] . 
get_vol
 ( 
method
 ) - 
intersection_vol

186 for 
iou_threshold
 in 
pr_at_ious
 . 
keys
 ( ) :

187 if 
iou_val
 > 
iou_threshold
 :

188 
pr_at_ious
 [ 
iou_threshold
 ] [ 'TP' ] += 1

193 
pr_at_ious
 [ 
iou_threshold
 ] [ 'FP' ] += 1

194 
pr_at_ious
 [ 
iou_threshold
 ] [ 'FN' ] += 1

197 for 
g_idx
 in 
fn
 :

198 
obs
 = 
self
 . 
gt_obs
 [ 
g_idx
 ]

199 
union_count
 [ 
obs
 . 
object_type
 ] += 
obs
 . 
get_vol
 ( 
method
 )

200 for 
iou_threshold
 in 
pr_at_ious
 . 
keys
 ( ) :

201 
pr_at_ious
 [ 
iou_threshold
 ] [ 'FN' ] += 1

204 for 
p_idx
 in 
fp
 :

205 
obs
 = 
self
 . 
pred_obs
 [ 
p_idx
 ]

206 
union_count
 [ 
obs
 . 
object_type
 ] += 
obs
 . 
get_vol
 ( 
method
 )

207 for 
iou_threshold
 in 
pr_at_ious
 . 
keys
 ( ) :

208 
pr_at_ious
 [ 
iou_threshold
 ] [ 'FP' ] += 1 
	}

211 def 
	$load_indices
 ( 
indices_file
 ) :

212 with 
open
 ( 
indices_file
 , 'r' ) as 
f
 :

213 def 
safe_int
 ( 
x
 ) :

215 return 
int
 ( 
x
 . 
split
 ( ',' ) [ 0 ] )

216 except 
ValueError
 :

218 
indices
 = [ 
safe_int
 ( 
line
 ) for 
line
 in 
f
 ] [ 1 : ]

219 return 
indices
 
	}

222 def 
	$tracklet_score
 ( 
pred_file
 , 
gt_file
 , 
filter_indices_file
 = None , 
exclude_indices_file
 = None , 
output_dir
 = None ,

223 
volume_method
 = 'sphere' ) :

224 
parser
 = 
argparse
 . 
ArgumentParser
 ( 
description
 = 'Evaluate two tracklet files.' )

225 
parser
 . 
add_argument
 ( '-g' , 
dest
 = 'override_lwh_with_gt' , 
action
 = 'store_true' ,

226 
help
 = 'Override predicted lwh values with value from first gt tracklet.' )

227 
parser
 . 
add_argument
 ( '-d' , 
dest
 = 'debug' , 
action
 = 'store_true' , 
help
 = 'Debug print enable' )

228 
parser
 . 
set_defaults
 ( 
debug
 = False )

229 
parser
 . 
set_defaults
 ( 
override_lwh_with_gt
 = False )

230 
args
 = 
parser
 . 
parse_args
 ( )

231 
override_lwh_with_gt
 = 
args
 . 
override_lwh_with_gt

233 if 
volume_method
 not in 
VOLUME_METHODS
 :

234 
sys
 . 
stderr
 . 
write
 ( 'Error: Invalid volume method argument "%s". Must be one of %s\n'

235 % ( 
volume_method
 , 
VOLUME_METHODS
 ) )

236 
exit
 ( - 1 )

238 if not 
os
 . 
path
 . 
exists
 ( 
pred_file
 ) :

239 
sys
 . 
stderr
 . 
write
 ( 'Error: Prediction file %s not found.\n' % 
pred_file
 )

240 
exit
 ( - 1 )

242 if not 
os
 . 
path
 . 
exists
 ( 
gt_file
 ) :

243 
sys
 . 
stderr
 . 
write
 ( 'Error: Ground-truth file %s not found.\n' % 
gt_file
 )

244 
exit
 ( - 1 )

246 
pred_tracklets
 = 
parse_xml
 ( 
pred_file
 )

247 if not 
pred_tracklets
 :

248 
sys
 . 
stderr
 . 
write
 ( 'Error: No Tracklets parsed for predictions.\n' )

249 
exit
 ( - 1 )

251 
gt_tracklets
 = 
parse_xml
 ( 
gt_file
 )

252 if not 
gt_tracklets
 :

253 
sys
 . 
stderr
 . 
write
 ( 'Error: No Tracklets parsed for ground truth.\n' )

254 
exit
 ( - 1 )

256 
num_gt_frames
 = 0

257 for 
gt_tracklet
 in 
gt_tracklets
 :

258 
num_gt_frames
 = 
max
 ( 
num_gt_frames
 , 
gt_tracklet
 . 
first_frame
 + 
gt_tracklet
 . 
num_frames
 )

260 
num_pred_frames
 = 0

261 for 
p_idx
 , 
pred_tracklet
 in 
enumerate
 ( 
pred_tracklets
 ) :

262 
num_pred_frames
 = 
max
 ( 
num_pred_frames
 , 
pred_tracklet
 . 
first_frame
 + 
pred_tracklet
 . 
num_frames
 )

265 
trans_noise
 = 
np
 . 
random
 . 
normal
 ( 0 , 0.3 , 
pred_tracklet
 . 
trans
 . 
shape
 )

267 
pred_tracklets
 [ 
p_idx
 ] . 
trans
 = 
pred_tracklet
 . 
trans
 + 
trans_noise

269 
pred_tracklets
 [ 
p_idx
 ] . 
size
 = 
pred_tracklet
 . 
size
 + 
np
 . 
random
 . 
normal
 ( 0 , 0.2 , 
pred_tracklet
 . 
size
 . 
shape
 )

272 
num_frames
 = 
max
 ( 
num_gt_frames
 , 
num_pred_frames
 )

273 if not 
num_frames
 :

274 
print
 ( 'Error: No frames to evaluate' )

275 
exit
 ( - 1 )

277 if 
filter_indices_file
 :

278 if not 
os
 . 
path
 . 
exists
 ( 
filter_indices_file
 ) :

279 
sys
 . 
stderr
 . 
write
 ( 'Error: Filter indices files specified but does not exist.\n' )

280 
exit
 ( - 1 )

281 
eval_indices
 = 
load_indices
 ( 
filter_indices_file
 )

282 
print
 ( 'Filter file %s loaded with %d frame indices to include for evaluation.' %

283 ( 
filter_indices_file
 , 
len
 ( 
eval_indices
 ) ) )

285 
eval_indices
 = 
list
 ( 
range
 ( 
num_frames
 ) )

287 if 
exclude_indices_file
 :

288 if not 
os
 . 
path
 . 
exists
 ( 
exclude_indices_file
 ) :

289 
sys
 . 
stderr
 . 
write
 ( 'Error: Exclude indices files specified but does not exist.\n' )

290 
exit
 ( - 1 )

291 
exclude_indices
 = 
set
 ( 
load_indices
 ( 
exclude_indices_file
 ) )

292 
eval_indices
 = [ 
x
 for 
x
 in 
eval_indices
 if 
x
 not in 
exclude_indices
 ]

293 
print
 ( 'Exclude file %s loaded with %d frame indices to exclude from evaluation.' %

294 ( 
exclude_indices_file
 , 
len
 ( 
exclude_indices
 ) ) )

296 
eval_frames
 = { 
i
 : 
EvalFrame
 ( ) for 
i
 in 
eval_indices
 }

298 
included_gt
 = 0

299 
excluded_gt
 = 0

300 for 
frame_idx
 , 
obstacle
 in 
generate_obstacles
 ( 
gt_tracklets
 ) :

301 if 
frame_idx
 in 
eval_frames
 :

302 
eval_frames
 [ 
frame_idx
 ] . 
gt_obs
 . 
append
 ( 
obstacle
 )

303 
included_gt
 += 1

305 
excluded_gt
 += 1

307 
included_pred
 = 0

308 
excluded_pred
 = 0

309 
gt_size
 = 
gt_tracklets
 [ 0 ] . 
size
 if 
override_lwh_with_gt
 else None

310 for 
frame_idx
 , 
obstacle
 in 
generate_obstacles
 ( 
pred_tracklets
 , 
override_size
 = 
gt_size
 ) :

311 if 
frame_idx
 in 
eval_frames
 :

312 
eval_frames
 [ 
frame_idx
 ] . 
pred_obs
 . 
append
 ( 
obstacle
 )

313 
included_pred
 += 1

315 
excluded_pred
 += 1

317 
print
 ( '%d ground truth object instances included in evaluation, % s excluded' % ( 
included_gt
 , 
excluded_gt
 ) )

318 
print
 ( '%d predicted object instances included in evaluation, % s excluded' % ( 
included_pred
 , 
excluded_pred
 ) )

320 
iou_thresholds
 = [ 0.1 , 0.2 , 0.3 , 0.4 , 0.5 , 0.6 , 0.7 , 0.8 ]

321 
pr_at_ious
 = { 
k
 : 
Counter
 ( ) for 
k
 in 
iou_thresholds
 }

323 
intersection_count
 = 
Counter
 ( )

324 
union_count
 = 
Counter
 ( )

325 for 
frame_idx
 in 
eval_indices
 :

327 
eval_frames
 [ 
frame_idx
 ] . 
score
 (

328 
intersection_count
 ,

329 
union_count
 ,

330 
pr_at_ious
 ,

331 
method
 = 
volume_method
 )

333 
results_table
 = { 'iou_per_obj' : { } , 'pr_per_iou' : { } }

339 
iou_sum
 = 0.0

340 for 
k
 in 
intersection_count
 . 
keys
 ( ) :

341 
iou
 = 
intersection_count
 [ 
k
 ] / 
union_count
 [ 
k
 ] if 
union_count
 [ 
k
 ] else 0.

342 
results_table
 [ 'iou_per_obj' ] [ 
k
 ] = 
float
 ( 
iou
 )

343 
iou_sum
 += 
iou

344 
results_table
 [ 'iou_per_obj' ] [ 'All' ] =

345 
float
 ( 
iou_sum
 / 
len
 ( 
intersection_count
 ) ) if 
len
 ( 
intersection_count
 ) else 0.

349 for 
k
 , 
v
 in 
pr_at_ious
 . 
items
 ( ) :

350 
p
 = 
v
 [ 'TP' ] / ( 
v
 [ 'TP' ] + 
v
 [ 'FP' ] ) if 
v
 [ 'TP' ] else 0.0

351 
r
 = 
v
 [ 'TP' ] / ( 
v
 [ 'TP' ] + 
v
 [ 'FN' ] ) if 
v
 [ 'TP' ] else 0.0

353 
results_table
 [ 'pr_per_iou' ] [ 
k
 ] = { 'precision' : 
p
 , 'recall' : 
r
 }

355 
print
 ( '\nResults' )

356 
print
 ( 
yaml
 . 
safe_dump
 ( 
results_table
 , 
default_flow_style
 = False , 
explicit_start
 = True ) )

358 if 
output_dir
 is not None :

359 with 
open
 ( 
os
 . 
path
 . 
join
 ( 
output_dir
 , 'iou_per_obj.csv' ) , 'w' ) as 
f
 :

360 
f
 . 
write
 ( 'object_type,iou\n' )

361 [ 
f
 . 
write
 ( '{0},{1}\n' . 
format
 ( 
k
 , 
v
 ) )

362 for 
k
 , 
v
 in 
sorted
 ( 
results_table
 [ 'iou_per_obj' ] . 
items
 ( ) , 
key
 = lambda 
x
 : 
x
 [ 0 ] ) ]

363 with 
open
 ( 
os
 . 
path
 . 
join
 ( 
output_dir
 , 'pr_per_iou.csv' ) , 'w' ) as 
f
 :

364 
f
 . 
write
 ( 'iou_threshold,p,r\n' )

365 [ 
f
 . 
write
 ( '{0},{1},{2}\n' . 
format
 ( 
k
 , 
v
 [ 'precision' ] , 
v
 [ 'recall' ] ) )

366 for 
k
 , 
v
 in 
sorted
 ( 
results_table
 [ 'pr_per_iou' ] . 
items
 ( ) , 
key
 = lambda 
x
 : 
x
 [ 0 ] ) ] 
	}

369 if 
__name__
 == '__main__' :

370 
tracklet_score
 ( 'tracklet_labels.xml' , 'tracklet_labels_gt.xml' , 
filter_indices_file
 = None ,

371 
exclude_indices_file
 = None , 
output_dir
 = './' , 
volume_method
 = 'sphere' )


	@./tracklets/tracklet_handling_test.py

4 import 
	~numpy

5 from 
	~config
 import *

6 import 
	~os

7 from 
	~kitti_data.io
 import 
read_objects

8 from 
	~net.processing.boxes3d
 import 
boxes3d_decompose

9 from 
	~tracklets.Tracklet_saver
 import 
Tracklet_saver

10 from 
	~data
 import 
obj_to_gt_boxes3d

16 def 
	$test_case_first_frame
 ( ) :

17 
tracklet_file
 = 
os
 . 
path
 . 
join
 ( 
cfg
 . 
RAW_DATA_SETS_DIR
 , '2011_09_26' , '2011_09_26_drive_0005_sync' , 'tracklet_labels.xml'

19 
num_frames
 = 809

20 
objects
 = 
read_objects
 ( 
tracklet_file
 , 
num_frames
 )

22 
a
 = 
Tracklet_saver
 ( './test/' )

25 for 
i
 in 
range
 ( 
num_frames
 ) :

26 
frame_no
 = 
i

27 
frame1
 = 
objects
 [ 
frame_no
 ]

28 
coordinate_3d_1
 , 
_
 = 
obj_to_gt_boxes3d
 ( 
frame1
 )

30 
translation1
 , 
size1
 , 
rotation1
 = 
boxes3d_decompose
 ( 
coordinate_3d_1
 )

33 
size
 = 
size1

34 
transition
 = 
translation1

35 
rotation
 = 
rotation1

38 for 
i
 in 
range
 ( 
len
 ( 
translation1
 ) ) :

39 
a
 . 
add_tracklet
 ( 
frame_no
 , 
size
 [ 
i
 ] , 
transition
 [ 
i
 ] , 
rotation
 [ 
i
 ] )

41 
a
 . 
write_tracklet
 ( ) 
	}

50 if 
__name__
 == '__main__' :

51 
test_case_first_frame
 ( )


	@./tracklets/Tracklet_saver.py

5 from 
	~__future__
 import 
print_function

12 from 
	~tracklets.generate_tracklet
 import *

13 import 
	~os

14 import 
	~sys

16 class 
	cTracklet_saver
 ( ) :

17 def 
	$__init__
 ( 
self
 , 
dir_path
 ) :

19 
file_path
 = 
os
 . 
path
 . 
join
 ( 
dir_path
 , 'tracklet_labels_pred.xml' )

20 if 
os
 . 
path
 . 
isfile
 ( 
file_path
 ) :

21 
sys
 . 
stderr
 . 
write
 ( "Error: The tracklet file %s already exists, change file name before prediction.\n" % 
file_path
 )

22 
exit
 ( - 1 )

24 
self
 . 
path
 = 
file_path

25 
self
 . 
collection
 = 
TrackletCollection
 ( ) 
	}

27 def 
	$add_tracklet_pose
 ( 
self
 , 
obs_tracklet
 , 
translation
 , 
rotation
 ) :

28 
keys
 = [ 'tx' , 'ty' , 'tz' , 'rx' , 'ry' , 'rz' ]

29 
values
 = [ 
translation
 [ 0 ] , 
translation
 [ 1 ] , 
translation
 [ 2 ] , 
rotation
 [ 0 ] , 
rotation
 [ 1 ] , 
rotation
 [ 2 ] ]

30 
pose
 = { 
k
 : 
v
 for 
k
 , 
v
 in 
zip
 ( 
keys
 , 
values
 ) }

31 
obs_tracklet
 . 
poses
 = [ 
pose
 ]

32 pass 
	}

36 def 
	$add_tracklet
 ( 
self
 , 
first_frame_nb
 , 
size
 , 
transition
 , 
rotation
 ) :

37 
obs_tracklet
 = 
Tracklet
 ( 
object_type
 = 'Car' , 
l
 = 
size
 [ 2 ] , 
w
 = 
size
 [ 1 ] , 
h
 = 
size
 [ 0 ] , 
first_frame
 = 
first_frame_nb
 )

40 if 0 < 
transition
 [ 1 ] < 8 :

41 
self
 . 
add_tracklet_pose
 ( 
obs_tracklet
 , 
transition
 , 
rotation
 )

42 
self
 . 
collection
 . 
tracklets
 . 
append
 ( 
obs_tracklet
 ) 
	}

44 def 
	$write_tracklet
 ( 
self
 ) :

45 
self
 . 
collection
 . 
write_xml
 ( 
self
 . 
path
 ) 
	}

48 if 
__name__
 == '__main__' :

50 
os
 . 
makedirs
 ( './test_output/' , 
exist_ok
 = True )

51 
a
 = 
Tracklet_saver
 ( './test_output/' )

53 
size
 = [ 1.5748 , 1.4478 , 4.2418 ]

55 
transition
 = [ 0 , 3 , 0 ]

57 
rotation
 = [ 0 , 0 , 0 ]

60 for 
i
 in 
range
 ( 324 , 647 ) :

61 
a
 . 
add_tracklet
 ( 
i
 , 
size
 , 
transition
 , 
rotation
 )

62 
a
 . 
write_tracklet
 ( )


	@./train.py

1 import 
	~mv3d

2 import 
	~mv3d_net

3 import 
	~glob

4 from 
	~config
 import *

6 import 
	~argparse

7 import 
	~os

8 import 
	~time

9 from 
	~utils.training_validation_data_splitter
 import 
TrainingValDataSplitter

10 from 
	~utils.batch_loading
 import 
BatchLoading3

13 if 
__name__
 == '__main__' :

14 
parser
 = 
argparse
 . 
ArgumentParser
 ( 
description
 = 'training' )

16 
all
 = '%s,%s,%s,%s' % ( 
mv3d_net
 . 
top_view_rpn_name
 , 
mv3d_net
 . 
imfeature_net_name
 , 
mv3d_net
 . 
fusion_net_name
 , 
mv3d_net
 . 
frontfeature_net_name
 )

18 
parser
 . 
add_argument
 ( '-w' , '--weights' , 
type
 = 
str
 , 
nargs
 = '?' , 
default
 = 
all
 ,

19 
help
 = 'use pre trained weights example: -w "%s" ' % ( 
all
 ) )

21 
parser
 . 
add_argument
 ( '-t' , '--targets' , 
type
 = 
str
 , 
nargs
 = '?' , 
default
 = 
all
 ,

22 
help
 = 'train targets example: -w "%s" ' % ( 
all
 ) )

24 
parser
 . 
add_argument
 ( '-i' , '--max_iter' , 
type
 = 
int
 , 
nargs
 = '?' , 
default
 = 1000 ,

25 
help
 = 'max count of train iter' )

27 
parser
 . 
add_argument
 ( '-n' , '--tag' , 
type
 = 
str
 , 
nargs
 = '?' , 
default
 = 'unknown_tag' ,

28 
help
 = 'set log tag' )

30 
parser
 . 
add_argument
 ( '-c' , '--clear-progress' , 
action
 = 'store_true' , 
default
 = False ,

31 
help
 = 'set continue train flag' )

33 
parser
 . 
add_argument
 ( '-b' , '--batch-size' , 
type
 = 
int
 , 
nargs
 = '?' , 
default
 = 1 ,

34 
help
 = 'set continue train flag' )

36 
parser
 . 
add_argument
 ( '-l' , '--lr' , 
type
 = 
float
 , 
nargs
 = '?' , 
default
 = 0.001 ,

37 
help
 = 'set learning rate' )

40 
args
 = 
parser
 . 
parse_args
 ( )

42 
print
 ( '\n\n{}\n\n' . 
format
 ( 
args
 ) )

43 
tag
 = 
args
 . 
tag

44 if 
tag
 == 'unknown_tag' :

45 
tag
 = 
input
 ( 'Enter log tag : ' )

46 
print
 ( '\nSet log tag :"%s" ok !!\n' % 
tag
 )

48 
max_iter
 = 
args
 . 
max_iter

49 
weights
 = [ ]

50 if 
args
 . 
weights
 != '' :

51 
weights
 = 
args
 . 
weights
 . 
split
 ( ',' )

53 
targets
 = [ ]

54 if 
args
 . 
targets
 != '' :

55 
targets
 = 
args
 . 
targets
 . 
split
 ( ',' )

57 
dataset_dir
 = 
cfg
 . 
PREPROCESSED_DATA_SETS_DIR

59 if 
cfg
 . 
DATA_SETS_TYPE
 == 'didi2' :

61 
train_key_list
 = [ 'suburu_pulling_up_to_it' , 'nissan_brief'

87 
train_key_full_path_list
 = [ 
os
 . 
path
 . 
join
 ( 
cfg
 . 
RAW_DATA_SETS_DIR
 , 
key
 ) for 
key
 in 
train_key_list
 ]

88 
train_value_list
 = [ 
os
 . 
listdir
 ( 
value
 ) [ 0 ] for 
value
 in 
train_key_full_path_list
 ]

90 
train_n_val_dataset
 = [ 
k
 + '/' + 
v
 for 
k
 , 
v
 in 
zip
 ( 
train_key_list
 , 
train_value_list
 ) ]

92 
data_splitter
 = 
TrainingValDataSplitter
 ( 
train_n_val_dataset
 )

95 elif 
cfg
 . 
DATA_SETS_TYPE
 == 'didi' or 
cfg
 . 
DATA_SETS_TYPE
 == 'test' :

96 
training_dataset
 = { '1'

101 
validation_dataset
 = { '1'

104 elif 
cfg
 . 
DATA_SETS_TYPE
 == 'kitti' :

106 
training_dataset
 = { '2011_09_26'

114 
validation_dataset
 = { '2011_09_26'

130 with 
BatchLoading3
 ( 
tags
 = 
training_dataset
 , 
require_shuffle
 = True , 
use_precal_view
 = True , 
queue_size
 = 30 , 
use_multi_process_num
 = 8 ) as 
training
 :

131 with 
BatchLoading3
 ( 
tags
 = 
validation_dataset
 , 
require_shuffle
 = False , 
use_precal_view
 = True , 
queue_size
 = 30 , 
use_multi_process_num
 = 1 ) as 
validation
 :

132 
train
 = 
mv3d
 . 
Trainer
 ( 
train_set
 = 
training
 , 
validation_set
 = 
validation
 ,

133 
pre_trained_weights
 = 
weights
 , 
train_targets
 = 
targets
 , 
log_tag
 = 
tag
 ,

134 
continue_train
 = not 
args
 . 
clear_progress
 , 
batch_size
 = 
args
 . 
batch_size
 , 
lr
 = 
args
 . 
lr
 )

135 
train
 ( 
max_iter
 = 
max_iter
 )


	@./kitti_data/draw.py

12 
COLOR
 = { 'Car'


	@./kitti_data/pykitti/utils.py

3 from 
	~collections
 import 
namedtuple

5 import 
	~matplotlib

6 
matplotlib
 . 
use
 ( 'AGG' )

7 import 
	~matplotlib.image
 as 
mpimg

8 import 
	~numpy
 as 
np

10 
__author__
 = "Lee Clement"

11 
__email__
 = "lee.clement@robotics.utias.utoronto.ca"

14 def 
	$rotx
 ( 
t
 ) :

16 
c
 = 
np
 . 
cos
 ( 
t
 )

17 
s
 = 
np
 . 
sin
 ( 
t
 )

18 return 
np
 . 
array
 ( [ [ 1 , 0 , 0 ] ,

19 [ 0 , 
c
 , - 
s
 ] ,

20 [ 0 , 
s
 , 
c
 ] ] ) 
	}

23 def 
	$roty
 ( 
t
 ) :

25 
c
 = 
np
 . 
cos
 ( 
t
 )

26 
s
 = 
np
 . 
sin
 ( 
t
 )

27 return 
np
 . 
array
 ( [ [ 
c
 , 0 , 
s
 ] ,

29 [ - 
s
 , 0 , 
c
 ] ] ) 
	}

32 def 
	$rotz
 ( 
t
 ) :

34 
c
 = 
np
 . 
cos
 ( 
t
 )

35 
s
 = 
np
 . 
sin
 ( 
t
 )

36 return 
np
 . 
array
 ( [ [ 
c
 , - 
s
 , 0 ] ,

37 [ 
s
 , 
c
 , 0 ] ,

38 [ 0 , 0 , 1 ] ] ) 
	}

41 def 
	$transform_from_rot_trans
 ( 
R
 , 
t
 ) :

43 
R
 = 
R
 . 
reshape
 ( 3 , 3 )

44 
t
 = 
t
 . 
reshape
 ( 3 , 1 )

45 return 
np
 . 
vstack
 ( ( 
np
 . 
hstack
 ( [ 
R
 , 
t
 ] ) , [ 0 , 0 , 0 , 1 ] ) ) 
	}

48 def 
	$read_calib_file
 ( 
filepath
 ) :

50 
data
 = { }

52 with 
open
 ( 
filepath
 , 'r' ) as 
f
 :

53 for 
line
 in 
f
 . 
readlines
 ( ) :

54 
key
 , 
value
 = 
line
 . 
split
 ( ':' , 1 )

58 
data
 [ 
key
 ] = 
np
 . 
array
 ( [ 
float
 ( 
x
 ) for 
x
 in 
value
 . 
split
 ( ) ] )

59 except 
ValueError
 :

62 return 
data
 
	}

65 def 
	$load_stereo_pairs
 ( 
imL_files
 , 
imR_files
 , ** 
kwargs
 ) :

67 
StereoPair
 = 
namedtuple
 ( 'StereoPair' , 'left, right' )

69 
impairs
 = [ ]

70 for 
imfiles
 in 
zip
 ( 
imL_files
 , 
imR_files
 ) :

72 
imformat
 = 
kwargs
 . 
get
 ( 'format' , '' )

73 if 
imformat
 is 'cv2' :

74 
imL
 = 
np
 . 
uint8
 ( 
mpimg
 . 
imread
 ( 
imfiles
 [ 0 ] ) * 255 )

75 
imR
 = 
np
 . 
uint8
 ( 
mpimg
 . 
imread
 ( 
imfiles
 [ 1 ] ) * 255 )

78 if 
len
 ( 
imL
 . 
shape
 ) > 2 :

79 
imL
 = 
imL
 [ : , : , : : - 1 ]

80 
imR
 = 
imR
 [ : , : , : : - 1 ]

83 
imL
 = 
mpimg
 . 
imread
 ( 
imfiles
 [ 0 ] )

84 
imR
 = 
mpimg
 . 
imread
 ( 
imfiles
 [ 1 ] )

86 
impairs
 . 
append
 ( 
StereoPair
 ( 
imL
 , 
imR
 ) )

88 return 
impairs
 
	}

90 def 
	$load_left_single
 ( 
imL_files
 , ** 
kwargs
 ) :

92 
StereoPair
 = 
namedtuple
 ( 'StereoPair' , 'left, right' )

94 
impairs
 = [ ]

95 for 
imfiles
 in 
zip
 ( 
imL_files
 ) :

97 
imformat
 = 
kwargs
 . 
get
 ( 'format' , '' )

98 if 
imformat
 is 'cv2' :

99 
imL
 = 
np
 . 
uint8
 ( 
mpimg
 . 
imread
 ( 
imfiles
 [ 0 ] ) * 255 )

102 if 
len
 ( 
imL
 . 
shape
 ) > 2 :

103 
imL
 = 
imL
 [ : , : , : : - 1 ]

106 
imL
 = 
mpimg
 . 
imread
 ( 
imfiles
 [ 0 ] )

108 
impairs
 . 
append
 ( 
StereoPair
 ( 
imL
 , 
imL
 ) )

110 return 
impairs
 
	}

115 def 
	$load_velo_scans
 ( 
velo_files
 ) :

117 
scan_list
 = [ ]

118 for 
filename
 in 
velo_files
 :

119 
scan
 = 
np
 . 
fromfile
 ( 
filename
 , 
dtype
 = 
np
 . 
float32
 )

120 
scan_list
 . 
append
 ( 
scan
 . 
reshape
 ( ( - 1 , 4 ) ) )

122 return 
scan_list
 
	}


	@./kitti_data/pykitti/raw.py

3 import 
	~datetime
 as 
dt

4 import 
	~glob

5 import 
	~os

6 from 
	~collections
 import 
namedtuple

8 import 
	~numpy
 as 
np

10 from 
	~kitti_data.pykitti
 import 
utils

11 from 
	~config
 import 
cfg

13 
__author__
 = "Lee Clement"

14 
__email__
 = "lee.clement@robotics.utias.utoronto.ca"

17 class 
	craw
 :

20 def 
	$__init__
 ( 
self
 , 
base_path
 , 
date
 , 
drive
 , 
frame_range
 = None ) :

22 if ( 
cfg
 . 
DATA_SETS_TYPE
 == 'didi2' ) :

23 
self
 . 
drive
 = 
drive

24 elif ( 
cfg
 . 
DATA_SETS_TYPE
 == 'didi' ) :

25 
self
 . 
drive
 = 
drive

26 elif 
cfg
 . 
DATA_SETS_TYPE
 == 'kitti' :

27 
self
 . 
drive
 = 
date
 + '_drive_' + 
drive
 + '_sync'

28 elif ( 
cfg
 . 
DATA_SETS_TYPE
 == 'test' ) :

29 
self
 . 
drive
 = 
drive

31 raise 
ValueError
 ( 'unexpected type in cfg.DATA_SETS_TYPE item: {}!' . 
format
 ( 
cfg
 . 
DATA_SETS_TYPE
 ) )

32 
self
 . 
calib_path
 = 
os
 . 
path
 . 
join
 ( 
base_path
 , 
date
 )

33 
self
 . 
data_path
 = 
os
 . 
path
 . 
join
 ( 
base_path
 , 
date
 , 
self
 . 
drive
 )

34 
self
 . 
frame_range
 = 
frame_range
 
	}

36 def 
	$_load_calib_rigid
 ( 
self
 , 
filename
 ) :

38 
filepath
 = 
os
 . 
path
 . 
join
 ( 
self
 . 
calib_path
 , 
filename
 )

39 
data
 = 
utils
 . 
read_calib_file
 ( 
filepath
 )

40 return 
utils
 . 
transform_from_rot_trans
 ( 
data
 [ 'R' ] , 
data
 [ 'T' ] ) 
	}

42 def 
	$_load_calib_cam_to_cam
 ( 
self
 , 
velo_to_cam_file
 , 
cam_to_cam_file
 ) :

44 
data
 = { }

48 
T_cam0unrect_velo
 = 
self
 . 
_load_calib_rigid
 ( 
velo_to_cam_file
 )

51 
cam_to_cam_filepath
 = 
os
 . 
path
 . 
join
 ( 
self
 . 
calib_path
 , 
cam_to_cam_file
 )

52 
filedata
 = 
utils
 . 
read_calib_file
 ( 
cam_to_cam_filepath
 )

55 
P_rect_00
 = 
np
 . 
reshape
 ( 
filedata
 [ 'P_rect_00' ] , ( 3 , 4 ) )

56 
P_rect_10
 = 
np
 . 
reshape
 ( 
filedata
 [ 'P_rect_01' ] , ( 3 , 4 ) )

57 
P_rect_20
 = 
np
 . 
reshape
 ( 
filedata
 [ 'P_rect_02' ] , ( 3 , 4 ) )

58 
P_rect_30
 = 
np
 . 
reshape
 ( 
filedata
 [ 'P_rect_03' ] , ( 3 , 4 ) )

61 
R_rect_00
 = 
np
 . 
eye
 ( 4 )

62 
R_rect_00
 [ 0 : 3 , 0 : 3 ] = 
np
 . 
reshape
 ( 
filedata
 [ 'R_rect_00' ] , ( 3 , 3 ) )

65 
T0
 = 
np
 . 
eye
 ( 4 )

66 
T0
 [ 0 , 3 ] = 
P_rect_00
 [ 0 , 3 ] / 
P_rect_00
 [ 0 , 0 ]

67 
T1
 = 
np
 . 
eye
 ( 4 )

68 
T1
 [ 0 , 3 ] = 
P_rect_10
 [ 0 , 3 ] / 
P_rect_10
 [ 0 , 0 ]

69 
T2
 = 
np
 . 
eye
 ( 4 )

70 
T2
 [ 0 , 3 ] = 
P_rect_20
 [ 0 , 3 ] / 
P_rect_20
 [ 0 , 0 ]

71 
T3
 = 
np
 . 
eye
 ( 4 )

72 
T3
 [ 0 , 3 ] = 
P_rect_30
 [ 0 , 3 ] / 
P_rect_30
 [ 0 , 0 ]

75 
data
 [ 'T_cam0_velo' ] = 
T0
 . 
dot
 ( 
R_rect_00
 . 
dot
 ( 
T_cam0unrect_velo
 ) )

76 
data
 [ 'T_cam1_velo' ] = 
T1
 . 
dot
 ( 
R_rect_00
 . 
dot
 ( 
T_cam0unrect_velo
 ) )

77 
data
 [ 'T_cam2_velo' ] = 
T2
 . 
dot
 ( 
R_rect_00
 . 
dot
 ( 
T_cam0unrect_velo
 ) )

78 
data
 [ 'T_cam3_velo' ] = 
T3
 . 
dot
 ( 
R_rect_00
 . 
dot
 ( 
T_cam0unrect_velo
 ) )

81 
data
 [ 'K_cam0' ] = 
P_rect_00
 [ 0 : 3 , 0 : 3 ]

82 
data
 [ 'K_cam1' ] = 
P_rect_10
 [ 0 : 3 , 0 : 3 ]

83 
data
 [ 'K_cam2' ] = 
P_rect_20
 [ 0 : 3 , 0 : 3 ]

84 
data
 [ 'K_cam3' ] = 
P_rect_30
 [ 0 : 3 , 0 : 3 ]

89 
p_cam
 = 
np
 . 
array
 ( [ 0 , 0 , 0 , 1 ] )

90 
p_velo0
 = 
np
 . 
linalg
 . 
inv
 ( 
data
 [ 'T_cam0_velo' ] ) . 
dot
 ( 
p_cam
 )

91 
p_velo1
 = 
np
 . 
linalg
 . 
inv
 ( 
data
 [ 'T_cam1_velo' ] ) . 
dot
 ( 
p_cam
 )

92 
p_velo2
 = 
np
 . 
linalg
 . 
inv
 ( 
data
 [ 'T_cam2_velo' ] ) . 
dot
 ( 
p_cam
 )

93 
p_velo3
 = 
np
 . 
linalg
 . 
inv
 ( 
data
 [ 'T_cam3_velo' ] ) . 
dot
 ( 
p_cam
 )

95 
data
 [ 'b_gray' ] = 
np
 . 
linalg
 . 
norm
 ( 
p_velo1
 - 
p_velo0
 )

96 
data
 [ 'b_rgb' ] = 
np
 . 
linalg
 . 
norm
 ( 
p_velo3
 - 
p_velo2
 )

98 return 
data
 
	}

100 def 
	$load_calib
 ( 
self
 ) :

104 
data
 = { }

107 
data
 [ 'T_velo_imu' ] = 
self
 . 
_load_calib_rigid
 ( 'calib_imu_to_velo.txt' )

110 
data
 . 
update
 ( 
self
 . 
_load_calib_cam_to_cam
 ( 'calib_velo_to_cam.txt'

114 
data
 [ 'T_cam0_imu' ] = 
data
 [ 'T_cam0_velo' ] . 
dot
 ( 
data
 [ 'T_velo_imu' ] )

115 
data
 [ 'T_cam1_imu' ] = 
data
 [ 'T_cam1_velo' ] . 
dot
 ( 
data
 [ 'T_velo_imu' ] )

116 
data
 [ 'T_cam2_imu' ] = 
data
 [ 'T_cam2_velo' ] . 
dot
 ( 
data
 [ 'T_velo_imu' ] )

117 
data
 [ 'T_cam3_imu' ] = 
data
 [ 'T_cam3_velo' ] . 
dot
 ( 
data
 [ 'T_velo_imu' ] )

119 
self
 . 
calib
 = 
namedtuple
 ( 'CalibData' , 
data
 . 
keys
 ( ) ) ( * 
data
 . 
values
 ( ) ) 
	}

121 def 
	$load_timestamps
 ( 
self
 ) :

123 
print
 ( 'Loading OXTS timestamps from ' + 
self
 . 
drive
 + '...' )

125 
timestamp_file
 = 
os
 . 
path
 . 
join
 (

126 
self
 . 
data_path
 , 'oxts' , 'timestamps.txt' )

129 
self
 . 
timestamps
 = [ ]

130 with 
open
 ( 
timestamp_file
 , 'r' ) as 
f
 :

131 for 
line
 in 
f
 . 
readlines
 ( ) :

135 
t
 = 
dt
 . 
datetime
 . 
strptime
 ( 
line
 [ : - 4 ] , '%Y-%m-%d %H:%M:%S.%f' )

136 
self
 . 
timestamps
 . 
append
 ( 
t
 )

139 if 
self
 . 
frame_range
 :

140 
self
 . 
timestamps
 = [ 
self
 . 
timestamps
 [ 
i
 ] for 
i
 in 
self
 . 
frame_range
 ]

142 
print
 ( 'Found ' + 
str
 ( 
len
 ( 
self
 . 
timestamps
 ) ) + ' timestamps...' )

144 
print
 ( 'done.' ) 
	}

146 def 
	$_poses_from_oxts
 ( 
self
 , 
oxts_packets
 ) :

148 
er
 = 6378137.

151 
scale
 = 
np
 . 
cos
 ( 
oxts_packets
 [ 0 ] . 
lat
 * 
np
 . 
pi
 / 180. )

153 
t_0
 = [ ]

154 
poses
 = [ ]

155 for 
packet
 in 
oxts_packets
 :

157 
tx
 = 
scale
 * 
packet
 . 
lon
 * 
np
 . 
pi
 * 
er
 / 180.

158 
ty
 = 
scale
 * 
er
 *

159 
np
 . 
log
 ( 
np
 . 
tan
 ( ( 90. + 
packet
 . 
lat
 ) * 
np
 . 
pi
 / 360. ) )

160 
tz
 = 
packet
 . 
alt

161 
t
 = 
np
 . 
array
 ( [ 
tx
 , 
ty
 , 
tz
 ] )

165 if 
len
 ( 
t_0
 ) == 0 :

166 
t_0
 = 
t

169 
Rx
 = 
utils
 . 
rotx
 ( 
packet
 . 
roll
 )

170 
Ry
 = 
utils
 . 
roty
 ( 
packet
 . 
pitch
 )

171 
Rz
 = 
utils
 . 
rotz
 ( 
packet
 . 
yaw
 )

172 
R
 = 
Rz
 . 
dot
 ( 
Ry
 . 
dot
 ( 
Rx
 ) )

175 
poses
 . 
append
 ( 
utils
 . 
transform_from_rot_trans
 ( 
R
 , 
t
 - 
t_0
 ) )

177 return 
poses
 
	}

179 def 
	$load_oxts
 ( 
self
 ) :

181 
print
 ( 'Loading OXTS data from ' + 
self
 . 
drive
 + '...' )

184 
oxts_path
 = 
os
 . 
path
 . 
join
 ( 
self
 . 
data_path
 , 'oxts' , 'data' , '*.txt' )

185 
oxts_files
 = 
sorted
 ( 
glob
 . 
glob
 ( 
oxts_path
 ) )

188 if 
self
 . 
frame_range
 :

189 
oxts_files
 = [ 
oxts_files
 [ 
i
 ] for 
i
 in 
self
 . 
frame_range
 ]

191 
print
 ( 'Found ' + 
str
 ( 
len
 ( 
oxts_files
 ) ) + ' OXTS measurements...' )

195 
OxtsPacket
 = 
namedtuple
 ( 'OxtsPacket' , 'lat, lon, alt, '

205 
oxts_packets
 = [ ]

206 for 
filename
 in 
oxts_files
 :

207 with 
open
 ( 
filename
 , 'r' ) as 
f
 :

208 for 
line
 in 
f
 . 
readlines
 ( ) :

209 
line
 = 
line
 . 
split
 ( )

211 
line
 [ : - 5 ] = [ 
float
 ( 
x
 ) for 
x
 in 
line
 [ : - 5 ] ]

212 
line
 [ - 5 : ] = [ 
int
 ( 
float
 ( 
x
 ) ) for 
x
 in 
line
 [ - 5 : ] ]

214 
data
 = 
OxtsPacket
 ( * 
line
 )

215 
oxts_packets
 . 
append
 ( 
data
 )

218 
T_w_imu
 = 
self
 . 
_poses_from_oxts
 ( 
oxts_packets
 )

221 
OxtsData
 = 
namedtuple
 ( 'OxtsData' , 'packet, T_w_imu' )

222 
self
 . 
oxts
 = [ ]

223 for ( 
p
 , 
T
 ) in 
zip
 ( 
oxts_packets
 , 
T_w_imu
 ) :

224 
self
 . 
oxts
 . 
append
 ( 
OxtsData
 ( 
p
 , 
T
 ) )

226 
print
 ( 'done.' ) 
	}

228 def 
	$load_gray
 ( 
self
 , ** 
kwargs
 ) :

234 
print
 ( 'Loading monochrome images from ' + 
self
 . 
drive
 + '...' )

236 
imL_path
 = 
os
 . 
path
 . 
join
 ( 
self
 . 
data_path
 , 'image_00' , 'data' , '*.png' )

237 
imR_path
 = 
os
 . 
path
 . 
join
 ( 
self
 . 
data_path
 , 'image_01' , 'data' , '*.png' )

239 
imL_files
 = 
sorted
 ( 
glob
 . 
glob
 ( 
imL_path
 ) )

240 
imR_files
 = 
sorted
 ( 
glob
 . 
glob
 ( 
imR_path
 ) )

243 if 
self
 . 
frame_range
 :

244 
imL_files
 = [ 
imL_files
 [ 
i
 ] for 
i
 in 
self
 . 
frame_range
 ]

245 
imR_files
 = [ 
imR_files
 [ 
i
 ] for 
i
 in 
self
 . 
frame_range
 ]

247 
print
 ( 'Found ' + 
str
 ( 
len
 ( 
imL_files
 ) ) + ' image pairs...' )

249 
self
 . 
gray
 = 
utils
 . 
load_stereo_pairs
 ( 
imL_files
 , 
imR_files
 , ** 
kwargs
 )

251 
print
 ( 'done.' ) 
	}

253 def 
	$load_rgb
 ( 
self
 , ** 
kwargs
 ) :

259 
print
 ( 'Loading color images from ' + 
self
 . 
drive
 + '...' )

261 
imL_path
 = 
os
 . 
path
 . 
join
 ( 
self
 . 
data_path
 , 'image_02' , 'data' , '*.png' )

262 
imR_path
 = 
os
 . 
path
 . 
join
 ( 
self
 . 
data_path
 , 'image_03' , 'data' , '*.png' )

264 
imL_files
 = 
sorted
 ( 
glob
 . 
glob
 ( 
imL_path
 ) )

265 
imR_files
 = 
sorted
 ( 
glob
 . 
glob
 ( 
imR_path
 ) )

268 if 
self
 . 
frame_range
 :

269 
imL_files
 = [ 
imL_files
 [ 
i
 ] for 
i
 in 
self
 . 
frame_range
 ]

270 
imR_files
 = [ 
imR_files
 [ 
i
 ] for 
i
 in 
self
 . 
frame_range
 ]

272 
print
 ( 'Found ' + 
str
 ( 
len
 ( 
imL_files
 ) ) + ' image pairs...' )

274 
self
 . 
rgb
 = 
utils
 . 
load_stereo_pairs
 ( 
imL_files
 , 
imR_files
 , ** 
kwargs
 )

276 
print
 ( 'done.' ) 
	}

278 def 
	$load_left_rgb
 ( 
self
 , ** 
kwargs
 ) :

284 
print
 ( 'Loading left color images from ' + 
self
 . 
drive
 + '...' )

286 
imL_path
 = 
os
 . 
path
 . 
join
 ( 
self
 . 
data_path
 , 'image_02' , 'data' , '*.png' )

288 
imL_files
 = 
sorted
 ( 
glob
 . 
glob
 ( 
imL_path
 ) )

291 if 
self
 . 
frame_range
 :

292 
imL_files
 = [ 
imL_files
 [ 
i
 ] for 
i
 in 
self
 . 
frame_range
 ]

294 
print
 ( 'Found ' + 
str
 ( 
len
 ( 
imL_files
 ) ) + ' left rgb...' )

296 
self
 . 
rgb
 = 
utils
 . 
load_left_single
 ( 
imL_files
 , ** 
kwargs
 )

298 
print
 ( 'done.' ) 
	}

300 def 
	$load_velo
 ( 
self
 ) :

303 
velo_path
 = 
os
 . 
path
 . 
join
 (

304 
self
 . 
data_path
 , 'velodyne_points' , 'data' , '*.bin' )

305 
velo_files
 = 
sorted
 ( 
glob
 . 
glob
 ( 
velo_path
 ) )

308 if 
self
 . 
frame_range
 :

309 
velo_files
 = [ 
velo_files
 [ 
i
 ] for 
i
 in 
self
 . 
frame_range
 ]

311 
print
 ( 'Found ' + 
str
 ( 
len
 ( 
velo_files
 ) ) + ' Velodyne scans...' )

314 
self
 . 
velo
 = 
utils
 . 
load_velo_scans
 ( 
velo_files
 )

316 
print
 ( 'done.' ) 
	}


	@./kitti_data/pykitti/odometry.py

3 import 
	~datetime
 as 
dt

4 import 
	~glob

5 import 
	~os

6 from 
	~collections
 import 
namedtuple

8 import 
	~numpy
 as 
np

10 from 
	~kitti_data
 import 
pykitti
 as 
utils

12 
__author__
 = "Lee Clement"

13 
__email__
 = "lee.clement@robotics.utias.utoronto.ca"

16 class 
	codometry
 :

19 def 
	$__init__
 ( 
self
 , 
base_path
 , 
sequence
 , 
frame_range
 = None ) :

21 
self
 . 
sequence
 = 
sequence

22 
self
 . 
sequence_path
 = 
os
 . 
path
 . 
join
 ( 
base_path
 , 'sequences' , 
sequence
 )

23 
self
 . 
pose_path
 = 
os
 . 
path
 . 
join
 ( 
base_path
 , 'poses' )

24 
self
 . 
frame_range
 = 
frame_range
 
	}

26 def 
	$load_calib
 ( 
self
 ) :

30 
data
 = { }

33 
calib_filepath
 = 
os
 . 
path
 . 
join
 ( 
self
 . 
sequence_path
 , 'calib.txt' )

34 
filedata
 = 
utils
 . 
read_calib_file
 ( 
calib_filepath
 )

37 
P_rect_00
 = 
np
 . 
reshape
 ( 
filedata
 [ 'P0' ] , ( 3 , 4 ) )

38 
P_rect_10
 = 
np
 . 
reshape
 ( 
filedata
 [ 'P1' ] , ( 3 , 4 ) )

39 
P_rect_20
 = 
np
 . 
reshape
 ( 
filedata
 [ 'P2' ] , ( 3 , 4 ) )

40 
P_rect_30
 = 
np
 . 
reshape
 ( 
filedata
 [ 'P3' ] , ( 3 , 4 ) )

43 
T1
 = 
np
 . 
eye
 ( 4 )

44 
T1
 [ 0 , 3 ] = 
P_rect_10
 [ 0 , 3 ] / 
P_rect_10
 [ 0 , 0 ]

45 
T2
 = 
np
 . 
eye
 ( 4 )

46 
T2
 [ 0 , 3 ] = 
P_rect_20
 [ 0 , 3 ] / 
P_rect_20
 [ 0 , 0 ]

47 
T3
 = 
np
 . 
eye
 ( 4 )

48 
T3
 [ 0 , 3 ] = 
P_rect_30
 [ 0 , 3 ] / 
P_rect_30
 [ 0 , 0 ]

51 
data
 [ 'T_cam0_velo' ] = 
np
 . 
reshape
 ( 
filedata
 [ 'Tr' ] , ( 3 , 4 ) )

52 
data
 [ 'T_cam0_velo' ] = 
np
 . 
vstack
 ( [ 
data
 [ 'T_cam0_velo' ] , [ 0 , 0 , 0 , 1 ] ] )

53 
data
 [ 'T_cam1_velo' ] = 
T1
 . 
dot
 ( 
data
 [ 'T_cam0_velo' ] )

54 
data
 [ 'T_cam2_velo' ] = 
T2
 . 
dot
 ( 
data
 [ 'T_cam0_velo' ] )

55 
data
 [ 'T_cam3_velo' ] = 
T3
 . 
dot
 ( 
data
 [ 'T_cam0_velo' ] )

58 
data
 [ 'K_cam0' ] = 
P_rect_00
 [ 0 : 3 , 0 : 3 ]

59 
data
 [ 'K_cam1' ] = 
P_rect_10
 [ 0 : 3 , 0 : 3 ]

60 
data
 [ 'K_cam2' ] = 
P_rect_20
 [ 0 : 3 , 0 : 3 ]

61 
data
 [ 'K_cam3' ] = 
P_rect_30
 [ 0 : 3 , 0 : 3 ]

66 
p_cam
 = 
np
 . 
array
 ( [ 0 , 0 , 0 , 1 ] )

67 
p_velo0
 = 
np
 . 
linalg
 . 
inv
 ( 
data
 [ 'T_cam0_velo' ] ) . 
dot
 ( 
p_cam
 )

68 
p_velo1
 = 
np
 . 
linalg
 . 
inv
 ( 
data
 [ 'T_cam1_velo' ] ) . 
dot
 ( 
p_cam
 )

69 
p_velo2
 = 
np
 . 
linalg
 . 
inv
 ( 
data
 [ 'T_cam2_velo' ] ) . 
dot
 ( 
p_cam
 )

70 
p_velo3
 = 
np
 . 
linalg
 . 
inv
 ( 
data
 [ 'T_cam3_velo' ] ) . 
dot
 ( 
p_cam
 )

72 
data
 [ 'b_gray' ] = 
np
 . 
linalg
 . 
norm
 ( 
p_velo1
 - 
p_velo0
 )

73 
data
 [ 'b_rgb' ] = 
np
 . 
linalg
 . 
norm
 ( 
p_velo3
 - 
p_velo2
 )

75 
self
 . 
calib
 = 
namedtuple
 ( 'CalibData' , 
data
 . 
keys
 ( ) ) ( * 
data
 . 
values
 ( ) ) 
	}

77 def 
	$load_timestamps
 ( 
self
 ) :

79 
print
 ( 'Loading timestamps for sequence ' + 
self
 . 
sequence
 + '...' )

81 
timestamp_file
 = 
os
 . 
path
 . 
join
 ( 
self
 . 
sequence_path
 , 'times.txt' )

84 
self
 . 
timestamps
 = [ ]

85 with 
open
 ( 
timestamp_file
 , 'r' ) as 
f
 :

86 for 
line
 in 
f
 . 
readlines
 ( ) :

87 
t
 = 
dt
 . 
timedelta
 ( 
seconds
 = 
float
 ( 
line
 ) )

88 
self
 . 
timestamps
 . 
append
 ( 
t
 )

91 if 
self
 . 
frame_range
 :

92 
self
 . 
timestamps
 = [ 
self
 . 
timestamps
 [ 
i
 ] for 
i
 in 
self
 . 
frame_range
 ]

94 
print
 ( 'Found ' + 
str
 ( 
len
 ( 
self
 . 
timestamps
 ) ) + ' timestamps...' )

96 
print
 ( 'done.' ) 
	}

98 def 
	$load_poses
 ( 
self
 ) :

100 
print
 ( 'Loading poses for sequence ' + 
self
 . 
sequence
 + '...' )

102 
pose_file
 = 
os
 . 
path
 . 
join
 ( 
self
 . 
pose_path
 , 
self
 . 
sequence
 + '.txt' )

106 
self
 . 
T_w_cam0
 = [ ]

107 with 
open
 ( 
pose_file
 , 'r' ) as 
f
 :

108 for 
line
 in 
f
 . 
readlines
 ( ) :

109 
T
 = 
np
 . 
fromstring
 ( 
line
 , 
dtype
 = 
float
 , 
sep
 = ' ' )

110 
T
 = 
T
 . 
reshape
 ( 3 , 4 )

111 
T
 = 
np
 . 
vstack
 ( ( 
T
 , [ 0 , 0 , 0 , 1 ] ) )

112 
self
 . 
T_w_cam0
 . 
append
 ( 
T
 )

113 
print
 ( 'done.' )

115 except 
FileNotFoundError
 :

116 
print
 ( 'Ground truth poses are not avaialble for sequence ' +

117 
self
 . 
sequence
 + '.' ) 
	}

119 def 
	$load_gray
 ( 
self
 , ** 
kwargs
 ) :

125 
print
 ( 'Loading monochrome images from sequence ' +

126 
self
 . 
sequence
 + '...' )

128 
imL_path
 = 
os
 . 
path
 . 
join
 ( 
self
 . 
sequence_path
 , 'image_0' , '*.png' )

129 
imR_path
 = 
os
 . 
path
 . 
join
 ( 
self
 . 
sequence_path
 , 'image_1' , '*.png' )

131 
imL_files
 = 
sorted
 ( 
glob
 . 
glob
 ( 
imL_path
 ) )

132 
imR_files
 = 
sorted
 ( 
glob
 . 
glob
 ( 
imR_path
 ) )

135 if 
self
 . 
frame_range
 :

136 
imL_files
 = [ 
imL_files
 [ 
i
 ] for 
i
 in 
self
 . 
frame_range
 ]

137 
imR_files
 = [ 
imR_files
 [ 
i
 ] for 
i
 in 
self
 . 
frame_range
 ]

139 
print
 ( 'Found ' + 
str
 ( 
len
 ( 
imL_files
 ) ) + ' image pairs...' )

141 
self
 . 
gray
 = 
utils
 . 
load_stereo_pairs
 ( 
imL_files
 , 
imR_files
 , ** 
kwargs
 )

143 
print
 ( 'done.' ) 
	}

145 def 
	$load_rgb
 ( 
self
 , ** 
kwargs
 ) :

151 
print
 ( 'Loading color images from sequence ' +

152 
self
 . 
sequence
 + '...' )

154 
imL_path
 = 
os
 . 
path
 . 
join
 ( 
self
 . 
sequence_path
 , 'image_2' , '*.png' )

155 
imR_path
 = 
os
 . 
path
 . 
join
 ( 
self
 . 
sequence_path
 , 'image_3' , '*.png' )

157 
imL_files
 = 
sorted
 ( 
glob
 . 
glob
 ( 
imL_path
 ) )

158 
imR_files
 = 
sorted
 ( 
glob
 . 
glob
 ( 
imR_path
 ) )

161 if 
self
 . 
frame_range
 :

162 
imL_files
 = [ 
imL_files
 [ 
i
 ] for 
i
 in 
self
 . 
frame_range
 ]

163 
imR_files
 = [ 
imR_files
 [ 
i
 ] for 
i
 in 
self
 . 
frame_range
 ]

165 
print
 ( 'Found ' + 
str
 ( 
len
 ( 
imL_files
 ) ) + ' image pairs...' )

167 
self
 . 
rgb
 = 
utils
 . 
load_stereo_pairs
 ( 
imL_files
 , 
imR_files
 , ** 
kwargs
 )

169 
print
 ( 'done.' ) 
	}

171 def 
	$load_velo
 ( 
self
 ) :

174 
velo_path
 = 
os
 . 
path
 . 
join
 ( 
self
 . 
sequence_path
 , 'velodyne' , '*.bin' )

175 
velo_files
 = 
sorted
 ( 
glob
 . 
glob
 ( 
velo_path
 ) )

178 if 
self
 . 
frame_range
 :

179 
velo_files
 = [ 
velo_files
 [ 
i
 ] for 
i
 in 
self
 . 
frame_range
 ]

181 
print
 ( 'Found ' + 
str
 ( 
len
 ( 
velo_files
 ) ) + ' Velodyne scans...' )

184 
self
 . 
velo
 = 
utils
 . 
load_velo_scans
 ( 
velo_files
 )

186 
print
 ( 'done.' ) 
	}


	@./kitti_data/pykitti/__init__.py

3 from 
	~kitti_data.pykitti.raw
 import 
raw

5 
__author__
 = "Lee Clement"

6 
__email__
 = "lee.clement@robotics.utias.utoronto.ca"


	@./kitti_data/pykitti/tracklet.py

29 from 
	~sys
 import 
argv
 as 
cmdLineArgs

30 from 
	~xml.etree.ElementTree
 import 
ElementTree

31 import 
	~numpy
 as 
np

32 import 
	~itertools

33 from 
	~warnings
 import 
warn

34 from 
	~config
 import 
cfg

36 
STATE_UNSET
 = 0

37 
STATE_INTERP
 = 1

38 
STATE_LABELED
 = 2

39 
stateFromText
 = { '0' : 
STATE_UNSET
 , '1' : 
STATE_INTERP
 , '2' : 
STATE_LABELED
 }

41 
OCC_UNSET
 = 255

42 
OCC_VISIBLE
 = 0

43 
OCC_PARTLY
 = 1

44 
OCC_FULLY
 = 2

45 
occFromText
 = { '-1' : 
OCC_UNSET
 , '0' : 
OCC_VISIBLE
 , '1' : 
OCC_PARTLY
 , '2' : 
OCC_FULLY
 }

47 
TRUNC_UNSET
 = 255

48 
TRUNC_IN_IMAGE
 = 0

49 
TRUNC_TRUNCATED
 = 1

50 
TRUNC_OUT_IMAGE
 = 2

51 
TRUNC_BEHIND_IMAGE
 = 3

52 
truncFromText
 = { '99' : 
TRUNC_UNSET
 , '0' : 
TRUNC_IN_IMAGE
 , '1' : 
TRUNC_TRUNCATED
 , '2'

53 : 
TRUNC_OUT_IMAGE
 , '3' : 
TRUNC_BEHIND_IMAGE
 }

56 class 
	cTracklet
 ( 
object
 ) :

76 
objectType
 = None

77 
size
 = None

78 
firstFrame
 = None

79 
trans
 = None

80 
rots
 = None

81 
states
 = None

82 
occs
 = None

83 
truncs
 = None

84 
amtOccs
 = None

85 
amtBorders
 = None

86 
nFrames
 = None

88 def 
	$__init__
 ( 
self
 ) :

90 
self
 . 
size
 = 
np
 . 
nan
 * 
np
 . 
ones
 ( 3 , 
dtype
 = 
float
 ) 
	}

92 def 
	$__str__
 ( 
self
 ) :

100 return '[Tracklet over {0} frames for {1}]' . 
format
 ( 
self
 . 
nFrames
 , 
self
 . 
objectType
 ) 
	}

102 def 
	$__iter__
 ( 
self
 ) :

111 if 
self
 . 
amtOccs
 is None :

112 return 
zip
 ( 
self
 . 
trans
 , 
self
 . 
rots
 , 
self
 . 
states
 , 
self
 . 
occs
 , 
self
 . 
truncs
 ,

113 
itertools
 . 
repeat
 ( None ) , 
itertools
 . 
repeat
 ( None ) , 
range
 ( 
self
 . 
firstFrame
 , 
self
 . 
firstFrame
 + 
self
 . 
nFrames
 ) )

115 return 
zip
 ( 
self
 . 
trans
 , 
self
 . 
rots
 , 
self
 . 
states
 , 
self
 . 
occs
 , 
self
 . 
truncs
 ,

116 
self
 . 
amtOccs
 , 
self
 . 
amtBorders
 , 
range
 ( 
self
 . 
firstFrame
 , 
self
 . 
firstFrame
 + 
self
 . 
nFrames
 ) ) 
	}

120 def 
	$parseXML
 ( 
trackletFile
 ) :

128 
eTree
 = 
ElementTree
 ( )

130 with 
open
 ( 
trackletFile
 ) as 
f
 :

131 
eTree
 . 
parse
 ( 
f
 )

134 
trackletsElem
 = 
eTree
 . 
find
 ( 'tracklets' )

135 
tracklets
 = [ ]

136 
trackletIdx
 = 0

137 
nTracklets
 = None

138 for 
trackletElem
 in 
trackletsElem
 :

140 if 
trackletElem
 . 
tag
 == 'count' :

141 
nTracklets
 = 
int
 ( 
trackletElem
 . 
text
 )

143 elif 
trackletElem
 . 
tag
 == 'item_version' :

145 elif 
trackletElem
 . 
tag
 == 'item' :

148 
newTrack
 = 
Tracklet
 ( )

149 
isFinished
 = False

150 
hasAmt
 = False

151 
frameIdx
 = None

152 for 
info
 in 
trackletElem
 :

154 if 
isFinished
 :

155 raise 
ValueError
 ( 'more info on element after finished!' )

156 if 
info
 . 
tag
 == 'objectType' :

157 
newTrack
 . 
objectType
 = 
info
 . 
text

158 elif 
info
 . 
tag
 == 'h' :

159 
newTrack
 . 
size
 [ 0 ] = 
float
 ( 
info
 . 
text
 )

160 elif 
info
 . 
tag
 == 'w' :

161 
newTrack
 . 
size
 [ 1 ] = 
float
 ( 
info
 . 
text
 )

162 elif 
info
 . 
tag
 == 'l' :

163 
newTrack
 . 
size
 [ 2 ] = 
float
 ( 
info
 . 
text
 )

164 elif 
info
 . 
tag
 == 'first_frame' :

165 
newTrack
 . 
firstFrame
 = 
int
 ( 
info
 . 
text
 )

166 elif 
info
 . 
tag
 == 'poses' :

168 for 
pose
 in 
info
 :

170 if 
pose
 . 
tag
 == 'count' :

171 if 
newTrack
 . 
nFrames
 is not None :

172 raise 
ValueError
 ( 'there are several pose lists for a single track!' )

173 elif 
frameIdx
 is not None :

174 raise 
ValueError
 ( '?!' )

175 
newTrack
 . 
nFrames
 = 
int
 ( 
pose
 . 
text
 )

176 
newTrack
 . 
trans
 = 
np
 . 
nan
 * 
np
 . 
ones
 ( ( 
newTrack
 . 
nFrames
 , 3 ) , 
dtype
 = 
float
 )

177 
newTrack
 . 
rots
 = 
np
 . 
nan
 * 
np
 . 
ones
 ( ( 
newTrack
 . 
nFrames
 , 3 ) , 
dtype
 = 
float
 )

178 
newTrack
 . 
states
 = 
np
 . 
nan
 * 
np
 . 
ones
 ( 
newTrack
 . 
nFrames
 , 
dtype
 = 'uint8' )

179 
newTrack
 . 
occs
 = 
np
 . 
nan
 * 
np
 . 
ones
 ( ( 
newTrack
 . 
nFrames
 , 2 ) , 
dtype
 = 'uint8' )

180 
newTrack
 . 
truncs
 = 
np
 . 
nan
 * 
np
 . 
ones
 ( 
newTrack
 . 
nFrames
 , 
dtype
 = 'uint8' )

181 
newTrack
 . 
amtOccs
 = 
np
 . 
nan
 * 
np
 . 
ones
 ( ( 
newTrack
 . 
nFrames
 , 2 ) , 
dtype
 = 
float
 )

182 
newTrack
 . 
amtBorders
 = 
np
 . 
nan
 * 
np
 . 
ones
 ( ( 
newTrack
 . 
nFrames
 , 3 ) , 
dtype
 = 
float
 )

183 
frameIdx
 = 0

184 elif 
pose
 . 
tag
 == 'item_version' :

186 elif 
pose
 . 
tag
 == 'item' :

188 if 
frameIdx
 is None :

189 raise 
ValueError
 ( 'pose item came before number of poses!' )

190 for 
poseInfo
 in 
pose
 :

192 if 
poseInfo
 . 
tag
 == 'tx' :

193 
newTrack
 . 
trans
 [ 
frameIdx
 , 0 ] = 
float
 ( 
poseInfo
 . 
text
 )

194 elif 
poseInfo
 . 
tag
 == 'ty' :

195 
newTrack
 . 
trans
 [ 
frameIdx
 , 1 ] = 
float
 ( 
poseInfo
 . 
text
 )

196 elif 
poseInfo
 . 
tag
 == 'tz' :

197 
newTrack
 . 
trans
 [ 
frameIdx
 , 2 ] = 
float
 ( 
poseInfo
 . 
text
 )

198 elif 
poseInfo
 . 
tag
 == 'rx' :

199 
newTrack
 . 
rots
 [ 
frameIdx
 , 0 ] = 
float
 ( 
poseInfo
 . 
text
 )

200 elif 
poseInfo
 . 
tag
 == 'ry' :

201 
newTrack
 . 
rots
 [ 
frameIdx
 , 1 ] = 
float
 ( 
poseInfo
 . 
text
 )

202 elif 
poseInfo
 . 
tag
 == 'rz' :

203 
newTrack
 . 
rots
 [ 
frameIdx
 , 2 ] = 
float
 ( 
poseInfo
 . 
text
 )

204 elif 
poseInfo
 . 
tag
 == 'state' :

205 
newTrack
 . 
states
 [ 
frameIdx
 ] = 
stateFromText
 [ 
poseInfo
 . 
text
 ]

206 elif 
poseInfo
 . 
tag
 == 'occlusion' :

207 
newTrack
 . 
occs
 [ 
frameIdx
 , 0 ] = 
occFromText
 [ 
poseInfo
 . 
text
 ]

208 elif 
poseInfo
 . 
tag
 == 'occlusion_kf' :

209 
newTrack
 . 
occs
 [ 
frameIdx
 , 1 ] = 
occFromText
 [ 
poseInfo
 . 
text
 ]

210 elif 
poseInfo
 . 
tag
 == 'truncation' :

211 if 
cfg
 . 
DATA_SETS_TYPE
 == 'kitti' :

212 
newTrack
 . 
truncs
 [ 
frameIdx
 ] = 
truncFromText
 [ 
poseInfo
 . 
text
 ]

213 elif 
cfg
 . 
DATA_SETS_TYPE
 == 'didi2' :

216 elif 
cfg
 . 
DATA_SETS_TYPE
 == 'didi' :

219 elif 
cfg
 . 
DATA_SETS_TYPE
 == 'test' :

222 raise 
ValueError
 ( 'unexpected type in cfg.DATA_SETS_TYPE :{}!' . 
format
 ( 
cfg
 . 
DATA_SETS_TYPE
 ) )

223 elif 
poseInfo
 . 
tag
 == 'amt_occlusion' :

224 
newTrack
 . 
amtOccs
 [ 
frameIdx
 , 0 ] = 
float
 ( 
poseInfo
 . 
text
 )

225 
hasAmt
 = True

226 elif 
poseInfo
 . 
tag
 == 'amt_occlusion_kf' :

227 
newTrack
 . 
amtOccs
 [ 
frameIdx
 , 1 ] = 
float
 ( 
poseInfo
 . 
text
 )

228 
hasAmt
 = True

229 elif 
poseInfo
 . 
tag
 == 'amt_border_l' :

230 
newTrack
 . 
amtBorders
 [ 
frameIdx
 , 0 ] = 
float
 ( 
poseInfo
 . 
text
 )

231 
hasAmt
 = True

232 elif 
poseInfo
 . 
tag
 == 'amt_border_r' :

233 
newTrack
 . 
amtBorders
 [ 
frameIdx
 , 1 ] = 
float
 ( 
poseInfo
 . 
text
 )

234 
hasAmt
 = True

235 elif 
poseInfo
 . 
tag
 == 'amt_border_kf' :

236 
newTrack
 . 
amtBorders
 [ 
frameIdx
 , 2 ] = 
float
 ( 
poseInfo
 . 
text
 )

237 
hasAmt
 = True

239 raise 
ValueError
 ( 'unexpected tag in poses item: {0}!' . 
format
 ( 
poseInfo
 . 
tag
 ) )

240 
frameIdx
 += 1

242 raise 
ValueError
 ( 'unexpected pose info: {0}!' . 
format
 ( 
pose
 . 
tag
 ) )

243 elif 
info
 . 
tag
 == 'finished' :

244 
isFinished
 = True

246 raise 
ValueError
 ( 'unexpected tag in tracklets: {0}!' . 
format
 ( 
info
 . 
tag
 ) )

250 if not 
isFinished
 :

251 
warn
 ( 'tracklet {0} was not finished!' . 
format
 ( 
trackletIdx
 ) )

252 if 
newTrack
 . 
nFrames
 is None :

253 
warn
 ( 'tracklet {0} contains no information!' . 
format
 ( 
trackletIdx
 ) )

254 elif 
frameIdx
 != 
newTrack
 . 
nFrames
 :

255 
warn
 ( 'tracklet {0} is supposed to have {1} frames, but perser found {1}!' . 
format
 (

256 
trackletIdx
 , 
newTrack
 . 
nFrames
 , 
frameIdx
 ) )

257 if 
np
 . 
abs
 ( 
newTrack
 . 
rots
 [ : , : 2 ] ) . 
sum
 ( ) > 1e-16 :

258 
warn
 ( 'track contains rotation other than yaw!' )

261 if not 
hasAmt
 :

262 
newTrack
 . 
amtOccs
 = None

263 
newTrack
 . 
amtBorders
 = None

266 
tracklets
 . 
append
 ( 
newTrack
 )

267 
trackletIdx
 += 1

270 raise 
ValueError
 ( 'unexpected tracklet info' )

276 if 
trackletIdx
 != 
nTracklets
 :

277 
warn
 ( 'according to xml information the file has {0} tracklets, but parser found {1}!' . 
format
 ( 
nTracklets
 , 
trackletIdx
 ) )

279 return 
tracklets
 
	}

283 def 
	$example
 ( 
kittiDir
 = None , 
drive
 = None ) :

285 from 
	~os.path
 import 
join
 , 
expanduser

286 import 
	~readline

289 
DEFAULT_DRIVE
 = '2011_09_26_drive_0001'

290 
twoPi
 = 2. * 
np
 . 
pi

293 if 
kittiDir
 is None :

294 
kittiDir
 = 
expanduser
 ( 
raw_input
 ( 'please enter kitti base dir (e.g. ~/path/to/kitti): ' ) . 
strip
 ( ) )

295 if 
drive
 is None :

296 
drive
 = 
raw_input
 ( 'please enter drive name (default {0}): ' . 
format
 ( 
DEFAULT_DRIVE
 ) ) . 
strip
 ( )

297 if 
len
 ( 
drive
 ) == 0 :

298 
drive
 = 
DEFAULT_DRIVE

301 
myTrackletFile
 = 
join
 ( 
kittiDir
 , 
drive
 , 'tracklet_labels.xml' )

302 
tracklets
 = 
parseXML
 ( 
myTrackletFile
 )

305 for 
iTracklet
 , 
tracklet
 in 
enumerate
 ( 
tracklets
 ) :

306 
print
 ( 'tracklet {0: 3d}: {1}' . 
format
 ( 
iTracklet
 , 
tracklet
 ) )

309 
h
 , 
w
 , 
l
 = 
tracklet
 . 
size

310 
trackletBox
 = 
np
 . 
array
 ( [

311 [ - 
l
 / 2 , - 
l
 / 2 , 
l
 / 2 , 
l
 / 2 , - 
l
 / 2 , - 
l
 / 2 , 
l
 / 2 , 
l
 / 2 ] ,

312 [ 
w
 / 2 , - 
w
 / 2 , - 
w
 / 2 , 
w
 / 2 , 
w
 / 2 , - 
w
 / 2 , - 
w
 / 2 , 
w
 / 2 ] ,

313 [ 0.0 , 0.0 , 0.0 , 0.0 , 
h
 , 
h
 , 
h
 , 
h
 ] ] )

316 for 
translation
 , 
rotation
 , 
state
 , 
occlusion
 , 
truncation
 , 
amtOcclusion
 , 
amtBorders
 , 
absoluteFrameNumber

317 in 
tracklet
 :

320 if 
truncation
 not in ( 
TRUNC_IN_IMAGE
 , 
TRUNC_TRUNCATED
 ) :

324 
yaw
 = 
rotation
 [ 2 ]

325 assert 
np
 . 
abs
 ( 
rotation
 [ : 2 ] ) . 
sum
 ( ) == 0 , 'object rotations other than yaw given!'

326 
rotMat
 = 
np
 . 
array
 ( [

327 [ 
np
 . 
cos
 ( 
yaw
 ) , - 
np
 . 
sin
 ( 
yaw
 ) , 0.0 ] ,

328 [ 
np
 . 
sin
 ( 
yaw
 ) , 
np
 . 
cos
 ( 
yaw
 ) , 0.0 ] ,

330 
cornerPosInVelo
 = 
np
 . 
dot
 ( 
rotMat
 , 
trackletBox
 ) + 
np
 . 
tile
 ( 
translation
 , ( 8 , 1 ) ) . 
T

336 
x
 , 
y
 , 
z
 = 
translation

337 
yawVisual
 = ( 
yaw
 - 
np
 . 
arctan2
 ( 
y
 , 
x
 ) ) % 
twoPi
 
	}

346 if 
__name__
 == "__main__" :

348 if 
len
 ( 
cmdLineArgs
 ) < 2 :

349 
example
 ( )

350 elif ( 
len
 ( 
cmdLineArgs
 ) == 2 ) and ( 
cmdLineArgs
 [ 1 ] == 'example' ) :

351 
example
 ( )

353 
parseXML
 ( * 
cmdLineArgs
 [ 1 : ] )


	@./kitti_data/io.py

2 from 
	~kitti_data.pykitti.tracklet
 import 
parseXML
 , 
TRUNC_IN_IMAGE
 , 
TRUNC_TRUNCATED

4 import 
	~numpy
 as 
np

5 import 
	~math

6 from 
	~config
 import 
cfg

8 def 
	$read_objects
 ( 
tracklet_file
 , 
frames_index
 ) :

9 
objects
 = [ ]

11 for 
n
 in 
frames_index
 : 
objects
 . 
append
 ( [ ] )

14 
tracklets
 = 
parseXML
 ( 
tracklet_file
 )

15 
num
 = 
len
 ( 
tracklets
 )

17 for 
n
 in 
range
 ( 
num
 ) :

18 
tracklet
 = 
tracklets
 [ 
n
 ]

21 
h
 , 
w
 , 
l
 = 
tracklet
 . 
size

22 if 
cfg
 . 
DATA_SETS_TYPE
 == 'didi2' or 
cfg
 . 
DATA_SETS_TYPE
 == 'didi' or 
cfg
 . 
DATA_SETS_TYPE
 == 'test' :

23 
h
 , 
w
 = 
h
 * 1.1 , 
l

24 
trackletBox
 = 
np
 . 
array
 ( [

25 [ - 
l
 / 2 , - 
l
 / 2 , 
l
 / 2 , 
l
 / 2 , - 
l
 / 2 , - 
l
 / 2 , 
l
 / 2 , 
l
 / 2 ] ,

26 [ 
w
 / 2 , - 
w
 / 2 , - 
w
 / 2 , 
w
 / 2 , 
w
 / 2 , - 
w
 / 2 , - 
w
 / 2 , 
w
 / 2 ] ,

27 [ - 
h
 / 2 , - 
h
 / 2 , - 
h
 / 2 , - 
h
 / 2 , 
h
 / 2 , 
h
 / 2 , 
h
 / 2 , 
h
 / 2 ] ] )

28 elif 
cfg
 . 
DATA_SETS_TYPE
 == 'kitti' :

29 
trackletBox
 = 
np
 . 
array
 ( [

30 [ - 
l
 / 2 , - 
l
 / 2 , 
l
 / 2 , 
l
 / 2 , - 
l
 / 2 , - 
l
 / 2 , 
l
 / 2 , 
l
 / 2 ] ,

31 [ 
w
 / 2 , - 
w
 / 2 , - 
w
 / 2 , 
w
 / 2 , 
w
 / 2 , - 
w
 / 2 , - 
w
 / 2 , 
w
 / 2 ] ,

32 [ 0.0 , 0.0 , 0.0 , 0.0 , 
h
 , 
h
 , 
h
 , 
h
 ] ] )

34 raise 
ValueError
 ( 'unexpected type in cfg.DATA_SETS_TYPE :{}!' . 
format
 ( 
cfg
 . 
DATA_SETS_TYPE
 ) )

37 
start_frame
 = 
tracklet
 . 
firstFrame

38 
end_frame
 = 
tracklet
 . 
firstFrame
 + 
tracklet
 . 
nFrames

40 
object_in_frames_index
 = [ 
i
 for 
i
 in 
frames_index
 if 
i
 in 
range
 ( 
start_frame
 , 
end_frame
 ) ]

41 
object_in_tracklet_index
 = [ 
i
 - 
start_frame
 for 
i
 in 
object_in_frames_index
 ]

43 for 
i
 in 
object_in_tracklet_index
 :

44 
translation
 = 
tracklet
 . 
trans
 [ 
i
 ]

45 
rotation
 = 
tracklet
 . 
rots
 [ 
i
 ]

46 
state
 = 
tracklet
 . 
states
 [ 
i
 ]

47 
occlusion
 = 
tracklet
 . 
occs
 [ 
i
 ]

48 
truncation
 = 
tracklet
 . 
truncs
 [ 
i
 ]

51 if 
cfg
 . 
DATA_SETS_TYPE
 == 'kitti' :

54 if 
truncation
 not in ( 
TRUNC_IN_IMAGE
 , 
TRUNC_TRUNCATED
 ) :

57 elif 
cfg
 . 
DATA_SETS_TYPE
 == 'didi2' :

60 elif 
cfg
 . 
DATA_SETS_TYPE
 == 'didi' :

63 elif 
cfg
 . 
DATA_SETS_TYPE
 == 'test' :

66 raise 
ValueError
 ( 'unexpected type in cfg.DATA_SETS_TYPE :{}!' . 
format
 ( 
cfg
 . 
DATA_SETS_TYPE
 ) )

69 
yaw
 = 
rotation
 [ 2 ]

71 
rotMat
 = 
np
 . 
array
 ( [

72 [ 
np
 . 
cos
 ( 
yaw
 ) , - 
np
 . 
sin
 ( 
yaw
 ) , 0.0 ] ,

73 [ 
np
 . 
sin
 ( 
yaw
 ) , 
np
 . 
cos
 ( 
yaw
 ) , 0.0 ] ,

75 
cornerPosInVelo
 = 
np
 . 
dot
 ( 
rotMat
 , 
trackletBox
 ) + 
np
 . 
tile
 ( 
translation
 , ( 8 , 1 ) ) . 
T

81 
x
 , 
y
 , 
z
 = 
translation

82 
yawVisual
 = ( 
yaw
 - 
np
 . 
arctan2
 ( 
y
 , 
x
 ) ) % ( 2 * 
math
 . 
pi
 )

84 
o
 = 
type
 ( '' , ( ) , { } ) ( )

85 
o
 . 
box
 = 
cornerPosInVelo
 . 
transpose
 ( )

86 
o
 . 
type
 = 
tracklet
 . 
objectType

87 
o
 . 
tracklet_id
 = 
n

89 if 
o
 . 
type
 == 'Van' or 
o
 . 
type
 == 'Truck' or 
o
 . 
type
 == 'Car' or 
o
 . 
type
 == 'Tram' :

90 
o
 . 
translation
 = 
translation

91 
o
 . 
rotation
 = 
rotation

92 
o
 . 
size
 = 
tracklet
 . 
size

96 
objects
 [ 
frames_index
 . 
index
 ( 
i
 + 
start_frame
 ) ] . 
append
 ( 
o
 )

98 return 
objects
 
	}


	@./kitti_data/__init__.py


	@./kitti_data/convert.py


	@
1
.
0
135
4301
./didi_data/__init__.py
./preprocess_for_mv3d.py
./convert_mv3d_for_eval.py
./tracker.py
./main.py
./data.py
./config.py
./test/test.py
./test/show_lidar.py
./test/load_lidar_binary.py
./mv3d.py
./raw_data.py
./task.py
./mv3d_net.py
./train_data_render.py
./test_remove_empty_box.py
./tracking.py
./UKF_Python_to_C++/samplePython.py
./net/processing/boxes3d.py
./net/processing/__init__.py
./net/processing/projection.py
./net/processing/boxes.py
./net/resnet.py
./net/configuration.py
./net/roipooling_op/roi_pooling_op.py
./net/roipooling_op/__init__.py
./net/roipooling_op/roi_pooling_op_grad.py
./net/roipooling_op/roi_pooling_op_test.py
./net/rpn_nms_op.py
./net/__init__.py
./net/rcnn_nms_op.py
./net/rpn_target_op.py
./net/blocks.py
./net/lib/nms/__init__.py
./net/lib/nms/py_cpu_nms.py
./net/lib/gt_data_layer/roidb.py
./net/lib/gt_data_layer/minibatch.py
./net/lib/gt_data_layer/__init__.py
./net/lib/gt_data_layer/layer.py
./net/lib/pycocotools/coco.py
./net/lib/pycocotools/__init__.py
./net/lib/pycocotools/cocoeval.py
./net/lib/pycocotools/mask.py
./net/lib/fast_rcnn/config2.py
./net/lib/fast_rcnn/config.py
./net/lib/fast_rcnn/nms_wrapper.py
./net/lib/fast_rcnn/bbox_transform.py
./net/lib/fast_rcnn/__init__.py
./net/lib/fast_rcnn/test.py
./net/lib/fast_rcnn/train.py
./net/lib/setup.py
./net/lib/roi_data_layer/minibatch2.py
./net/lib/roi_data_layer/roidb.py
./net/lib/roi_data_layer/minibatch.py
./net/lib/roi_data_layer/roidb2.py
./net/lib/roi_data_layer/__init__.py
./net/lib/roi_data_layer/layer.py
./net/lib/__init__.py
./net/lib/psroi_pooling_layer/psroi_pooling_op.py
./net/lib/psroi_pooling_layer/psroi_pooling_op_test.py
./net/lib/psroi_pooling_layer/__init__.py
./net/lib/psroi_pooling_layer/psroi_pooling_op_grad.py
./net/lib/datasets/imagenet3d.py
./net/lib/datasets/pascal_voc2.py
./net/lib/datasets/nissan.py
./net/lib/datasets/nthu.py
./net/lib/datasets/factory.py
./net/lib/datasets/pascal3d.py
./net/lib/datasets/ds_utils.py
./net/lib/datasets/kitti.py
./net/lib/datasets/coco.py
./net/lib/datasets/pascal_voc.py
./net/lib/datasets/__init__.py
./net/lib/datasets/imdb.py
./net/lib/datasets/kitti_tracking.py
./net/lib/datasets/kittivoc.py
./net/lib/datasets/imdb2.py
./net/lib/datasets/voc_eval.py
./net/lib/utils/blob.py
./net/lib/utils/bbox_test.py
./net/lib/utils/timer.py
./net/lib/utils/__init__.py
./net/lib/utils/boxes_grid.py
./net/lib/rpn_msr/anchor_target_layer.py
./net/lib/rpn_msr/proposal_layer.py
./net/lib/rpn_msr/generate_anchors.py
./net/lib/rpn_msr/generate.py
./net/lib/rpn_msr/__init__.py
./net/lib/rpn_msr/proposal_target_layer_tf.py
./net/lib/rpn_msr/anchor_target_layer_tf.py
./net/lib/rpn_msr/proposal_layer_tf.py
./net/lib/roi_pooling_layer/roi_pooling_op.py
./net/lib/roi_pooling_layer/__init__.py
./net/lib/roi_pooling_layer/roi_pooling_op_grad.py
./net/lib/roi_pooling_layer/roi_pooling_op_test.py
./net/rcnn_target_op.py
./net/utility/draw.py
./net/utility/demo.py
./net/utility/file.py
./net/utility/__init__.py
./net/utility/test_remove_empty_box.py
./net/utility/remove_empty_box.py
./utils/check_data.py
./utils/lidar_top_feature_visualize.py
./utils/batch_loading.py
./utils/batch_loading_for_data_py_output.py
./utils/training_validation_data_splitter.py
./utils/timer.py
./utils/check_top_view.py
./utils/3d_visualize.py
./test.py
./lidar_data_preprocess/python_call_liblidar_test_osx.py
./lidar_data_preprocess/Python_to_C_Interface/SampleProgram.py
./lidar_data_preprocess/Python_to_C_Interface/ver3/createTopAndFrontMaps.py
./lidar_data_preprocess/Python_to_C_Interface/ver3/ExampleUsage_TopAndFront.py
./lidar_data_preprocess/Python_to_C_Interface/ver3/createTopMaps.py
./lidar_data_preprocess/Python_to_C_Interface/ver3/ExampleUsage_Top.py
./lidar_data_preprocess/Python_to_C_Interface/ver2/SampleProgram.py
./lidar_data_preprocess/python_call_liblidar_test_ubuntu.py
./tracklets/generate_tracklet.py
./tracklets/parse_tracklet_round.py
./tracklets/parse_tracklet.py
./tracklets/evaluate_tracklets.py
./tracklets/tracklet_handling_test.py
./tracklets/Tracklet_saver.py
./train.py
./kitti_data/draw.py
./kitti_data/pykitti/utils.py
./kitti_data/pykitti/raw.py
./kitti_data/pykitti/odometry.py
./kitti_data/pykitti/__init__.py
./kitti_data/pykitti/tracklet.py
./kitti_data/io.py
./kitti_data/__init__.py
./kitti_data/convert.py
